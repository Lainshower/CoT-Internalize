WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Namespace(train_path='data/gsm8k/train_orig.txt', val_path='data/gsm8k/valid_orig.txt', save_model='mistral-optimizer-shift/gsm8k_entropy', save_data='mistral-optimizer-shift/gsm8k-training-data', base_model='mistralai/Mistral-7B-v0.1', epochs=1, batch_size=4, warmup_ratio=0.3, hidden_improve=0.5, hidden_interval=4, lr=5e-05, accumulate=1, max_grad_norm=1.0, bf16=False, max_new_tokens=150)
Namespace(train_path='data/gsm8k/train_orig.txt', val_path='data/gsm8k/valid_orig.txt', save_model='mistral-optimizer-shift/gsm8k_entropy', save_data='mistral-optimizer-shift/gsm8k-training-data', base_model='mistralai/Mistral-7B-v0.1', epochs=1, batch_size=4, warmup_ratio=0.3, hidden_improve=0.5, hidden_interval=4, lr=5e-05, accumulate=1, max_grad_norm=1.0, bf16=False, max_new_tokens=150)
Namespace(train_path='data/gsm8k/train_orig.txt', val_path='data/gsm8k/valid_orig.txt', save_model='mistral-optimizer-shift/gsm8k_entropy', save_data='mistral-optimizer-shift/gsm8k-training-data', base_model='mistralai/Mistral-7B-v0.1', epochs=1, batch_size=4, warmup_ratio=0.3, hidden_improve=0.5, hidden_interval=4, lr=5e-05, accumulate=1, max_grad_norm=1.0, bf16=False, max_new_tokens=150)
--> Running with torch dist debug set to detail
Clearing GPU cache for all ranks
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]wandb: Tracking run with wandb version 0.17.8
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.78s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.89s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.06s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.17s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.08s/it]
Creating features from dataset file at data/gsm8k/train_orig.txt
Creating features from dataset file at data/gsm8k/valid_orig.txt
Epoch 0
  0%|          | 0/584 [00:00<?, ?it/s]Creating features from dataset file at data/gsm8k/train_orig.txt
Creating features from dataset file at data/gsm8k/valid_orig.txt
Epoch 0
  0%|          | 0/584 [00:00<?, ?it/s]Creating features from dataset file at data/gsm8k/train_orig.txt
Creating features from dataset file at data/gsm8k/valid_orig.txt
Epoch 0
  0%|          | 0/584 [00:00<?, ?it/s]Loss LossLoss  tensor(1.4295, device='cuda:0', grad_fn=<NllLossBackward0>)tensor(1.3018, device='cuda:2', grad_fn=<NllLossBackward0>)

tensor(1.3660, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8522127270698547Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6967393159866333

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021012887358665466
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3079429268836975Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.056877583265304565

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09299691766500473
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.031246164813637733
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12272239476442337
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04926737770438194
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10631074011325836
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.129892498254776
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06816889345645905
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12237747013568878
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06443751603364944
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13366450369358063
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07378659397363663Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1146993339061737

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12292426824569702
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06782087683677673
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11836376041173935
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06275391578674316
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12367900460958481
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12384714186191559
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06251216679811478
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12022114545106888
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11328810453414917
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0641712099313736
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11588460952043533
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0641392320394516Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2848632335662842
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09861353039741516

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04210507497191429
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11596119403839111
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0716613307595253
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11886713653802872
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10903145372867584
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07122574001550674Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8240581154823303
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1074531301856041

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11070360988378525
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08236510306596756
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06675021350383759
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11116726696491241
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08458980917930603
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06607069820165634Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10621260106563568

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0858982726931572
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10314737260341644
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0644468367099762
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08563479781150818
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10376646369695663
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.057104870676994324Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07999108731746674

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13228999078273773
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08100797981023788
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09535563737154007
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08497989922761917Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.059426162391901016

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1528051495552063
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08176369965076447
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06303545087575912Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10624294728040695

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12822040915489197Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08379516750574112

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06664510071277618
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17043735086917877
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07849717885255814
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06342244893312454
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.25708186626434326
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08007543534040451
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.060664188116788864
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18063528835773468
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06945640593767166
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05637110397219658
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0530170239508152
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07250937819480896
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0675455704331398
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05515805259346962
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08144643902778625
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05408235266804695
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07920383661985397
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05176449194550514
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09182026982307434
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.053481459617614746
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08423300832509995
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05364135652780533Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08127753436565399

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07393519580364227
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.053249455988407135
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07375269383192062
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06012478470802307
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07603129744529724
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07436559349298477
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06406275182962418
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06821142137050629
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07598264515399933
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06892158091068268
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11346758157014847
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06720609217882156
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21601594984531403
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07757412642240524
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08826242387294769
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08942466229200363
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1321602761745453
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1584295779466629
  0%|          | 1/584 [00:03<36:08,  3.72s/it]  0%|          | 1/584 [00:07<1:09:15,  7.13s/it]  0%|          | 1/584 [00:10<1:39:20, 10.22s/it]Loss Loss tensor(7.5457, device='cuda:2', grad_fn=<NllLossBackward0>)
Loss tensor(7.3900, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(7.6064, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7390342354774475
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021603968925774097
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.540594220161438Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5822999477386475

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00474664056673646
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01197180524468422
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07211170345544815Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013122200965881348

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02460121363401413
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01190638355910778
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004141506273299456
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017605572938919067
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3794274926185608
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005863375496119261
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028467932716012
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012596217915415764
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.036233916878700256
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01054723933339119Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02452986128628254

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05435064435005188
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.031894560903310776
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014227920211851597
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07022757083177567
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04074420407414436
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02279246784746647Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07712680846452713

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06987107545137405
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0905814915895462
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02891230583190918
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08051393926143646
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0931733176112175
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07218299806118011
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04503690451383591
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08880987763404846
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09387105703353882
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05620362237095833Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09522631764411926

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10914990305900574
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1082124263048172
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06948484480381012
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09589000046253204
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08679737150669098
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0824054628610611
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08194819837808609
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10156919062137604
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09444522112607956
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09873827546834946
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09506742656230927
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09739556163549423
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08497793972492218
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15341590344905853
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11693571507930756
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09866134077310562
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08953625708818436
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11178392171859741
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10593973100185394Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09808439761400223
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10328412801027298

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08923158794641495
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13935576379299164
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09703173488378525
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13789792358875275
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14685241878032684
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08774636685848236Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09933564066886902

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10424590855836868
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10115101933479309
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1031196117401123
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17542466521263123
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11322887986898422
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10733029246330261Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1445356160402298
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09662210941314697

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14494428038597107
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15364080667495728
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09641341120004654
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15087251365184784
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11975114047527313
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09105104207992554
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1685723066329956
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10419762134552002
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.322903573513031
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09354643523693085
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1106506958603859
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2621346712112427
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00910441018640995
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15744109451770782Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09743166714906693

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11520577222108841
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12449783831834793
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1267808973789215
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10052147507667542
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14448116719722748
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10589442402124405
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2204073816537857
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11643362790346146
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12488245218992233
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3312024176120758
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19643555581569672
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15523329377174377
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4652632474899292
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20456185936927795
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.25884076952934265
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19230400025844574
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3092763125896454
  0%|          | 2/584 [00:09<50:09,  5.17s/it]  0%|          | 2/584 [00:15<1:11:42,  7.39s/it]  0%|          | 2/584 [00:13<1:03:45,  6.57s/it]Loss Loss tensor(7.0328, device='cuda:1', grad_fn=<NllLossBackward0>)
Loss tensor(6.3205, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(6.8912, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5553656816482544
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.32388409972190857
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.38337111473083496Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029360635206103325
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014693678822368383

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023410769179463387
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11825694143772125Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02722414769232273

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023853233084082603
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015322591178119183Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3339923620223999
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026657024398446083

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020141348242759705
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029364686459302902
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021393118426203728Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0194022748619318Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03346832096576691


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.035498082637786865
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024129677563905716
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020867951214313507
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03959174081683159
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027911141514778137
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027942189946770668Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0383305549621582

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05294962227344513
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.035750750452280045
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026497695595026016
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03484093397855759
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0517776682972908
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03625463321805
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.051119863986968994
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02987707406282425
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03639799356460571
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04084866866469383
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03306780010461807
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04188065230846405
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05057130753993988
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02948574908077717Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.041777633130550385

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03904680162668228
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.053521912544965744
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07089020311832428
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02934493124485016
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05458734184503555
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.059605494141578674
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02941226400434971
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06882310658693314
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13359346985816956
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08404390513896942Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02965099737048149Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.058781590312719345


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10243535786867142Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10260443389415741

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02950977347791195
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12468993663787842
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03403091058135033Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10206951200962067

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14557293057441711
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13149283826351166
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.037113629281520844
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08287197351455688
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13208027184009552
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04468083009123802Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12492205202579498

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14522479474544525
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09359138458967209
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16318584978580475
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04519098997116089
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13646821677684784
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1834121197462082
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05439484119415283
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11961708962917328
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2006639540195465
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06592068821191788Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11611805856227875

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.24727097153663635
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07326223701238632Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1291944682598114
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2702922523021698

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3855510950088501Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15043728053569794

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07502100616693497
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17570257186889648Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.22429673373699188

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09125559777021408Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.26354458928108215Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.35639363527297974


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13695085048675537
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08789879083633423
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09419548511505127
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10559418052434921
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5649608969688416
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09960317611694336
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.037810664623975754
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11096109449863434Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3648955523967743

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1169196367263794
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12800773978233337
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14948056638240814
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15984879434108734
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4703659415245056
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.26931115984916687
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.43760672211647034
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07421610504388809
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4437479078769684
  1%|          | 3/584 [00:16<57:16,  5.91s/it]  1%|          | 3/584 [00:22<1:08:56,  7.12s/it]  1%|          | 3/584 [00:20<1:04:38,  6.68s/it]Loss Loss Loss tensor(15.2616, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(15.2051, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(15.0594, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6199358701705933Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0690421611070633

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005082494462840259
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02281244844198227
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6107969880104065Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05159749463200569
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02068905346095562

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06499312072992325
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1753160059452057
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16102059185504913Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08518113940954208

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011358692310750484
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08689568936824799
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023147577419877052
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011629253625869751
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07453133910894394
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03570181876420975Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010485014878213406
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06296246498823166

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008933056145906448
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.045462142676115036
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04704757034778595
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012343309819698334
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.039969317615032196
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0103440647944808
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05211465060710907
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04281651973724365
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012539009563624859
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03999105468392372
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05210507661104202
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009709193371236324
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.038831330835819244
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01153209526091814
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.035880252718925476Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.044134266674518585

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008606692776083946
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.053999852389097214
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026320060715079308
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01496009062975645
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0550779327750206
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012962517328560352
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020518222823739052Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08071352541446686

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0241410955786705
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06340847909450531
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021962683647871017
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013525878079235554
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09136422723531723
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021353252232074738Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019756706431508064

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10494940727949142
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02481154166162014
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12786583602428436
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021992195397615433
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027401035651564598
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11680317670106888
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023326396942138672
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02056734450161457
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1662391573190689
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02698267437517643
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03176543489098549
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15468263626098633
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025099284946918488
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18099066615104675Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.031050387769937515

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027797173708677292
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18248111009597778
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04195726290345192
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030871087685227394
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19768066704273224
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03338169306516647
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03607506677508354Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2039688378572464

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0323939174413681
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21462517976760864
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04578852280974388Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03422875702381134

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21244081854820251
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.034528475254774094
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.051641639322042465
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.26805931329727173
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04415605217218399
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.35555705428123474
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05899221450090408
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12337325513362885
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07542607188224792
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022086773067712784
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.059225860983133316
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09370779991149902
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4925907254219055
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08161279559135437Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07637466490268707Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.831169843673706


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07201363146305084
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07884681224822998
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08771795779466629
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0868711993098259
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09604460746049881
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10175376385450363
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10660909861326218
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16491560637950897
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4968421161174774
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.35228222608566284
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06931767612695694
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.32166245579719543
  1%|          | 4/584 [00:22<55:53,  5.78s/it]  1%|          | 4/584 [00:28<1:02:56,  6.51s/it]  1%|          | 4/584 [00:25<1:00:24,  6.25s/it]Loss Loss Loss tensor(21.2036, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(21.1276, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(20.8186, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12060560286045074Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15140943229198456

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00044737564167007804
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004914617165923119
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011419156799092889
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009876338299363852
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024291991721838713
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003081722417846322
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017059409292414784
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005210419651120901
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029256471898406744
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00495962193235755Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006106141023337841

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010518282651901245
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006218669470399618Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013676236383616924

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013122277334332466
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008777529001235962
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014811716973781586
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012451538816094398
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015007666312158108
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01241547241806984Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012729199603199959

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012191222980618477
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015127339400351048
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01670842058956623
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014216461218893528Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013132022693753242

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01674243062734604
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01293643657118082
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014614061452448368
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010950128547847271
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017345242202281952
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01807808317244053Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020291607826948166

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021832536906003952
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013124835677444935
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026525771245360374
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016868745908141136
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03638788312673569
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014900975860655308
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04237926006317139
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01679583452641964Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.042825303971767426

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.043877508491277695
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02018861472606659
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.048727329820394516
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021388351917266846
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04270273074507713
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04131074249744415
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04141872003674507
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.040335655212402344
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03699781745672226
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03486744314432144
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025408171117305756
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.037704821676015854
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.036564022302627563
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00723779434338212
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03884120658040047
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04074284806847572
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0394337996840477Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9772828817367554

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.040065016597509384
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04032453894615173
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04169510304927826
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.972225546836853
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10157732665538788
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04613485187292099
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07889539748430252
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06474047154188156
  1%|          | 5/584 [00:27<54:46,  5.68s/it]  1%|          | 5/584 [00:31<57:35,  5.97s/it]  Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0842670276761055
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004952937597408891
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027249467093497515
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019695784896612167
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019029122777283192
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004517941735684872
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011605391278862953
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010156610980629921
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0156876128166914
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012846237979829311
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015026959590613842
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011842953972518444
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01058009173721075
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007787860929965973
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014410966075956821
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009498626925051212
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014689313247799873
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01124354638159275
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012042075395584106
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016107870265841484
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016128666698932648
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019837379455566406
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026021772995591164
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.033705972135066986
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03221995756030083
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03448764979839325
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.036603931337594986
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.034184470772743225
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03228835389018059
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026263263076543808
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01288340799510479
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7151905298233032
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014262650161981583
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6815736889839172
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07001721113920212
  1%|          | 5/584 [00:33<1:00:53,  6.31s/it]Loss Loss Loss tensor(13.3134, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(13.4486, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(13.5054, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013969912193715572
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11749126762151718
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00020954068168066442
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021915463730692863
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0095751928165555Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000649275491014123
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001516419812105596

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00837007723748684Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003944108262658119

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001655201893299818Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003355054068379104
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029798869509249926

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007852970738895237
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004207103047519922
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010731293150456622
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022028815001249313
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007468001917004585
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001289714709855616Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002233161125332117
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007316750939935446

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003147960640490055
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013596870936453342
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00025992069276981056
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002618528204038739
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012037191540002823
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000379294331651181
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00303656910546124
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012739366851747036
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002441579941660166
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012054876424372196
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006883621099404991
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019368670182302594
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013875404372811317
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001403534784913063
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007035310845822096Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012276837602257729

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025175760965794325
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014417031779885292
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014948277967050672
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001143418368883431
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015120210126042366
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002196488669142127
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01703837886452675
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010802516480907798Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016248539322987199

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011856243945658207
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017082624835893512
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012767688604071736Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014164101332426071

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020760002080351114
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015517547726631165
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020234514959156513
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010805493220686913
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015190866775810719
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022920267656445503
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014013380277901888
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015156368725001812
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002654316835105419
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010312000522390008Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033297231420874596
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01667889952659607

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029917710926383734
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02113337814807892
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013585808919742703
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003027078928425908Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02010566182434559

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028200019150972366
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019565746188163757
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012802500277757645
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002687406027689576
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019765252247452736
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014149852795526385
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025511663407087326
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01750038005411625
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011082536075264215
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002232830272987485
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016809431836009026
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001189572038128972Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022323436569422483
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01642378233373165

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.471243679523468
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01873021386563778
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014799879863858223
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018173933029174805
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02994334138929844
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014163197483867407
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.802878737449646
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03198620304465294
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015182523056864738
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3641020357608795
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11387147009372711
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9824935793876648
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015672063454985619
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018063925672322512
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001872911350801587
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019205467542633414
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018375104991719127
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001843210426159203
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018606081139296293
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001764621352776885
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002108437940478325
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004008654039353132
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02266729436814785
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01628888212144375
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9995276927947998
  1%|          | 6/584 [00:39<59:16,  6.15s/it]    1%|          | 6/584 [00:34<56:46,  5.89s/it]  1%|          | 6/584 [00:37<58:38,  6.09s/it]Loss Loss tensor(11.9643, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(12.1545, device='cuda:0', grad_fn=<NllLossBackward0>)
Loss tensor(12.0705, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016589805483818054Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.530449628829956

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000781669863499701
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00018648174591362476
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01245332881808281Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002460384275764227
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000470923725515604

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00029250516672618687Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006707009393721819

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0039765979163348675
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01160057820379734
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.539034802699462e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000429251667810604
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015603034757077694

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009348896564915776
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015642750076949596Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026127362623810768

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002633311552926898
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028167275711894035
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003517456934787333
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030967791099101305
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.051358357071876526
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004207806661725044
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004872610734310001Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.047667063772678375

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003657145192846656
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04913140833377838
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008728118264116347
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004279961343854666
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04723779112100601
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009141843183897436
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05630464106798172
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035778596065938473
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015295554185286164
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0509202778339386
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002859454369172454
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.059493035078048706
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001487977453507483Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002140381606295705

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06426112353801727
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035769001115113497
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001732412027195096Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07974343001842499

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023027106653898954
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05069640278816223
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003267212538048625
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015052002854645252
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.061134230345487595
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024365996941924095
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019955651368945837
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06727645546197891
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026540877297520638
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015103593468666077Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06535807996988297
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031107121612876654

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06239819526672363
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003072870895266533
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001986199291422963
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06651467829942703
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003441826906055212
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001929906546138227Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08122038841247559
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00394773855805397

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07639142125844955
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0048357960768043995
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022606821730732918
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07364333420991898
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004259446170181036
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016976443585008383
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0720437541604042
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004238052759319544
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06460299342870712
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003868833649903536
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018611022969707847
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06339892745018005
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003623437602072954
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022886665537953377Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.059885915368795395
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003472514683380723

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07293032854795456
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030594670679420233
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002118748612701893
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17762871086597443
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028739054687321186Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022982258815318346

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10570074617862701
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3994547724723816
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002307081827893853
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5462040305137634
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01909719593822956
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5317331552505493
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7790967226028442
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026090107858181
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4821723997592926
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026049171574413776
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002672449918463826
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025884374044835567
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024898527190089226
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026133356150239706
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024096325505524874
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003097174223512411
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016865050420165062
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022328581660985947
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03181583061814308
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9989676475524902
  1%|          | 7/584 [00:39<56:17,  5.85s/it]  1%|          | 7/584 [00:45<57:58,  6.03s/it]  1%|          | 7/584 [00:43<57:32,  5.98s/it]Loss Loss Loss tensor(10.2629, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(9.9330, device='cuda:0', grad_fn=<NllLossBackward0>)tensor(10.2233, device='cuda:2', grad_fn=<NllLossBackward0>)

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014027586206793785Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3369813859462738

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016781294718384743
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015700100921094418
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012521622702479362
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027775384951382875Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0042526600882411

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008026316645555198Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010452319867908955

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00018464749155100435
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004781199153512716
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014374736696481705
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002055820223176852Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007044770754873753

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00030961527954787016
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006900547305122018
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002644672058522701
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009162687696516514
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001956793013960123
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012824732810258865
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00039193208795040846
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026941215619444847
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024963166564702988
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000587685382924974Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037342985160648823Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02484695427119732


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026787806302309036
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033937084954231977
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000728759856428951
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026730433106422424
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004055500496178865
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012873202795162797
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.031986404210329056
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003530364716425538
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014041317626833916Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029478013515472412

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00298263318836689
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03693767637014389
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017057537334039807
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023307243827730417
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0390951931476593
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035752065014094114
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015562026528641582
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05448593571782112
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026847810950130224
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002030131174251437
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0328126884996891
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037311387713998556
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00159566814545542Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04107830673456192

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028511660639196634
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04767177253961563
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003268182510510087
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022491272538900375
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04863220825791359
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003893411485478282
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002105548745021224Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0454840287566185

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0040297843515872955
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.050288472324609756
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0046326895244419575Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002741198753938079

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.058949053287506104
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005486748646944761
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001981158507987857
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05501985549926758
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006543830502778292
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022420731838792562
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05543294548988342
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005756273865699768Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05428096279501915
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00285501591861248

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05003457888960838Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005853334907442331

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026640291325747967
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05105927214026451
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00552330631762743
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029122517444193363
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04775558412075043
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005106354132294655
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033100529108196497
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06008489802479744
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004939525853842497
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034027269575744867
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1580493152141571
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004212500527501106
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07556610554456711
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00382547196932137
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003355107270181179
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5734086632728577
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.463990181684494
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003639459377154708Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6932219862937927

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019237924367189407
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036675608716905117
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7164782881736755
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003562894882634282Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5196845531463623

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003769742790609598
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003691862104460597
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004723592195659876
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025817761197686195
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03059995174407959
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06248403713107109
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9970449805259705
  1%|▏         | 8/584 [00:46<58:34,  6.10s/it]  1%|▏         | 8/584 [00:52<59:43,  6.22s/it]  1%|▏         | 8/584 [00:49<59:25,  6.19s/it]Loss Loss Loss tensor(8.1338, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(7.7987, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(8.5123, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.269316703081131
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018721340224146843Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000673749833367765
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013811719603836536

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004350585862994194
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005233754054643214
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029106996953487396
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02301984466612339
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017981453565880656
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00033991446252912283
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034214560873806477
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03703642264008522
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007406420772895217
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00460987351834774
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021899366402067244
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003625184763222933Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00046265023411251605

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00540572265163064
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004900666535831988Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011795655591413379

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008212119340896606
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017928611487150192
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013567070476710796
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006937937578186393
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01455189473927021
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002583707682788372
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016929171979427338
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008819563663564622
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002445375779643655
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01721537858247757
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013574246549978852
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002967830980196595
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019576430320739746
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016055852174758911
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018389681354165077
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026836313772946596
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020523439161479473
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024912206456065178
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024045882746577263
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019565040711313486
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02452571503818035
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019628156442195177
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002393757225945592
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03905871883034706
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028819984290748835
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019820048473775387
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023367464542388916
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024379270616918802
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002972195390611887Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03016280010342598

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034051863476634026
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03712477162480354
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026651460211724043Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026672054082155228

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03878561779856682
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031646001152694225
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003851603716611862
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03830884397029877
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038993763737380505
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028206720016896725
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04568669945001602
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004221017938107252
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05126984789967537
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032820450142025948
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04856119304895401
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005021187476813793
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004267972894012928
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.052233967930078506
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006084575317800045
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004197280388325453
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05227972939610481
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007163047790527344
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05095628276467323
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004791343118995428
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0064039817079901695
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05119292065501213
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0066846152767539024Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006477737333625555

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.051593005657196045
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006581321358680725
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0058236015029251575
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06810738891363144
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006124586798250675
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005701660178601742
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1757870465517044
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006063288077712059
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006448559928685427Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07656707614660263

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005159629974514246
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6525859236717224
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00688170688226819
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004719993565231562
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6548663973808289
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0068212938494980335
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4201609790325165
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0070012882351875305Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01597071997821331

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5429455041885376
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007372317835688591Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7255129218101501

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011581658385694027
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.050198450684547424
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.040023401379585266
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13554953038692474
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9881961345672607
  2%|▏         | 9/584 [00:53<1:01:38,  6.43s/it]  2%|▏         | 9/584 [00:59<1:02:26,  6.52s/it]  2%|▏         | 9/584 [00:57<1:02:13,  6.49s/it]Loss Loss Loss tensor(6.7425, device='cuda:0', grad_fn=<NllLossBackward0>)tensor(6.6316, device='cuda:1', grad_fn=<NllLossBackward0>)

tensor(6.9350, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01694462262094021Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012529310770332813Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13485772907733917


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00042491487693041563
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00039493932854384184
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006395189557224512Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022787339985370636
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004345197696238756

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005259233294054866Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012991498224437237

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03819124028086662
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008563334704376757
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012477290583774447
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014675890270154923
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001711900345981121
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021377175289671868Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00032263240427710116

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021067641209810972
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008000337984412909
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00029110279865562916
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027940021827816963Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012795899529010057

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003624433884397149Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019238097593188286

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00036556049599312246
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004428356885910034
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019039842300117016
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00048116748803295195Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0049268160946667194

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023653837852180004
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005082571879029274
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022399239242076874
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006140111363492906
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005382366944104433
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021287263371050358
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007449798285961151
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0058273449540138245
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001816963660530746
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008703022031113505
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0071952310390770435
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026479351799935102
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009460821747779846Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007390961982309818

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002419223077595234
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011065561324357986
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001029284088872373Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003429262200370431

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00974871963262558
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027793357148766518
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010405608918517828
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011956273578107357
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033838865347206593
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014470744645223022Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015582287684082985

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004330671392381191
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01726403459906578
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001476190984249115Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004902086220681667

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020265894010663033
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005949434358626604
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002000401960685849
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02598855085670948
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0075727361254394054
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018691698787733912Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029225315898656845

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009060573764145374
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028569689020514488
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022037953604012728Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008321831934154034

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030394069850444794
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008967879228293896
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029114987701177597Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.032337434589862823

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009224731475114822
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03189411014318466
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032567756716161966
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008758333511650562
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030993647873401642
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003896998940035701Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008945981971919537

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03117232583463192
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007795814424753189
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04114958271384239
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005591138731688261
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007440068759024143
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1369008868932724
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005093847867101431
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.43397772312164307
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05152786523103714
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005166192073374987
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015989283099770546
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.32199040055274963
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9197888374328613
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5330652594566345
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005691720172762871
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7244521975517273
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0063779656775295734
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00634591793641448
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006472002249211073
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0068147676065564156
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012158348225057125
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06426616758108139
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018813110888004303
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10659747570753098
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9916322231292725
  2%|▏         | 10/584 [00:59<1:00:27,  6.32s/it]  2%|▏         | 10/584 [01:05<1:00:59,  6.38s/it]  2%|▏         | 10/584 [01:03<1:00:51,  6.36s/it]Loss Loss Loss tensor(6.5891, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(6.7276, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(6.3041, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3337355852127075
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016198571771383286Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06977670639753342

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010152215836569667
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007779242005199194
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03606259450316429Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013787603005766869
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002256056759506464

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02247723937034607
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030354024842381477
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022207493893802166
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0070124962367117405
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00027955323457717896
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008342244662344456
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004922887892462313
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002451915293931961
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011656188406050205
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009730479214340448
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013499702326953411
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015557390870526433
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001537527423352003
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019484877586364746
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002273199614137411
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019915332086384296
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02000984363257885
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022554341703653336
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02295497991144657
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002902729669585824
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027668236289173365
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024418307468295097
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002743239514529705
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002648575697094202
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023617951199412346
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004435388837009668Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002537586959078908Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02102603390812874


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.031391892582178116
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021840985864400864
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004705160390585661
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02760971337556839
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031011037062853575Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005856675561517477

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03680821880698204
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002911719959229231
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005968066863715649
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03033502586185932
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004076795186847448
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006573403254151344Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.039105288684368134

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003364636329934001
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0460834763944149
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004095238633453846
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005424076225608587
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.054062891751527786
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005303958430886269
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008277329616248608
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06525303423404694
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006083045620471239
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007026652339845896Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07914747297763824

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00738080870360136
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09299283474683762
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008932727389037609Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009507301263511181

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09289177507162094
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011417931877076626
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10256654024124146
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008178800344467163
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010606623254716396
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10608191788196564
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009804511442780495
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10197459161281586Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01156015507876873

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011736100539565086
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10980668663978577
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012101734057068825
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013309425674378872Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12874647974967957
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011557591147720814

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14136143028736115
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011983530595898628
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01665056310594082
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4435654282569885
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01061766967177391
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01885359175503254Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010599085129797459
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1178150549530983

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5464152693748474
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4020102918148041
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021742792800068855
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5061599016189575
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014606980606913567
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02255723439157009
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4159902036190033
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0250374935567379Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8140019178390503

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02713633142411709
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028449414297938347
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029286528006196022
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03273874148726463
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.035557664930820465
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.27017882466316223
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08796853572130203
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.22831636667251587
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9236302375793457
  2%|▏         | 11/584 [01:05<1:00:00,  6.28s/it]  2%|▏         | 11/584 [01:11<1:00:23,  6.32s/it]  2%|▏         | 11/584 [01:09<1:00:17,  6.31s/it]Loss Loss tensor(5.9099, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(7.2824, device='cuda:1', grad_fn=<NllLossBackward0>)
Loss tensor(6.2183, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05430196225643158Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013666867278516293

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00033685233211144805
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012336429208517075Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.27057158946990967

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007945547113195062
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001397893764078617
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026512793265283108
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012166538275778294
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00520741380751133
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013489522971212864Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00039819604717195034

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00735036376863718
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006001105648465455
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002310636918991804
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00913294404745102
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002482645446434617Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009095494751818478
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008920618332922459

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014605161268264055
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011784817092120647
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003478449070826173Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00218634563498199
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013156836852431297

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002176925539970398
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017784958705306053
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031543029472231865
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002654209965839982
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017392095178365707
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004764702171087265
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002550634788349271
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020210929214954376
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004856866784393787Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002474695909768343

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02092207595705986
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021533824037760496
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006130964960902929Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01966170407831669

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002987401792779565
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017452556639909744
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006123426835983992
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002879153238609433
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02580227144062519
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003985858056694269
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006515194661915302
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022978341206908226
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033230758272111416
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005409871693700552Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.031385648995637894
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004025220405310392

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02468562126159668
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005277309101074934
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008047991432249546
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03166811913251877
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006078748032450676
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007017097901552916
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.038230203092098236
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007388446480035782
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04389278218150139
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008881205692887306
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009476244449615479
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.052217576652765274
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007896575145423412
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01136320736259222
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06414248049259186
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010560950264334679
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009398074820637703Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07522732764482498

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011561764404177666
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07434464246034622
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011467992328107357Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012216581963002682

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08216064423322678
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011620794422924519
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012708766385912895
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0854264423251152
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012005187571048737
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015502584166824818Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08226659148931503
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010718056932091713

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08749070763587952Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011215634644031525

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017808636650443077
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.47396260499954224Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10023234039545059

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020386071875691414
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11500299721956253Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01467182394117117

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020932285115122795Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.41638681292533875Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.35540348291397095


Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7747257947921753
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0922209620475769
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023191407322883606
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4156290292739868
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7344684600830078
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02502792328596115
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02623424492776394
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026583950966596603
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02948756515979767
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.032517749816179276
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.24464814364910126
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07109246402978897
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20288385450839996
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9402449727058411
  2%|▏         | 12/584 [01:17<58:20,  6.12s/it]    2%|▏         | 12/584 [01:11<58:04,  6.09s/it]    2%|▏         | 12/584 [01:14<58:16,  6.11s/it]  Loss Loss Loss tensor(5.8372, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.4926, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(6.1109, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08942724019289017
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026449233293533325Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008430765941739082
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010250151390209794

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000405185273848474
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007613970898091793Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0074910568073391914
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012274738401174545

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006067441310733557
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014814442256465554
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005630621686577797
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004547810181975365
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001132608624175191
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003690440789796412
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005273683462291956
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005241705803200603
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011209100484848022
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004402144346386194
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004987705033272505
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013696716632694006Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005103367147967219

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00611531175673008
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008351714350283146
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005622558295726776
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013136831112205982
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013139685615897179
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006547180470079184
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013261456042528152
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006759551353752613
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011912562185898423Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016029330436140299

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006168936844915152
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015441745053976774
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001595927868038416
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0056024412624537945
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015203896909952164
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008200546726584435
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001545996987260878Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013322036247700453

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007540139835327864
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001800453057512641
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019324535969644785Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010680373758077621
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001777272904291749

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0077666486613452435
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002436757553368807
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019383806502446532
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009839662350714207
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020465191919356585
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01257591787725687
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001995144644752145Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024617586750537157

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013726914301514626
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032709958031773567
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01594635285437107
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017326610395684838Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037859545554965734

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01975352130830288Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004632303025573492

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024844068102538586
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02335614711046219
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005878281779587269
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002244399394840002Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023042112588882446
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007016635034233332

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025747016072273254
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006521817296743393
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002859543776139617
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02720634639263153
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00716382497921586
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002432800829410553
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026588495820760727
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007641931995749474
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027534808963537216Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007236965466290712
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029028120916336775

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007396643050014973
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02966221235692501
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00364671996794641
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006667292211204767
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.035273462533950806
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003874671645462513Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007288710679858923
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09409522265195847

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3932584524154663Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02761305496096611

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00456604827195406
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09630164504051208
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009990575723350048
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005288190674036741Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9824678301811218

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.29580143094062805
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8701273202896118
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005998861510306597
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006159582640975714
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006837220396846533
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007553431671112776
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007892485707998276
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00789378210902214
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00853816419839859
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009472386911511421
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.059845566749572754
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015040876343846321
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.044743213802576065
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9964073300361633
  2%|▏         | 13/584 [01:19<1:02:58,  6.62s/it]  2%|▏         | 13/584 [01:25<1:03:09,  6.64s/it]  2%|▏         | 13/584 [01:22<1:03:06,  6.63s/it]Loss Loss Loss tensor(5.4973, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(5.9668, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.4373, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.26748302578926086Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029101138934493065Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013364349491894245


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004946035332977772
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020106693264096975
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06722879409790039Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01762990653514862
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020584000274538994

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01561766117811203Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02043951116502285

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08464544266462326
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033674819860607386
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015008755726739764
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014789347536861897Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002539831679314375

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009688704740256071
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004605854337569326Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004826678894460201

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011834348551928997
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004952647141180933
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00367543357424438
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012025275500491261
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001142665627412498
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001673172228038311Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016665620496496558

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018288338324055076
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00217794394120574
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002379171084612608
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017679743468761444
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023411752190440893
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002371825510635972
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002581627108156681Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002192426472902298

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002485462697222829
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020424805115908384
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003149761352688074Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021840513218194246

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019341559382155538
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029102254193276167
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038807084783911705
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002520716981962323
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029262586031109095
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025403585750609636
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035042983945459127Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004027900286018848

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031072988640516996
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033787726424634457
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037021306343376637
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025936532765626907
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004054676741361618
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032489660661667585
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030638519674539566
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00547970924526453
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004331952426582575Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00399785628542304

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006401833612471819
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004363464191555977
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007945822551846504
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004056933335959911
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0053372131660580635
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009979961439967155
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004764608107507229Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006663409527391195

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011847976595163345
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007706619333475828
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004469460807740688Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011056246235966682

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007506640162318945
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01218193955719471
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004920908249914646
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008134135976433754
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013156350702047348
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006355449557304382Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008702270686626434
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01245676539838314

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008681757375597954
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012589001096785069
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006747901439666748
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008776959031820297
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011578585021197796
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008358314633369446
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008652357384562492
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013197989203035831
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00987484771758318
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010177738964557648
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7862663865089417
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.038854606449604034
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010908922180533409
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017003577202558517
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00787624716758728
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5262101888656616
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011057383380830288
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3088502585887909
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027885688468813896
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9975855350494385
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012380300089716911
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013234952464699745
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013632247224450111
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013895982876420021
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014816511422395706
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016835948452353477
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14875613152980804
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06170807406306267
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07192013412714005
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9436333179473877
  2%|▏         | 14/584 [01:32<1:05:20,  6.88s/it]  2%|▏         | 14/584 [01:26<1:05:12,  6.86s/it]  2%|▏         | 14/584 [01:30<1:05:18,  6.87s/it]Loss Loss Loss tensor(5.6548, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(5.7470, device='cuda:0', grad_fn=<NllLossBackward0>)tensor(5.5349, device='cuda:1', grad_fn=<NllLossBackward0>)

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029796678572893143Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05489594489336014
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008475154638290405

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012206350220367312
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008942889980971813
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008853508159518242Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007836706005036831
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024117787834256887

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004998668562620878
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013805292546749115Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025934926234185696

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022880725737195462
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001200854778289795
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00045076748938299716
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00036820469540543854
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016612304607406259
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003644434327725321
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003065249649807811
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005628943908959627
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005519256228581071Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032494752667844296

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008520135888829827
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0041438075713813305
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012568517122417688
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003665444441139698
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009225761750712991
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012691422598436475
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004128668922930956
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009458576678298414Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003964817151427269
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015404382720589638

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003563924925401807
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014783964725211263
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001252998597919941
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003252374706789851
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014790280256420374
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011603465536609292Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004261728376150131

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013064246159046888
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0041359285824000835
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017104980070143938
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014781476929783821
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005392297636717558
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017279600724577904
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001348487101495266
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004537798464298248
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023412746377289295
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001343601499684155Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005526114255189896
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020325740333646536

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0069535160437226295
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024263078812509775
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001143702887929976
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003278670134022832
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007858355529606342
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001553886104375124
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003851348767057061
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009546400979161263
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014162760926410556
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004753926303237677
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011956615373492241
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005961662158370018
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017655236879363656Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01371748000383377

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007050044368952513
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013413106091320515
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001656841253861785
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006615842692553997
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015154539607465267
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018512974493205547
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007311526220291853
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01611803099513054
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007940645329654217Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002377751749008894
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01607634872198105

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007514143828302622
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01656719669699669
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026637078262865543
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00752875255420804
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01715691201388836
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00314980442635715
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0069907046854496
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01994851976633072
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038466542027890682Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008084649220108986
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03337125480175018

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.555167555809021
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015301790088415146
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004145328886806965
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011527770198881626
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04301554709672928
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9955225586891174
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3455643951892853
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004306280054152012
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7560309171676636
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004822822753340006
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005182924680411816
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005463586188852787
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005415433086454868
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006127202417701483
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006945203524082899
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023112038150429726
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019950270652770996
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01914605125784874
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9987185001373291
  3%|▎         | 15/584 [01:33<1:04:18,  6.78s/it]  3%|▎         | 15/584 [01:39<1:04:23,  6.79s/it]  3%|▎         | 15/584 [01:36<1:04:22,  6.79s/it]Loss Loss Loss tensor(5.3940, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(5.2016, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.6826, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01684081368148327
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007277370896190405Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2233044058084488

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003906488884240389
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009013139642775059
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009871807880699635
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002449843450449407
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004743517376482487
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00037285921280272305
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033149151131510735
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005337515030987561Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0043787406757473946

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007229006849229336
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008013789192773402
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007970936596393585
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008925481815822423
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01110889669507742
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009906608611345291Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012667683186009526

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01165301725268364
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001195756602101028
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01132257655262947
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015314007177948952
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01063640508800745
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014796297764405608
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01012782845646143
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014460639795288444Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013028274290263653

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01288014929741621
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013363260077312589
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01646864414215088
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01575147546827793Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017648598877713084

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019638072699308395
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016959944041445851
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02537127211689949
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021132798865437508
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02989192120730877
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021607251837849617
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.038926541805267334
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002460171701386571
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.044434577226638794
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032789644319564104Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04966575652360916

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05154423043131828
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038152490742504597
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05923135206103325
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004696349147707224
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06290227174758911
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0054405550472438335
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06306596100330353
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06495502591133118
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0057299393229186535
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0685030072927475
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006216269452124834Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08055131137371063

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08719583600759506
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006793487351387739
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.062321145087480545
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007537286728620529
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18957406282424927
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008093277923762798Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9292431473731995

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0078975735232234
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008917609229683876
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010635114274919033
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014730564318597317
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01733406074345112
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03019873984158039
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9988125562667847
  3%|▎         | 16/584 [01:38<1:00:03,  6.34s/it]  3%|▎         | 16/584 [01:42<1:00:05,  6.35s/it]Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0070808217860758305
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00036486441968008876
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006610616110265255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017547537572681904
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015072512906044722
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00026769094984047115
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004248175537213683
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006481323507614434
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009811428608372808
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001013339264318347
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012623139191418886
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001224855543114245
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001234323950484395
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00110105169005692
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014393674209713936
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001462799496948719
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001978170359507203
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001760276616550982
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002099978504702449
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028445515781641006
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033640949986875057
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0041491128504276276
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005193781107664108
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006141584366559982
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005802418105304241
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006443304475396872
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007037041708827019
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0066703567281365395
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006657143123447895
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0062254504300653934
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007303754333406687
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5027956962585449
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010352173820137978
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.30217236280441284
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8095037937164307
  3%|▎         | 16/584 [01:44<1:01:31,  6.50s/it]Loss Loss Loss tensor(5.9412, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.2892, device='cuda:0', grad_fn=<NllLossBackward0>)tensor(6.0480, device='cuda:2', grad_fn=<NllLossBackward0>)

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005824126303195953
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09515547007322311
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010707174660637975
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037821936421096325
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.031200753524899483Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022809484507888556
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015275289304554462

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021975485142320395
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003609603503718972
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019712433218955994
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.954207831062376e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006509839440695941
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018203954678028822
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00017077135271392763
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009656184702180326
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003751150507014245Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00033164676278829575

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012218671618029475
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005264492938295007
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010965026740450412
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017284186324104667
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008380907820537686
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023418960627168417
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001759510050760582
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008884064736776054
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028228380251675844
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001140999491326511
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021007462055422366
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011171209625899792
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00319468742236495
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000302018626825884
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011344051454216242
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003437878331169486
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00042188013321720064
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010223537683486938
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036975182592868805
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005045786965638399Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013374066911637783

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036337124183773994
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001359707210212946
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000603521941229701
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00450994772836566
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018371359910815954
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004753973800688982
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006434462266042829
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016600941307842731
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00607834430411458
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007274086819961667
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019833503756672144
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006043449509888887
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007251284550875425
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002673074835911393
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007327719125896692
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009122879710048437
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003176709869876504
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009706794284284115
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009719454101286829Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0039068954065442085

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011949840001761913
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004853356163948774
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011669618543237448
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016067076474428177
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00573956873267889
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012536284048110247
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01744069531559944
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005443771835416555
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013946780236437917
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019660232588648796
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006053566001355648
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019164077239111066Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02047715336084366

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006604933645576239
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0247455146163702
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002255774335935712
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006257690489292145
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02647717297077179
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028181930538266897
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006243041716516018
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025446325540542603
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005858357064425945Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02619577944278717

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031380238942801952
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006990266498178244Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02641349472105503

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034421253949403763
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4648255705833435
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02996174432337284
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036509502679109573
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009417850524187088Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.051820140331983566

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.27209943532943726Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022260338068008423

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004040828440338373
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8422496318817139
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06657887250185013
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004587814211845398Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9884253144264221

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004656731151044369
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004578340798616409
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004975718911737204
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005959818605333567
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018289167433977127
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006297580432146788
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014284752309322357
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9989268779754639
  3%|▎         | 17/584 [01:52<1:03:56,  6.77s/it]  3%|▎         | 17/584 [01:46<1:04:19,  6.81s/it]  3%|▎         | 17/584 [01:50<1:04:21,  6.81s/it]Loss Loss Loss tensor(5.3521, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.9061, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(5.9648, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0618673600256443
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005705932155251503
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007588243577629328
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00340298586525023
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.055195536464452744Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01918022148311138Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004624946974217892


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0061796074733138084
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005460664629936218
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04187457263469696
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.556231477996334e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004357210418675095
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025812399107962847
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001688635820755735
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006436256226152182
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006255102925933897Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003440221771597862

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007901928620412946
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005483915447257459
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.665379573358223e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012854868546128273

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000860928266774863
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001821736921556294
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013299970305524766
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009126908844336867
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002021263586357236
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016498517652507871
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011652939720079303
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022781111765652895
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00025641059619374573
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011370157590135932
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002359551377594471
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011495565995573997
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00036495618405751884Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002491500461474061

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001033036271110177
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024782540276646614
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004326620837673545
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013397898292168975
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030066741164773703
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005072829080745578
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013607458677142859Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033225042279809713

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004591021221131086Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001834082417190075

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000500051595736295
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0040517994202673435
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016727115726098418
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005838926299475133
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005084385629743338
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001999765168875456
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005788845592178404Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006512925028800964
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002675955183804035

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007654455490410328
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003198987804353237
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007047763792797923
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00971775408834219
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0039123957976698875
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007651736959815025
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010701839812099934
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00482213357463479
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000948515662457794
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013047605752944946
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0056958929635584354
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009649909334257245Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01315675675868988

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005424472503364086
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015197932720184326Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0060163806192576885

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011132436338812113
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017425742000341415
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0065259127877652645
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014636743580922484
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01667504943907261
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006162618286907673
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016834194539114833Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006137472111731768
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01667792722582817

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005781914573162794
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016880199313163757
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020846163388341665
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007025181315839291
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019925549626350403
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002264975802972913Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4569750428199768
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04967079311609268

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00903500709682703
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016414370387792587
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026921904645860195
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.26349109411239624
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05262388288974762
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002762338612228632
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.849226176738739
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9938147664070129
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003069831058382988
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034608712885528803
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034494861029088497
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035210479982197285
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003667334094643593
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004712135065346956
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022416945546865463
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007407282013446093
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016811195760965347
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9971139430999756
  3%|▎         | 18/584 [01:53<1:04:30,  6.84s/it]  3%|▎         | 18/584 [01:59<1:04:15,  6.81s/it]  3%|▎         | 18/584 [01:56<1:04:32,  6.84s/it]Loss Loss Loss tensor(6.1596, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(5.0904, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(5.6822, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07734445482492447Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6358000636100769
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006016346160322428

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04973289370536804
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03515864908695221
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5069319009780884Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.22736211121082306
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03498237580060959

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0315716490149498Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.039477210491895676
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026202723383903503

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.029114279546775e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005959697300568223
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003770955838263035Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.373800665140152e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001060029841028154
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.465150312986225e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001996273873373866
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002340952487429604
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015603023348376155Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025729616172611713
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00037161691579967737

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003065758151933551
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005498008686117828
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000283535395283252Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003139633685350418
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000581966305617243

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034389521460980177
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007665193406865001
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00035328621743246913
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007824053755030036Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003680874826386571

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037309532053768635
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008418344077654183Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004329665098339319

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003918564412742853
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007862835191190243
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00046991955605335534
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010474049486219883Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0050990525633096695

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000578064180444926
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010956157930195332
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005529222544282675
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015118386363610625
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008565668016672134
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006438798154704273
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013732104562222958
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00608873413875699
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007128036813810468Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016508980188518763

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0075761703774333
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00220578839071095
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00931778084486723
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007220917614176869
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026619487907737494
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010808845981955528
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000949051056522876Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003275403054431081
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012730649672448635

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0039636301808059216
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015204070135951042
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009734667255543172
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004650067538022995
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017056437209248543
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00131289754062891
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004441973753273487
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017208494246006012
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011570563074201345Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004888089373707771

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019723746925592422
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005269944202154875
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013433428248390555Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021728970110416412

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00494494428858161
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021567633375525475
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004918580874800682
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001671047997660935
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02290414460003376
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0046747964806854725
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023027166724205017
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019314083037897944Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005826194770634174

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03080182708799839
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.38841861486434937
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002167648635804653Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07878205180168152
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007434466388076544

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030784698203206062Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2235281765460968

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026177463587373495Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8918349742889404

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07173559069633484
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027919316198676825Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9597746729850769

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029567445162683725
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003260855795815587
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036443525459617376
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036968435160815716
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003715335624292493
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004150737076997757
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00524882972240448
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02996676228940487
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015012002550065517
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019686436280608177
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5800228714942932
  3%|▎         | 19/584 [02:06<1:04:42,  6.87s/it]  3%|▎         | 19/584 [02:00<1:04:53,  6.89s/it]  3%|▎         | 19/584 [02:03<1:04:55,  6.89s/it]Loss Loss Loss tensor(5.2577, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(5.7023, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.7351, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04354780167341232
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1806912124156952Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005471554584801197
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009112397208809853

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01319395937025547
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05870441719889641
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12489023804664612Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019460199400782585Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012581761926412582


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.795463867892977e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01312164030969143
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07331140339374542
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.294078487670049e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.0453815068322e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.037504110485315e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030570682138204575Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.1928805128700333e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010330479562981054
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.2816674320201855e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.928667178523028e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00018499704310670495
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.560855920019094e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.989410055917688e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021341054525692016

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.665455783950165e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003401275316718966
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.860053453128785e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.713317012938205e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004055673780385405
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.79796576150693e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00030779733788222075
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.3712232430407312e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.0014703194610775e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003022527089342475
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.278813553857617e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.401970313163474e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00033450438058935106
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.094762359978631e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.151984856231138e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003337786183692515
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.098145240684971e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.8122984076617286e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009633898735046387
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.918334757850971e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004999312805011868
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.522018859162927e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.864297367632389e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008478351519443095
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.117843001149595e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.745152495568618e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014092890778556466

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00018260370416101068
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021443001460283995
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.167320291046053e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003931102401111275
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003989930264651775
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007446706295013428
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.81046726135537e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005011048633605242
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002335271332412958
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.65023209573701e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006269417703151703
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002075956668704748
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016738456906750798
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006584416143596172
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002713116817176342
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014483129780273885
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008412727154791355
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028467283118516207
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008840864524245262
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00025354113313369453Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032623650040477514

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00908159650862217
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003659244393929839
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00041880219941958785
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009383280761539936
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003485489170998335
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010478408075869083
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006155422306619585Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003494691103696823

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013696196489036083
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00345832877792418
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011058668605983257Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028869504109025
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00449374271556735

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017467696219682693
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4246107339859009
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014381416840478778
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05871828645467758
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008210652507841587
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9944139719009399
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.26174384355545044
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001741904648952186
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8632989525794983
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001980549655854702
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024399624671787024
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027615714352577925
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028345196042209864
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028592911548912525
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003475738689303398
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00433816434815526
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01819954626262188
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009981149807572365
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026484016329050064
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9748678803443909
  3%|▎         | 20/584 [02:06<1:03:16,  6.73s/it]  3%|▎         | 20/584 [02:12<1:03:08,  6.72s/it]  3%|▎         | 20/584 [02:10<1:03:17,  6.73s/it]Loss Loss Loss tensor(4.9662, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.3393, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(5.4651, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005290235858410597
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1295992136001587
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027587630320340395
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016156332567334175
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10177093744277954
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004787360318005085
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05839156359434128
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08013100922107697
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.5219999315595487e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.799422746757045e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.974989795096917e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001500131911598146
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.109875125228427e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003573016729205847
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.0277327419316862e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004958535428158939
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.953788523678668e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008574282401241362
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.4148101147147827e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009913258254528046
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.4601289118872955e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001541396719403565
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.0405717300018296e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001795105985365808
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.7898527554934844e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013835245044901967
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.979164830525406e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014455517521128058
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.487587572541088e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002015664242208004
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014209229266270995
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002513301093131304
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003844230668619275
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007247228175401688
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005663569085299969Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006113545969128609

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00905122235417366
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009878640994429588
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011561807245016098
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001494230586104095
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014189714565873146
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019689968321472406
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01777067966759205
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002693240065127611
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019792985171079636
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003046157071366906
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022396987304091454
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035797778982669115
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02260633558034897
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034612377639859915
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02865685522556305
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037588083650916815
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028083786368370056
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004032488446682692
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028597615659236908
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00378667120821774
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03031192719936371
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037792350631207228
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030851522460579872
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036892443895339966
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04557819291949272
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004836754873394966
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04934117570519447
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4518022835254669
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03280387073755264
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008102110587060452
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18728923797607422
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2473481446504593
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9586220383644104
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.854993999004364
  4%|▎         | 21/584 [02:19<1:02:40,  6.68s/it]  4%|▎         | 21/584 [02:13<1:02:45,  6.69s/it]Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21636554598808289
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.048465546220541
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011579299345612526
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00837182067334652
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.214735655405093e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.7568951079738326e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.1485920771956444e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.5032811613054946e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.570245361421257e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001010760897770524
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00018643752264324576
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002340756036574021
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022219899983610958
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00024225382367148995
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003825862368103117
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004913830780424178
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009202025830745697
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011481940746307373
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017465915298089385
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023050943855196238
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028387997299432755
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033796674106270075
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037695325445383787
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004174697678536177
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004429112188518047
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0051070149056613445
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005542801693081856
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005530017428100109
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0057784318923950195
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006263923831284046
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008774729445576668
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008117858320474625
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009756451472640038
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.050134990364313126
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9734675288200378
  4%|▎         | 21/584 [02:17<1:03:08,  6.73s/it]Loss Loss Loss tensor(5.1137, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(5.3652, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(5.4523, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09280004352331161
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005537426099181175
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10863792896270752Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002427987288683653
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008469193242490292

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03620443865656853Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004654169548302889

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02644360065460205Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0465850867331028
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10888829082250595

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.6843003070098348e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.8448994296704768e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006075337994843721
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.9017310225754045e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.946711123920977e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.054419489169959e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001008348262985237
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006212127860635519
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.716830284858588e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015212249127216637
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.196692771074595e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.5055119547469076e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00027030642377212644
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.5378816897282377e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.733791790087707e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003238757490180433
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.281437865458429e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005844080005772412
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.20476761367172e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.506046677008271e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008997455588541925
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.382628245977685e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.7486478100181557e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005007305881008506
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.385339368833229e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.8890452085761353e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005256259464658797
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.290238237241283e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.066284600412473e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005477629601955414

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.47752177529037e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00048184904153458774
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.944156045094132e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.226542558986694e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021068761125206947
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012333330232650042
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005787104601040483
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.0189726607641205e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010027337702922523
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008641037275083363
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.821162191452459e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010680164268705994
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011775583261623979
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00018508805078454316
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001251310168299824Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017672714311629534

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000354737916495651
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003963614348322153
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000132862085592933
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019055848242715001
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004442453850060701
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002454706991557032
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012551099061965942
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005824001971632242
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017437100177630782
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001473230222472921
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006408659275621176
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001995054306462407
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00864820834249258
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00023211975349113345
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024385247379541397
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009687506593763828
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00029734880081377923
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028962434735149145
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010630528442561626
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029017215128988028Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00045562515151686966

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011083261109888554
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029776678420603275
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009779066313058138
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012021894566714764
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003019088413566351
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011001540115103126
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01858646236360073
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004033945966511965
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001377482432872057
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023312602192163467
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.445232093334198
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016667930176481605
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01985250413417816
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009121793322265148
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021097136195749044
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0867844671010971
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2834243178367615
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026055672205984592Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9891148805618286
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8422420024871826

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028606783598661423
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029853780288249254
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033791502937674522
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004829231183975935
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004263703245669603
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00806546863168478
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029181459918618202
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9931856393814087
  4%|▍         | 22/584 [02:26<1:03:16,  6.76s/it]  4%|▍         | 22/584 [02:20<1:03:20,  6.76s/it]  4%|▍         | 22/584 [02:23<1:03:13,  6.75s/it]Loss Loss Loss tensor(6.0115, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(6.0183, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(6.0768, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7677423357963562Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9159567952156067

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011305276304483414
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020368916913866997
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.41955894231796265Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01889718323945999
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16999340057373047

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019580945372581482
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03307054936885834Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3224915862083435

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015534303383901715
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.975235104560852
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.044189129024744034Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002975112001877278
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.398987458553165e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.5657822586945258e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.8906164516229182e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005883877165615559
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.3211812731460668e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00091181555762887
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.613166285911575e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.414773891563527e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016193861374631524
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.143018931150436e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019212549086660147
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.567932283971459e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.463659469271079e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035161394625902176
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006886296905577183
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013357927673496306
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0065039703622460365
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010039861081168056
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002188701619161293Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003275224007666111Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005985555471852422


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002601478190626949Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003580875229090452

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00030839943792670965
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003076197172049433
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037376529071480036
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008075868827290833
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012931390665471554
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028607912827283144
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00110602006316185Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012084979098290205
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014905346557497978

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010844053758773953
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027470558416098356
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007697380497120321
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012908020289614797
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034631674643605947
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008377524209208786
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00017611954535823315
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034479510504752398
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008837929926812649
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002442254335619509
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004401084501296282
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008605067851021886
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005990750156342983
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01476236991584301
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026264379266649485Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000582909444347024
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0062184580601751804

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007326131453737617
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007396758999675512
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007758030551485717
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007805301574990153
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0069138165563344955
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011318245669826865Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009139153989963233

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00818728655576706
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011115885572507977
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009542955085635185Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009104326367378235

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001157374121248722
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009559865109622478
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011606079060584307
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012110078241676092
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010379496030509472
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012637145118787885
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038599956315010786Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010295352898538113

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015049796784296632
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018417159095406532
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001741058542393148
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06723765283823013
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.034163884818553925
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005320804659277201Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018910679500550032

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020193755626678467
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12475749850273132Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10743965208530426

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019222648115828633
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1669870913028717
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11426632106304169
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002294642850756645
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025294548831880093
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002757577458396554
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030995693523436785
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003438557032495737
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05387851595878601
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019624313339591026
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012123643420636654
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04725618287920952
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.47512686252593994
  4%|▍         | 23/584 [02:27<1:04:29,  6.90s/it]  4%|▍         | 23/584 [02:33<1:04:26,  6.89s/it]  4%|▍         | 23/584 [02:31<1:04:25,  6.89s/it]Loss Loss Loss tensor(5.5438, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(6.0832, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.6799, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1890340894460678Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005538600031286478

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0064461627043783665
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12385944277048111
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10371088981628418Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011101573705673218

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012405059300363064
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008632894605398178Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16769328713417053

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09469158202409744
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.5052715955098392e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.97297026211163e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0712900385260582
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007049643434584141
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.105011263774941e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.6384433769853786e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.904359346051933e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.572686394676566e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.841932190582156e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.9382556274649687e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.374090273515321e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.3287564545171335e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014168240886647254
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.240837294375524e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1308566172374412e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.133396866265684e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002099505509249866
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.6947786207310855e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.67541748448275e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00036333908792585135

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.2889107135124505e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004745435144286603
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.8593402021215297e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.7638415455585346e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007617758237756789
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.221908238832839e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.8777750382432714e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014196592383086681
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.41002435865812e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011459809320513159

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013617570220958441
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007570005254819989
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001195915974676609
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002362876111874357
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008642164175398648
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011226464994251728Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004485734098125249
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009628492407500744

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009437965927645564
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007832879200577736
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011833228199975565
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004194614943116903
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022380284499377012
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016048875113483518
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001946327742189169
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013486234238371253
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00018230173736810684
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024210033006966114
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002090570516884327
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025106659159064293Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00026865824474953115
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032469425350427628

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027935411781072617
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030580146703869104Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002381652157055214Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004610290750861168


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029355091974139214
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0065044923685491085
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003849244967568666
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029268732760101557Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005678518791683018
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008123079314827919

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002935361582785845
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00973454862833023
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007468832191079855
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038838901091367006
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008784618228673935
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001154798548668623
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4426853656768799
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010374276898801327
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008671891875565052
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013517489423975348
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.26386770606040955
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011340209282934666
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015304168919101357
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8401976227760315
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011503543704748154
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015349271707236767
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011466057039797306
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018397882813587785
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012091346085071564
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002004023641347885Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017496667802333832

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02274092473089695
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020897970534861088
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023492010310292244
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00205832626670599
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1015014797449112
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022371383383870125
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9786673188209534
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032156489323824644
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005350027233362198
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007161474786698818
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025158008560538292
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9760289788246155
  4%|▍         | 24/584 [02:38<59:55,  6.42s/it]    4%|▍         | 24/584 [02:32<59:58,  6.43s/it]    4%|▍         | 24/584 [02:36<59:54,  6.42s/it]  Loss Loss Loss tensor(5.2328, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(5.4395, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(5.5816, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005103804171085358Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10069694370031357

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0043043941259384155
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06260655075311661
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06388765573501587
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010369538329541683
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008659291081130505
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004930902272462845Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05553244799375534

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08398651331663132
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004444114863872528Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04065970703959465

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.765957222232828e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.3528753445134498e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.8928582196385833e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.692623183975229e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.615866782842204e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.728613814426353e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.350192168407375e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.691762220929377e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010947941336780787
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.411885841662297e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.220743777405005e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015008248738013208

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.335888711968437e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002568601630628109
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.3597363249573391e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.979604687425308e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003424357855692506
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.367580236750655e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.076059460407123e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00048823034740053117

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.25695616286248e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008322164067067206Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.5056655178777874e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.4318585676373914e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005344522069208324
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.713495531585068e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006319589447230101
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.094886703067459e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.65702929534018e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008024088456295431Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.918212552089244e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.845204138197005e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009418276604264975
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022856256691738963

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003476852783933282
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00031286675948649645
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.510028758086264e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017413300229236484
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005794962053187191
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001465506065869704Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026941876858472824

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009949894156306982
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00418079225346446
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00018428389739710838Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001503628445789218

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005362937692552805
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002374043921008706
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003587873943615705Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0064741699025034904
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025583398528397083

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008404947817325592
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029944723937660456
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00033116049598902464
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009782706387341022
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002917618490755558
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005026370054110885
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008715055882930756
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031051465775817633
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007960230577737093
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01017766259610653
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003261886304244399
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009698295034468174Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011589749716222286
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030759109649807215

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011755638755857944
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030413654167205095
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001229104120284319
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011141793802380562
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030280519276857376
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014975713565945625
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012037964537739754
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004014152567833662
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016682411078363657Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016772372648119926

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.44881877303123474
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02511652372777462
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001633004518225789Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008103055879473686

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023282144218683243
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.24492047727108002
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018861154094338417Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8551251292228699

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09389498084783554
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9899309873580933
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002040732651948929
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021886571776121855
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002076930832117796
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002216649940237403
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032308774534612894
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008182629011571407
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007819979451596737
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024396877735853195
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.992455244064331
  4%|▍         | 25/584 [02:45<59:30,  6.39s/it]  4%|▍         | 25/584 [02:39<59:31,  6.39s/it]  4%|▍         | 25/584 [02:42<59:28,  6.38s/it]Loss Loss Loss tensor(5.5838, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.7430, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.6670, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.047557029873132706
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07730581611394882Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004988429136574268
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004591258242726326

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003383851144462824
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05402307212352753
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03515952453017235
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007571990601718426
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004128880333155394
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03137680143117905
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.067513607442379
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.8946471755043603e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.6722964346627123e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004655163735151291
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.765517976717092e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.7667679205478635e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.9346413157327333e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.327015868620947e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.637508820655057e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.969927315163659e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012552874977700412
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.690903657930903e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021639680198859423
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.0798703442560509e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.4029322301212233e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002859841624740511
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.59435803652741e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.3548675017082132e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004005720547866076
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.541253161325585e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.8410186132532544e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006489335210062563
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.7901430662022904e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000452960142865777
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.791449125856161e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.1722079913597554e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005413178587332368
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.0360959246754646e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.665443263249472e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00074460927862674
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.693576480960473e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011472302867332473
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009191607823595405
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001239401171915233
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010369006486143917
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003172829980030656
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00030693551525473595
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011447137512732297
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001742859953083098Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00044349030940793455

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00018587814702186733Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025873419363051653Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007501929649151862


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003620883682742715
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011617792770266533
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002417325013084337
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004388037137687206
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016286541940644383
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004819813184440136
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005576362833380699
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023175908718258142
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00044964972767047584Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006863663904368877
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025397087447345257

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007533015683293343
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002947839442640543
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006577910971827805
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007048459257930517
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002849656855687499
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009384683798998594Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008518445305526257
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030149279627949

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009354756213724613
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031489955727010965
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011178096756339073
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00947277620434761
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029799696058034897
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014022313989698887Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009187035262584686

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029514222405850887
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010355493985116482
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001654811087064445
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013839536346495152
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029408445116132498
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03295976296067238
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003918507136404514
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017688365187495947
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019417237490415573
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.43971532583236694
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017904334235936403Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09477649629116058

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9920571446418762
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007753721438348293
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020902343094348907
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23569050431251526
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002228113589808345Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8638832569122314

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002315409015864134
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002277537016198039
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002533965278416872
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003651281353086233
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01559340301901102
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009185312315821648
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.033031538128852844
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9947834610939026
  4%|▍         | 26/584 [02:46<1:00:28,  6.50s/it]  4%|▍         | 26/584 [02:51<1:00:28,  6.50s/it]  4%|▍         | 26/584 [02:49<1:00:27,  6.50s/it]Loss Loss Loss tensor(5.6036, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.9012, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.9369, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004671730566769838
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04676032066345215Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030272649601101875

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002182932570576668
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028990383725613356
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.032766733318567276Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006568376440554857
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017853504046797752

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019599836319684982
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.060841310769319534Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002695088041946292

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1311177331663202e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.5341988728323486e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037123137153685093
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.2136762709124014e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.5239728529413696e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.2242618342716014e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.452080222312361e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.114972282171948e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.514739885053132e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.39383976906538e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.097306479408871e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012860038259532303
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.3108172424836084e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.184942998923361e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016985010006465018
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.109133856720291e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.2196216630400158e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00024321254750248045
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.386375672358554e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00039231323171406984
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.1979738448862918e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.21233125962317e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002772845036815852
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.208478301530704e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.608952829381451e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00033625419018790126
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.947677345830016e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.101205195183866e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004656638775486499
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.84361652424559e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.897104660514742e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005768717965111136
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.139658893924206e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000130756467115134

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002105606021359563
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003152061835862696
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.095195127883926e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011588555062189698
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004660732811316848
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014768260007258505
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016771102091297507
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007738502463325858
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00019372956012375653Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002461956115439534

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011726529337465763
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030221708584576845
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00039343175012618303
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016302010044455528
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003915394190698862
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003803902363870293
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002304743742570281
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004489236511290073
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005428448785096407
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024965370539575815
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005055464804172516
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008198941359296441Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002887552371248603

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004843730479478836
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002779579721391201
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000981291406787932
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0057691652327775955
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029259598813951015
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012571614934131503
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006153712514787912
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030364503618329763
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013857977464795113
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006390860769897699
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002877001417800784
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006037397310137749
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015249500283971429
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00285431370139122
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006464746315032244
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015747783472761512
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028426419012248516
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008702725172042847
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018241445068269968
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003780217142775655
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02733839862048626
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018652306171134114Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.437559574842453

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008511287160217762
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007626729551702738
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018587616505101323
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.060448989272117615
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23203514516353607
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9967560768127441
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018974384292960167
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8664770722389221
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020259215962141752
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027738837525248528
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01668890193104744
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038866985123604536
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026237089186906815
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9978477954864502
  5%|▍         | 27/584 [02:53<1:02:12,  6.70s/it]  5%|▍         | 27/584 [02:58<1:02:11,  6.70s/it]  5%|▍         | 27/584 [02:56<1:02:10,  6.70s/it]Loss Loss Loss tensor(5.7497, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(5.3393, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.0442, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018830034881830215Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04082207381725311

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018617543391883373
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004558560438454151
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010693497955799103Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007790641859173775

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006478311261162162
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011365620885044336
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011938941664993763
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001494087977334857
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.145491847244557e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002079935045912862Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02281622588634491

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.5254723621183075e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.517291583601036e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.4786303381697508e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.620083225541748e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.926265309128212e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.874995743695763e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.999697921448387e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.7931034790308331e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.944968431023881e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.5435683710384183e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001150964162661694

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.115427029522834e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00017251008830498904
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.888414878223557e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.6182459451956674e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00026798577164299786
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.224346063594567e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.4099501640885137e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00020164958550594747
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.0003423994930927e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.0399840650497936e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002520472335163504
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.5705189071013592e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.868578278343193e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.673689803283196e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00037710764445364475


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005231647519394755Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.061525810859166e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.51638804608956e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015757463406771421
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.3366573663661256e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.53977552044671e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014656776329502463
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.028643787838519e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.562259659403935e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025276702363044024
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000209314443054609
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011123786680400372
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003907486330717802
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003404785820748657
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015629820700269192
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005229707341641188
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006008755881339312
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00647131260484457
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00033870365587063134
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000944793107919395
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008012859150767326
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004424469661898911
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009352930821478367
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013597403885796666
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007634982466697693
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008860675618052483
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001987942960113287
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001190593815408647Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010118992999196053

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021182908676564693
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011553396470844746
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016135451151058078
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00243391958065331
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011377941817045212
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019878388848155737
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023236817214637995
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011272509582340717
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002376680262386799
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024235984310507774
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011986641213297844
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026223422028124332Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024869064800441265
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017575174570083618

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020921118557453156Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002359961159527302
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002664803061634302

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026088643819093704
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002351781353354454
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003014238318428397Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030435139313340187

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002338510937988758
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9974017143249512
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003285375190898776
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031006503850221634
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003323131473734975Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3909290134906769

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006841818802058697
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003250590292736888
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21405643224716187
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003600419731810689Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8948196172714233

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005185908172279596
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010304170660674572
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017745058983564377
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012775626964867115
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9994155168533325
  5%|▍         | 28/584 [03:00<1:03:08,  6.81s/it]  5%|▍         | 28/584 [03:06<1:03:08,  6.81s/it]  5%|▍         | 28/584 [03:03<1:03:07,  6.81s/it]Loss Loss Loss tensor(5.5956, device='cuda:0', grad_fn=<NllLossBackward0>)tensor(5.2042, device='cuda:1', grad_fn=<NllLossBackward0>)

tensor(4.9356, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024270500987768173Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004899510648101568
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028528960421681404

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009987603407353163
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00100980163551867
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017221610993146896Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007205273024737835
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002371035050600767

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010498526506125927
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016923010116443038Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02715110220015049

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.229194241313962e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.488928647740977e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002818623324856162
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1857642675749958e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.0410308277641889e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.7703833918858436e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.4907570807263255e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.0435750229808036e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.6853691451833583e-05


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.749872848857194e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.931242988779559e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.893336947337957e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.534279236802831e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.618821433017729e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.546072785975412e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.229185368691105e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.03475120139774e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012695923214778304
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1425022421462927e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.6285037418128923e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00019878389139194041
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.7950811525224708e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.400543962721713e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015295020421035588
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.8806673324434087e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.6350123739102855e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00018444099987391382
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.2434462152887136e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00025328347692266107
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.487898695515469e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.826027674833313e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00032453518360853195

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.896814349805936e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009345287689939141
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00019782240269705653
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.582662899745628e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007928310660645366
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003239522920921445
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.440746412612498e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013392235850915313
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005843433900736272

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002086848486214876
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000938511046115309
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011939175601582974
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029721418395638466
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013905158266425133
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001611293846508488
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004513823427259922
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021235633175820112
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000291532080154866
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005213921424001455
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022206734865903854
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00039240208570845425Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005863773170858622Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00254568038508296


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005851516965776682
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002420759527012706
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000648628338240087
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006803852040320635
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025114610325545073
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001032323925755918Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007575820200145245

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025538622867316008
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007532205432653427
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024304960388690233Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014802198857069016

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007275877054780722
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002435817616060376
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020578906405717134Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007866127416491508

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024274089373648167
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011507520452141762
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002409564796835184Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031998229678720236

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026097698137164116
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.42529162764549255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026030431035906076Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0172012597322464

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0074812849052250385
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04545016586780548
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026992899365723133Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.997717022895813

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23786385357379913
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031233816407620907Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8727302551269531

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033295571338385344
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033840967807918787
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034448562655597925
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037652894388884306
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015737716108560562
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022597743198275566
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017196841537952423
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029356928542256355
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9985495209693909
  5%|▍         | 29/584 [03:07<1:03:01,  6.81s/it]  5%|▍         | 29/584 [03:12<1:03:00,  6.81s/it]  5%|▍         | 29/584 [03:10<1:03:00,  6.81s/it]Loss Loss Loss tensor(5.1728, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(5.3708, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(6.0323, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04184475913643837Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015812160447239876Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004962916020303965


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013760325964540243
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007835592259652913
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010114988312125206Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007995149120688438
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020293204579502344

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01568414643406868
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001193249481730163Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026401225477457047

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.81157029652968e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.224854587344453e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024835860822349787
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.6471243725391105e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.87796624940529e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.4999361610534834e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.905108885897789e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.9102124042547075e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.5997818486066535e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.099807458464056e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.7793219032901106e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.7802095650695264e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.995897223940119e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.406409400166012e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.397102763206931e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.53407584852539e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011537612590473145
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1498493222461548e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00017851483426056802
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.3463915820466354e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.6402800611103885e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002702471683733165
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.964168404811062e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.8663618902792223e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002149486681446433

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.883433964801952e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.2058839022065513e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00025984557578340173

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.3255946366116405e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00034865763154812157
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.614714609691873e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.549006841145456e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004296497208997607
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.507578680408187e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001827809028327465

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012670500436797738
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003065849596168846
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001090319361537695
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.290086457738653e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005558872944675386
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019089459674432874
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.807927563088015e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029895633924752474Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008937816601246595

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004187510348856449Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013358421856537461

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013055140152573586
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007035143673419952
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002078272867947817
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022539214114658535Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007794844917953014

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002127064624801278
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00837740022689104
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00239864201284945
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00032832109718583524
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00816748570650816
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022570574656128883
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005604574107564986
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009845135733485222
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002306255279108882
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008997256518341601Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010846175253391266

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00230364385060966
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010816746391355991
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012546955840662122
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021857554093003273
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010653396137058735
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001873325789347291Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002193266060203314
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011309410445392132

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021893733646720648
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015588550828397274
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021629089023917913
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002877095714211464
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.034740522503852844
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022572926245629787
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.41889289021492004
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023358985781669617
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002307911403477192
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007344284560531378
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06354285031557083
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002647680463269353
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.995514988899231
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23595236241817474
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028580038342624903
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8763669729232788
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028930525295436382
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002973010530695319
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032147569581866264
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023986561223864555
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01818222552537918
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01612527295947075
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024569423869252205
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.998902440071106
  5%|▌         | 30/584 [03:13<1:01:51,  6.70s/it]  5%|▌         | 30/584 [03:19<1:01:50,  6.70s/it]  5%|▌         | 30/584 [03:16<1:01:50,  6.70s/it]Loss Loss Loss tensor(5.3477, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.2668, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(5.3293, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002546782372519374Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022054491564631462
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004045888315886259

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006551972473971546
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00029485413688234985
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017445760313421488Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007557509816251695

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00024230085546150804
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016946127288974822
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007341431919485331
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.174542745109648e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012367937713861465

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.125677156072925e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.0430595643338165e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.3792596241255524e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.4314310798654333e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.810710265701346e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.904192559886724e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.116042866073258e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.1651327238651e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.423943652109301e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.4318865396489855e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.0559492693573702e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.4268158565755584e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.9418188458075747e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.5013110896688886e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.920482074841857e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.9087526854709722e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.107036602363223e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.3438403786713025e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.168434315943159e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.14501902621123e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.444209480425343e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.7388949749583844e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.96431026578648e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.444369500968605e-05


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001123771580751054
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.1206973188964184e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.2820179108530283e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00018193137657362968
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.7054728232324123e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.0587622455204837e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003906612691935152
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.586087404983118e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.3430289072857704e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006774530047550797

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.610650598304346e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001220431295223534
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.990921373362653e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016222592967096716

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018593629356473684
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002766941033769399
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.806465247180313e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002597615821287036

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004993699258193374
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003360278671607375
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.2076112953946e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007869782275520265
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004428523126989603
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013335369294509292
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011653901310637593
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004953740164637566
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002514635561965406
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017764335498213768
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004746598191559315
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004447156097739935
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005495279096066952
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017897350480780005
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00067821831908077
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006326979957520962
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00197385111823678
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000967534608207643Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0060569210909307
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018310160376131535

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006422416772693396
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018270941218361259
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012464943574741483
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0070230187848210335
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017770463600754738
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015257160412147641
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00828888826072216
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016694377409294248
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016457474557682872Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007079639937728643
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016672848723828793

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008681927807629108
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016605331329628825
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016561379889026284
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012573436833918095
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023203503806144
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001877403468824923Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9994354844093323
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3692919611930847

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006382869090884924
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00209544925019145
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20461924374103546
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020036338828504086Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9063706994056702

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002096098382025957
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022386338096112013
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003773307427763939
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003307361388579011
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005773037672042847
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00574921490624547
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9999332427978516
  5%|▌         | 31/584 [03:19<1:01:01,  6.62s/it]  5%|▌         | 31/584 [03:25<1:01:01,  6.62s/it]  5%|▌         | 31/584 [03:23<1:01:01,  6.62s/it]Loss Loss Loss tensor(5.1546, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(5.6637, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.4500, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003857092931866646
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027634594589471817
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003698210930451751
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007543052779510617
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00105956825427711
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004728218074887991
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030555359553545713
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01420954242348671
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032790133263915777Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006244935095310211

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.6094363053962297e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.5869838939106558e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000406598555855453
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.689350359716627e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.1123218983993866e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008047299925237894Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.097495214708033e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.3197380212659482e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.6696623106327024e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.84037343539967e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.8134947822545655e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.364277063155896e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.2593179639661685e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.529866022399801e-07Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.708638698502909e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.946337164961733e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.792016731400508e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.3979198456581798e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.190665590111166e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.0937105798802804e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.145637159235775e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.1038165414211107e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.3730901628150605e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.719194011064246e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.854492256825324e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.922659288946306e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001141508764703758

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.838964403257705e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00017184577882289886
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.389145371736959e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.967302761040628e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00025154888862743974
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016676085942890495
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.0575805390544701e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006906163762323558

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002834330953191966
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008232019026763737
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005084851873107255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.602351949259173e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014152525691315532
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007892570574767888
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.7858845239970833e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021955138072371483
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011691072722896934
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.2327383703668602e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029803463257849216
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001761973020620644
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.792504139710218e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004076769109815359
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017670532688498497

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019115194445475936Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005114266183227301

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.9396821598056704e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017498809611424804
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005951565224677324
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001162115004262887
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017050161259248853
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005616965238004923
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016164649277925491
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006084210705012083
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00019270932534709573
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015094965929165483
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0069431280717253685
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003264257684350014
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00150231400039047
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006737997289747
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015034213429316878
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005188212380744517Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007665742188692093

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002504636999219656
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00815237034112215
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007144943810999393Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.37181800603866577
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009493531659245491

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006387615110725164
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014759373851120472
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009454110404476523
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20461559295654297
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010113007389008999
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011321866186335683Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9053127765655518

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029812350869178772
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9987517595291138
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001245173392817378
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001225650543347001
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013350480003282428
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001460660365410149
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013739864807575941
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015609724214300513
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016600782983005047
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008302184753119946
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0053944955579936504
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030446569435298443
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007881075143814087
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9998897910118103
  5%|▌         | 32/584 [03:33<1:04:32,  7.01s/it]  5%|▌         | 32/584 [03:27<1:04:32,  7.02s/it]  5%|▌         | 32/584 [03:31<1:04:32,  7.02s/it]Loss Loss Loss tensor(5.5171, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.8426, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(5.5883, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.034362245351076126
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0047865742817521095Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008578852284699678

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004198980052024126
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021047070622444153
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012378194369375706Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00033861727570183575

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004950836766511202
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007117678178474307
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002944298612419516
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.429935067193583e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022296518087387085
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.341972983937012e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005344499368220568
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.76768911741965e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.97653805318987e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.407000902683649e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.424450526130386e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.025992540045991e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.7711083728499943e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.311118290293962e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.712391394903534e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010199112875852734
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.1503748232353246e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001553186884848401
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.5969497983169276e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021270626166369766Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.0604812713572755e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00020175290410406888
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.112205144541804e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.730882993608247e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00023857600172050297
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.9196098593238275e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.4065452887734864e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003983511123806238
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.0839766218850855e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.6964944481733255e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005425963317975402
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.4565894161933102e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011264901841059327
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.70657435269095e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.772726682247594e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013139728689566255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.067349436809309e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.377322562097106e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021350043825805187
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.825086580240168e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.7728579374961555e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003241509897634387
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.539317786926404e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.417745993938297e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004084429237991571
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001121611931012012Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001938243949552998

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005071279127150774
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00032174313673749566
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022115837782621384
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006554494146257639
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005630164523608983
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002876616781577468
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007130013313144445
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008456637151539326
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004589478194247931
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006554547697305679
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012317296350374818
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007107984274625778Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0071603707037866116

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017878778744488955
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007859236560761929
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009229117422364652
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001785851432941854
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007718740031123161
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011465225834399462
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001882518525235355
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00804191268980503
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016913446597754955Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008927826769649982

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013956549810245633
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012466039508581161
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016017864691093564
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014394057216122746
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01142740435898304
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001466086832806468
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014054819475859404
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016457153484225273
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013612931361421943
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021689752116799355
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015236807521432638
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013414801796898246
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9986222982406616
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015451384242624044
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013511573197320104
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001561976969242096
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029683103784918785
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015499636065214872
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.37726500630378723
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001758586848154664Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006442546378821135

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2069656401872635
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006293156649917364Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9023551344871521

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037427342031151056
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0099642314016819
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006296256091445684
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9998803734779358
  6%|▌         | 33/584 [03:34<1:03:01,  6.86s/it]  6%|▌         | 33/584 [03:40<1:03:02,  6.86s/it]  6%|▌         | 33/584 [03:37<1:03:01,  6.86s/it]Loss Loss Loss tensor(6.7848, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(5.5567, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.1439, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002004186622798443Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022319257259368896
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0057135759852826595

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006204973324202001
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002671173424459994
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015615989686921239Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006153872818686068

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00031996556208468974
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001267608837224543
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012353595229797065
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.291183818670106e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018343431875109673
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.727962393895723e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.512123945867643e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.913052293886722e-07

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.215029199869605e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.706228757342615e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.1080255641645635e-07Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.433673767489381e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.4820709566265577e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.5385725419037044e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.629593940488121e-07Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.335075123482966e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.9209570382372476e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.8185120249399915e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.85102133199689e-07Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.7753278118325397e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.782256150472676e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.08767482440453e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.4508666481560795e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1563781299628317e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.767295831697993e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.5919806173769757e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.2638021164311795e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.15318601578474e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.1038493287051097e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012523765326477587
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.393874067114666e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.102633127127774e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021047766495030373
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.323097295535263e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.585399387404323e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000428985949838534
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.041828090819763e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012126332148909569
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007465957896783948
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.2624943337868899e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002840497181750834

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012449055211618543
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004818130983039737
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018784354906529188
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.9081686332356185e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008464750135317445
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025736764073371887
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.645363904070109e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012620381312444806
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034129272680729628
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.133215356385335e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018441971624270082
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003986429888755083

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026485049165785313
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00470831198617816
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012426132161635906
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002653836039826274
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0042533231899142265
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022936688037589192Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002780660055577755
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004542027600109577

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002486255718395114Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005079368595033884

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00039259952609427273
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023307744413614273
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005168909672647715
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006090305978432298
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002086093183606863
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004971104674041271
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008372263400815427Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001948291901499033
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005518087651580572

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019061642233282328
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007589489687234163
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001068510115146637
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019255010411143303Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014740864746272564

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011938897660002112
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005166566930711269
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01127071026712656
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5710673332214355
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02144291251897812Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001299633993767202

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9992141127586365
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009759066626429558
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012673554010689259Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3115139603614807

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7591407895088196
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013245914597064257
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013929380802437663
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014121475396677852
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013286704197525978
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001520749880000949
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035842289216816425
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007622120901942253
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008128228597342968
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007973687723279
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9998878836631775
  6%|▌         | 34/584 [03:40<1:00:40,  6.62s/it]  6%|▌         | 34/584 [03:46<1:00:40,  6.62s/it]  6%|▌         | 34/584 [03:43<1:00:40,  6.62s/it]Loss Loss Loss tensor(5.0959, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.4873, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(5.1094, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004274006467312574Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03695107251405716Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004647753667086363


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005656884168274701
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00019562436500564218
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013195091160014272Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026443081442266703
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008295329753309488

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014111052267253399
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003239006910007447
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009407089091837406
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.9498149817518424e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010194857604801655Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.492485004448099e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.181604703670018e-07


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.195006219262723e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.315596922628174e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1815512834800757e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.3790889170195442e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.8818682292476296e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.851949928612157e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.7939981262315996e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.887862476403825e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.2163976634838036e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.4863990044395905e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.9040353183518164e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.7602017123863334e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.240521649189759e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.708601798280142e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.8704939722956624e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.2731398783216719e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.34103998891078e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.052954864164349e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.6882266208995134e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001063371091731824
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.820500625006389e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.5750045097083785e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.567092638462782e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.4934833315201104e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016193758347071707
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.3884035979572218e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002508640172891319Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010118517093360424


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003752563789021224Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00023431844601873308

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.6223350030486472e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00039290013955906034
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001241358113475144
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.5535586246405728e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006793815991841257
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013268089387565851
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.581897519528866e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009925425983965397
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002142676617950201
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.991719030542299e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014383253874257207
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032336281146854162
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020213990937918425
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015895802062004805
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004078149329870939
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020294608548283577
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002792486047837883Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005529181566089392

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020984632428735495
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007148704491555691
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018519636942073703
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00044367386726662517
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007674814201891422
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017136608948931098
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007034433539956808Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001495606848038733

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006840808782726526
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007797623053193092Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013995832996442914

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008728543180041015
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008574905805289745
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001366328913718462
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011470392346382141
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008615270256996155
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013848459348082542
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008577873930335045
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013930650893598795
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004305732902139425
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009569765068590641
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.427127867937088
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014102405402809381
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013867711648344994
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0072589656338095665
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001359885442070663
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014812435023486614
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23254182934761047
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014699570601806045Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01866295002400875
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8735917806625366

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.035387489944696426
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015733273467049003Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9979614019393921

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001512122922576964
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015552934492006898
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017192695522680879
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01082523912191391
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005350126419216394
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010699247010052204
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00864692497998476
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9998112320899963
  6%|▌         | 35/584 [03:52<1:00:00,  6.56s/it]  6%|▌         | 35/584 [03:46<1:00:00,  6.56s/it]  6%|▌         | 35/584 [03:50<1:00:00,  6.56s/it]Loss Loss Loss tensor(5.3484, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(5.0397, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(5.0815, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035978220403194427
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04557192698121071
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00945980567485094Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00030568178044632077

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005683839553967118
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001816664240323007
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037097730673849583Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00620240718126297

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029094627127051353
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007241097628138959Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017999760806560516

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.3356660019780975e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.126621082737984e-07

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017763208597898483
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.4600425604148768e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.2637862027986557e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.4266870493884198e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.3444799808203243e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.1479331887094304e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.655289674497908e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.695356907788664e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.8071974611521e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001388825330650434
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.20199659554055e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.663183062803e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001781462924554944

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.697610948933288e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002772038278635591
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.635701877006795e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.4763430954189971e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003976462467107922
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.9238210370531306e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003494660195428878

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.4259646377468016e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00040317364619113505
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.3286691430257633e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.1117297364980914e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006405170424841344

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.263702819822356e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008215900743380189
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.056667603435926e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.415657844627276e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002104030456393957

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017755223670974374
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010961263615172356
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.599321229965426e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002666427753865719
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00023822448565624654
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.887449879082851e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003814373631030321

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000381153920898214
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004707522690296173
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.781383854104206e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006369663751684129
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007859808392822742
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011500433902256191
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006993463728576899
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009028746862895787
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014871654275339097
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008602616377174854
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012860508868470788
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00026839933707378805Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007698885165154934

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017564041772857308
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008542030118405819
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003402132133487612Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017568020848557353
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009231801144778728

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008874465711414814
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018171720439568162
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005062968120910227
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009526836685836315
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001598389120772481
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007347211358137429Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011115814559161663

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014809120912104845
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016454290598630905
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009061169694177806
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012743871193379164
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.033718422055244446
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013022455386817455
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012012795777991414
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01756232976913452
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012943358160555363
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0800536721944809
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001174061675556004
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9943272471427917
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014433662872761488Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011946795275434852

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003972059581428766Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013848359230905771

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.36213621497154236
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015581233892589808
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006140951532870531
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015220990171656013
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1951058954000473
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9109617471694946
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014630502555519342
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015033056261017919
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016432387055829167
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013810333795845509
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010564848780632019
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004591143690049648
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019026700407266617
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9995931386947632
  6%|▌         | 36/584 [03:51<55:41,  6.10s/it]    6%|▌         | 36/584 [03:57<55:42,  6.10s/it]    6%|▌         | 36/584 [03:55<55:42,  6.10s/it]  Loss Loss Loss tensor(5.8236, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(5.8520, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(5.9726, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006919963750988245Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03239700570702553
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0051965247839689255

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007580487290397286
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002543534792494029
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002083759754896164Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018906668992713094

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007533205207437277
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006997818127274513
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003621406212914735
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.115613243513508e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02449364960193634
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010254618246108294Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.2867764780821744e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.853133527329192e-07

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.0655517144186888e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.3283543012221344e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.6841231374419294e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.985923290703795e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.144196645938791e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.497340574336704e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.1750469133839943e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.685158925596625e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.4187570387730375e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.287994215701474e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.532083640806377e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.686907676747069e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.149178145482438e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001538866345072165

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.4084461327001918e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021335500059649348
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.3636627954838332e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.8072967577609234e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00019989002612419426
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.989042903005611e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.3023825633572415e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00024246081011369824
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.9281596400542185e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.361418202985078e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00037571575376205146

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.831109203631058e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005346153629943728
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.3831725381314754e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001210921400343068
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009131298866122961
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.890616375836544e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000269557349383831
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012004313757643104
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00044092736789025366
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.957002187846228e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00198407843708992

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007427167729474604
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026979707181453705
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010557331843301654Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003521123668178916
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001179877799586393

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015125474892556667
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005159847903996706
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016032432904466987Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002062247134745121
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00501119764521718

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020690944511443377Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005375645123422146

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002760913921520114
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002142665907740593Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005011874716728926

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005735969636589289Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018724908586591482
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00039483141154050827

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0061921305023133755
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017453506588935852
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006471035303547978
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006188259460031986
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014958175597712398
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008736388990655541
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007244108244776726
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014177109114825726
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008609584532678127
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011537661775946617Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001396220293827355

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013401168398559093
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014314457075670362
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013920398196205497
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01766098663210869
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005026905331760645
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015991197898983955
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015461823204532266Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.45650729537010193

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03975643590092659
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007722354959696531
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015708849532529712
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9980983138084412
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.24470627307891846
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015257977647706866
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8549708724021912
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016787034692242742
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017312437994405627
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016635231440886855
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018696447368711233
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002257363172248006
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00708662997931242
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007886861450970173
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008370308205485344
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014359323307871819
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9997643232345581
  6%|▋         | 37/584 [03:56<51:14,  5.62s/it]  6%|▋         | 37/584 [04:02<51:14,  5.62s/it]  6%|▋         | 37/584 [03:59<51:14,  5.62s/it]Loss Loss Loss tensor(5.3241, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(5.0923, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(5.7022, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00491331284865737
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019492870196700096
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000279434461845085
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004663384170271456
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005062363110482693Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001413873746059835Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008949162438511848


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038567264564335346
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01415729708969593
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002908527385443449
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.661646249180194e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.4736722770721826e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00043084879871457815
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.558744421956362e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.940554726497794e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009926480706781149
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.83580923982663e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.3029198271397036e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.2356371371424757e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.250616249621089e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.1312912394932937e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.0603773009497672e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.3516835224436363e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.410993369674543e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.712780587899033e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.214529093995225e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.973444341274444e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.011153941974044e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.0308760465704836e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.037549959117314e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.593959940597415e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.400369183102157e-05


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.760476051364094e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.8850665583158843e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.323499408405041e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.787461410975084e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.051232488360256e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014938671665731817
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.991206985025201e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.539760215673596e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021988201478961855
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011957849346799776
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.4913620361767244e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005706754163838923
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00026846167747862637
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007265667081810534
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.1721365556004457e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00043540855403989553

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011251154355704784
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007219294202513993
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.3774700821377337e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001559707336127758
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001012794324196875
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.568053216440603e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020162397995591164
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014394475147128105
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.324784044409171e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028580049984157085

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001928910263814032
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032392884604632854
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010563643445493653Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019441659096628428

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003624680684879422
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002018898958340287
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021052085503470153
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033126508351415396
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017446409910917282
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003808851819485426
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003615805762819946Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016289445338770747

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004133961163461208Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001386404619552195

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005514484364539385
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004135672003030777Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013191464822739363

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007882180507294834
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004613384138792753
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013019110774621367
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001028707716614008
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005461657419800758
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013391789980232716
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008077399805188179
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004844485316425562
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012877020053565502
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011927468702197075Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.42380157113075256

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010961228050291538
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00718713877722621
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014988624025136232
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03001643344759941
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.22614321112632751
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015919868601486087
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9991106986999512
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8768821954727173
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014651184901595116
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017461756942793727
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017705855425447226
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001681476947851479
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001797468401491642
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002148759551346302
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014157121069729328
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009789659641683102
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011700852774083614
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018264470621943474
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9995850324630737
  7%|▋         | 38/584 [04:02<53:38,  5.90s/it]  7%|▋         | 38/584 [04:08<53:38,  5.89s/it]  7%|▋         | 38/584 [04:06<53:38,  5.90s/it]Loss Loss Loss tensor(5.2778, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(5.4764, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.8700, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004134633112698793Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030812950804829597
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035087994765490294

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00057337706675753
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022622066899202764
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013612000038847327Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015234961174428463

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004384935018606484
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005609673913568258
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00025041360640898347
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.563743914332008e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01307167299091816
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007631871267221868Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.473493042198243e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.0787168131828366e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.990287602093304e-07Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.5038414858281612e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.339058700177702e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.1591167751466855e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.208290768772713e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.94515591324307e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1907185353265959e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.885156886302866e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.9276812963653356e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.972469135580468e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.158614946296439e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.083908495682408e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.106132564629661e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013255979865789413

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.75825288251508e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011006068234564736

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.787689133285312e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015606720990035683Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.641050382924732e-06


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002537953550927341
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.288093062612461e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.129843990900554e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00040434033144265413
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.7443884644308127e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.6025423974497244e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009511057869531214
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.8566904802573845e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012325503630563617
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.138945173006505e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.3172829969553277e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019522549118846655
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011230060772504658
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.6619198251864873e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002687766682356596
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00024922663578763604
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.694255792652257e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032400276977568865
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000397695490391925
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004334994591772556
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.600235792575404e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006452833767980337
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0047546448186039925
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010764106991700828Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008918014937080443

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005674308631569147
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012493608519434929
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021473733067978173
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005331476218998432
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016459586331620812
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003440348373260349Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005920953117311001
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016706737224012613

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006711628288030624
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017385265091434121
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005353249725885689
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006716430187225342
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001490021706558764
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006600483320653439
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013957974733784795Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007452001445926726

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007945423945784569
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011817466001957655
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009308418375439942Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010163937695324421

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011258093873038888
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009420580230653286
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012053746031597257
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011105482699349523
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01117524690926075
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012906589545309544Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011423964751884341
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01274070143699646

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9990886449813843
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004305433016270399
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014182613231241703
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3622399568557739
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013542724773287773
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0061981105245649815
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18976424634456635
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015029758214950562
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9124201536178589
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015856008976697922
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001547369989566505
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00153088360093534
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017529973993077874
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002278654370456934
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032971662003546953
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007056350354105234
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004561965819448233
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.999936044216156
  7%|▋         | 39/584 [04:08<52:54,  5.83s/it]  7%|▋         | 39/584 [04:14<52:54,  5.83s/it]  7%|▋         | 39/584 [04:12<52:54,  5.83s/it]Loss Loss Loss tensor(5.1722, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.7139, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.2367, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04080790653824806
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00830218754708767
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007551276357844472
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035375060979276896
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005145673640072346Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031827117782086134

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002791623119264841
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006594634032808244Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01164316013455391

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.1264451030874625e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008109051268547773
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.163443453668151e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010695574805140495
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020670637022703886
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.5067340427776799e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.587914818581339e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.843679436016828e-07Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.999133382923901e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.591747935795865e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.362515417393297e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.630992414902721e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.0537817161093699e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.3999581976095214e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.2495421490020817e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.7716257616484654e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.175594120984897e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014981228741817176
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.7227757729851874e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.276376673966297e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011891798203578219
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.355582288757432e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.442779638542561e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00020017733913846314
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.888486263458617e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003537113661877811
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.986940545379184e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.2345124559942633e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004963953397236764
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.787629480531905e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00195930153131485
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.694722959655337e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016258291434496641
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.8887207008665428e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.6287178116035648e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024189716205000877
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.303190457401797e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.3249878470087424e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003327675862237811

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001157375518232584
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004351196810603142
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00025509411352686584
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007466654293239117Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.321242133504711e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00040213324245996773Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0066910372115671635

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.5955008873716e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0070643057115375996Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001715665275696665
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006433238158933818

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006596858147531748
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008837985224090517
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003463304601609707
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007746349088847637
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012304302072152495
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005781720974482596Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007687057834118605

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016082827933132648
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0076270694844424725
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008208164945244789
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016540605574846268
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007985713891685009
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012101721949875355Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017338033067062497
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009501924738287926

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019394682720303535
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014787750551477075
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015486940974369645
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.043080925941467285
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013935116585344076
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002187158213928342Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014383542351424694

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011798040941357613
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07151905447244644
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021757083013653755Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011232409160584211

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9950204491615295
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011066747829318047
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002166035119444132
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011474830098450184
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021790401078760624
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004465630743652582
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024460298009216785
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.33612167835235596
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021447811741381884
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005834819283336401
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002189815044403076Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1748892068862915

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002268827287480235
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9253290891647339
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028085329104214907
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030933383852243423
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024182436987757683
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007638349197804928
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02834751270711422
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9987209439277649
  7%|▋         | 40/584 [04:14<53:18,  5.88s/it]  7%|▋         | 40/584 [04:20<53:19,  5.88s/it]  7%|▋         | 40/584 [04:18<53:18,  5.88s/it]Loss Loss Loss tensor(4.6190, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(5.2777, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.0849, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00364120420999825
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019137974828481674
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00612896541133523Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005240336759015918
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007760458975099027

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000913637166377157
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026302251499146223Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016484371153637767
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017548153176903725

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.414366341938148e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004145977145526558Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0061246370896697044

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.372599609174358e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.569381306078867e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012766752624884248
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.948006673861528e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.5424175217049196e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.148143706421251e-07Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.177439116872847e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.567294586697244e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.73395292222267e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.316158876667032e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.4702120552101405e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.138104875688441e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.324485522985924e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.271420726174256e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.93118716601748e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.2313965271459892e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.544865755131468e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.6796909625991248e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.5959658412612043e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001062437440850772
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.14728443097556e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.972862593102036e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.327207615366206e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.484956323518418e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.805834451981355e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011123126751044765

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.389906386379153e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00019947337568737566Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001333453255938366

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.936740409291815e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00025730347260832787
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000290180672891438
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.636350654938724e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004586575669236481
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008057617233134806

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007307938067242503
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007408291567116976
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.9115895813447423e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010058474726974964
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001195433083921671
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.903832475771196e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013959809439256787
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016795623814687133
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.203312270576134e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018187272362411022
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002020277315750718
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010819023009389639
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018539513694122434
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002802858129143715
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00020534059149213135
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019426157232373953
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029536818619817495
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00031784342718310654Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016432184493169188
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003407844342291355

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015450160717591643
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030508670024573803
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004960588994435966
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013007372617721558
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033299054484814405
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007235862431116402
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012334384955465794
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034752970095723867
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008644177578389645Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012032556114718318

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003614514833316207
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001251343172043562
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001127027440816164Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037354601081460714

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0049884868785738945
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0041753677651286125
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012129397364333272Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.39033544063568115
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006486246827989817

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006970553193241358Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008916174992918968

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001258878968656063
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20559418201446533
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005795465316623449
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8971886038780212
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011542082065716386Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016542606055736542

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9995240569114685
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012857712572440505
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012472275411710143
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012370108161121607
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012972638942301273
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013804089976474643
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007160183507949114
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0054755015298724174
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036035063676536083
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00776284234598279
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9998917579650879
  7%|▋         | 41/584 [04:26<54:35,  6.03s/it]  7%|▋         | 41/584 [04:21<54:36,  6.03s/it]  7%|▋         | 41/584 [04:24<54:36,  6.03s/it]Loss Loss Loss tensor(5.1235, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.8094, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.5351, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03572729974985123
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006749142776243389
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006435554474592209Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00354989105835557

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028876662254333496
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003310707106720656
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002709269057959318
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010533357970416546
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008740096818655729
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004768652142956853
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.135495252441615e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01706850528717041
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014249413507059216
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.2377558959997259e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.263632374408189e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.37059412029339e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.056394921761239e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.106849804789817e-07

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.5795434087049216e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.9825115487037692e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.4757791859665303e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.31164075457491e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.986743003129959e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.4575581392127788e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012812207569368184
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.0585390454216395e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00017902303079608828
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.920880878169555e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.0487888125207974e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016798345313873142
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1586469554458745e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.111484824738e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002098243567161262

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.4840002222626936e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003464490582700819
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.307409527536947e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.9956709365942515e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00047101223026402295
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.3459615729516372e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.1925184885039926e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013316975673660636
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.687932909699157e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.6580621124594472e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013388324296101928

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011964227451244369Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002088799374178052

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.600209311116487e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002855791011825204
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002597218262962997
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.897906935890205e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00041731924284249544
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036984640173614025

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004788510967046022
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006702555110678077
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.909428025712259e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005124976392835379
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009333381312899292
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.537260873708874e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006310441065579653
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00129893037956208
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005631403531879187
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012560766481328756
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017057150835171342
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006112237926572561
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00024313312314916402
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017302733613178134
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006186364218592644
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003622150979936123
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006453726906329393
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018206745153293014
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007302847690880299
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005636478308588266Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015320256352424622

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008362356573343277
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014373068697750568
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007950064027681947Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012543195858597755

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012079632142558694
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011338184587657452
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010422467021271586Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001137685845606029

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020483912900090218
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011015081545338035
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001201131148263812
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03902893513441086
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011548371985554695
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013643193524330854
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9979894757270813
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004708375781774521
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015367799205705523
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3642841577529907
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014164376771077514
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006724106147885323
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014835777692496777
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19695381820201874
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014034813502803445
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9100065231323242
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014781871577724814
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015175265725702047
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017838815692812204
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032252580858767033
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030962920282036066
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010717666707932949
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012600800022482872
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9998165965080261
  7%|▋         | 42/584 [04:28<57:15,  6.34s/it]  7%|▋         | 42/584 [04:33<57:16,  6.34s/it]  7%|▋         | 42/584 [04:31<57:15,  6.34s/it]Loss Loss Loss tensor(4.9043, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(5.9374, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.5729, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003305182559415698Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03398716822266579

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001152654062025249
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0040237195789813995
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016347818309441209Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000560654909349978
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001853667781688273

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005948888137936592
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00023118819808587432
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0071138646453619
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015457846224308014
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.86412636746536e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007230752962641418
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.687824457505485e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.88278066465864e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.426958296084194e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.234892223095812e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.4288675629359204e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.472699389334593e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.0351182683953084e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.3196405461712857e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.392703001736663e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.340847688879876e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.2429214823205257e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.378732046461664e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.185438461310696e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.713988346338738e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.084256503731012e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.573860446223989e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.620114057412138e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010328493954148144

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1482403351692483e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.996086737373844e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.459709882416064e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001428096875315532
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.5012390576885082e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002623597392812371
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.0662688509910367e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.0706745999632403e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003909588267561048
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.396722604520619e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.524944764241809e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010620224056765437
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.227130117826164e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.6875890651135705e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012958990409970284

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000130629661725834
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020817548502236605
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.4616494556539692e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00028680762625299394
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027377468068152666
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.674082447309047e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036680763587355614
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00047009901027195156

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004815458320081234
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007635782239958644
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.824508065823466e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005250538233667612
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010746043408289552
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015749306476209313
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006350573152303696
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014939846005290747
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0056549180299043655
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00026095021166838706
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001973493490368128
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005776934791356325
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004254055384080857
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001986886840313673
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006226151250302792
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005696584703400731
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002090027555823326
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006245221942663193
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007694241357967257
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017548913601785898
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007746363524347544
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008940760162658989
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0080869160592556
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001643001800402999
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001059129135683179
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011296773329377174
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013806682545691729
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011266941437497735
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010040882974863052
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012897264678031206
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010692427167668939
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016859116032719612
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012429595226421952
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010674988152459264
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026519345119595528
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013037774479016662
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9985913634300232
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005406077019870281
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010726526379585266
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.41260281205177307
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010472547728568316
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007767237722873688
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011009512236341834
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.22668275237083435
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001215546508319676Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8820427656173706

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022716568782925606
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001908687292598188
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00649208202958107
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006491520442068577
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9999403953552246
  7%|▋         | 43/584 [04:35<1:01:11,  6.79s/it]  7%|▋         | 43/584 [04:41<1:01:11,  6.79s/it]  7%|▋         | 43/584 [04:39<1:01:11,  6.79s/it]Loss Loss Loss tensor(4.9056, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.1378, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(5.5879, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005439969711005688Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022955594584345818
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004563422873616219

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018830166663974524
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000641523627564311
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002987259766086936Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002162833698093891
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014172476949170232

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0059977867640554905
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004163537814747542Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02470543049275875

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.977765001967782e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.369287118308421e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009142011404037476
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.76983358466532e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1356307823007228e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.468971941510972e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.673635961196851e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.0307240902184276e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.6120886104763485e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.4111619697796414e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.5605969565513078e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.8502486606594175e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.00376222084742e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.065407796995714e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.545799816289218e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.52122991293436e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.689610305940732e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.58751463459339e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.192357664578594e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014308917161542922
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.023711203946732e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013020919868722558
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.6677886125980876e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.14040959085105e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016920616326387972
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.1290353692602366e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002576888364274055
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1614130926318467e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.383662498090416e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003740319807548076
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014582784206140786
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.2621512471232563e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007730430224910378
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00031345459865406156
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.13608325086534e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008620418375357985
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005166410119272768
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001409568591043353Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.4666834835661575e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008448362350463867

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019201238173991442
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012003654846921563
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.383466875879094e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024295682087540627
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.41055773687549e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016668307362124324

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033854367211461067
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022263270802795887
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010612504411255941
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003504622494801879
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022163507528603077
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001773447438608855
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004060088656842709
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002334832912310958
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037543235812336206
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00026121814153157175Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019631616305559874

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003994006663560867
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001836376846767962
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00042351006413809955Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00408411119133234

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015449492493644357
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003985915798693895
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014312779530882835
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005749735282734036
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004322741646319628
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013777733547613025
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007364214397966862
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004711981862783432
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014419006183743477
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009581558406352997
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007022560108453035
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006029887590557337
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010143937543034554Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013428169302642345
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4514223337173462

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007171334698796272
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010712698567658663
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008632979355752468
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03168434277176857
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9989926815032959
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010094597237184644Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.25228410959243774

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8554468750953674
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010764079634100199
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010370344389230013
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009674495086073875
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010024422081187367
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001116477302275598
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008306982927024364
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006444756407290697
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028944655787199736
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010536570101976395
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9998598694801331
  8%|▊         | 44/584 [04:42<59:26,  6.60s/it]    8%|▊         | 44/584 [04:47<59:25,  6.60s/it]    8%|▊         | 44/584 [04:45<59:26,  6.60s/it]  Loss Loss Loss tensor(4.6308, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.7816, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.6961, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03242983669042587
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006109674577601254
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0067535084672272205Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032745148055255413

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016146370908245444
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002913676726166159
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002806097501888871Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004239511676132679

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005179251311346889
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.4214764279313385e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004453382280189544
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1167930097144563e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01616336964070797
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.798439476871863e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.0935503926011734e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007049532141536474Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.395122452180658e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.3580989111214876e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.258254870772362e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.5450881392098381e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.3192959613661515e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.715624087722972e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.2325903046294115e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011953624925808981
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.832040991052054e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016259876429103315
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.597568022290943e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016914874140638858
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.559914032142842e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.287252745096339e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00020318478345870972
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.887152605690062e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.0500060852791648e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003380806010682136

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00046340623521246016
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.3545974979933817e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.4979082152422052e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009262761450372636
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.801911639631726e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.1760350136901252e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012009396450594068
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.8363319870550185e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.104062099941075e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018907602643594146

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.8352794439997524e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026258870493620634
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.780018545920029e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010242050484521315

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033479472622275352
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002212028339272365
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.488321378128603e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003921681083738804

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003671332378871739
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004614340141415596
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.856667798478156e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006023846217431128

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0055072554387152195
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008555300300940871
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001370219688396901
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005158120300620794
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011807687114924192
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00019116020121145993
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00555943138897419
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001576519338414073
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005638548173010349Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00035858788760378957Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015639611519873142


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005639367736876011
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016488295514136553
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005271272384561598
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005727049428969622
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013878594618290663
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007978735957294703Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006889748852699995

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001298723742365837
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010769440792500973
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011338697513565421
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010947135742753744
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012112411670386791
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014698123559355736Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010105883702635765

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015710074454545975
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009691372397355735Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025456484407186508

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017365326639264822
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9987373352050781
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010146360145881772
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019799419678747654
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004301086533814669
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021601603366434574
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.32676562666893005
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020294010173529387
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0062844594940543175
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021540913730859756
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18442441523075104
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9267488121986389
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021043296437710524
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021172936540097
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020799818448722363
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026869510766118765
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002922820160165429
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006645791698247194
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010664820671081543
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010930264368653297
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9998071193695068
  8%|▊         | 45/584 [04:47<57:20,  6.38s/it]  8%|▊         | 45/584 [04:53<57:20,  6.38s/it]  8%|▊         | 45/584 [04:51<57:20,  6.38s/it]Loss Loss Loss tensor(4.8063, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(5.1719, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.6958, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022437427192926407
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005345781333744526
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006328667048364878Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005594138638116419
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008522575371898711

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009863836457952857Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003214707365259528
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003831109788734466

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00032172302599065006Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030464166775345802

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017514385282993317
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.171413709424087e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.7589210794285464e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006856993422843516Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.522295396076515e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.377522024398786e-07

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.0416061741125304e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.38156233587506e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.318540626016329e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.636967863305472e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.2811018425272778e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.6571585774727282e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.9616137908305973e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.808175617654342e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.7218450213695178e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.8734466215828434e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.597610081371386e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.83646067045629e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1844606888189446e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.563363290799316e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.892914386000484e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.4992732758400962e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.521719792042859e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.86296111275442e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.0402239897521213e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.2835575944336597e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011206965427845716
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.211602597730234e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00018943783652503043
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.673780444543809e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.6907970095635392e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002984095481224358
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011814525350928307
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.5092431062366813e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005465016001835465

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002583062741905451
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008116289391182363
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.090079528396018e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00043719366658478975
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013030808186158538
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.185475311009213e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007248746114782989
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017573790391907096
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010400657774880528
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.289928857469931e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002356624696403742
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014430575538426638
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001451310090487823
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032552736811339855
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001956153428182006
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00025778874987736344Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037173195742070675
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019213521154597402

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0039171380922198296Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020202805753797293

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00043465642374940217
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003898368217051029
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017093607457354665
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00426895497366786
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00159618747420609Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006674425676465034

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00462847575545311
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001347876968793571
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009063052712008357
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004630000330507755
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012438517296686769
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012459997087717056
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001187846064567566Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004877896513789892

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016187502769753337Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001242839964106679
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0058894711546599865

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005242949351668358Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00796057004481554

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018371326150372624
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4006042182445526
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008180199190974236
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018093662802129984Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00785860512405634

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013991154730319977
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23075270652770996
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017759200418367982
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.886462926864624
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02730509825050831
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002000887179747224
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9991135001182556
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020929216407239437
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001989007228985429
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002145580016076565
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024128765799105167
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0063745868392288685
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006461567711085081
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015131112188100815
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014693550765514374
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9996915459632874
  8%|▊         | 46/584 [05:00<58:07,  6.48s/it]  8%|▊         | 46/584 [04:54<58:07,  6.48s/it]  8%|▊         | 46/584 [04:58<58:07,  6.48s/it]Loss Loss Loss tensor(4.8749, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.7933, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(5.0658, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008020345121622086Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0044916365295648575
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01850348524749279

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001693469937890768
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010633065830916166
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006462006829679012Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001143686007708311
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017945730360224843

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025004297494888306
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006913621909916401
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005388112622313201
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.806080030699377e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.62381978600024e-07

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001618888694792986Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.0243327324133134e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.542167739098659e-06


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.8003382820097613e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.878626769932453e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1949389772780705e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.085210437347996e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.8057737634080695e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.8795217329170555e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.415132702386472e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.315884168841876e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.649224582768511e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.8294364255998516e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.291648292564787e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.536175659566652e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.611021722666919e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.654840010218322e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.9047074601985514e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012421802966855466
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.654947123432066e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.522453542042058e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.148396202363074e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.877720155287534e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.2361715562292375e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012821902055293322

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.921057840576395e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00018304947298020124
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.632934774737805e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013795400445815176Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00024994774139486253

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.3908763725776225e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002985007013194263
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007237033569253981
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.7426623748615384e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005007028230465949
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006761613767594099

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008202588651329279Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010431073606014252

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.935145261697471e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011689038947224617
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014774003066122532
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.651031774003059e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001608323073014617
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019437987357378006
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011601197911659256Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021818492095917463

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003183359280228615
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002135584829375148
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001944567629834637
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028546738903969526
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002245865296572447
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003247851855121553
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003200023202225566
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019084449158981442
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004883504007011652Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030865678563714027

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017726997612044215
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003218945348635316
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006982649210840464
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014951290795579553
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00328077026642859
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009530386887490749
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013830692041665316
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033498816192150116
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013234345242381096Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033069890923798084Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001302535180002451


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001365148345939815Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003712479956448078

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001334527274593711
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005723464768379927
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006333708763122559
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001412540441378951
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.41830524802207947
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01113716047257185
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001374811981804669
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008387510664761066
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008018973283469677
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014026754070073366Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.24169538915157318
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012645882554352283

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8751099705696106
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9995566010475159
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013445359654724598
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013537216000258923
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001330001512542367
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015190847916528583
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011611144989728928
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008316603489220142
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006775595247745514
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0063719553872942924
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9997907280921936
  8%|▊         | 47/584 [05:00<57:35,  6.43s/it]  8%|▊         | 47/584 [05:06<57:35,  6.43s/it]  8%|▊         | 47/584 [05:04<57:35,  6.43s/it]Loss Loss Loss tensor(6.2209, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(5.8097, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.3891, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012501702643930912Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02501031570136547
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005805895198136568

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009979859460145235
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013572374591603875
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006321453955024481Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014094485668465495
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022241498809307814

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009035149589180946
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007948421989567578Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0386514887213707

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.940011644473998e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.805607987800613e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023547066375613213
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.243342921952717e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.512170229034382e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.188751523135579e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.2883419660502113e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.6134880499739666e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.210533461446175e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.4642097236646805e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.736544385901652e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.745872724422952e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.170194971375167e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.971605762373656e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1724006981239654e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.2016346772725228e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.816236368147656e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.236744148831349e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.1221721908659674e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014821872173342854
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.2986714359140024e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.4974664484034292e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022201468527782708
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.610306445509195e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.2066764106275514e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00018892355728894472


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.4905671529704705e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002180351730203256

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.922524284571409e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.582474401919171e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00032789388205856085

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014177526463754475Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004233364306855947

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.611285349819809e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009289602749049664
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002985138853546232
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011018726945621893
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008204803452827036
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005062353448010981
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00017767533427104354Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012521143071353436
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008404296240769327

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017208254430443048
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012179395416751504
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022529425041284412
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021360034588724375
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016948232660070062
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00039850143366493285
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032465492840856314Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002379294019192457

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00048077854444272816
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002995438640937209
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002295510610565543
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035463429521769285
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007223669672384858Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024080879520624876

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032594630029052496
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00205798028036952
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009899053256958723
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036846825387328863
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018911268562078476
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00125396519433707
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037167214322835207Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015974604757502675

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016675129299983382
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037008628714829683
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014833109453320503
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038351104594767094
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016758483834564686
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013806588249281049
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0047281356528401375
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018252014415338635
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014612100785598159
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008396049961447716
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006330923177301884
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017531111370772123Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008468227460980415

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4667263925075531
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009832817129790783
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018998408922925591Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024217091500759125Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009883941151201725


Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.999163806438446
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2790720760822296
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001834425376728177Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8381991386413574

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018601090414449573
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019133670721203089
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024642692878842354
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008758272044360638
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036020108964294195
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006134806200861931
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0120947090908885
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9997439384460449
  8%|▊         | 48/584 [05:08<1:00:37,  6.79s/it]  8%|▊         | 48/584 [05:14<1:00:37,  6.79s/it]  8%|▊         | 48/584 [05:11<1:00:37,  6.79s/it]Loss Loss Loss tensor(4.9267, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.4873, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.7879, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006945529021322727Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02498532086610794
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0055361781269311905

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001232256880030036
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016369834775105119
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004953480325639248Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013029120163992047

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004766335478052497
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003600139752961695
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002961553167551756
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01686699688434601
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005356089677661657Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.279106294939993e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.7472681785620807e-07Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.485552719619591e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.64287449328549e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.313415721910133e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.937833965523168e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.3053559086984023e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.5568946764688008e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.279537741538661e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.8750477213179693e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.070109076157678e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.234315161331324e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.79188459191937e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.550947894837009e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.70259101348347e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.015181861585006e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.481036507466342e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.412337047047913e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.536534783663228e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.454537939745933e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1841565537906718e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.0291240869264584e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012235644680913538
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.5227062249323353e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.956918276846409e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021469035709742457

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.0562174540827982e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00032927628490142524
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.9530961910495535e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.21117477142252e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000650234695058316
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.621635111514479e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.418420965317637e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009073024848476052
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011546353925950825
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.4802898628404364e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014467801665887237
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002528474142309278
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.166326733771712e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002074263524264097
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00044197894749231637
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001243799488293007Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026146278250962496

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007446878007613122
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033615627326071262
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002309593983227387
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010881786001846194
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004182975739240646
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015218890039250255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00037627489655278623Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0043751029297709465

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002162360120564699
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00409158319234848
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020848754793405533
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005652364925481379
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004734195303171873
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021723981481045485
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008328212425112724Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005038030911237001

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018599031027406454
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004872451536357403
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010767548810690641
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016859947936609387
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005132010672241449
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013187333242967725Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014189152279868722

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00618039071559906
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013229561736807227
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016036928864195943
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009129391983151436
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012094008270651102
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001592800603248179
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00932417530566454
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012895169202238321
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014887502184137702
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013942848891019821Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0056164865382015705

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016764499014243484Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03502649813890457Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4068085849285126


Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9987772703170776
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009090851992368698
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017203307943418622
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2518719732761383
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016366580966860056Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8778402805328369

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018009673804044724
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002094787545502186
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005316636525094509
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004738633520901203
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009127259254455566
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012639095075428486
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9998026490211487
  8%|▊         | 49/584 [05:15<1:01:04,  6.85s/it]  8%|▊         | 49/584 [05:21<1:01:04,  6.85s/it]  8%|▊         | 49/584 [05:18<1:01:04,  6.85s/it]Loss Loss Loss tensor(5.6434, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.9091, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.1788, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0107444291934371Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0046606119722127914
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026262883096933365

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002279166365042329
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018567363731563091
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009170867502689362Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001414093654602766

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026292402762919664
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006985251675359905Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03528977930545807

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011038106866180897
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.69678081269376e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021754298359155655
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.266649052122375e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1914925153178046e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.4024559504832723e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.0994611329806503e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.9950255136791384e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.657201775946305e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.9299195628263988e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.4400725326122483e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.128543175989762e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.133459348551696e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.035348865727428e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.64943220524583e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.16243516257964e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.826969183748588e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.124205876607448e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.8201555576524697e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.2742248145514168e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012513836554717273
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.0795432646991685e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.8570441170595586e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002015655772993341
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.6629906642483547e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.874002140946686e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001543183025205508
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.550438123056665e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.141134170116857e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001814508141251281

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.774913344997913e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00026501083630137146
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.449974560178816e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011052402260247618
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00033031986095011234
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.342308915918693e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00023682609025854617

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009582550264894962
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004179093230050057
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010068910341942683Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000745219353120774

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007161303656175733
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011863763211295009
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012888875789940357
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001079360255971551
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017019995721057057
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022927207464817911
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015307803405448794
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002290240954607725
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000310257775709033
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022917126771062613
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004029396455734968
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000489307043608278
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002160503761842847
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033556718844920397
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007157271611504257Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022662358824163675
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003930338658392429

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001962876645848155
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035096893552690744
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009698648354969919
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017727422527968884
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0040102433413267136
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00140477588865906
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015027298359200358
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003974258899688721
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014065306168049574
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003990039229393005Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013493049191311002

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001266943640075624
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003856831695884466
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014813514426350594Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001353096915408969
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004410411696881056

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005754685029387474
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008783501572906971
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013313161907717586
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.40159568190574646
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010922246612608433
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015277289785444736
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009520180523395538
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01243652869015932
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014239754527807236
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2597734332084656
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02744830586016178
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013827683869749308Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.877386212348938
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9989615082740784

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013841460458934307
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001590397791005671
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017772497609257698
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006890523713082075
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010842696763575077
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012369672767817974
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9995704293251038
  9%|▊         | 50/584 [05:22<1:02:24,  7.01s/it]  9%|▊         | 50/584 [05:28<1:02:24,  7.01s/it]  9%|▊         | 50/584 [05:26<1:02:26,  7.02s/it]Loss Loss Loss tensor(4.6726, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(5.8576, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.2627, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007513686083257198Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01803324744105339Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004896300844848156


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021520499140024185
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00227726879529655
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006067282985895872Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011090902844443917
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005616264534182847

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00042020712862722576Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018744606524705887

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023162676952779293
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.3496069679349603e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.199046093664947e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005715168081223965
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.734492785653856e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.5418129300524015e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.920450346115103e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1394248531360063e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.215405846887734e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.01496118279465e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.788338502403349e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1456136235210579e-06


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.817874908738304e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.282313057046849e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.764838202689134e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.736743787565501e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.3738391973893158e-05


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.903828837792389e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1909269233001396e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.9990176244609756e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.3967662097420543e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.4657531210104935e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.565698302234523e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.171093264129013e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.9412816982367076e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.157449337886646e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.7970456358161755e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.574870662414469e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013635953655466437
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.632442844216712e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.7129481420852244e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00020008801948279142
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.527393558528274e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00042562384624034166Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021019199630245566

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.5945795641746372e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00038319884333759546Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005739067564718425

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.063085023313761e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009414832456968725Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006681056693196297

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.958763409173116e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013307173503562808Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010286764008924365


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014701775508001447Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001862452132627368

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.932271207915619e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022465523798018694
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00302146770991385
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010449084220454097
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021071915980428457
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028253644704818726
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021962111350148916
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021196380839683115Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003270856337621808

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019052617717534304
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003060828661546111
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00032449798891320825Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032061554957181215
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001705101109109819

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032385445665568113Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001449404750019312

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005184089532122016
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013579169753938913
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003265062114223838
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007756465929560363
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012016232358291745
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003191294614225626
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010853048879653215
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001292938250117004
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037088000681251287
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00542136374861002
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00151697953697294
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005904402118176222
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.38088613748550415
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00154219102114439
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007787242066115141
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009509144350886345
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016339131398126483
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009118638001382351
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.25558704137802124
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015940540470182896Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8882952928543091

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020374098792672157
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9994848370552063
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016117529012262821
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015973137924447656
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015248792478814721
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015491038793697953
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001744828186929226
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012238897383213043
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006344099063426256
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00930871069431305
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009769609197974205
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9997544884681702
  9%|▊         | 51/584 [05:33<55:45,  6.28s/it]    9%|▊         | 51/584 [05:27<55:45,  6.28s/it]    9%|▊         | 51/584 [05:30<55:45,  6.28s/it]  Loss Loss Loss tensor(5.1542, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.3351, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(5.8441, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02086011692881584Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.036929335445165634

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007684533949941397
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002766270190477371
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003946713171899319
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016333244740962982
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0039454237557947636
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005770223680883646
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001389394048601389
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08377084881067276
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016606418415904045
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002925403416156769
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.690986096036795e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.0894916158576962e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.6197212719125673e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.2340620944305556e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.9869981770170853e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.319077561376616e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.248831373843132e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.497466605040245e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.348898179770913e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.89117371418979e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.762794782844139e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.506426815467421e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010985491826431826
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1712449122569524e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.8914483007392846e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001410736149409786
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.2426935174735263e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.833862137980759e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00023407551634591073
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.334130815346725e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003509554953780025Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.252771395840682e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.818360270699486e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003127484524156898
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.25520954397507e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00036303713568486273
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.446283805416897e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.260156366508454e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005290649714879692
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000115122165880166
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010105986439157277
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006553811836056411
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00017186578770633787
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001158090090029873
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015723292017355561
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003443899331614375
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00018187928071711212
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011763785732910037
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005941851413808763
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022813960094936192Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001687555923126638
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009977133013308048

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00218763155862689
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015261083608493209
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003602381912060082
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027459654957056046
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021540638990700245
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00043612084118649364
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003361708717420697
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003305584890767932
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006047089118510485
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030525762122124434
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004113043658435345
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008219953160732985
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004438336007297039
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003170415759086609
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001026552519761026
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004065228626132011
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002762006828561425
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012664932291954756
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004206982906907797
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002450015163049102
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014417367056012154Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00422460213303566
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002080786507576704

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004240774549543858
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001954268431290984
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001504058949649334
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0041739679872989655
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016975762555375695
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005119631066918373
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018471756484359503
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001336029963567853
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007647380698472261
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007357766851782799Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014034032355993986

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010089662857353687
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.538148045539856
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013257183600217104
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01856383867561817
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014326321892440319Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013163532130420208

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06267590075731277
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.382533997297287Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00132660660892725

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9968469738960266
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7460765838623047
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001580298412591219
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008789964020252228
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0048979283310472965  9%|▉         | 52/584 [05:40<57:50,  6.52s/it]  9%|▉         | 52/584 [05:34<57:50,  6.52s/it]
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012577936053276062
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027579816058278084
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9991233944892883
  9%|▉         | 52/584 [05:38<58:12,  6.56s/it]Loss Loss Loss tensor(5.2772, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.8735, device='cuda:0', grad_fn=<NllLossBackward0>)tensor(5.1476, device='cuda:2', grad_fn=<NllLossBackward0>)

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022696828469634056Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0044420575723052025
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022090638056397438

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003437706967815757
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004222380928695202
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015534845180809498Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017997696995735168

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032445343676954508Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03568383306264877

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001348002697341144
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.293691055565432e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002311666961759329
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007399866357445717Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1351650073265773e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.289126875140937e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.9188717033102876e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.8421278582536615e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.505995876679663e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.2253590234176954e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.659518824861152e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.6513355149072595e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.656085133727174e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.7990436137770303e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.665274329658132e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.525123121216893e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.171108205104247e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.7108750398620032e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.886096449918114e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.592698628082871e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.9665678337332793e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010878340253839269Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.483668504282832e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.881737080111634e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001665281888563186
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.256808122387156e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.7877220418304205e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014879295486025512
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.126528751337901e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.652018080581911e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.61735931923613e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00017683449550531805
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.75433873059228e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002017306542256847
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002672433911357075
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.479933603666723e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003622084332164377Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003320479881949723


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006181764765642583Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008283744100481272

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.954215784091502e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000963799306191504
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006890188669785857
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016354257240891457Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013789047952741385
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010509665589779615

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021290937438607216
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015221924986690283
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002069815673166886
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019892938435077667
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018737587379291654
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00035620329435914755
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002079498954117298
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002609121147543192
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018238842021673918
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000454564142273739Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002655760617926717

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016161492094397545
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031664702109992504
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006831870996393263
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001376166008412838
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029818720649927855
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012934571132063866
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031319335103034973
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010111804585903883
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011076155351474881
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003188947681337595
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012249004794284701
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029244970064610243
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012747878208756447
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004410524386912584
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031599521171301603
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015594157157465816
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.32308652997016907
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003783583641052246
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001680538640357554
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00910115335136652
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005453412886708975
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2355479598045349
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0076421648263931274
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018627768149599433
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012306194752454758Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9158020615577698

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.035979386419057846
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017835849430412054
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.998899519443512
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018835131777450442
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018222794169560075
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016820532036945224
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001831001485697925
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020498523954302073
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01411548350006342
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007257130928337574
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011645238846540451
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027427708730101585
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9990313053131104
  9%|▉         | 53/584 [05:46<57:40,  6.52s/it]  9%|▉         | 53/584 [05:41<57:40,  6.52s/it]  9%|▉         | 53/584 [05:44<57:34,  6.51s/it]Loss Loss Loss tensor(5.0064, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(6.1797, device='cuda:0', grad_fn=<NllLossBackward0>)tensor(5.3090, device='cuda:2', grad_fn=<NllLossBackward0>)

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026975557208061218Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014439896680414677

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022665963042527437
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02105226367712021Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021469173952937126

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007089995197020471
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0074858288280665874
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.456461738300277e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.72956082073506e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016297188121825457
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.3065114217170049e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.2164515510448837e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.190830491599627e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.205961664003553e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.996076338808052e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.19984751008451e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010121628292836249
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00019911947310902178
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.314806235721335e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011507206363603473
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.831049293192336e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013803655747324228

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021737940551247448
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.0632439625624102e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002624851476866752
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.620926741452422e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006271129823289812

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007223394932225347
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.5832537832902744e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012567625381052494
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.757815258926712e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017877212958410382

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002528401557356119
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.854360668105073e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004834518767893314
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.7292490964755416e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004107758868485689
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0047354912385344505
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.494728874415159e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004440641961991787
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011875174095621333
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004919811151921749
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002492495987098664
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005299482960253954
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005182189401239157
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00035044379183091223
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005329881329089403
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005949843907728791
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0061400821432471275
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009376046247780323
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008585418690927327
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010387163609266281
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012756128562614322Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018495624884963036

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03622395172715187
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019180730450898409
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9985569715499878
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018555023707449436
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002020798623561859
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001903350232169032
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021142037585377693
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021673855371773243
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002117943251505494
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021913740783929825
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024476968683302402
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010055085644125938
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006723733153194189
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015307488851249218
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017208509147167206
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.999312698841095
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006536001339554787
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003597790142521262
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007805338827893138
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02795727550983429
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.145363957126392e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.102497872641834e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.3144942840881413e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.3767506718286313e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.068923655926483e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.525480330310529e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.5278712453437038e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.811300535337068e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.212201252405066e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.9344699214561842e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.785352914244868e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.438418783247471e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00020975369261577725
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003890182706527412
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006749098538421094
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001073848339729011
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015664702514186502
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002449566265568137
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023139938712120056
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024225469678640366
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021493604872375727
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018966052448377013
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016265178564935923
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015319088706746697
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012933537364006042
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014664240879938006
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004856247454881668
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3564663827419281
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01062967162579298
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.26632553339004517
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8949800133705139
  9%|▉         | 54/584 [05:49<1:02:28,  7.07s/it]  9%|▉         | 54/584 [05:52<1:02:23,  7.06s/it]  9%|▉         | 54/584 [05:55<1:02:34,  7.08s/it]Loss Loss Loss tensor(5.1521, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.3035, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(5.6097, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03506706282496452
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02637157030403614Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004694027826189995

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0073408093303442
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006799596827477217
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04922927916049957Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0057644532062113285

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025581775698810816
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020278049632906914
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001611502026207745
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.905810657073744e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05871286243200302
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004202086944133043
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.7958413081942126e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.084487848856952e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.7016205902109505e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.33285595641064e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.0352504836628214e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.694441718631424e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.163991590961814e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.461614935280522e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.82084533359739e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.591606067260727e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.798179583711317e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.0036960702564102e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001238948170794174
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.2495407645474188e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1834718861791771e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002177409187424928
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.8127949917688966e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.2550710127688944e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003759689279831946
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.181265856255777e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.3462554711150005e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00027040846180170774
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.651066799648106e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.019898475846276e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00032876929617486894
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.3879121221834794e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.499719453742728e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00043940055184066296
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.946797995828092e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.831778152147308e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000498961890116334
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011879198427777737
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001131080134655349Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001551890280097723

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002501295821275562
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009423642768524587
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016907589451875538Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004406262014526874

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014601047150790691
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007337910938076675
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00020365670206956565Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020072241313755512
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001139140804298222

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025866078212857246
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001631946419365704
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003395738312974572
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003610163927078247
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024961591698229313
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000411882356274873
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004237533546984196
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023577797692269087
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004665046464651823
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006179658230394125
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024477147962898016
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004150319378823042
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008869652519933879Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021784265991300344

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004724983591586351
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001904745353385806
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001140987384133041
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00467535387724638Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016331318765878677

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001546588377095759
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0046850284561514854
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015055873664095998
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012755696661770344
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004873022902756929
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016259668627753854
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005182595457881689
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014737474266439676
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017564406152814627Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0077039459720253944
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004405153449624777

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007683662697672844
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3224596381187439
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015900532016530633
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014809736981987953
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010362663306295872
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017354910960420966
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04325984790921211
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.24610541760921478
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017169836210086942Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9979271292686462
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9120105504989624

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001703734160400927
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00177385238930583
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019080162746831775
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009260782040655613
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038833804428577423
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00862653087824583
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02122618816792965
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9981011152267456
  9%|▉         | 55/584 [05:55<59:09,  6.71s/it]    9%|▉         | 55/584 [06:01<59:08,  6.71s/it]    9%|▉         | 55/584 [05:58<59:06,  6.70s/it]  Loss Loss Loss tensor(5.0626, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.7511, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.5582, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03922729939222336Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008848121389746666

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026821356266736984Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003919909242540598
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011175427585840225

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014174627140164375
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004468158353120089
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01618233136832714
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006088618189096451
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03601964935660362
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.339234343817225e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012197395553812385
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.61425098971813e-07Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.2859063645009883e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1966569672949845e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007512536249123514Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.2273017748375423e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.942248445629957e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.884541729348712e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.6337980923708528e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.5604364256869303e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.438660395564511e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.0409348710236372e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.494737019442255e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.689344005892053e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.941719326889142e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00017115708033088595
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.8436336328450125e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.0185265384498052e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002691154077183455

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.4447574105579406e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00023385437089018524

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.768067345954478e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00028281559934839606
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.119487519143149e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.6844029232743196e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00046436028787866235

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.4534652261063457e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006241243099793792
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.829677972244099e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.5710043701110408e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012574167922139168
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001439806801499799
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.365632023313083e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014311184640973806

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003124709764961153
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002195197157561779
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005773127195425332
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.285761967068538e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031414651311933994
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000972908572293818
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.267881639767438e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004027524497359991

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015138883609324694
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00811582151800394
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.919717558659613e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002183035248890519
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007058609277009964
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003301933640614152
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001744544570101425Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00784381665289402

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003163662739098072
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007636721711605787
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022986992553342134
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00326299830339849
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008091750554740429
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004287867632228881Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029198545962572098
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008458320051431656

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025414403062313795
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008927474729716778
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005748051917180419
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021832273341715336
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009230513125658035
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008609447977505624Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020792661234736443
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010657140985131264

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016799079021438956
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01735747419297695
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001261276425793767
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020065142307430506
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022711720317602158
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001621379517018795Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005592372268438339
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02909770794212818

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.41169071197509766
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04407748207449913
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026029422879219055
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9969882965087891
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014103570021688938
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3268554210662842Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024904701858758926

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8496952056884766
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002627080539241433
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025597293861210346
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027549793012440205
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002760533010587096
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028740239795297384
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003065369324758649
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035318925511091948
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022194871678948402
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012391043826937675
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020461250096559525
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016351472586393356
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9988027215003967
 10%|▉         | 56/584 [06:02<59:42,  6.79s/it] 10%|▉         | 56/584 [06:08<59:41,  6.78s/it] 10%|▉         | 56/584 [06:05<59:40,  6.78s/it]Loss Loss Loss tensor(5.0881, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.8000, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.0466, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03606060892343521Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.045268844813108444

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01054005790501833
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08460456877946854
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008325980976223946
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001899924362078309
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004167452454566956Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025098901242017746

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1175142390129622e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.1145046957826708e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.0273029804229736e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.107987933821278e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.3687167160678655e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.242037215997698e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.7726228988030925e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.0649945579643827e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000105961189547088
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.019490784732625e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013837315782438964
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00025095586897805333
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.006592669407837e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00047620132681913674
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.510130333481357e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002968384069390595
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.750236156629398e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00034701585536822677
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.620216249255463e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00045579715515486896

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005092278006486595Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.692842286312953e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018352163024246693
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013789357035420835
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011050401953980327
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016936496831476688
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017046788707375526
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003068892692681402
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002415125723928213
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003941857139579952
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031472633127123117
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005882742698304355
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0057421475648880005
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008671767427586019
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004917616955935955
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010988910216838121
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005302886478602886
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001693475292995572
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005005931947380304
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005657815840095282
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001593413413502276
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005047849379479885
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016893643187358975Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004873593337833881

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004903440363705158
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015787724405527115
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005130656994879246
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001727945520542562
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013326799497008324
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015191963175311685
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018392564728856087
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016559012234210968
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014611692167818546
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.053198251873254776
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014811904402449727Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9966208934783936

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015882777515798807
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026515034958720207
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009620897471904755
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008721843361854553
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021533645689487457
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9950675964355469
 10%|▉         | 57/584 [06:07<54:53,  6.25s/it] 10%|▉         | 57/584 [06:10<54:51,  6.25s/it]Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005474525038152933
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010451710782945156
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029533999040722847
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07074674218893051
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1590552730922354e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.839322067098692e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.824117473210208e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.140776920598e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.0793639376061037e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.3265364032122307e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.448162169661373e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.1344730561831966e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.206998710287735e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.82925315736793e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.943816646933556e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013317118282429874
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000293403776595369
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005178654100745916
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008604437462054193
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013391663087531924
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019333483651280403
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003032154869288206
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028388190548866987
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002949802903458476
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026830495335161686
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023396541364490986
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002024561632424593
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018937551649287343
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015052898088470101
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017939487006515265
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004827467259019613
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3517877459526062
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012265119701623917
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2823807895183563
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8894498944282532
 10%|▉         | 57/584 [06:13<56:10,  6.39s/it]Loss Loss Loss tensor(5.2965, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.8228, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(5.6103, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03677491471171379Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006239189300686121
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.055218763649463654

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007521091494709253
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01305691059678793
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08944790065288544Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017379557248204947

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008012894541025162
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019329251954331994
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05214395001530647
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023784607648849487
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.278518066617835e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004010882694274187Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.3211113127908902e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.2904902177979238e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.3555267034680583e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.5769322746782564e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.0110596778977197e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.9568039937876165e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.727807097675395e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.00917940371437e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.912733806530014e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.866998203098774e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013081608631182462
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.661896910984069e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016919051995500922
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.838788405933883e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.5995430405600928e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003178920887876302
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.3909781046095304e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.0936775146983564e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005763472290709615
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.6538500605965964e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.198720878572203e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00038596810190938413

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.6710633139591664e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00042928746552206576

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.9821446989662945e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.782828131690621e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000616745906881988
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.752112626098096e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007216285448521376
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.684086398920044e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011634695692919195
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019383623730391264
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021049012138973922
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012059832806698978
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013545200927183032
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00038249173667281866
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013254933583084494
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021246285177767277
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006554003339260817
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00020387528638821095
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029407364781945944
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010611357865855098
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0039006087463349104
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015737302601337433Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00024092529201880097

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007052143570035696
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025717862881720066
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004312741511967033
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0060190604999661446
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023813690058887005
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006933390628546476
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004909286508336663Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024627973325550556Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0064983307383954525


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007285250350832939
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022738438565284014
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007484038360416889
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0072117638774216175
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001971764490008354
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010623804992064834
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006980715319514275
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017064339481294155
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001395843573845923Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007120179012417793

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015806304290890694
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008496706373989582
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022003392223268747Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001235308009199798

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014757614582777023
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014949124306440353
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002071312628686428
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016669414937496185
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0040032509714365005
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02445545420050621
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002246161689981818Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.31570082902908325

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05647154152393341
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011543690226972103
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002097839256748557
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9956798553466797
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.26491913199424744
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023020075168460608
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.90947425365448
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002261926420032978
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021808345336467028
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022479244507849216
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026900875382125378
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008130263537168503
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0060513936914503574
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009683900512754917
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01881360448896885
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9950004816055298
 10%|▉         | 58/584 [06:14<57:51,  6.60s/it] 10%|▉         | 58/584 [06:20<57:27,  6.55s/it] 10%|▉         | 58/584 [06:18<57:49,  6.60s/it]Loss Loss Losstensor(5.1951, device='cuda:2', grad_fn=<NllLossBackward0>)
 tensor(5.0924, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.9133, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06343836337327957
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007008149288594723Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.050207771360874176

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013405593112111092
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012623718939721584
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1271519511938095Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01071977335959673
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019262190908193588

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029697857797145844
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023523219861090183
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.3461289199767634e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.058774299919605255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.460620271449443e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.945302513689967e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004472570493817329
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.2855171007686295e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.3759239411447197e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.1382270865142345e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.891833449008118e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.120882219169289e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.638105565391015e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.4997815419046674e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001341576426057145
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.361410553130554e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00017327579553239048
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.433237897203071e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.2642378351301886e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00035144193680025637
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.860922207531985e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.3947537556523457e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007198985549621284
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.006919359904714e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.5697816201718524e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00039231713162735105

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.003572394140065e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00043383942102082074
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.420724770985544e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.360049959155731e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005926306475885212
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.406083851587027e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011352368164807558Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006573635037057102
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.302250403678045e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00211594277061522
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.263438940048218e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010733790986705571
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001285400940105319
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001937686902238056
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001155532372649759
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020716176368296146
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003327693557366729
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00017111167835537344
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030327471904456615
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005800592480227351
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004405130632221699
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00019745716417673975Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009564778883941472

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010367156006395817
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014404365792870522
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004080916114617139
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007175495848059654
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002525017596781254
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008383331820368767
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004060726787429303Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022467062808573246

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008413552306592464
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023296999279409647
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006440207362174988
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00897729117423296
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021866988390684128
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009485781192779541Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008746477775275707

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019003566121682525
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00854981504380703
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001643082476221025
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014300844632089138
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008625324815511703
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015170862898230553
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026163500733673573
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00960768386721611
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011785451788455248
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01882447488605976
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021083049941807985Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014320379123091698

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02730390429496765
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038420420605689287
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023604198358953Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028286563232541084

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2873217463493347
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04930970445275307
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023413721937686205Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01142401434481144
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9948513507843018

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2601270377635956
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025861936155706644
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.919745147228241
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002413378329947591
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023773936554789543
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023636550176888704
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026595720555633307
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022616920992732048
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012854469940066338
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013152029365301132
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014381373301148415
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9900365471839905
 10%|█         | 59/584 [06:20<56:35,  6.47s/it] 10%|█         | 59/584 [06:26<56:18,  6.44s/it] 10%|█         | 59/584 [06:24<56:34,  6.47s/it]Loss Loss Loss tensor(5.3778, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(5.3529, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.8246, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1078590527176857Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007244422100484371

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03269457817077637
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016457432880997658
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10466259717941284Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027561165392398834

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004353775642812252
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006612335331737995Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019394703209400177

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009133844636380672
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0329262800514698
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019583324901759624Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.409363438957371e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.853184805142519e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.55440009420272e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.5028688267193502e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.951086899993243e-07Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.7870823942066636e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.555687231302727e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1958051118199364e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.313385943532921e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.7209902327740565e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.2395850010070717e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.95180647703819e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.456368621205911e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.767303380504018e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.98964940966107e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.3987092643219512e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.340631443890743e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012112880358472466

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.012257209571544e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002039153187070042
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.2459182218881324e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.144904985674657e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001852851128205657
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.783502663485706e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.461786789353937e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002517174289096147
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.185068872990087e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.9361655833781697e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00037272972986102104

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.795744073111564e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004975486663170159
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.872546120779589e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.184195030480623e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001302935997955501
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010011751874117181
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00019519909983500838
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010863984934985638
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001704586175037548Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003404955205041915

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00168722087983042
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000598559679929167
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00023278186563402414Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022927564568817616

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009832567302510142
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029986847657710314
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00042341506923548877
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014829107094556093
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004509102553129196
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005317605682648718Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026463638059794903

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005253381561487913
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023345453664660454
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005461482796818018
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023878009524196386
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007959497161209583
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005147313699126244
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002236918779090047
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011520104017108679
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005535540170967579Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00192668242380023

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001485489308834076Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005349716637283564

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001647511264309287
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00548404548317194
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019977695774286985
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001539164804853499
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005628371611237526
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023222032468765974Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011738224420696497
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006266810465604067

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001435670885257423
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009345872327685356
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022557340562343597
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003718104911968112
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01245145034044981
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.28832873702049255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03613143414258957Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021404807921499014

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013154172338545322
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09144426137208939
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023465119302272797Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2938079535961151Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9937386512756348


Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9104346036911011
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021795430220663548
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021868296898901463
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002249955665320158
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024624925572425127
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024688318371772766
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007859633304178715
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026469949632883072
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04950474202632904
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9866567850112915
 10%|█         | 60/584 [06:28<58:48,  6.73s/it] 10%|█         | 60/584 [06:33<58:36,  6.71s/it] 10%|█         | 60/584 [06:31<58:47,  6.73s/it]Loss Loss Loss tensor(4.4832, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.3951, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(5.6232, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007725024130195379
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10502239316701889
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028520788997411728
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030203912407159805
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2194133847951889Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00794557761400938

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05918566882610321
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08536343276500702
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3686826229095459Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.188898750115186e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03774314746260643

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.959112523763906e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.4197915990953334e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012803365476429462
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.5332704758038744e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0052308267913758755Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.825999672495527e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.482662476832047e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.42492716704146e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.172822173131863e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013534534082282335
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1411731065891217e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002543973387219012
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.4330367775983177e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.24627022666391e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00035172628122381866
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.559817534754984e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.328775306319585e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006561626214534044
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.82600841880776e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.3640664949198253e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013316103722900152
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.2383307775016874e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008761194767430425
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.248279532883316e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.4859702029498294e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010877061868086457
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001197716046590358

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001610798528417945
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001653947401791811
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.017490133875981e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001950456527993083
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00034559861524030566
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000156053138198331
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005786547902971506
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006469356012530625
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002115911483997479
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036111855879426003
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010882943170145154
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00023216151748783886Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005528497975319624
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016813956899568439

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0069719781167805195Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002361348131671548

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00027398092788644135
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008418873883783817
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003583155572414398
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00045194951235316694
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023284710943698883
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032471970189362764
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005624225013889372Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003201886545866728Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011277375742793083


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029345983639359474Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01351914368569851

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009563892963342369
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013703091070055962Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002496386179700494

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015271376818418503
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002099502831697464
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011120840208604932
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014547665603458881
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020115566439926624
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016387976938858628Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015368873253464699
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015149826649576426

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014961672946810722
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019127379637211561
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022129788994789124Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0170928742736578
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004252216778695583

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.035659536719322205Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.32082924246788025

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002650851383805275
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06277978420257568
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01487655658274889
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0052461461164057255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.041279830038547516
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3187848627567291
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8870790004730225
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16741955280303955
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003253777977079153
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9724913239479065
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036032856442034245
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003605540608987212
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038910103030502796
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036604716442525387
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003817342920228839
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038426269311457872
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0045971074141561985
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07804286479949951
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029233841225504875
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014908252283930779
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0564204566180706
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8973449468612671
 10%|█         | 61/584 [06:41<1:00:28,  6.94s/it] 10%|█         | 61/584 [06:35<1:00:36,  6.95s/it] 10%|█         | 61/584 [06:39<1:00:36,  6.95s/it]Loss Loss Loss tensor(5.8018, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.9654, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(5.0103, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12270185351371765Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08550330251455307
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008856939151883125

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07661900669336319
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09004264324903488
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3599017560482025
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.034340597689151764
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0069056786596775055
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004897605627775192
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04622645676136017
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004468297585844994Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.594830428075511e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10552920401096344

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.0600120226154104e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.316597604272829e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.8708423112911987e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.2366848497767933e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.587584018940106e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.761292873605271e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.684515341883525e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.695010142721003e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015797866217326373
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.484785111140809e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.0321610716346186e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022427998192142695

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.336942533380352e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00043670073500834405
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.928913115989417e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.3812596989737358e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009595499723218381
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.4737704734434374e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005881917313672602Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.113835919066332e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.433658902300522e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001011354150250554
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.938336446182802e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019291543867439032
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014551672211382538
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001337876165052876
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002600600477308035
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010767378989839926
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001074047468136996
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004766541998833418
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00019084775703959167
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00018074101535603404Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004740886855870485
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004276762483641505

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005625056568533182
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006860148278065026
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003648076090030372
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006821615621447563
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001302429474890232
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005269603570923209
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008153478614985943
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001845822436735034
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008815404144115746
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009655987843871117
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024237327743321657
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010429444955661893Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009303819388151169

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00304523971863091
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010192390531301498
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037111870478838682
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012028974015265703
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010149870999157429
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004754221998155117
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015314100310206413
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010107332840561867
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004213917534798384
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001714423531666398Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01085330918431282

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004075251054018736Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011053737252950668

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018581871408969164
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01072460226714611
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00365896662697196
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012363997288048267
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018329655285924673Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030746408738195896

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019991137087345123
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002530222525820136
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001877039554528892
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02335907146334648
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002360488520935178
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017676398856565356
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04357951134443283
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017779263434931636
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017930216854438186
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06841973960399628
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002211358631029725
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018361816182732582Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9873077273368835

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005359521601349115
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018494924297556281
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4193743169307709
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018803664715960622Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018258623778820038

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3789469599723816
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002172147622331977
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8128085136413574
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012799922376871109
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006366576533764601
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014050370082259178
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014134897850453854
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9245152473449707
 11%|█         | 62/584 [06:42<1:00:40,  6.97s/it] 11%|█         | 62/584 [06:48<1:00:35,  6.96s/it] 11%|█         | 62/584 [06:46<1:00:40,  6.97s/it]Loss Loss Loss tensor(4.9412, device='cuda:0', grad_fn=<NllLossBackward0>)tensor(5.7091, device='cuda:2', grad_fn=<NllLossBackward0>)

tensor(4.7056, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1485542207956314
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0085804658010602
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07931987196207047
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08056028187274933
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3747389316558838
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2378898710012436
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04165193811058998
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7948670387268066Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09384722262620926
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16267922520637512

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008511713822372258
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.37181947240606e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019103968515992165Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016311823856085539
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.752221376402304e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001786325010471046
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008342289365828037
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003367783036082983
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003538855817168951
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005660293623805046
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007328122155740857
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.533620373578742e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008409966714680195
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010101574007421732
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001513448660261929Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00839201919734478
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001406162977218628

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009849064983427525
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001354033825919032
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003139699110761285
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010271416045725346
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013480412308126688
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000566258211620152
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009067034348845482
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012341189431026578
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009138037450611591
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001516563119366765
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008379595819860697
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010591919533908367
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014597986591979861
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008895461796782911
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010113272815942764
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019332491792738438
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01396593265235424
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011196036357432604
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022804467007517815
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008312526158988476
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002750806277617812
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010943867964670062
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009172420017421246
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003461309941485524
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010885066585615277Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010042061097919941
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004160178825259209

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010538507252931595
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001032702042721212
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005027731414884329
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018017925322055817
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012530959211289883Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012095476500689983

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004758711904287338
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01332780346274376
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004752351902425289
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001125256298109889
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01194269210100174
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004298872780054808
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013182418420910835
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012685524998232722
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036678097676485777
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011893326416611671
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029673564713448286
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001095929415896535
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0114144217222929Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002681128215044737

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011360147036612034
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011613866314291954
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020623269956558943
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012499485164880753
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002496018772944808
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001324450597167015
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03443137928843498
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005860305856913328
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07049506157636642
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4566321074962616
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013983567478135228
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0398787297308445
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017414914444088936
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23022040724754333
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.35258355736732483
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018791747279465199
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9179514050483704
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7949110865592957
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001487518078647554
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001527141430415213
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013592533068731427
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014635853003710508
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012899675639346242
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001274544163607061
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001339673064649105
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014782274374738336
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02503085508942604
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013236209750175476
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005194064229726791
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.033883653581142426
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.47466710209846497
 11%|█         | 63/584 [06:49<58:57,  6.79s/it]   11%|█         | 63/584 [06:54<58:53,  6.78s/it]   11%|█         | 63/584 [06:52<58:57,  6.79s/it]  Loss Loss Loss tensor(4.4077, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.7545, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(5.1139, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05574323609471321
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.26826372742652893Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1501542329788208

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006403868552297354
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.24741721153259277Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0462510846555233
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05640246719121933

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010891715995967388
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012028818018734455
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03758086636662483
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.039558809250593185
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.261348708998412e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006388822104781866
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.521467424936418e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.284192618797533e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.756737780553522e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.440893695165869e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.241168688982725e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.35887419473147e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014939125685486943
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.216771230858285e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00030526076443493366
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.064739631663542e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000507097109220922
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.7492870028945617e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.7536100131110288e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008474760106764734
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.5830522392643616e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.2871055736904964e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017748017562553287
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.403689621947706e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014043267583474517
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001576664362801239
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.775381189072505e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002374841133132577
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011169771460117772

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004038630984723568
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00020432514429558069
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011255081335548311
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005314646754413843
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004315724945627153
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00023132104251999408
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012512516230344772
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006837088149040937
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007942844182252884
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004024368245154619
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013038659235462546
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009442193433642387
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004291388322599232Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020005640108138323

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010041185654699802
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025783791206777096
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000640715123154223
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011143960058689117
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031872964464128017
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012226643739268184Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014058231376111507

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003678363747894764
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010022851638495922
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001618808601051569
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004185997880995274
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010802050121128559
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002563801361247897
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003639569040387869
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010349718853831291
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026603294536471367
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003345633391290903
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011923735961318016
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030216830782592297
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028178186621516943
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010628396645188332
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034898039884865284
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002331591909751296
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011145330965518951
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035562217235565186
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018632712308317423
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011193363927304745
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00397207448258996
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017677204450592399
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014579201117157936
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003035350702702999
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014012545580044389
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027387229725718498
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00291632954031229
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001766847213730216
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03991680592298508
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002840940374881029
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0344308540225029
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00467679463326931
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09872905164957047
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028349028434604406Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.39825454354286194

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9770599603652954
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026003739330917597Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015533532947301865

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3178841173648834
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002814983483403921
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8579697012901306
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030358266085386276
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004152724985033274
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03380841016769409
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014437755569815636
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01179160363972187
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.035233933478593826
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9293860197067261
 11%|█         | 64/584 [06:56<1:00:02,  6.93s/it] 11%|█         | 64/584 [07:02<1:00:00,  6.92s/it] 11%|█         | 64/584 [06:59<1:00:02,  6.93s/it]Loss Loss tensor(4.3536, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(5.4390, device='cuda:1', grad_fn=<NllLossBackward0>)
Loss tensor(5.5358, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2590279281139374Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.060106031596660614
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0057578966952860355

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.29983770847320557
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15000088512897491Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03515732288360596
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.34487271308898926

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012584613636136055
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010082933120429516
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029369179159402847
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11834389716386795
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006389905698597431Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.3796723326086067e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.6241916657454567e-06

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.409762186696753e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.175216872681631e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.3393954405910335e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.363935583271086e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.352799118758412e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013845963985659182
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.2235113899805583e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.2351589248282835e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002708827378228307

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.027939808613155e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004148390144109726Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.5974415621021762e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.7953865103190765e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007222412386909127
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.598609302775003e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014661202440038323
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.365275036543608e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.523016392951831e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001142594963312149
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016024131036829203

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017357526812702417
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013868260430172086
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012100746971555054
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002750911982730031
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00023196298570837826
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00025967974215745926
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035440369974821806
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000461654388345778
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003716411010827869
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008539402857422829
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006842256989330053
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004515037580858916
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00486898235976696
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012938251020386815
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000617020356003195
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005564790219068527
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002078919904306531
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005920160561800003
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011067866580560803
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002700603101402521
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006076754070818424
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014071306213736534
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00338702742010355Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008960491046309471

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020761401392519474
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038624859880656004
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006160356104373932
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021168640814721584
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004278457257896662
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006333010736852884
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002333258744329214
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006285013630986214
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035451471339911222
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002695757895708084
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007122144568711519
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003206164576113224
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025946039240807295
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006211935076862574
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00260390667244792
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032133611384779215Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0062331571243703365

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021639231126755476
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006430349312722683
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017717441078275442
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023700580932199955
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007888148538768291
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017293620621785522
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0187892597168684
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022730035707354546
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014566932804882526
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027017468586564064
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022615629713982344
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018099613953381777
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022064460441470146
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002301369560882449Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005029046908020973

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09637545049190521
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.39539554715156555
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001958373934030533Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9449185729026794

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014483216218650341
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021445322781801224
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.29095175862312317
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002234499668702483Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8496896624565125

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002984320977702737
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.039399199187755585
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015299133025109768
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013278859667479992
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04791182279586792
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8997113108634949
 11%|█         | 65/584 [07:04<1:01:59,  7.17s/it] 11%|█         | 65/584 [07:09<1:01:57,  7.16s/it] 11%|█         | 65/584 [07:07<1:01:59,  7.17s/it]Loss Loss tensor(4.2902, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.0350, device='cuda:2', grad_fn=<NllLossBackward0>)
Loss tensor(4.6424, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06274724751710892Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007199806626886129

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21805617213249207Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.29863572120666504
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11608479171991348

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.035691212862730026
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005778511054813862
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6289401054382324Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025656215846538544

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0933191180229187
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.147333311266266e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005828600376844406Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.047046786581632e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.048730524023995e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.992433671053732e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028488945681601763Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001707826304482296

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.059383612300735e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000293708813842386
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.756107152090408e-06Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.9152843378833495e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005935864755883813


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.139926750212908e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008412452880293131
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.5448655176442116e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.963780080899596e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012022119481116533
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.268192813266069e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001542199170216918Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016791856614872813


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017437117639929056
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00029899849323555827
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.914215580560267e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00218465318903327
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002942164137493819
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012363815039861947
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028687671292573214
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004117431817576289
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00017716726870276034
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006678653880953789Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029237731359899044

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004716457799077034Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008218023576773703Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000298385217320174


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0039366306737065315Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013924012891948223

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00041736772982403636Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018647563410922885Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0046396111138165


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022196131758391857
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004854901228100061
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00045291901915334165
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026277874130755663
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005328238941729069
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002958789700642228
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005208076909184456Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006857445929199457

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038623956497758627
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0060291350819170475
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002606842899695039
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007077455520629883Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007155642379075289

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00239275093190372
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006742160767316818
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007610803004354239Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019373102113604546

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007501579821109772
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015878096455708146
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007036651950329542
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010779723525047302
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013059270568192005
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0068796537816524506
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011043066624552011Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006912261247634888
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012761694379150867

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007985261268913746
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010849679820239544
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012270353036001325
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01706988923251629
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013325827894732356
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023395324125885963
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004498422145843506
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013704578159376979
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03657623752951622
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2603791058063507
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014878289075568318
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07816026359796524
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018938111141324043
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9466124773025513
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.28591418266296387
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017345374217256904
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9098021388053894
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015459648566320539
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016859301831573248
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015926946653053164
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017094035865738988
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015898296842351556
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001603321055881679
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016247188905254006
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019422998884692788
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02408253774046898
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009264659136533737
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009845218621194363
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0186320673674345
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7454521059989929
 11%|█▏        | 66/584 [07:09<58:19,  6.76s/it]   11%|█▏        | 66/584 [07:15<58:17,  6.75s/it]   11%|█▏        | 66/584 [07:13<58:19,  6.76s/it]  Loss Loss Loss tensor(4.8866, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.6338, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.4739, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04833274707198143Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3161430060863495

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06244921311736107
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6127017140388489Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02685120329260826

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007936991751194
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029717838391661644
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00556324515491724Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007683017756789923

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001280852360650897
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000251897843554616
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021163218189030886
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004237391403876245
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002274804748594761
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00219721463508904
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009528965689241886
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006663381354883313Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001715070684440434
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20552289485931396

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016116448678076267
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011296361684799194
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008284082869067788
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001626884681172669
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1534775048494339
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007923252996988595Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012353319907560945

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015176486340351403
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012819806579500437
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00018154799181502312
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006673927418887615
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014982486609369516
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013826527865603566
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006889300420880318
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00024190011026803404
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027053772937506437
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006272273603826761Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00032675269176252186
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017398908967152238

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005894670612178743
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002021967200562358
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005518522812053561
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000688218220602721
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002182736061513424
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008276200387626886
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005712064448744059Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026782562490552664

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008205741760320961
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005051145330071449
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006843546289019287
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007375140557996929
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029009527061134577
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006052246899344027
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006940317107364535
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003271794877946377
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008793376036919653Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010512365261092782
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002841806970536709

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008661017054691911
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030375001952052116
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008197713759727776
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014039279194548726
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030905636958777905
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009216727921739221
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030240707565099
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001691325451247394
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020122285932302475Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032007654663175344

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010757787385955453
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002440681681036949
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038669519126415253
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012815174413844943
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028490915428847075
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008970593102276325
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019105059327557683Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004421277437359095

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010484855622053146
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002743507269769907
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018575776368379593
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002583517460152507
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013008125824853778
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05238788202404976Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002087053842842579

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001338278059847653Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9943415522575378
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016612127656117082

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013036361197009683
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001143443281762302
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012667002156376839
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011987527832388878
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010449161054566503
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011529194889590144Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012688327115029097

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005915372166782618
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011584468884393573
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3039248287677765
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001287534716539085Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02660500444471836

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4167836010456085
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001594858942553401
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8167557120323181
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014520586468279362
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006598389241844416
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009079283103346825
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022533148527145386
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7236604690551758
 11%|█▏        | 67/584 [07:17<59:33,  6.91s/it] 11%|█▏        | 67/584 [07:22<59:32,  6.91s/it] 11%|█▏        | 67/584 [07:20<59:33,  6.91s/it]Loss Loss Loss tensor(4.4837, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.2394, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.1564, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008137510158121586Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.033970337361097336

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2775179147720337Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21199284493923187
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1168338730931282

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004042946267873049
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013377604074776173
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5097600817680359
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0616522841155529
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004557687323540449Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008074897341430187

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.82513130211737e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004507821868173778
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016919521149247885Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.658643542323261e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005971221253275871

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.452134352410212e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015392550267279148
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006031116936355829

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013564404798671603
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005816876073367894
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021058082347735763
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003419567656237632
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008123490842990577
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00046748213935643435
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010382944019511342
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022108491975814104
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005814473261125386
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001179019920527935
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002287677489221096Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006046935450285673
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001275444170460105

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005784055101685226
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012252683518454432
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003414831589907408Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005723850918002427

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012768086744472384
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007578496588394046
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00044814482680521905Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001493386342190206

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008071305928751826
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016123001696541905
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00054212287068367Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012827226892113686

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020461955573409796
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016674340004101396
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005641119205392897Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022203177213668823

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020042911637574434
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026558940298855305
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005686244112439454
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002426865743473172
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032021200750023127
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002844708738848567Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004034378100186586
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005775043391622603

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006334217730909586
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003945800941437483
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007095678593032062
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0047760396264493465
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025902423076331615
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005675324238836765
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023876074701547623
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007673607324250042
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001918197376653552Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004943856969475746

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009703825926408172
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004798280540853739
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014996626414358616
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004443485289812088
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011829858412966132
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011603772873058915
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004587498027831316
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001176575431600213
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004814529325813055Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013342616148293018
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009954978013411164

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005401077680289745
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012237454066053033
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016840780153870583Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024487821385264397
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005007090978324413

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.24578209221363068Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02451995387673378

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020067936275154352Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021149959415197372
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03557540103793144

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.30555054545402527
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05402678996324539
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002864889334887266
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8926750421524048
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.989582359790802
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022918039467185736
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002487931167706847
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002168956445530057
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020753084681928158
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019683658611029387
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001984675182029605
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021587780211120844
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002374454168602824
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.037930186837911606
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017173435539007187
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018182769417762756
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02537812478840351
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8126106262207031
 12%|█▏        | 68/584 [07:23<56:50,  6.61s/it] 12%|█▏        | 68/584 [07:28<56:49,  6.61s/it] 12%|█▏        | 68/584 [07:26<56:50,  6.61s/it]Loss Loss Loss tensor(5.3259, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.1892, device='cuda:0', grad_fn=<NllLossBackward0>)tensor(5.2411, device='cuda:2', grad_fn=<NllLossBackward0>)

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2966521680355072Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3654326796531677

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18303103744983673
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.951810359954834Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19876250624656677

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14410923421382904
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003728915471583605
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0075170136988162994
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011696905130520463
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012118826620280743
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013500190107151866
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019809849560260773
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002139276039088145Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02027759701013565

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0186601672321558
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003206253459211439
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012720318511128426
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00040314122452400625
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010719871148467064
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003745183639694005Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009999196045100689

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006706414744257927
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002772158186417073
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006446129642426968
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00024469956406392157
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00760818412527442
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001904573291540146
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007581289391964674
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015006061585154384Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015301473438739777

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007290256675332785
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013902122736908495
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008349092677235603
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00017352044233120978Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009128381498157978

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009667638689279556
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001640988775761798
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02236521616578102
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002713758440222591Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010311252437531948

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011395148001611233
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00017762983043212444
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010405887849628925
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010396521538496017
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00019820306624751538
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010567713528871536
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00023037378559820354
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011283636093139648
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00024308721185661852Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01155713852494955

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013992458581924438
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004434681322891265
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07530739158391953
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002432570472592488
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07396198064088821
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08286099135875702
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00024726521223783493
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23239976167678833
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022420825553126633Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8346724510192871

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021999837190378457
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021768997248727828
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022705289302393794
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00024414501967839897
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00030315155163407326
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00506721343845129
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025828175712376833
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004091575741767883
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006720948498696089
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07709293812513351
 12%|█▏        | 69/584 [07:29<55:08,  6.42s/it] 12%|█▏        | 69/584 [07:32<55:08,  6.42s/it]Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012427081353962421
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8016495704650879
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0189523845911026
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3103805184364319
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004112442838959396
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004661065759137273
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005781367071904242
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006697640637867153
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000884939159732312
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009793775388970971
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010425965301692486
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010433892020955682
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006206444231793284
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005508759059011936
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007350181695073843
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006544164498336613
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014650122029706836
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013537240447476506
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016041035996749997
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019500927301123738
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002226344309747219
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00432260986417532
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019672266207635403
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017768590478226542
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001420694519765675
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011040978133678436
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008648934890516102
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008802368538454175
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007593980408273637
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009193991427309811
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004570718854665756
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18997474014759064
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020432863384485245
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.26906701922416687
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.38926663994789124
 12%|█▏        | 69/584 [07:35<55:57,  6.52s/it]Loss Loss Loss tensor(4.4332, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.6676, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.2174, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2996610105037689Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014069708995521069
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.261415034532547

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6642262935638428
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18884634971618652
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9500799179077148Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01665678806602955

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18086399137973785
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033950426150113344
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.22781996428966522
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010486218379810452Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1135484129190445
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000334487616783008

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005958616267889738Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00038344963104464114

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010857247252715752Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00955983530730009
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004922595690004528

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006178912590257823
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016148505732417107
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00017316208686679602Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009097837610170245
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016998419538140297

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009579947218298912Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015429271385073662

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00027079525170847774
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009830875787883997
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010752280242741108
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00034778585541062057
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009154196595773101
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009284933097660542
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006421328871510923
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003053310210816562Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008130385540425777

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005902064149267972
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0061113121919333935
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022955899476073682
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007656810339540243Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005940130911767483

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007179160602390766Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007156270556151867

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021320395171642303
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013031840790063143
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00696504395455122
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001435061334632337Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016745241009630263
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012342700734734535

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016691755736246705
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006734036840498447
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014197728887666017
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019610172603279352
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007956729270517826
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013347022468224168Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002224097726866603
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008929080329835415

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036192380357533693
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010278018191456795
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016990206495393068
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001987333642318845
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013689186424016953
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017923018895089626
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015438901027664542Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010892627760767937

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001447588438168168
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011377654038369656
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021223319345153868
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001125646522268653
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009581881575286388
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001708943018456921Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008929973118938506
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008762539364397526

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009326086146757007
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008547497913241386
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00019528449047356844
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008242927142418921
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008589115925133228
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00023197969130706042
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009998715249821544
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008682236075401306
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002621845924295485
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00482054241001606
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011128024198114872
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.232557013630867
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00032542203553020954Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030726579949259758

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02378629893064499
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.038083791732788086
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002636794524732977
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.335660845041275
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10786806046962738
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5822692513465881
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002569554781075567Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.30744636058807373

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8597027659416199
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021325345733202994
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001879258343251422
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00017845284310169518
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001827702362788841
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00019267301831860095
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002480516559444368
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018241079524159431
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011430034646764398
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003624011529609561
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009080372750759125
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08623862266540527
 12%|█▏        | 70/584 [07:40<53:51,  6.29s/it] 12%|█▏        | 70/584 [07:35<54:06,  6.32s/it] 12%|█▏        | 70/584 [07:38<54:06,  6.32s/it]Loss Loss Loss tensor(4.9563, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.8595, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(5.0553, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4322091341018677Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.22758802771568298Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015855442732572556


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16079109907150269
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.040688201785087585
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.25784915685653687
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015910794958472252
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07110223174095154
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017152834683656693
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3292687237262726
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15564222633838654
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025725416839122772
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004020009655505419
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004148105159401894
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001231166417710483Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004832075792364776

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006562001071870327
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006341857952065766
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019995172042399645Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010676832869648933

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008281696354970336
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011127651669085026
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003132682992145419
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015462350565940142
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010317210108041763
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001576133887283504Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003827603068202734

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0071921441704034805
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001626562443561852
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005815077573060989Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032997848466038704

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015233128797262907
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0075410958379507065
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024232789874076843
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008999192505143583
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003397064981982112
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007559049990959466
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021482394076883793Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003402018453925848

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009836724493652582
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004174575675278902
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021871323697268963Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008657540311105549
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036850241012871265

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001971740974113345
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015023812651634216
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012326425639912486
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016743867890909314
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0042165773920714855
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012025607284158468Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004981939680874348

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019970466382801533
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005387692712247372
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00148677674587816
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023833310697227716
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005946627818048
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013584927655756474Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028023826889693737
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02630775421857834

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005518491845577955
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007440577261149883
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005692479200661182
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008721831254661083Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028092493303120136

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008292184211313725Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002661047736182809
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016673089703544974

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021888476330786943
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009318474680185318
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017391931032761931
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008456075564026833
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019382582977414131
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009184150956571102Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013627554289996624

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014212776441127062
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00965110119432211
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022086447570472956
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012432249495759606
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01156841404736042
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002488898579031229
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014906483702361584
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06006177142262459
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007766843307763338Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007163977716118097

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05222855880856514
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2675430178642273
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07440000027418137
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029469237197190523
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02401796355843544
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10945753753185272
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031528060790151358Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9439917206764221
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3997047245502472

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7957091331481934
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031116728205233812
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003200255101546645
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002968559740111232
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032659524586051702
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003531603142619133
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004578354302793741
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07063442468643188
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030226808041334152
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.032181672751903534
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04317295551300049
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8583039045333862
 12%|█▏        | 71/584 [07:40<50:51,  5.95s/it] 12%|█▏        | 71/584 [07:45<50:40,  5.93s/it] 12%|█▏        | 71/584 [07:43<50:51,  5.95s/it]Loss Loss Loss tensor(4.8223, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.8057, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.7925, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01026151329278946
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23470555245876312Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.32511427998542786
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18378476798534393

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04836656153202057
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.48160475492477417Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011032884940505028
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0808948278427124

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009396116249263287Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.28796443343162537
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.204938605427742

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021359373931773007
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003676035674288869
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016582312062382698Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002596033737063408
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0058702221140265465

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000553500431124121Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003274150367360562

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009333781898021698
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003985384537372738Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009975562803447247
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009042571182362735

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000721747986972332
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010374256409704685
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013952117878943682
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000927173939999193
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0077506303787231445
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017419428331777453
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001157994382083416
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007105719763785601
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017228382639586926Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012748318258672953

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00935815554112196
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008827802375890315
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004678851459175348
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013267843751236796
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007819547899998724
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004698657430708408
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013126065023243427
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010436370503157377
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005635556764900684
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010150986490771174
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005092965438961983
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00137159728910774
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001966916024684906
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018974557518959045
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008515700465068221Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002158125163987279

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0061240727081894875
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002603173954412341
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007255948148667812Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000829836877528578

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003005820559337735
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00803773757070303
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001017685979604721
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034329365007579327
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009037056006491184
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009534428245387971
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00495890062302351
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03397732228040695
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002956811338663101
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036027252208441496
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010225611738860607
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002683141967281699
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001219907426275313Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011896329000592232

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002182573080062866
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011132314801216125
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014046537689864635
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001718830200843513
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012838725931942463
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013610349269583821
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016373558901250362
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012250855565071106
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014493860071524978
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018358852248638868
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012423339299857616Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013117281487211585

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004981471225619316Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015803867718204856
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014289404265582561

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005920511670410633
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002030763076618314
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01635846123099327
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23009003698825836
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08631020784378052
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021783632691949606
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01842126064002514
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07250078022480011
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002113207010552287
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2666524350643158
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07726406306028366
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8709492087364197
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11682022362947464
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002226511249318719
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8985488414764404
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021720302756875753
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002199070295318961
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026235284749418497
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003191293915733695
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.048855073750019073
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020527375862002373
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015246965922415257
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0225494597107172
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8419902920722961
 12%|█▏        | 72/584 [07:52<51:11,  6.00s/it] 12%|█▏        | 72/584 [07:46<51:19,  6.01s/it] 12%|█▏        | 72/584 [07:49<51:19,  6.01s/it]Loss Loss Loss tensor(4.4720, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.8268, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.0183, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1964276283979416Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018954183906316757

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.331069678068161
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11582845449447632
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5781736969947815Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12083198130130768
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005300917197018862

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01026445347815752
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.34404537081718445
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032591165509074926
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05335713550448418
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00017470913007855415
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009589794091880322Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008888534503057599
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021043738524895161

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00145975302439183
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00037028358201496303
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00026622790028341115Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023456241469830275

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00031081639463081956Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025915268342942Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006055405829101801


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00041345442878082395
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029300583992153406
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009335755021311343Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005659660091623664Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002369099063798785


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000816020998172462Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023664417676627636

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001208435627631843
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011237889993935823
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027849830221384764
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013781074667349458Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016379014123231173Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000689952343236655


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016196796204894781Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006450906512327492

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011263919295743108
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018722127424553037
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009097084403038025
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001161080552265048Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017029825830832124

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008023236296139657
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004606476053595543
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018931964877992868Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010767736239358783

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016835577553138137
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016779275611042976
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019870735704898834
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000768889905884862
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002022314118221402
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021389080211520195
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023777238093316555Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002456170739606023
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007389847887679935

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027639262843877077
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00918532069772482
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008996424148790538
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005808799061924219
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031875513959676027
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007613896741531789Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025924332439899445Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036323198582977057


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023654350079596043
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00327106611803174
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021788817830383778
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019090771675109863
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003411322832107544
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008669099770486355
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015132349217310548Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003382268361747265

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009628511616028845Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003448842791840434
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011790760327130556

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036012609489262104
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012366673909127712
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001131835044361651
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004153646528720856
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010992324678227305
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013062374200671911
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027670353651046753
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012959599262103438
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003609713865444064Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006312395446002483
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023149190470576286

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.24657213687896729
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.049748893827199936
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015849294140934944
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03673788532614708
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06210274621844292
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017180024879053235Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9803676009178162
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3936108946800232

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7446037530899048
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001557615352794528
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015774487983435392
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015243043890222907
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015591233968734741
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016803947510197759
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001972993602976203
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.034265369176864624
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016347957774996758
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026195473968982697
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.033904269337654114
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7897444367408752
 12%|█▎        | 73/584 [07:51<50:07,  5.89s/it] 12%|█▎        | 73/584 [07:57<50:02,  5.88s/it] 12%|█▎        | 73/584 [07:55<50:07,  5.89s/it]Loss Loss Loss tensor(5.0213, device='cuda:0', grad_fn=<NllLossBackward0>)tensor(4.6559, device='cuda:2', grad_fn=<NllLossBackward0>)

tensor(4.6972, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02428281120955944
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2950565218925476Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3107382655143738

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5214232802391052Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007242477964609861
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.31471773982048035

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.055431708693504333
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00539487274363637Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.35182812809944153

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02714693360030651
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.948183287633583e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01671483740210533
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15761148929595947
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012122761836508289
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00031634251354262233Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013580360682681203

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015708713908679783
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022382824681699276
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005181874148547649Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001810176036087796

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021955158445052803
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003651311155408621
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007877167081460357Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00029002156225033104

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003907337784767151Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005295472801662982

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009555220603942871
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010337346466258168Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004825671669095755

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012604158837348223
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005217122379690409
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00428792554885149
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011039559030905366
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004751414817292243
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004652920179069042
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001282364595681429
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000744118879083544
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007152074482291937
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014125427696853876
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007098327041603625
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003238501725718379
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000797220622189343Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002111769514158368
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00322897220030427

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00214006588794291
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037155221216380596
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000744444492738694
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002715787384659052
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003600479569286108
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008997651166282594
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031612711027264595
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01387501135468483
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009315773495472968
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036124526523053646
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005911223124712706
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007126855663955212
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038663228042423725
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032424128148704767Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007130013778805733

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016904051881283522
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029987541493028402
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00890342053025961
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001978839747607708
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024593567941337824
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01235264539718628
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026561052072793245Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019905201625078917
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.032703716307878494

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015908974455669522
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014591467566788197
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035578878596425056
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017025134293362498
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015578839927911758
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00758172245696187Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015490115620195866

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01326614711433649
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00186326599214226
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0041802143678069115Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01295017171651125

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00778504554182291
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011197702959179878
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00433627562597394
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2571052312850952
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011381059885025024
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.041920218616724014
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035790170077234507
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011807487346231937
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3905890882015228
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7472627758979797
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003259817138314247Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013799190521240234

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11111148446798325Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002942749997600913

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1006455346941948
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028627035208046436
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17198437452316284
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2671392858028412
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003049451159313321
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8635520935058594
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034214805345982313
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08145542442798615
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.040212132036685944
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0640079602599144
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08805593103170395
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7876802682876587
 13%|█▎        | 74/584 [08:02<48:00,  5.65s/it] 13%|█▎        | 74/584 [07:57<48:04,  5.66s/it] 13%|█▎        | 74/584 [08:00<48:04,  5.65s/it]Loss Loss Loss tensor(4.8888, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.8912, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(5.2128, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3232392966747284Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18579673767089844
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014348297379910946

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04617933928966522
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08716806769371033
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7994778156280518Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026865296065807343

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005461457651108503Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08748798072338104Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010379176586866379


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013462950300890952
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011480863206088543Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.41113534569740295
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00023010466247797012

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.9622177205746993e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.105163705185987e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004539346555247903

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.5908539100782946e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004888182156719267
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.279939068714157e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.666751945274882e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000706931110471487
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.439782060217112e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.426378190051764e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008723321952857077
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.258172652451321e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010568950528977439
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014785678358748555
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010594357445370406
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015049395733512938Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032072258181869984
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00037066321237944067

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016482218634337187
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008427374414168298
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001885599922388792
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021275582257658243
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003344899450894445
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00038125592982396483
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002932811388745904
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00037530765985138714
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005772667936980724
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003198803635314107
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007635537767782807
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00041779185994528234
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009869538247585297
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009223510860465467
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005291880224831402
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0040831551887094975
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002021980006247759
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004767914302647114Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000820593093521893
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002772602951154113

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005204756278544664Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033567354548722506

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009253398166038096
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00606669532135129
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037997979670763016
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019279991975054145
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012542742304503918
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004125551320612431
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013290251372382045
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005491397809237242
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005475297104567289
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015029828064143658
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006049768533557653
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032655224204063416
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017318867612630129
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005720533896237612
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029360917396843433
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019490832928568125
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005433306097984314
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024231900461018085
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030971013475209475
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0055032637901604176
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001980308908969164
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018081263406202197
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005653084255754948
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016358650755137205
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018678826745599508Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005958809517323971

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001766934641636908
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007443471811711788
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017941651167348027
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016485094092786312
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030106784775853157
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016101672081276774Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020228552166372538

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030275408178567886
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007372722961008549
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016131127486005425
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03338176757097244
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.32099592685699463
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016980883665382862
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.060323163866996765
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027185622602701187
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017455174820497632Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.973505973815918

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3459330201148987
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022766306065022945Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7742258310317993

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020391002297401428
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012062515132129192
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011808640323579311
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016594724729657173
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5051342248916626
 13%|█▎        | 75/584 [08:02<47:24,  5.59s/it] 13%|█▎        | 75/584 [08:08<47:22,  5.58s/it] 13%|█▎        | 75/584 [08:05<47:24,  5.59s/it]Loss Loss Loss tensor(4.4938, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.9659, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(5.1479, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18761566281318665Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022793887183070183
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18765169382095337

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12972493469715118
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03943707048892975
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1542956680059433Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011401655152440071

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01850561425089836
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007387975230813026
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4601045250892639
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08980248123407364
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.0271441169606987e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.0164798924233764e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02068270370364189
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.4945127986720763e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011551377247087657
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.335056706215255e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.3863698515924625e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002532713406253606
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.568321310216561e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.9417444238788448e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003196965844836086
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.288310810807161e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.088875958696008e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005442770197987556
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.866088708397001e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007960684015415609
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012255003093741834
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004405038198456168
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014803363010287285
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021359584934543818
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011268032249063253
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003547458676621318
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00032811504206620157
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00035540718818083405
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016137078637257218
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006955674034543335
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003304863930679858
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002010107273235917
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001214509247802198
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007385105709545314
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002634771168231964
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007327993516810238
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008696871227584779
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029193097725510597
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008896226645447314Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024879660923033953

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008700109086930752
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024071040097624063
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003544062841683626
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012596908491104841
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004266511648893356
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029787893872708082
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00148196320515126
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005043112672865391
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033932647202163935
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006534066051244736
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004420458804816008
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003832592163234949
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018131926655769348
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002022581174969673
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007524468936026096
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007313070818781853
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002305989619344473Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007738714572042227Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035342564806342125


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00688382750377059
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033235526643693447
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002876600483432412
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007054067682474852
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027498595882207155
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036629149690270424
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006244574207812548
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023006158880889416
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007742037996649742
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006509097758680582
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018746507121250033
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004043942783027887Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006606406066566706

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001990784890949726
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007717813365161419
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0041977036744356155Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018263190286234021

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.052516721189022064
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021845188457518816
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035247388295829296
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.051009051501750946
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009809181094169617
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034187985584139824Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05328240618109703

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3477230668067932
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09001678228378296
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032535649370402098
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9682901501655579
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03770339861512184
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00315543613396585
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.477365106344223
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032832170836627483
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6483520865440369
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038203056901693344
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08220644295215607
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04031303897500038
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03523198887705803
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05334150046110153
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9632337689399719
 13%|█▎        | 76/584 [08:09<50:03,  5.91s/it] 13%|█▎        | 76/584 [08:14<50:01,  5.91s/it] 13%|█▎        | 76/584 [08:12<50:02,  5.91s/it]Loss Loss Loss tensor(4.1689, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.5126, device='cuda:0', grad_fn=<NllLossBackward0>)tensor(4.5675, device='cuda:2', grad_fn=<NllLossBackward0>)

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3969970643520355Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005943437106907368
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21111246943473816

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.37074005603790283
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08210619539022446
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8691172003746033Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09406757354736328
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012523596175014973

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11637557297945023Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14364385604858398
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007167050149291754

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022545139654539526
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1317976714053657e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006152461748570204Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003772679774556309

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.4631084923166782e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.7577980543137528e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006619435152970254

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.0357607354526408e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008212692919187248
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.069924787268974e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.56080566032324e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012690008152276278
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.515630305628292e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.8261787014780566e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001706907176412642

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.696974039892666e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002448182087391615
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.568888784386218e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011342226935084909
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037746569141745567
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.930035594152287e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00020765388035215437
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032630362547934055
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013494314043782651Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013951478467788547

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004469456151127815
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00020389151177369058
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022430135868489742Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00645515276119113

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000433561421232298
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007761516608297825
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002809110446833074
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018634231761097908Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003118503373116255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006533330888487399

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009718459099531174
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011834694305434823
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00039510888746008277
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01150535885244608
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019447555532678962
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006430275971069932
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013598156161606312
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002311338670551777
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017531709745526314
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007749322685413063Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026752050034701824

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019090751186013222
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028924348298460245
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011154772946611047Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015878433361649513

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003007239894941449
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015620945952832699
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010964175453409553
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002237895503640175
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01310050580650568
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001265374943614006
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020105966832488775
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011487023904919624
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015484399627894163
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016716780373826623
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010196082293987274
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019111336441710591Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014315369771793485
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010507962666451931

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012019150890409946
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01065334863960743
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020785110536962748
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013128590071573853
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01528861839324236
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001779685029760003
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012492663227021694Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03345256671309471

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017161256400868297Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.041802674531936646
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001513649825938046

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0671941414475441
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005692432168871164
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013735078973695636
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10795678198337555
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2803017199039459
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9509522914886475
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011391290463507175Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019455986097455025

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.26820531487464905
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00106306211091578
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8311169147491455
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010795833077281713
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010833899723365903
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015007656766101718
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030119922012090683
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003582135308533907
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007225332781672478
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012203913182020187
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2944239675998688
 13%|█▎        | 77/584 [08:15<51:28,  6.09s/it] 13%|█▎        | 77/584 [08:21<51:27,  6.09s/it] 13%|█▎        | 77/584 [08:19<51:29,  6.09s/it]Loss Loss Loss tensor(4.9492, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.9956, device='cuda:2', grad_fn=<NllLossBackward0>)tensor(5.3256, device='cuda:1', grad_fn=<NllLossBackward0>)

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05944003909826279
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1297232210636139Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016493109986186028
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11760974675416946

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.22084683179855347
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13592968881130219Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01572728343307972
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008619951084256172

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02191953919827938
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004622387234121561
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15985804796218872
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011462275142548606
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003699973691254854Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.2278221877058968e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00019502437498886138
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.8829894290538505e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.7428111681947485e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00034082509228028357
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.0953462303150445e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00041628172039054334
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.588154792552814e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.031490218243562e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006226637633517385
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008048375602811575Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.275278428802267e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010249980259686708
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.267167479265481e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010737773118307814Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001211771392263472

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00018939506844617426
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011678325245156884
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004614790959749371
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014001679664943367
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014634045073762536
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021208553516771644
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00020884520199615508Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020239599980413914

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002931752533186227
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023226761259138584
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006155566079542041Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00027186109218746424

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004071569070219994
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008714079740457237
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00038721441524103284
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002702353522181511
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017770283157005906
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003071372164413333
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023705000057816505
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00043790784548036754
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003609443549066782Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028920460026711226

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004648842441383749
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032259661238640547Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004394554533064365

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003525263164192438
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00481615774333477
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005408775177784264
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0050385016947984695
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003803091589361429
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008050005999393761
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027505827601999044Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036606439389288425

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033949625212699175
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009143731440417469Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025528217665851116

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003399880602955818
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002152848057448864
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001506628468632698
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030681893695145845
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018646942917257547
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001209333655424416
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033133579418063164
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015647188993170857
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003517461009323597
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017230166122317314
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013171423925086856
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0048862420953810215Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001642450224608183

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016243190038949251
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020036017522215843
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015867076814174652
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019174352055415511
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007205310743302107Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0158709604293108

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020399936474859715Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3158656060695648Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03885377570986748


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04644860699772835
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.041618216782808304
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016917153261601925Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9886974096298218

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4063463509082794
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016371285310015082Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8115119934082031

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014039367670193315
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012887308839708567
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001303089433349669
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013274757657200098
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014471804024651647
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017886593705043197
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016861077398061752
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0076223076321184635
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018736911937594414
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019049599766731262
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9816144108772278
 13%|█▎        | 78/584 [08:23<55:22,  6.57s/it] 13%|█▎        | 78/584 [08:29<55:21,  6.56s/it] 13%|█▎        | 78/584 [08:26<55:22,  6.57s/it]Loss Loss Loss tensor(4.4260, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.8896, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.3406, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.35957759618759155Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021978158503770828Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13311639428138733


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12042471021413803
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1558513194322586
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8842435479164124Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017618974670767784
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05683626979589462

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00644564488902688
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2920941412448883
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06847366690635681Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003957247361540794
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.2910949408251327e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.188037125160918e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.6775276890257373e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.789020284893923e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011404384713387117
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.4159395504975691e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.344778476981446e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021411475609056652
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.7238582333666272e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.1281819499563426e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022910260304342955
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.453857425483875e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00032115078647620976
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.5838721891632304e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.401323217782192e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004984377883374691
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002947613247670233
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.30941220454406e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008927839808166027
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007742135785520077
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00028495065635070205
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022428184747695923
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.532599607249722e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003534602001309395
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010826517827808857
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011859174264827743
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008044479764066637
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013824430061504245
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001114248181693256
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00024157889129128307Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019180676899850368

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002624653512611985
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023415659088641405
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013363045582082123
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006347280461341143Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034365912433713675

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001702982553979382Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003923999611288309
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004491189029067755

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005321270786225796
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005121190100908279
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00025895918952301145
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006457204930484295
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005625985097140074
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003495030978228897
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008792872540652752
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00782226026058197
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009880296420305967Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014527210034430027

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004095379263162613
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008863847702741623
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037081956397742033
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006731864996254444
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009344196878373623
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003043816424906254
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00783576536923647
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008779896888881922Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002568166935816407

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007450407836586237
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021015231031924486
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011284402571618557Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006845137570053339

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022838274016976357
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006553265266120434
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021453704684972763
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014883861877024174
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007219989784061909
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002609041053801775
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021174801513552666
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007609833497554064
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009521042928099632
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3132525384426117
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05014210566878319
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015458922134712338
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03733209893107414
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.046081509441137314
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015881244326010346
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3393835723400116
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.061957430094480515
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8272828459739685
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012650208082050085Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09631399065256119

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9650751948356628
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011475671781226993
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009695738554000854
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009681349620223045
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010263699805364013
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012886460172012448
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01399364322423935
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008809011429548264
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017847103998064995
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01720360480248928
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2963937520980835
 14%|█▎        | 79/584 [08:36<56:29,  6.71s/it] 14%|█▎        | 79/584 [08:30<56:29,  6.71s/it] 14%|█▎        | 79/584 [08:33<56:29,  6.71s/it]Loss Loss Loss tensor(4.8491, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.7131, device='cuda:1', grad_fn=<NllLossBackward0>)tensor(4.7640, device='cuda:0', grad_fn=<NllLossBackward0>)

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4164389371871948Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17328865826129913

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2080714851617813
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8187833428382874
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06591031700372696
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00768957007676363
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08759473264217377
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006867871154099703Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005856038769707084

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009738189983181655
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.140881254803389e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001611715997569263
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013499276246875525Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001841217395849526

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023979218676686287
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00020604778546839952
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025791535153985023
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00024864572333171964Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029208955820649862

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034464076161384583
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00032713316613808274
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026465109549462795
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003438458952587098
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031058969907462597
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0042148916982114315
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00044379071914590895
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004592545796185732
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000439923198428005
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01008934248238802
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004122115205973387
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0060628377832472324
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004608675662893802
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007850165478885174
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006628528353758156
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008996323682367802
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000738944741897285
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01178770326077938
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01355062983930111
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001021752250380814
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010144985280930996
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011085228761658072
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010120009072124958
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013900601770728827Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008332230150699615

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008294404484331608
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016357711283490062
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00759683083742857
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002040019491687417
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0075143687427043915
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002270093420520425
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00829391460865736
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018707109848037362
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012863416224718094
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018618907779455185Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028717001900076866

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028939317911863327
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014975749654695392
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04969135299324989
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013679398689419031
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06484188139438629
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.95127934217453
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013741436414420605
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012945797061547637
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014376008184626698
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019674741197377443
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005754861515015364
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004312568344175816
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0069823055528104305
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009030682034790516
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.39477217197418213
 14%|█▎        | 80/584 [08:36<54:23,  6.47s/it] 14%|█▎        | 80/584 [08:39<54:23,  6.47s/it]Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010383877903223038
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13668973743915558
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01735256053507328
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2884947955608368
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.349123916355893e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.465441689826548e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001291441440116614
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015533521946053952
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00017938022210728377
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021105955238454044
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00035003156517632306
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006673785974271595
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00047106423880904913
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006397676770575345
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012520173331722617
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016691670753061771
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002888972871005535
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004184612538665533
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005113060120493174
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005715580191463232
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006148295011371374
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005905519239604473
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004201875533908606
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037724561989307404
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031089135445654392
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002630408853292465
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002132682828232646
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00235419487580657
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022168790455907583
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027271434664726257
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0074119181372225285
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3166894018650055
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030583929270505905
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3357528746128082
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8266987800598145
 14%|█▎        | 80/584 [08:42<55:23,  6.59s/it]Loss LossLoss tensor(4.4011, device='cuda:1', grad_fn=<NllLossBackward0>)
 tensor(4.7065, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.4366, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23612260818481445Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4804152548313141
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012632361613214016

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11431711912155151
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.27613672614097595
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.843144953250885Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0248067956417799
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14858639240264893

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13419568538665771
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2114461213350296
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008352597244083881
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014321611961349845
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001075060063158162
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00564955361187458Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023749498650431633
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013713266525883228

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.468812640989199e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003865048987790942

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00018642879149410874
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0045421551913022995
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001598685485078022
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002254906139569357
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005960443988442421
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00024525096523575485
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00025300082052126527
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006143959239125252
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006655015517026186Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00027954872348345816Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003013609675690532


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003489113296382129Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006713456008583307

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00039867221494205296
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004802008916158229Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005476916208863258

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00039898703107610345
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00047096353955566883
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005984909366816282
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004840064502786845Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005980248097330332
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00788373313844204

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010572614846751094
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008575192652642727
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00042819546069949865
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013521219370886683
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018817486241459846
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004022381326649338
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002306438982486725
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010337050072848797
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00041194763616658747
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003158788662403822
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01332845725119114
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005870781606063247Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037028007209300995

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015438524074852467
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004343647044152021
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019306477159261703Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006483427714556456

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004698887001723051
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021229831501841545
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009251981973648071
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005011325236409903
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01757095381617546
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009050168446265161
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033078454434871674
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01700441911816597
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001137827057391405
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014226575382053852
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029160231351852417
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01256751548498869Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013715983368456364Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002392176305875182


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011102166026830673
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002029143273830414
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016767941415309906
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010633835569024086Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016198685625568032

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018489696085453033
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017728928942233324
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01126833725720644
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001588419545441866Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016653204802423716

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015145919285714626
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019857787992805243
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04148727282881737
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015103815821930766
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005973495077341795Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04602416232228279

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012332831975072622
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.27795279026031494
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.078829325735569
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001041378709487617Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029326729476451874

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19277840852737427
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.32755962014198303
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9166321754455566
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8322705030441284
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009080901509150863
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000897818710654974
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000968138687312603
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012276426423341036
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004216945730149746
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003574848873540759
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01158176176249981
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017198042944073677
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.24025198817253113
 14%|█▍        | 81/584 [08:43<57:05,  6.81s/it] 14%|█▍        | 81/584 [08:49<56:46,  6.77s/it] 14%|█▍        | 81/584 [08:47<57:05,  6.81s/it]Loss Loss Loss tensor(4.5668, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.6359, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.9894, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6381528377532959Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029871834442019463

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10560529679059982
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6275653839111328Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.48055195808410645

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18890079855918884
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010994627140462399
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00994854886084795
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07276424765586853
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6190470457077026
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014868220314383507
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.558251410140656e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21466030180454254
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.055345536675304e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.4816493755206466e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00032338345772586763
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.479258056264371e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004603845882229507
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.850624802405946e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010066914546769112Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.933980330359191e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007864972576498985
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.949044422479346e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012364434951450676Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008403715910390019
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001269894273718819

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005944413715042174
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012609843397513032
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00020338479953352362
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014519389951601624
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015781145775690675
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00025013540289364755
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006275537307374179
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028126651886850595
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00047922023804858327
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005622772732749581
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0067845978774130344
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008294613799080253
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010107961716130376
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030810029711574316
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010389902163296938
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004610107571352273
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034499079920351505
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028031219262629747Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005171204102225602

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004156054463237524
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023511750623583794
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006446324987336993Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038554188795387745

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028315007220953703Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016731074079871178

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007248166366480291
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031425636261701584
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00463285855948925
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027981731109321117Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034262763801962137

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005435172934085131
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008022552356123924
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009655667236074805Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005468366667628288

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026968680322170258
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006119250785559416
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001099599408917129
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002484662691131234
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0350012481212616
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001168156391941011Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002042478648945689

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007317563518881798Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013330192305147648
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017299526371061802

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013747905613854527
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00840972363948822
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005252310540527105
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014734036521986127
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007803216576576233
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015680063515901566
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013809310039505363
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009300020523369312
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015971899265423417
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016991582233458757
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00821482390165329
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00681665213778615
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001589366002008319
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008487205021083355
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1867552548646927
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016868853708729148
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009386609308421612
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03590879961848259
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010190527886152267Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015507100615650415Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.307394415140152


Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6883084774017334
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10116945952177048
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015904527390375733
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08331294357776642
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017857926432043314
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1116546019911766
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020469778683036566
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20358437299728394
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04819425195455551Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7801170349121094

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023359576240181923
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04154102876782417
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04675305262207985
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.43789994716644287
 14%|█▍        | 82/584 [08:55<53:49,  6.43s/it] 14%|█▍        | 82/584 [08:49<54:03,  6.46s/it] 14%|█▍        | 82/584 [08:52<54:02,  6.46s/it]Loss Loss Loss tensor(4.5096, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.4994, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.3331, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6711431741714478Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03544047474861145

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10919506102800369
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3299398124217987Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7360482215881348
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015711307525634766

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12151634693145752
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015318755991756916Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8313840627670288

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001469306298531592
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08318261057138443
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021486559882760048Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00018581314361654222
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.299157977104187

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016186571447178721
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002433351764921099
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004331170639488846
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00029009635909460485Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025882406625896692

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007054395391605794
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003184978850185871
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00393835362046957
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001025301986373961Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003725968999788165

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004357483237981796
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008888671873137355
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001178822829388082
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005271906964480877
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001961267087608576
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014635376865044236
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001060345908626914
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004835860803723335
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009336427901871502
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001262866659089923Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005747479386627674

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013796775601804256
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01009748037904501
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015720704104751348
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010983225656673312
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005689023993909359
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001968494849279523Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003148559480905533

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005890699569135904
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002296661725267768
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001360658323392272
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006991258356720209
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00250582629814744
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00135735550429672
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002943221712484956
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006226681638509035
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017124348087236285Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003194430610165
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021337199956178665

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009700781665742397
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006620918400585651
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017003691755235195
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00241469987668097
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0076830703765153885
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004859853535890579
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021741397213190794
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00750133628025651
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018080610316246748
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020702669862657785
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008677711710333824
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015145490178838372
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.037897706031799316
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023586235474795103
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012112277327105403
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008556714281439781
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024548412766307592Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013077437179163098

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00948439072817564
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001237794873304665
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027752858586609364
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008781183511018753
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001404251204803586
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008548091165721416Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009258599951863289
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005187737289816141

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15912379324436188
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008975697681307793
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027356951031833887
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03979900851845741
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009839081205427647
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028594329487532377
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23858723044395447
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011067946441471577
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4597298204898834
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002620989689603448
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013194233179092407
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002532263984903693Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12044116109609604

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10026143491268158
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024612140841782093
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14705637097358704
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026069481391459703
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19147761166095734
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002863934263586998
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5107768774032593
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034416138660162687
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.060341086238622665
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.036662064492702484
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07172262668609619
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0642131045460701
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6523439288139343
 14%|█▍        | 83/584 [09:01<52:31,  6.29s/it] 14%|█▍        | 83/584 [08:55<52:41,  6.31s/it] 14%|█▍        | 83/584 [08:58<52:41,  6.31s/it]Loss Loss Loss tensor(4.6001, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.4581, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.5542, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5473341941833496Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014133594930171967
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3575746715068817

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17299678921699524
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14956116676330566
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7692519426345825Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020863816142082214

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12563775479793549
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01055699959397316
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3720662593841553
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17465756833553314
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009904760867357254Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014766764070373029

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001713141449727118
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00019237172091379762
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002743036486208439
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00019281372078694403
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000264223461272195
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00032153306528925896
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0042671686969697475
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00034013844560831785
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0050171492621302605
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00043988789548166096
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004905338282696903
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006978951394557953
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000596077530644834
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006131351110525429Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00680309534072876

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009307495784014463
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00766718527302146
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008559687412343919
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013367340434342623
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008328666910529137
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008138319244608283Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012688043061643839

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006951052229851484
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001355271670036018
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007222867105156183
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000978614785708487
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021824154537171125
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009755768813192844
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009164231596514583
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002576500177383423
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010543783195316792
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004155580885708332
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008677066070958972Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020053237676620483

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005796300247311592
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014704904519021511
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008634772384539247
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007084620650857687
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018578119575977325
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012399394763633609Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00775963393971324

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021368978545069695
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00817058514803648
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024955349043011665
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013800000306218863Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007342192344367504

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027069013565778732
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005390049424022436
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019659751560539007
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01885928586125374
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004785264376550913
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020860228687524796
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01766272634267807
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003940024878829718
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002541030989959836Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015359572134912014
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003263432066887617

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013463105075061321
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025083362124860287
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030283178202807903
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01181301660835743
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027057132683694363
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034840498119592667
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012409566901624203
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026034305337816477
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035183948930352926Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01393512636423111
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003089796518906951

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01898140460252762
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006652622018009424
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028161967638880014
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05463984236121178
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.27157333493232727
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002719011390581727
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06133386492729187
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024019917473196983
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022757048718631268
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07644826173782349
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2874492108821869
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001882630749605596Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8207283020019531

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1179933026432991
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8784500956535339
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018305729608982801
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018646464450284839
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002017167629674077
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025689476169645786
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016404153779149055
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010253247804939747
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011127311736345291
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01320380624383688
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3281702399253845
 14%|█▍        | 84/584 [09:08<53:55,  6.47s/it] 14%|█▍        | 84/584 [09:02<54:01,  6.48s/it] 14%|█▍        | 84/584 [09:05<54:01,  6.48s/it]Loss Loss Loss tensor(4.8596, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.3954, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.9110, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5931713581085205Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010862909257411957
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.35579442977905273

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3848625123500824
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1648813784122467
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.668161928653717Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024015814065933228

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12157242000102997
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012514473870396614Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4124276340007782

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001035878958646208Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01166500337421894

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16899409890174866
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001351050304947421
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010920424247160554
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014525819278787822
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001729776500724256
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00023687997600063682
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001854945730883628
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002664836123585701
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002350872673559934
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00035258670686744153
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003042090917006135
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00030589933157898486
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00041861325735226274Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004159071948379278

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004265489405952394
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006902663153596222
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004367509391158819
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011503864079713821
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005158782005310059Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005657667061313987

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009771637851372361
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006518058944493532
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005818625795654953
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010774055263027549
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005075371358543634
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001808763132430613
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000764614378567785Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005640586372464895

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002195486333221197
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0076248846016824245
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008072661003097892
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003650182858109474
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00807381235063076
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007445490336976945
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004805273842066526
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017929082736372948
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0056146131828427315Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000793333922047168
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010758315213024616

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006087342742830515
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013956278562545776
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001153484801761806
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00630368385463953
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015201196074485779
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012640998465940356
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006074308417737484
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01771809160709381
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019444606732577085Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0040976181626319885
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02245393954217434

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036108975764364004
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013748266734182835
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018296007765457034
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029939403757452965
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012600958347320557
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023001329973340034Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002512820065021515

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010720441117882729
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019153744215145707
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010015862062573433
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002559647196903825
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002078649355098605
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008823461830615997
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029337771702557802Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019988941494375467
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009352837689220905

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023332135751843452
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010108459740877151
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003201564308255911
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005468003451824188
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01362260989844799
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.22327980399131775
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024050266947597265Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04375123605132103

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023038504645228386
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04683502018451691
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002259853295981884
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.24208344519138336
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.049772027879953384
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7561836838722229
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019099696073681116
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11469265818595886
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8832561373710632
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001693405443802476
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001605204539373517
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001663692994043231
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018289838917553425
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002320194151252508
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013595717959105968
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008666116744279861
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007381897419691086
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01886703446507454
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.44796034693717957
 15%|█▍        | 85/584 [09:13<51:40,  6.21s/it] 15%|█▍        | 85/584 [09:08<51:45,  6.22s/it] 15%|█▍        | 85/584 [09:11<51:45,  6.22s/it]Loss Loss Loss tensor(5.0685, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.4313, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.2557, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10104087740182877Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4800492823123932
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021742744371294975

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11537212133407593
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2721267342567444
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.831084668636322Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07595863193273544
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02687176503241062

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0076724146492779255Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1595468968153

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0702696368098259
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010114184988196939
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0055312421172857285Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006909282528795302
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001341279421467334

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010931040160357952
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.925779937068e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00019418988085817546
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017794219311326742
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002641337923705578
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001380255416734144Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022333848755806684

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003668863791972399
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035360378678888083
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022016062575858086Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004950198926962912

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003500808496028185
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007737113046459854
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004003406036645174
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00030048881308175623
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001094442792236805
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004004566930234432
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012545372592285275
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00047080227523110807Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038588037714362144

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013947029365226626
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003914263099431992
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00046642287634313107Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023048794828355312

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005176424514502287
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028328869957476854
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005542042199522257Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00561206741258502

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0047734384424984455
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00941980816423893
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005123476148582995Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006106311455368996

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006759988144040108
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0073954458348453045
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005151271470822394Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009307995438575745

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008345008827745914
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010908037424087524
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00050045718671754Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009002347476780415
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013597062788903713

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00936534721404314
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016021816059947014
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006953945849090815
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006101558450609446
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010504381731152534
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007724971510469913
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009932866320014
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005367636680603027
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011508590541779995Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008548153564333916Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004403808154165745


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008196370676159859
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00374569627456367
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010390754323452711
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00779009610414505
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002799359615892172
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001391799421980977Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00783346127718687
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00299057480879128

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028692905325442553Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008781159296631813

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017283610068261623
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032915999181568623
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012295452877879143
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0074222455732524395
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021218229085206985Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.042351238429546356

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3627067506313324
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04768698289990425
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023468853905797005
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04030466079711914
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0713542252779007
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018055600812658668
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3890672028064728
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11252572387456894
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016851391410455108Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7836964726448059
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9707286953926086

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013675912050530314
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011588847264647484
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010935090249404311
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011046704603359103
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011535099474713206
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014738908503204584
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00728546641767025
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006702212616801262
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019485263153910637
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016682423651218414
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2792319059371948
 15%|█▍        | 86/584 [09:14<52:22,  6.31s/it] 15%|█▍        | 86/584 [09:20<52:19,  6.30s/it] 15%|█▍        | 86/584 [09:17<52:22,  6.31s/it]Loss Loss Loss tensor(4.2886, device='cuda:0', grad_fn=<NllLossBackward0>)tensor(4.4465, device='cuda:1', grad_fn=<NllLossBackward0>)

tensor(4.3822, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6259092092514038Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023079756647348404
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8274186849594116

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21046826243400574
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11013298481702805
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7663648724555969
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02597934938967228
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1344132423400879
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011655964888632298Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8631769418716431

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.353223979473114
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011308483226457611
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014494111761450768Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013081432553008199
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000150233056047

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002099263481795788
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001349633384961635Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002135950344381854

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003414555685594678
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00027611746918410063
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022885426005814224
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003941591829061508
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00035720091545954347
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005639067851006985
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004575081984512508
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00035218975972384214
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005641654599457979
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004415043513290584Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009723760304041207

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007071221247315407
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020096914377063513
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006174175068736076
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010881996713578701
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011409580474719405
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005956346285529435
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006951758172363043Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011098423274233937

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017652050592005253Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007360612042248249

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007871559937484562
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009235953912138939
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018179253675043583
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008864985429681838
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00878974050283432
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003693327773362398
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007134531624615192
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025378739461302757
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033100249711424112
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007257616962306201Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009546794928610325

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003444019705057144
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012484459206461906
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003869368229061365
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009722218965180218
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012934278696775436
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004032853990793228
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010066535323858261Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01513633131980896

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008277924731373787
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04199331998825073
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002051791176199913
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028533763252198696
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011482544243335724
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025099257472902536
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012640678323805332
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010973673313856125
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020526573061943054
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016591688618063927
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009301524609327316
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017678672447800636
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009871548041701317
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001798203564248979
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013267291942611337
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008741002529859543
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001423993380740285
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020717012230306864Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009431317448616028

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013613651972264051
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0106144854798913
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00388539326377213
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001522096456028521
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013165787793695927
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001671245088800788Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005055766552686691
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10695994645357132

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16503925621509552
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09018144011497498
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015515758423134685
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02530079148709774
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11772118508815765
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012708563590422273
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12442844361066818
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19808417558670044
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3271573483943939
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.37696102261543274
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011702068150043488
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001135468715801835
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001198048354126513
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00130408292170614
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016570284496992826
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024793529883027077
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013295258395373821
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019386980682611465
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01418393850326538
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13840608298778534
 15%|█▍        | 87/584 [09:26<52:06,  6.29s/it] 15%|█▍        | 87/584 [09:20<52:08,  6.29s/it] 15%|█▍        | 87/584 [09:24<52:08,  6.29s/it]Loss Loss tensor(4.7625, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.5886, device='cuda:2', grad_fn=<NllLossBackward0>)
Loss tensor(4.8289, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.409659206867218
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5946148037910461Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02778056263923645
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.31044137477874756

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11868195980787277
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4915013909339905Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07941817492246628

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019368285313248634
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19931291043758392
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012384639121592045
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005889162421226501
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6762955784797668Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000904901884496212

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017571771517395973
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.970481576398015e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013753647217527032
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011833220924017951
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011738506145775318
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001460402854718268
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00018489055219106376
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018869872437790036
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001586349098943174
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020629356149584055
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001965576084330678
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002591166994534433Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029062959365546703

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000261867098743096
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005666676443070173
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002913750649895519
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003653826133813709Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031468451488763094

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00034748410689644516
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034659048542380333Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008117101970128715

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00037274492206051946Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004394012503325939Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001642853021621704


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001024885568767786Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004158434923738241

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005913977511227131
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009952718392014503
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01475343108177185
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008768985862843692
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016262782737612724Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004890021402388811

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000619079452008009
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018095873529091477
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005640759598463774
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006103519815951586Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037148878909647465

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006712718750350177
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007550426758825779
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038725617341697216
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009006366017274559
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02492564357817173
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004665046464651823
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009562970953993499Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006609431933611631
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005335565190762281

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0070797596126794815
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00575096532702446
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025043359491974115
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006436979863792658
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008926653303205967
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012433325173333287
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006876877974718809
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003989268094301224
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001480531063862145Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0063629248179495335

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035556084476411343
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006728763226419687
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029687799979001284
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016536021139472723
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007503132801502943
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025395373813807964
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020047856960445642Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00904811266809702

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019318906124681234
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06329861283302307
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0044752429239451885Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020804894156754017

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05619019642472267
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002002268098294735
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06324274837970734
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018718206556513906
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002250717021524906
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08245551586151123
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019208784215152264Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8187196850776672

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006768609397113323
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001759712235070765
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.26173335313796997
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016044466756284237
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04104665666818619
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3378790020942688
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001575941452756524
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.585431694984436
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016409229720011353
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017937328666448593
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002127061365172267
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028332790359854698
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01628694124519825
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022853530943393707
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01892036385834217
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6343362331390381
 15%|█▌        | 88/584 [09:29<57:38,  6.97s/it] 15%|█▌        | 88/584 [09:35<57:37,  6.97s/it] 15%|█▌        | 88/584 [09:32<57:38,  6.97s/it]Loss Loss Loss tensor(4.3296, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.4785, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.3166, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4445338249206543Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14624574780464172
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01939120516180992

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2545081377029419
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.25669020414352417
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.743931233882904Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07706087082624435

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012635979801416397
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08583628386259079
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007580199744552374
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00031043862691149116Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13443158566951752

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006178233306854963
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003749438328668475Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.3785278244758956e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.2251184165943414e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.201014260412194e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006425929022952914
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.44718316430226e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.755614645546302e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007988139986991882

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.02668767189607e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012867347104474902
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.709407898597419e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013703691365662962
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001726836897432804
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.830772614805028e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002552893420215696
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002475819317623973

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004900016356259584
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032650099601596594
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016354651597794145
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007273594965226948
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003115987405180931
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007276497781276703Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021582462068181485
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030914938542991877

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007373930420726538
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004007183481007814
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003114014398306608Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011809015413746238
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004592438228428364

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014890097081661224
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009866633452475071
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004036799364257604
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028224377892911434
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007517346180975437
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003903017845004797
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004064562381245196Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009038131684064865

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00525007164105773
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01037969347089529
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003961615148000419
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005973638501018286Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015274361707270145

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005369322607293725
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006442777346819639
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020171595737338066
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006430505309253931Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007279400713741779
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013462654314935207

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004322758875787258
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014052464626729488
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003830229863524437
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010832954430952668Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012269352562725544

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032073892652988434Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010669163893908262
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011620521545410156

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002737360307946801Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011221878230571747

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013144704280421138
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020651088561862707Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01104037370532751

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001613957341760397
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022115425672382116
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012224170379340649
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022744943853467703
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021495011169463396
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018309039995074272
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002964059356600046Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024338620714843273
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06554574519395828

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005968611221760511Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06651999801397324

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022612162865698338
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2799083888530731
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11323866248130798
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002279912354424596
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03616810590028763
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019765167962759733Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19149406254291534

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9164371490478516
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.31278666853904724
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016423725755885243Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8589046001434326

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016300121787935495
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016087155090644956
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00168359256349504
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002073038835078478
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010324982926249504
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009328012354671955
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022940056398510933
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02890009991824627
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.49724629521369934
 15%|█▌        | 89/584 [09:33<51:30,  6.24s/it] 15%|█▌        | 89/584 [09:39<51:29,  6.24s/it] 15%|█▌        | 89/584 [09:37<51:30,  6.24s/it]Loss Loss Loss tensor(4.0972, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.4764, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.1704, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6015365719795227
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.621368944644928Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11940758675336838

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.27638527750968933Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06806650012731552

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.27355876564979553
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0151155861094594
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008940112893469632
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02874067798256874
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014171929797157645
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002444606798235327
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002340251812711358
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00041991868056356907
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027395368088036776
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000658653094433248
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004190749488770962
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008571894722990692
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004105708561837673
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012676664628088474
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0052517070434987545
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012107229558750987
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008491536602377892
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00157988874707371
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005168666131794453
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018780125537887216
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005365182179957628
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014175582909956574
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006850901525467634
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014105213340371847
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006452163681387901
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018721778178587556
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01894630305469036
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019603227265179157
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007595145143568516
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004901430103927851
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009027590043842793
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026364841032773256
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008805306628346443
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030051744543015957
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009270159527659416
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031513385474681854
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.038797199726104736
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003306256840005517
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00896722823381424
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00922346580773592
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010096250101923943
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031580233480781317
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009340200573205948
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033574611879885197
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010178363882005215
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003057762747630477
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009748639538884163
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030933478847146034Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010294564999639988

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011571508832275867
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030782341491431
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012547190301120281
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003086554817855358
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12437697499990463
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00371455866843462
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11180794984102249
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038839885964989662
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14576305449008942
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06534026563167572
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18129311501979828
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04259733483195305
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6775074005126953
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.077708899974823
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06175253912806511
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.721294105052948
 15%|█▌        | 90/584 [09:40<52:17,  6.35s/it] 15%|█▌        | 90/584 [09:43<52:16,  6.35s/it]Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.031146707013249397
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09209601581096649
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0132324593141675
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6611763834953308
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.898051990196109e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010826911602634937
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016055162996053696
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021840643603354692
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003134069265797734
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00042972309165634215
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008440563105978072
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001658200053498149
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010790351079776883
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010861438931897283
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001686811214312911
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017330552218481898
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003470756346359849
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028805697802454233
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003490935545414686
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003914582077413797
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004213592037558556
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009704278782010078
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002986121689900756
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026642843149602413
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022210488095879555
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019048390677198768
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014578233240172267
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015218937769532204
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014697947772219777
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001633714884519577
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005628238432109356
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19214090704917908
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03475825488567352
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23094166815280914
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6793534159660339
 15%|█▌        | 90/584 [09:46<53:25,  6.49s/it]Loss Loss Loss tensor(4.9359, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.4785, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.4807, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4740231931209564Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03143477812409401
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5876520872116089

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15117184817790985
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12094360589981079
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5934361815452576Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014563864096999168

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06846370548009872
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012517450377345085
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.736830472946167
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2882397174835205
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.2873321945080534e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029418082907795906Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00033918797271326184

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.893780689802952e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005045951693318784
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.205578003777191e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.616963168606162e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011486239964142442Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008586294716224074

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001174014323623851
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010367300128564239
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00018229600391350687
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00017402948287781328
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017642686143517494
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00026587280444800854
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00024556429707445204
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002150127897039056
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000740144110750407
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00041972444159910083Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016211109468713403
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035276359412819147

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008926873560994864
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007696858141571283
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005283365026116371
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008619347354397178Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038799098692834377

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000840022461488843
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00421101413667202
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014832285232841969
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005209035240113735
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013898451579734683Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016056355088949203

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004663944244384766
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003606714541092515
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008564277668483555
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01925494708120823
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003018690040335059
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009089234517887235
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005264913663268089
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003541755024343729
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0060945297591388226
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011620663572102785Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004013179801404476

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006255912594497204
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004413690883666277
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007742518093436956
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012197759933769703Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010500960052013397

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04424288868904114
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003444579429924488
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004451444838196039Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008661354891955853
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031330203637480736

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010384428314864635
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002635570243000984
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015092401299625635
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009573688730597496
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022631215397268534
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017374423332512379
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011031740345060825
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017496022628620267
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009889614768326283Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018190668197348714
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017605586908757687

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010767984203994274
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016723041189834476
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022348284255713224
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018364746356382966Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011577310040593147

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012841886840760708Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007287351414561272
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00888888817280531

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1297381967306137
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18732447922229767
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002586215268820524
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11529553681612015
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04045457765460014
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029655443504452705
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14298689365386963
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.25088781118392944
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026593944057822227Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5771192908287048

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.24273933470249176
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6627296209335327
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026888626161962748
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002575579797849059
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002700638724491
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032080719247460365
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003171354765072465
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07901462912559509
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04196073114871979
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08757834881544113
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07331166416406631
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6331513524055481
 16%|█▌        | 91/584 [09:54<55:52,  6.80s/it] 16%|█▌        | 91/584 [09:48<56:13,  6.84s/it] 16%|█▌        | 91/584 [09:51<56:14,  6.84s/it]Loss Loss tensor(4.2371, device='cuda:2', grad_fn=<NllLossBackward0>)tensor(4.6469, device='cuda:1', grad_fn=<NllLossBackward0>)

Loss tensor(4.6982, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.035310741513967514
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2776283323764801Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.49714395403862

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10198929160833359
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19165246188640594
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2644318640232086Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011069419793784618

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03986204415559769
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6666210889816284
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012922623194754124
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.819871199084446e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2249542474746704
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.039058052003383636
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.3576317441184074e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003308916056994349
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001303812168771401Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004936726181767881

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.170964429154992e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008793571614660323
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011676167923724279
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021845812443643808
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010927331168204546
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00019414683629292995
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00035699360887520015Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019298880361020565
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002927286259364337

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022047576494514942
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007493614102713764
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005321389762684703
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033202830236405134
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001622624695301056
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009143445058725774
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006800240371376276
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008943069842644036
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036977885756641626
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010481626959517598Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000825700000859797

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038322200998663902
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013256013626232743
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015030403155833483
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004635251127183437
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012845670571550727
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023875681217759848Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004044193774461746
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032768091186881065

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015048898756504059
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020499282982200384
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015492389211431146Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00428117485716939
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023989565670490265

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0053615877404809
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027279111091047525
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015484187752008438
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006076356396079063
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003058909671381116
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008253281004726887
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018564806086942554
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010602971538901329
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03283316642045975
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018142088083550334Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024850787594914436

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009384100325405598
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022778038401156664
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007423845585435629Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010467139072716236

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019394158152863383
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009118341840803623
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002085963962599635Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016609115991741419

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00967498030513525
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013297327095642686
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025165691040456295
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009097050875425339
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013314038515090942
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031247539445757866Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012550760293379426Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009947886690497398


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01076163724064827Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013432060368359089

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004355440381914377
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01188580971211195
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005630659405142069
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012791477143764496Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10248454660177231

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17515313625335693
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10239331424236298
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05031832307577133
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005287205800414085
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1332784742116928
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.31606364250183105
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20458664000034332
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005626027472317219Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6407211422920227

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7621763348579407
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004537624306976795
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004348407033830881
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038448090199381113
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003909975290298462
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0040398938581347466
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004410919267684221
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09562628716230392
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06428017467260361
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12003714591264725
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11403406411409378
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9000952839851379
 16%|█▌        | 92/584 [10:00<53:25,  6.52s/it] 16%|█▌        | 92/584 [09:54<53:40,  6.55s/it] 16%|█▌        | 92/584 [09:57<53:41,  6.55s/it]Loss Loss Loss tensor(4.4882, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.2411, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.8397, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7404953241348267Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8210546970367432

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0418531633913517
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07533411681652069
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.036687783896923065
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5033814907073975
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06323078274726868
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012790238484740257
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016024168580770493
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3345576822757721
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8684490323066711
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.039570365101099014Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006047418573871255

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.0961658164160326e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009801550768315792
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00020370168203953654
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.68447677930817e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016837009461596608
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00033797239302657545
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018257193733006716
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013117707567289472
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025707967579364777
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00017613591626286507
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005145972245372832
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002821044996380806
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00025317471590824425
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006239414215087891Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00461942795664072

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003641389776021242
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010512394830584526
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008297215099446476
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009606751846149564
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004851561039686203
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008440912934020162
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00219895550981164
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0052856081165373325
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014484140556305647Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000992376240901649

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006301870569586754
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008255441789515316
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005429618060588837
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025722223799675703
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013427563244476914
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023409713059663773
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012534713605418801Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011582552688196301
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00585643807426095

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004023242276161909Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0070925066247582436

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013269108021631837
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002008299808949232
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006422344595193863
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007936999201774597Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015042917802929878
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023841788060963154

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.047002580016851425
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027160905301570892
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016021139454096556
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009394163265824318
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002895873738452792
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008011328056454659
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011019619181752205
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012053702026605606
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002046138048171997
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010241973213851452
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002163661178201437
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011422309093177319
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024453254882246256Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019466651137918234

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011186694726347923
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016502923099324107
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00245786109007895
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012399032711982727
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001416542218066752
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030175987631082535Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014001963660120964

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011515601072460413
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014928140677511692
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013262181542813778Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011641541495919228

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15393617749214172
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011432053288444877
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036539901047945023Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15626496076583862

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001263305195607245
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14337792992591858
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003991236444562674
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004591567907482386
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17076995968818665
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.31948164105415344
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036798259243369102
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12408126890659332
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027191411703824997
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003693112637847662
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14528626203536987
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034862470347434282Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.45282864570617676

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003653016872704029
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004087753128260374
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00445743091404438
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08652037382125854
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06716381758451462
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08462405949831009
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0702204704284668
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4146791994571686
 16%|█▌        | 93/584 [09:58<48:50,  5.97s/it] 16%|█▌        | 93/584 [10:04<48:40,  5.95s/it] 16%|█▌        | 93/584 [10:02<48:50,  5.97s/it]Loss Loss Loss tensor(4.3740, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.4219, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.4130, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.44813063740730286
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3490537703037262Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.26197394728660583

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7593299150466919Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13027110695838928

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17651906609535217
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019057128578424454
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005507520399987698
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013684608042240143Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009544408530928195

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017610612558200955
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010828445374500006
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002521704649552703
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00020333558495622128
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004514279309660196
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005797797814011574
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000370212976122275Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007197624072432518

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009305547922849655
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005752812721766531
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007087350822985172
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009650939609855413
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007354286033660173
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012711192248389125
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008751978166401386
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016680252738296986
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009435843676328659
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001831874717026949Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017778655514121056

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011092914268374443
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001639235531911254
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01250455528497696
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013657476752996445
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015887372428551316
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01568377949297428
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019650645554065704
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03217034786939621
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013435661792755127
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002150116953998804
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013342656195163727
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003702921327203512
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012852348387241364
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026120624970644712
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013129638507962227
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002828448312357068Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011213025078177452

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01191256195306778
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032473423052579165
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013647692278027534
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036859193351119757Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01597421057522297

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0893137976527214
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005805986002087593Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10710754245519638

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.116681769490242
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033330535516142845
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2032882571220398
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003355162451043725Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.777230441570282

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030068187043070793
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002874118508771062
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002719518728554249
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026620253920555115
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002915505087003112
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003465662244707346
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05392429232597351
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03278939425945282
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.038889046758413315
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05055670067667961
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5411040782928467
 16%|█▌        | 94/584 [10:04<46:34,  5.70s/it] 16%|█▌        | 94/584 [10:07<46:34,  5.70s/it]Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03473915904760361
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.291365385055542
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01873897574841976
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4040474593639374
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.6169781853677705e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.937141733942553e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011488557356642559
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016853869601618499
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00025606551207602024
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00036122140591032803
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006100796745158732
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012134845601394773
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000850039126817137
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009670361177995801
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016576038906350732
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020115498919039965
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036612360272556543
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036835267674177885
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0045639523304998875
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004818944726139307
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005035466514527798
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008340072818100452
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035066267009824514
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003144235583022237
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002665995853021741
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00225836387835443
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017834443133324385
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016929616685956717
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017267516814172268
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020236242562532425
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0047647347673773766
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19176732003688812
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03412282466888428
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23324766755104065
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8109890818595886
 16%|█▌        | 94/584 [10:10<47:11,  5.78s/it]Loss Loss Loss tensor(4.3091, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.7234, device='cuda:0', grad_fn=<NllLossBackward0>)tensor(4.6232, device='cuda:2', grad_fn=<NllLossBackward0>)

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6465324759483337
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.657234251499176Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020481549203395844

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07412564754486084
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15721188485622406
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6543203592300415
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11238884180784225
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01274914015084505
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012541413307189941Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.28950774669647217

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003545760118868202
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6262442469596863
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017245903611183167
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006031231605447829
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.450808799243532e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.638847894966602e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.213765689404681e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011313405120745301
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.586065087001771e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015899465652182698
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.719319885130972e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015822899877093732
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00288700801320374
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012811549822799861
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00024448538897559047
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036276173777878284
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00019647764565888792
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00041474736644886434
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004989617969840765
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002644711930770427
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005348947015590966
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008789838291704655
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006358491373248398
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007298444397747517
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00473878113552928
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014089540345594287
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009536523721180856
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005067294463515282
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006727352156303823
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006503229378722608
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0059341066516935825
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006627973634749651
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000645061896648258
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0055055683478713036
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012421002611517906
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007579652592539787
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023022664710879326
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014639373403042555
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008342817891389132
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006663019303232431
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032311095856130123
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026896889321506023Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009071674197912216

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027374133933335543
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008591985329985619
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011345745297148824
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035767382942140102
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00902580190449953
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015990217216312885
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0042031146585941315
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04445817321538925
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015326099237427115
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004717952571809292
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009064706042408943
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001625629374757409
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008554523810744286
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01009813230484724
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005029458552598953
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036794492043554783
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009928662329912186
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015587419038638473
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032798084430396557
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013034525327384472
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016808235086500645
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027588598895817995
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010203178972005844
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016690457705408335
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002358430763706565
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010876873508095741
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017162964213639498
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018489767098799348
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01204610988497734
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016412900295108557
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017884252592921257
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014372984878718853
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017848642310127616
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017935923533514142
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11278021335601807
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019526187097653747
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020779878832399845
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12053929269313812
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005866832099854946
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022142184898257256
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09925069659948349
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20397411286830902
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10919596999883652
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04671541601419449
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024308688938617706
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6534324288368225
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025187747552990913Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.24470825493335724

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6929683685302734
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.032610561698675156
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017481282353401184
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.36769071221351624 16%|█▋        | 95/584 [10:10<48:08,  5.91s/it] 16%|█▋        | 95/584 [10:16<47:50,  5.87s/it]
 16%|█▋        | 95/584 [10:13<48:17,  5.93s/it]Loss Loss tensor(4.3493, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.5308, device='cuda:0', grad_fn=<NllLossBackward0>)
Loss tensor(3.8492, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4199960231781006
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03457862511277199Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5508614778518677

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.22792331874370575
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4257946312427521
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6287867426872253Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1824968457221985
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04342691972851753

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4769417345523834
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02332811802625656Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19420196115970612

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.552167855668813e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008113663061521947
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016255740076303482Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013032629794906825

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014086647424846888
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012049996439600363
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022036500740796328
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025662113912403584
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002274707512697205Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003273204492870718
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003673685248941183

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004892937722615898
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006514968816190958
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004107218701392412Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006355668301694095
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008199809119105339

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008341689244844019
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01008561346679926
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006285040872171521
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001428442308679223
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012546072714030743
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010206280276179314
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009609827538952231Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010440709069371223

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001314846915192902Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012477964628487825
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011290493421256542

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023515040520578623
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013924005441367626
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001729896990582347
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033440866973251104
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014747463166713715
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019445677753537893Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005967162549495697
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024155188351869583

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0062637184746563435Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014920123852789402

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018283217214047909
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0069193108938634396
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01450173556804657
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019036999437958002
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006528518162667751
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015333388932049274
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006440604571253061
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024611412081867456Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016640393063426018

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010951532050967216
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.037646930664777756
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025534953456372023Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004518489819020033

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014170384034514427
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004062179010361433
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004019617103040218Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014741765335202217

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034126872196793556
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01274111308157444
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027367870789021254
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028756202664226294
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013709010556340218
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002508640056475997
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00228860997594893
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01187923178076744
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00280955177731812
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021557919681072235
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012330560013651848
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002985746134072542Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021799770183861256

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013821367174386978
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025093064177781343
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016970187425613403
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005074366461485624
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0063505833968520164
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10478982329368591
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027177254669368267Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2558032274246216
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11967035382986069

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04130077734589577
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12810386717319489
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002729307860136032
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.28833359479904175
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21244749426841736
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022885396610945463
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6613613963127136
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7799113392829895
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021509674843400717
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019354564137756824
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019276944221928716
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019846318755298853
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002286881674081087
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04068002849817276
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02592354267835617
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04252118617296219
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03875725343823433
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5427612066268921
 16%|█▋        | 96/584 [10:17<50:23,  6.20s/it] 16%|█▋        | 96/584 [10:23<50:10,  6.17s/it] 16%|█▋        | 96/584 [10:20<50:20,  6.19s/it]Loss Loss Loss tensor(4.0685, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.1207, device='cuda:0', grad_fn=<NllLossBackward0>)tensor(3.9856, device='cuda:1', grad_fn=<NllLossBackward0>)

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.49117258191108704Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13339455425739288

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11876609921455383
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018845444545149803
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6370833516120911Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16484999656677246
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06211278587579727

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01827697642147541
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013182283379137516
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06661534309387207
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20014935731887817
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011052221059799194
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00026257731951773167
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.9466731575666927e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004462983342818916
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.564826303976588e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.378442387562245e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008020055247470737
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013475959713105112
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.809626549715176e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010518371127545834
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011758453183574602
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017258832231163979
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00023552231141366065Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001850255357567221

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019202898256480694
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00027096402482129633
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003435287799220532
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002211065264418721
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004092833842150867
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005197347491048276
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006910525262355804Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025923913344740868

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000588021706789732Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009496869170106947

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024994416162371635
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013107978738844395
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028379217255860567
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007202531560324132
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002398895798251033
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004007033538073301
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007489986019209027
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002926054410636425
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004587635863572359
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007995037594810128Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004490283317863941
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006903393194079399

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005083417985588312
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008749878033995628Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00576381292194128

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006722511723637581
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007182111963629723
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013068804983049631
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007608260493725538
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008496466092765331
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015548337250947952
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007983713410794735
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01009391900151968
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007448200602084398Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020539863035082817
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009865278378129005

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005363811738789082
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008344724774360657
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020092916674911976
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004714663606137037
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008337048813700676
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002431700238958001
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00389317749068141
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008443491533398628
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030884044244885445Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003254379378631711
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008896559476852417

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025620500091463327
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008162609301507473
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003645380027592182
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002345151035115123
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007759496103972197Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002408091677352786
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036221377085894346

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028317610267549753
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008483384735882282
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032153178472071886
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005388658959418535
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01238279975950718
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031500665936619043
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2957460582256317
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030049240216612816
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030654806178063154
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029783273115754128
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04527872055768967
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002853874582797289Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.33786287903785706
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.050089653581380844

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8539049029350281
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09813157469034195
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027172421105206013
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9713881611824036
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026863685343414545
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029358500614762306
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033698275219649076
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02886192873120308
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020353633910417557
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0235783401876688
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025102650746703148
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5916205644607544
 17%|█▋        | 97/584 [10:28<49:21,  6.08s/it] 17%|█▋        | 97/584 [10:23<49:31,  6.10s/it] 17%|█▋        | 97/584 [10:26<49:29,  6.10s/it]Loss Loss tensor(4.6431, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.0998, device='cuda:2', grad_fn=<NllLossBackward0>)
Loss tensor(4.0829, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5637794137001038Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04574915021657944
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7384017705917358

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09703851491212845
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14413170516490936
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7270762920379639Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0221441350877285

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10360118746757507Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8248104453086853
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013904755003750324

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.112747774343006e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3018040060997009
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018514953553676605Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.355212099151686e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003092748811468482
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.371527004172094e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010346245835535228

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005019315867684782
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001447207760065794
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.813440945232287e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021830697369296104

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009562671184539795
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00031762273283675313
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001161248073913157Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014330582052934915

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008730569970794022
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001920502632856369
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00020923445117659867
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020219592843204737
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026033297181129456
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003384669544175267
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011019131634384394
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004126157611608505
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00048375219921581447Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011159557616338134
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00850946456193924

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018865336896851659Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0043501462787389755

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007564793340861797
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019669265020638704
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004841482266783714
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001255236566066742
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00479764211922884
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006255353335291147
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006971211405470967
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030160800088196993
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006106049288064241
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00380953517742455
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007519819773733616Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021188106387853622

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004357815254479647
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007255402859300375
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009807705646380782
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004685612395405769
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008675431832671165
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011437174398452044Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0143988486379385
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009053975343704224

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033985970076173544
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011006578803062439
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004642678424715996
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030995935667306185
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.050408679991960526
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002626401372253895
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011945364065468311
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014954127836972475
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002254778053611517
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01375516876578331
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001856339629739523
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012693128548562527
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017199303256347775
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017969823675230145
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013809951953589916
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020697086583822966
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017927407752722502
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013356219045817852
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024654597509652376Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00203441409394145
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014733301475644112

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005543841980397701
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01647287979722023
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008043271489441395
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17844314873218536
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018937723711133003
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02982979454100132
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002755648922175169Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18389451503753662

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20434032380580902
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1953652799129486
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029436792246997356
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.48250749707221985
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1831461489200592
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002651948481798172
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2048371583223343
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025476592127233744Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4235946536064148

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002355885924771428
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024505751207470894
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026071981992572546
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028821013402193785
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05415009707212448
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.046037063002586365
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0659497007727623
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.049154460430145264
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.37549328804016113
 17%|█▋        | 98/584 [10:36<51:52,  6.41s/it] 17%|█▋        | 98/584 [10:30<51:59,  6.42s/it] 17%|█▋        | 98/584 [10:33<51:58,  6.42s/it]Loss Loss Loss tensor(3.8831, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.2745, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.4733, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014673997648060322Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3887442648410797

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4044918417930603Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19261863827705383
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2857970595359802

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01599148102104664
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09979244321584702
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7577601671218872Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2127159833908081
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.24760696291923523

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.5204433768521994e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004659817204810679

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01446677278727293
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.9653677958995104e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007808121736161411
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013713260414078832Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.800493429182097e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017561499029397964
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010273933003190905
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017576582031324506
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.195650687208399e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00017112174828071147
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002807790646329522
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012872013030573726
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00026761560002341866
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029815074522048235
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00041354968561790884
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022105358948465437
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003784970613196492
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006516468711197376
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005327579565346241
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003114569990430027
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006274728802964091
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0045076399110257626
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004464293597266078
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000678384501952678
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005125181283801794
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00048174808034673333Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010930993594229221
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007101245224475861

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012455544201657176
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007586765103042126
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006432675872929394
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019894354045391083
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014988626353442669
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007502918015234172Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022606069687753916

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010041528381407261
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003193732351064682
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000753224128857255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01378193125128746
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036447204183787107
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008480994147248566
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003921751398593187
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015157277695834637
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012636457104235888Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005415674764662981

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017029186710715294
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027913167141377926
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001408613519743085Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028746895492076874

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002514040097594261
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014024443924427032
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020780034828931093
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021561519242823124
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013781481422483921
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020039938390254974
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019157155184075236
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013274863362312317
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015533700352534652
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026287198998034Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013066944666206837

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014909720048308372
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011682849377393723
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002995843766257167
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015316650969907641
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012157676741480827
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003261617850512266
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018503234023228288
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013494035229086876
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003832753049209714
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00425266707316041Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016378391534090042

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20559455454349518
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07874753326177597
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027956643607467413
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025501122698187828
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06856243312358856
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027953244280070066Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2560563385486603

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.130557119846344
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.890227198600769
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16520099341869354
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025294029619544744
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8082091808319092
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002355493837967515
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022728750482201576
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023295320570468903
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024677435867488384
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003150214208289981
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026664482429623604
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014661853201687336
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03345686197280884
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027697933837771416
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5086669325828552
 17%|█▋        | 99/584 [10:42<51:30,  6.37s/it] 17%|█▋        | 99/584 [10:36<51:35,  6.38s/it] 17%|█▋        | 99/584 [10:40<51:34,  6.38s/it]Loss Loss Loss tensor(4.4135, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(3.5443, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(3.8899, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015725571662187576
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5775420665740967Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13872456550598145
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5664149522781372Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029813013970851898


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2387060523033142
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.44201746582984924
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6196085214614868
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10389984399080276
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015098748728632927
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.531006511067972e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2712925970554352
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010168913286179304
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02430625632405281
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005746406386606395
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.482038876740262e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016874024004209787

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009447428747080266
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002477537782397121
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016487660468555987
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001586474827490747
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004052820731885731
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019498763140290976
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006072908872738481
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002859113272279501
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008665617206133902
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00026692828396335244Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002958359196782112

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013890378177165985
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038113256450742483
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00036055795499123633
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011385559337213635
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00615523848682642
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00047772141988389194
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011978000402450562
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038798453751951456
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019421849865466356
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005058858077973127
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0044934810139238834
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002257355023175478
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006605161470361054
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0058122375048696995
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038072681054472923
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008073460194282234
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004220420029014349
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0061722081154584885
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006432866211980581
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017943400889635086
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005747728515416384
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007276242249645293
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009087884798645973
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006544397212564945
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001040482078678906
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007012576796114445
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012935498729348183
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012084842892363667
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00814061425626278
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012574530206620693
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023320140317082405
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00487729674205184
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012611525133252144
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018765201093629003
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004318714141845703
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0294729582965374
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026323788333684206Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035966739524155855

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011252920143306255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031590303406119347
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002606831258162856
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011253612115979195
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025402959436178207
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002661291277036071
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002390639390796423Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010242207907140255

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004349883180111647
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024674932938069105
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011751378886401653
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024435671512037516Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002980537712574005
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010036767460405827

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0058371457271277905
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01078005600720644
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024042760487645864
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.289986252784729
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011789733543992043
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025867829099297523Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021442656870931387
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012571996077895164

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.337172269821167
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06870291382074356
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002186303725466132Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6299945116043091
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07683878391981125

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05600244551897049Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019798679277300835

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10354336351156235
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002063584513962269Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7143977880477905

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022391914390027523
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002536924323067069
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03507992997765541
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017818763852119446
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015094319358468056
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02111993543803692
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6840539574623108
 17%|█▋        | 100/584 [10:49<52:40,  6.53s/it] 17%|█▋        | 100/584 [10:43<52:44,  6.54s/it] 17%|█▋        | 100/584 [10:46<52:44,  6.54s/it]Loss Loss Loss tensor(3.9624, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(3.9190, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.5608, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.40883001685142517Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.43998822569847107

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03557337075471878
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20977817475795746
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23824283480644226
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8094649314880371
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03281715512275696
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1582099348306656
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009997056797146797
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2052597552537918
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006768032908439636Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.43131983280181885

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022044379147700965
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.939344267360866e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003309790918137878
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.8203196304966696e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.54494402220007e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005589243955910206
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.8447782824514434e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.485251990146935e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000723789562471211
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012082812463631853
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013020825572311878
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.204934521112591e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00029698986327275634
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019867708906531334
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.0200160078238696e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005871254252269864

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030944482423365116
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009690928854979575
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005589867010712624
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010754609684227034
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015417770482599735
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003443489084020257
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001490409136749804Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00017714628484100103
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0039048080798238516

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016156219644472003
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005445275455713272
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000273471960099414
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025103348307311535
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005730911158025265
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00044848042307421565Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00277075101621449

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015995221212506294
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004722295794636011
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0078918831422925
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003032760287169367
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004570345859974623Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011164654977619648

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003415205283090472
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006086563691496849
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013308318331837654
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005021184333600104Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0068805161863565445
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016343411058187485

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0072920117527246475Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04242100194096565

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005823856918141246
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011110563762485981
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014425894245505333
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018984171329066157Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005019474774599075

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015192662365734577
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004476586822420359
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013800383545458317
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008682486950419843
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037581815849989653
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014501090161502361
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012115590507164598
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033145458437502384
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013797594234347343
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026734729763120413
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015243877423927188Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014743806794285774

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025303263682872057
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017213163897395134
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018174793804064393
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026003019884228706
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019327295944094658
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003370387014001608Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003066787263378501
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1308973878622055

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006328088231384754
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13229429721832275
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001685295719653368
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3014273941516876
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1403498351573944
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016937083564698696Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03471432998776436
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21444888412952423

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.768230140209198
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.34454911947250366
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014647920615971088Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.737303614616394

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001389636192470789
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013140145456418395
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001326108118519187
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014327383833006024
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016027938108891249
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021587945520877838
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015363216400146484
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030720360577106476
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023645572364330292
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.41860729455947876
 17%|█▋        | 101/584 [10:48<49:02,  6.09s/it] 17%|█▋        | 101/584 [10:54<49:00,  6.09s/it] 17%|█▋        | 101/584 [10:52<49:01,  6.09s/it]Loss Loss Loss tensor(3.9236, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.8498, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.5206, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4376887083053589Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6550171375274658Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027781406417489052


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19247522950172424
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.38057956099510193
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.872926652431488
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3559328317642212
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.060919374227523804
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010737966746091843Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3194068670272827

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.49460116028785706
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00035922275856137276
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.646203549578786e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009193251840770245
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005804940592497587Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.7886958529707044e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.5709847502876073e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.897464042296633e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009429290075786412
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001595255744177848
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.6651896405383013e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012640110217034817
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00032076871138997376
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001972572412341833
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.2380303057143465e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005257651791907847
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002251952886581421
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008000743691809475
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.031783777871169e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003174619982019067
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012363253626972437
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005397845059633255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.32117220852524e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012359180254861712

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004378749057650566Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013162532122805715

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.820065315579996e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005486174486577511Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020525234285742044

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014496031508315355Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007574268616735935Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022760271094739437


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003567131469026208
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00868991483002901
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00019030096882488579
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035059654619544744
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02477429248392582
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00020437662897165865
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012811955064535141
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0047290148213505745
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002482038689777255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02108525112271309
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005800647661089897
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004125196719542146
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02169414423406124
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006405262276530266
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025904979556798935
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009619758464396Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005031893379054964

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03643246367573738
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00458799721673131
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008011189056560397
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003967368509620428Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021167820319533348

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007750559016130865
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003357931040227413Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01987387426197529

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012658634223043919
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002997515955939889
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01681017130613327
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013238326646387577
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023928293958306313Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018458595499396324

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001557652372866869Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002330915303900838Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014963198453187943


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01514423917979002Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002384959487244487

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018966140924021602
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015646962448954582
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002863925648853183
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001354855252429843
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019044559448957443
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005078672431409359
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012372308410704136Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.053322289139032364

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.25327250361442566
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07710129767656326
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009736337815411389Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04040849581360817

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13261279463768005
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.36278313398361206
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009375545778311789Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6389965415000916
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3010413348674774

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.42631417512893677
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008244146592915058
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008287017117254436
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008940565166994929
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010272992076352239
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011404333636164665
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005658053793013096
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010076980106532574
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017676472663879395
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2136164903640747
 17%|█▋        | 102/584 [11:01<51:10,  6.37s/it] 17%|█▋        | 102/584 [10:55<51:11,  6.37s/it] 17%|█▋        | 102/584 [10:59<51:11,  6.37s/it]Loss Loss Loss tensor(4.0344, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.4013, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.8170, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015315537340939045
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.302893728017807
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5598194003105164Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12408992648124695
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3726115822792053

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03631379082798958
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13840456306934357
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.701647162437439Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2680693566799164

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1976611614227295
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.2326064178487286e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018499966710805893
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005275161820463836
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.484664431307465e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009035092080011964
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001510234724264592
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020911572501063347
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016289122868329287
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00024073435633908957
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002233987906947732
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.672357944305986e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004266714386176318
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003665566211566329
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006204975070431828
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004026554059237242
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015785197319928557
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007514212047681212
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004599360283464193
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009648950654082
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005207272246479988
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00028384331380948424Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010592563776299357
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004691987298429012

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012071422534063458Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005172578152269125

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00042420162935741246
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006473775953054428
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001927121658809483
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006164620281197131
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0066743153147399426Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022509885020554066

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000707646831870079
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01267725694924593
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034238894004374743
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004054363816976547Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000874068180564791Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007851877249777317


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005680391564965248
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012816772796213627
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009185578674077988Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006671832408756018
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014620688743889332

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0071800462901592255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018487868830561638
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008958723046816885
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007009720895439386
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02149980142712593
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009341201512143016
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004999788943678141
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01512986421585083
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012555993162095547
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004631495103240013
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014549131505191326
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013230497715994716
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004057783633470535
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012262276373803616
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036054698284715414
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00163980049546808Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011302173137664795

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029940875247120857
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010949984192848206
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016736770048737526
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028953249566257
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01066077221184969
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003039133735001087Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002688729902729392
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011529665440320969

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036701292265206575
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015605460852384567
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031098192557692528Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0059879799373447895
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03758978471159935

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2888461649417877
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05285000428557396
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038606461603194475
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024741942062973976
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06816081702709198
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004345518536865711
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.33648228645324707
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12776395678520203
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003403374459594488Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8447198867797852
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8264739513397217

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003242803504690528
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002613122807815671
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022195109631866217
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022329548373818398
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020759496837854385
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002173204440623522
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002749289618805051
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013151699677109718
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011105583049356937
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017888136208057404
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02146725542843342
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.43854010105133057
 18%|█▊        | 103/584 [11:06<48:20,  6.03s/it] 18%|█▊        | 103/584 [11:00<48:21,  6.03s/it] 18%|█▊        | 103/584 [11:04<48:21,  6.03s/it]Loss Loss Loss tensor(4.5389, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(3.8582, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.3424, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.341309130191803
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4270695745944977Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21473026275634766
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.061528678983449936

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17006467282772064
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07475600391626358
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6069654226303101Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030096428468823433
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14842012524604797

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002922959974966943
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6494205594062805
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015082668513059616
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00043588640983216465
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.356192898238078e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006563662900589406
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.740519453771412e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015163950622081757
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008945228764787316
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015463202726095915
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015066046034917235
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.220973541028798e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022907659877091646
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002047612564638257
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00044303544564172626
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012497910938691348
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00282824388705194
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007504055975005031
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005082276184111834
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00018062243179883808
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011674717534333467
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026872865855693817
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002888294402509928Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029140750411897898Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001956113614141941


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036629238165915012
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015312304021790624
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004374712589196861
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035894843749701977
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00155017024371773
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006185202510096133
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010779758915305138
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023780171759426594
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008633495890535414
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004228248260915279
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002537427470088005
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007278368808329105
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012741652317345142
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005007124040275812
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008319893851876259
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000783237162977457
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036017433740198612
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010925467126071453
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007892524590715766
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028835952281951904
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004837882239371538
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009540033061057329
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010674070566892624
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005701081827282906
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010777184506878257
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011325448751449585
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0062975031323730946
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003998875617980957Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010407389141619205
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016938475891947746

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010855435393750668
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004616064950823784
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013704303419217467
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010233686305582523
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004265432711690664
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024438307154923677
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011383864097297192
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037040547467768192
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012660708278417587
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003039315575733781
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032311188988387585
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014295998029410839
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003914256580173969
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026706710923463106
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11420948058366776
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007745805662125349
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002612908137962222
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13453412055969238
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038995996583253145
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1427987664937973
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026883105747401714
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003914302214980125
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17445601522922516
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031006091739982367
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8517354130744934
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034347253385931253
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006690097972750664
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031015847343951464
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23735679686069489
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002874410478398204Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04576525092124939

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2849588692188263
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002899185521528125
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6359420418739319
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031640054658055305
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038915439508855343
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04645759239792824
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04459404945373535
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06961620599031448
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06013798713684082
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6602487564086914
 18%|█▊        | 104/584 [11:06<47:11,  5.90s/it] 18%|█▊        | 104/584 [11:12<47:11,  5.90s/it] 18%|█▊        | 104/584 [11:09<47:11,  5.90s/it]Loss Loss Loss tensor(3.5271, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(3.7848, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.1701, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5041108131408691
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.644227147102356
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13343170285224915
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6316719651222229Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.109560027718544

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018024666234850883
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.26029524207115173
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026123542338609695
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000494540436193347
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008054131758399308
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.206586400978267e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013963031815364957
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015941493620630354
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017715066205710173
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002834651619195938
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002674621937330812Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003077224362641573

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003974587190896273
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003785457229241729
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006068114656955004
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005241576000116765
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004733383189886808
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005922843120060861Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005555341951549053

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007637139409780502
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007949258433654904Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008134154602885246

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016937267035245895
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010005506919696927
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009607493877410889
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009535206481814384
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010108166374266148
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011052993359044194
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009617120027542114
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016111299628391862Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009980925358831882

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030725106596946716
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018146424554288387
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00915833842009306
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002751334570348263Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009708988480269909

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009380890987813473
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002277742139995098
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009297411888837814
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0083738649263978Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024048134218901396

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00881396047770977
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023601753637194633
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010054784826934338
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024632601998746395
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011496380902826786
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004873927682638168Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07780967652797699

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06662939488887787
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023331502452492714
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0795573741197586
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022795693948864937
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08775068074464798
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021783022675663233Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7881511449813843

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019759766291826963
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018775513162836432
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001860101823695004
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002034710953012109
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024267863482236862
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026670193299651146
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016806647181510925
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028826819732785225
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019383063539862633
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.42737945914268494
 18%|█▊        | 105/584 [11:13<49:24,  6.19s/it] 18%|█▊        | 105/584 [11:16<49:24,  6.19s/it]Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025117380544543266
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21841977536678314
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03346569091081619
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.609844446182251
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.330297765089199e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010092688171425834
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00017286668298766017
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00026603680453263223
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00047969186562113464
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00071798509452492
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010199141688644886
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001610014820471406
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015954801347106695
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017382539808750153
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026684915646910667
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028826307971030474
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004247281700372696
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00409442326053977
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004700442310422659
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005369513761252165
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005661856383085251
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008386670611798763
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003953628242015839
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036648581735789776
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032453995663672686
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028686337172985077
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023616242688149214
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023375023156404495
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002431627595797181
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002781209070235491
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0053794002160429955
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.22591285407543182
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025318482890725136
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.25451207160949707
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6796045899391174
 18%|█▊        | 105/584 [11:19<50:09,  6.28s/it]Loss Loss Loss tensor(4.1424, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.5381, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(3.9379, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3893042802810669
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.048364412039518356Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.28897419571876526
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1964433789253235
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12864075601100922

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16966144740581512Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009710585698485374
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.049463603645563126

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6336276531219482
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009132818318903446
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20202751457691193
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.736510552698746e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028564753010869026Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00020775840675923973Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.895614231121726e-05


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003284070116933435
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.082042455091141e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.724316623760387e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005708449753001332
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014793816080782562
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.738282824400812e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006194616435095668

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00032648255000822246
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009032880188897252
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014143387670628726
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005854061455465853
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012743721017614007
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010062602814286947
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00017344790103379637
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025779714342206717
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017804866656661034
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002315662568435073
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005425960756838322
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013230612967163324Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00259106676094234

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00034838233841583133
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001359795918688178
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003058567177504301
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007192939519882202
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021277007181197405
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004328308627009392
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001287522492930293
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022723597940057516
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004260963760316372
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000687910825945437
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004440679214894772
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014309440739452839
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008335578022524714
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035732872784137726
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005331557244062424
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012193412985652685
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00442872941493988
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005808030255138874
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014578498667106032Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005138832610100508
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0057191187515854836

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0055848220363259315
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006725247483700514
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0047271763905882835
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01305435225367546
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029155006632208824
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018737625796347857
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004011581651866436
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007543154992163181
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002050836803391576
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037069865502417088
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008800790645182133
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020544948056340218
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003262188518419862
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008670410141348839
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024371163453906775Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002893626457080245

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010256840847432613
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002410242334008217
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009537332691252232
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007360971532762051
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023960783146321774
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010416597127914429
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002815013052895665
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002507994882762432
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012128256261348724
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028304019942879677
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013355623930692673
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031257804948836565
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005951243918389082
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07264844328165054
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030853338539600372Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23678772151470184

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09345956891775131
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.043409690260887146
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1267007291316986
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003220067359507084
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2658686935901642
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17861810326576233
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030922216828912497
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6711832284927368
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8381484150886536
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031206703279167414
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035825225058943033
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004081544931977987
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04740544408559799
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.038253553211688995
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0619414784014225
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05974613130092621
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9356839060783386
 18%|█▊        | 106/584 [11:23<46:03,  5.78s/it] 18%|█▊        | 106/584 [11:18<46:17,  5.81s/it] 18%|█▊        | 106/584 [11:21<46:17,  5.81s/it]Loss Loss Loss tensor(4.3200, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.2945, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.4733, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5587145686149597Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03785455971956253

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.655958890914917Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18230699002742767
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2314794957637787

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02759864553809166
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08716642111539841
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5188611149787903
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7909975051879883
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2808477282524109
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.88781830528751e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006221060757525265
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015415756031870842Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015514706319663674

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009802054846659303
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.032788462936878204Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00025436695432290435

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015710389707237482
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003720621461980045
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014079322863835841
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018936992855742574Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006257552304305136

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00023334006255026907
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008868766017258167
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027932452503591776
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001197293633595109
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002832314930856228
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003662110830191523Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019240181427448988

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037324565928429365
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014684874331578612
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006620822008699179
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004912760341539979
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001473982585594058
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003671018872410059
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002224573865532875Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006185542442835867
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004011936020106077

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002322978340089321
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006431664223782718
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005147410556674004
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004227327182888985
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008418761426582932Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004689388442784548
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032662125304341316

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017072847113013268
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003706695744767785
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011856893543154001
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004355641547590494
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005956957582384348
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00475458474829793
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008845089003443718Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000790985650382936

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011393153108656406
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008689590729773045
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008347181719727814
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034660000819712877
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009236393496394157
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011100254487246275Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003138360334560275
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03690154850482941

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002730119042098522
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00880800373852253
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011992999352514744
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024093035608530045
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009444101713597775
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003644336946308613Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019956068135797977
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008873573504388332

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019922952633351088
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010184137150645256
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017165696481242776
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002035772893577814
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00923678558319807
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026265920605510473
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022777789272367954
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010126580484211445
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00256784213706851
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005526850465685129
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01114879734814167
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1935747116804123
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027452961076050997Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012281719595193863

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02929059974849224
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09015095233917236Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21632838249206543
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006883380003273487

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5034356117248535
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10378089547157288
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026141246780753136
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10278935730457306
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002637834521010518
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12976795434951782
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002377432305365801Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7061014771461487

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023821950890123844
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002208282006904483
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022587182465940714
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002517149318009615
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002781927352771163
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04757130146026611
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03155171126127243
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.043399374932050705
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.031837478280067444
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5411943793296814
 18%|█▊        | 107/584 [11:29<46:19,  5.83s/it] 18%|█▊        | 107/584 [11:24<46:29,  5.85s/it] 18%|█▊        | 107/584 [11:27<46:29,  5.85s/it]Loss Loss Loss tensor(4.0009, device='cuda:1', grad_fn=<NllLossBackward0>)tensor(4.0900, device='cuda:0', grad_fn=<NllLossBackward0>)

tensor(4.1146, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.49499648809432983Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4006086587905884
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013476084917783737

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17633898556232452
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.275441974401474
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7893947958946228Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2452741116285324
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05006462708115578

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.22605159878730774
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014488023705780506
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4083276689052582
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002495520166121423
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014162274077534676
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.355422061053105e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003894930996466428
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.574754398665391e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.973906420171261e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005901644472032785
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.175200592726469e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007919975905679166
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012057206913596019
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013089384883642197
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001977207139134407
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.355894583975896e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00043565823580138385
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015401914715766907
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.326584404334426e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000739437120500952
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002043449552729726
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013066898100078106Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009975838474929333
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037525701336562634

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013313241070136428
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024597502779215574
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016169009904842824
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001411985605955124
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003207694971933961
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002047997695626691
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001522216247394681
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004741151351481676
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002525254094507545
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002343022497370839
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005561396013945341
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002573867386672646
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025943710934370756
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016474105417728424
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003895506728440523
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00032696608104743063Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007510728668421507

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037450382951647043
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013759915716946125
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005514348158612847
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004888677969574928
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015087253414094448
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007128113647922873
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006068537011742592
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018219316378235817
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010729219065979123
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006737599149346352
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024802513420581818
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001083612092770636
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006868792697787285
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013351451605558395
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021279938519001007Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004746359307318926

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012256979942321777
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004084720276296139
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01041425485163927
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00229361723177135
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003469080664217472
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011007357388734818
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002722908742725849
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030239762272685766
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00925453007221222
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002395150251686573
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031583518721163273Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009833593852818012

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023462858516722918
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010214339010417461
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002212475286796689Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023710436653345823

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012117838487029076
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026581124402582645
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020957408472895622
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00202055717818439
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004816033877432346
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04472354054450989
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001665209187194705
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2841395437717438
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.045319173485040665
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014588673366233706
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028292858973145485
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10540719330310822
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014088520547375083Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8238793611526489

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.36751818656921387
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014344269875437021Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7333460450172424

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001575143774971366
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001798512996174395
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011910349130630493
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008156671188771725
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010075440630316734
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011519009247422218
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.36183854937553406
 18%|█▊        | 108/584 [11:30<47:22,  5.97s/it] 18%|█▊        | 108/584 [11:36<47:15,  5.96s/it] 18%|█▊        | 108/584 [11:33<47:22,  5.97s/it]Loss Loss Loss tensor(3.8405, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.8721, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(3.8031, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03613891080021858
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5538861155509949Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3079410195350647

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.39160287380218506
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7346227765083313
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04821070283651352
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23163127899169922
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7247041463851929
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017158735543489456
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.030891669681296e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1531635820865631
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021968968212604523
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014220851880963892
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.688048597425222e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19521360099315643

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003355695225764066
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00023549764591734856
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010564212425379083
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000356753240339458
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005144901806488633
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015478808199986815
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006449163192883134
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022418999287765473Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007527604466304183

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009246710105799139
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009795998921617866
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00028933241264894605
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001133369980379939
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001521778292953968
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00029800008633174
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016883517382666469
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015451934887096286
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003650865110103041
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012901065638288856
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019976662006229162
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004959157085977495
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012572570703923702
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003944640979170799
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00033140103914774954
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019277643878012896
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001966903917491436
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000408067338867113
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021377557422965765
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002431812696158886
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006704895640723407Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003349717939272523
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003950405400246382

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032906397245824337
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035960625391453505
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000870358431711793
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037669199518859386
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013437013141810894
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016809959197416902
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004678549710661173
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004806043114513159
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012968028895556927
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00510753970593214
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008190502412617207
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024446756578981876Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009725925512611866
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008443727158010006

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036495011299848557
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010086016729474068
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002478949259966612
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031515383161604404
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021410763263702393
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029156983364373446
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002708261366933584
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007907805033028126
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0041694906540215015
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023688848596066236
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007583337835967541
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024411771446466446
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018896813271567225
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006255360320210457
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022861536126583815
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018968478543683887
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006641011219471693
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018795588985085487
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018539370503276587
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005860175937414169
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016466312808915973
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002031642245128751
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005845923908054829
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001594479545019567
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004665714222937822
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006425157189369202
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016075613675639033
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21400311589241028
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00737073365598917
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001686486299149692
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.038663141429424286
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0364094115793705
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020805555395781994
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2994039058685303
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.043178826570510864
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016218718141317368
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4890173673629761
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06317359209060669
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012717248871922493
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07989687472581863
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015854697674512863
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8464821577072144
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01621660217642784
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.38954949378967285
 19%|█▊        | 109/584 [11:41<46:19,  5.85s/it] 19%|█▊        | 109/584 [11:36<46:24,  5.86s/it] 19%|█▊        | 109/584 [11:39<46:23,  5.86s/it]Loss Loss Loss tensor(4.2730, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(3.8920, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(3.8905, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.49422943592071533
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011270205490291119
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.30651676654815674
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3507516384124756
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.45980799198150635
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23227448761463165
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05789891630411148
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8572239279747009
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2801072895526886
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.49117565155029297
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013192691840231419
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006814008229412138
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.334336260100827e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015302828513085842
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001143628265708685
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011945233563892543
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.849657827639021e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002006091643124819
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00020946432778146118
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002550732344388962
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010470835695741698
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00031233791378326714
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004156508482992649
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005230199312791228
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004501463379710913
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001798799348762259
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007479554624296725
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00508388364687562
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002558837877586484Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008941068081185222
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006367407739162445

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011967099271714687
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0055239093489944935
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003673789033200592Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006499751470983028
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012677392223849893

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00907871499657631
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00151104258839041
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004176165966782719
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010113387368619442
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002510698977857828
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021161939948797226
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029170794878154993
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005094519583508372
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013533496297895908
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004287164658308029
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005586189799942076
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018323270604014397
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0048888688907027245
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005495877703651786
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019291600212454796
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006146710831671953
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006211699219420552
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022118400782346725
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00707270996645093
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009747502044774592
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02215658314526081
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0071594733744859695
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01635749265551567
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006463645026087761
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011297324672341347
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015134298242628574
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0046864221803843975
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015537338331341743
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012939449399709702
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004164382349699736
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011862371116876602Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003623977769166231

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001602647011168301
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032028963323682547
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010032069869339466
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002205368597060442
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002569476841017604
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010287703946232796
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00237582391127944
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026263331528753042
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011669416911900043
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00264032487757504
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002659820718690753Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015121102333068848

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002928920090198517
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03149591386318207
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002561883768066764Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005105618387460709

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04221205785870552
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.25444266200065613Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.041107021272182465

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021612364798784256
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14375713467597961Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020164037123322487

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7072298526763916
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019646461587399244Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.25359559059143066

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7088154554367065
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015636368189007044
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013492940925061703
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012449081987142563
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001151238102465868
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011607436463236809
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013751591322943568
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00410933094099164
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0049202232621610165
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006021121516823769
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015117909759283066
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23016878962516785
 19%|█▉        | 110/584 [11:41<44:26,  5.62s/it] 19%|█▉        | 110/584 [11:46<44:23,  5.62s/it] 19%|█▉        | 110/584 [11:44<44:26,  5.63s/it]Loss Loss Loss tensor(3.5212, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.1006, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(3.9328, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.38010281324386597Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4453376233577728
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016951464116573334

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1850423365831375
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3614615797996521
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.86412113904953Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.25134992599487305
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.050531644374132156

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01133511122316122Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.42924463748931885

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23523278534412384
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.5461070840246975e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011920674704015255Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00036541270674206316

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.407641533063725e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006027097115293145
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.9735378120676614e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012870310456492007
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010086940601468086
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.165544280316681e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00019113739836029708

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012372120982035995
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00033388694282621145
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.389434515265748e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019593366887420416
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00052548514213413
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011429100413806736Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020175802055746317

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000747636251617223
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002530874917283654
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015739718219265342
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010926006361842155
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004067365080118179
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001673993974691257Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011726815719157457

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002979038516059518
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012698749778792262
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022149011783767492Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001991181168705225Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0039280978962779045


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023136790841817856
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005564203951507807
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002515588130336255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037337210960686207
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006441871635615826
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000256772298598662
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004285650793462992
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018938520923256874
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00032282015308737755Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005922648590058088

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010355574078857899
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0074071395210921764
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005505530280061066Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01665664091706276

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007832994684576988
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018657829612493515
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006977089215070009
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007763987872749567
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022308357059955597
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00114222033880651
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005323444493114948
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022658593952655792
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012257673079147935
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0047734929248690605
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016971928998827934
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020184917375445366
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004225288052111864
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01570490188896656
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003772431518882513
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002243798691779375Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013110143132507801

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003005373291671276
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012059989385306835
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026207887567579746
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031549944542348385
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010549504309892654
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002672425005584955
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031071542762219906
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01078849472105503
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002179266419261694Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034617038909345865
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012284529395401478

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00601997971534729
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015352055430412292
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002001381479203701
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3118266761302948
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03238428756594658
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016002171905711293
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02785063162446022
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.039942417293787
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013336044503375888Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.33173203468322754
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07377094775438309

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6883149147033691
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18582119047641754
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012312158942222595
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7762771248817444
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001213461859151721
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012055104598402977
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014961798442527652
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003365949494764209
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004072206560522318
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014161834493279457
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01867012493312359
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.328514963388443
 19%|█▉        | 111/584 [11:53<47:02,  5.97s/it] 19%|█▉        | 111/584 [11:47<47:05,  5.97s/it] 19%|█▉        | 111/584 [11:51<47:04,  5.97s/it]Loss Loss tensor(4.5853, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.3619, device='cuda:1', grad_fn=<NllLossBackward0>)
Loss tensor(4.3907, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018196335062384605
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6097126603126526Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6645647883415222
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10054555535316467

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11478342115879059
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5107460021972656Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02073436602950096

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12439204007387161
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.46923500299453735
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02251669205725193
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.342237298260443e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03002428263425827Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.31452423334121704
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.241429557325318e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006573066930286586
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013297835539560765
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001180278486572206
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011566953035071492
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001904727832879871
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000222149770706892Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022787635680288076

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002915272780228406
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028041317127645016
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004063144442625344
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00040099836769513786
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004580474458634853
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005817180499434471
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006067842477932572Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005222818348556757

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008800003561191261
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010693176882341504
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0061705391854047775
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008823418756946921Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008268565870821476Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010396485449746251


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010475357994437218Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006361858453601599

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012732998002320528
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006633124314248562
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016719931736588478
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001468322821892798
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008319049142301083
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001821110025048256
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012695991899818182
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008120241574943066
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028426407370716333
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001274282461963594Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017624275758862495
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002422743011265993

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008360540494322777
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002350389026105404
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016603367403149605Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030943648889660835Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00793572049587965


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00377293792553246
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008234742097556591
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016955448081716895
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009129934944212437Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0069334423169493675

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033032342325896025
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.038765087723731995Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003039117669686675

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001881948090158403Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029008567798882723
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00938037596642971

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002704703714698553Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010395800694823265

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017983316211029887
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010028233751654625Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024879216216504574

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019221790134906769Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020158253610134125Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011385329067707062


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002199534559622407Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010824496857821941

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002092468785122037
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012140687555074692
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021485337056219578
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005607526283711195
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013157512992620468
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002423314144834876
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016187617555260658
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004823048133403063
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020988478790968657
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11961645632982254
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2152775526046753
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022393837571144104
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11630269885063171
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02239813096821308
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021152871195226908
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0913853719830513
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2656582295894623
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8070641756057739
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11632005870342255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022071453277021646Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6143697500228882

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020935111679136753
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002208908088505268
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025242078118026257
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029795030131936073
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03838113322854042
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027460621669888496
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03667076677083969
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023209508508443832
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6014602780342102
 19%|█▉        | 112/584 [12:00<48:46,  6.20s/it] 19%|█▉        | 112/584 [11:54<48:47,  6.20s/it] 19%|█▉        | 112/584 [11:58<48:47,  6.20s/it]Loss Loss Loss tensor(4.2899, device='cuda:1', grad_fn=<NllLossBackward0>)tensor(4.6756, device='cuda:2', grad_fn=<NllLossBackward0>)

tensor(3.4850, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.531670093536377Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01995486579835415

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20711462199687958
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4407844841480255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3428409993648529
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8060169816017151
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06574387103319168Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13949626684188843

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01499948650598526
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14656215906143188
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016425160691142082Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4231002926826477

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00032786690280772746
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.705964915454388e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.6191060139099136e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005690424586646259
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011176102270837873
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010531517182243988
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010924447560682893
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00020721480541396886
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001944975956575945Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014211289817467332
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003096831205766648

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002445897785946727
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000518525077495724
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00028719910187646747
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027825345750898123
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007584046688862145
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00044305299525149167Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003200774546712637

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009820841951295733Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003811508882790804

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005251327529549599Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013785383198410273
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003590978216379881

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038640249986201525Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015381365083158016

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006492611137218773
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004972123075276613
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017921769758686423
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007146744173951447
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005140365567058325
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028719056863337755
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007181368418969214
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009846270084381104
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003285213839262724
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006067404989153147
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007372953114099801Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0046488032676279545

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007684944663196802
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0043767415918409824
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010243933647871017
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008015739731490612
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004154142923653126
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010900931665673852
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008881685324013233
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0048311506398022175
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014144019223749638
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011171974241733551
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005097739864140749
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007095166016370058
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0067366124130785465
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001383994473144412
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006559266708791256
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037794054951518774
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018749629380181432
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005318025127053261
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033556469716131687
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004968286957591772
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019698680844157934Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029864157550036907

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0042019435204565525
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026935788337141275
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021759653463959694
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004205925390124321
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021168484818190336
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023909895680844784
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004324921872466803
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022400084417313337
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005648375488817692
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001852583372965455
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002154771238565445
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010087849572300911
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023828367702662945
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017114978982135653
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014401848427951336
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00450502336025238
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001289532519876957
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04056916385889053
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.24221135675907135
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011069572065025568Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08347814530134201

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.031581081449985504
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8881922960281372
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009874127572402358Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3626951277256012

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6561248302459717
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000921090948395431
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009529761737212539
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011293074348941445
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00449893856421113
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003340939525514841
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009665997698903084
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01747090369462967
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2582610249519348
 19%|█▉        | 113/584 [12:03<53:56,  6.87s/it] 19%|█▉        | 113/584 [12:08<53:55,  6.87s/it] 19%|█▉        | 113/584 [12:06<53:56,  6.87s/it]Loss Loss Loss tensor(4.0167, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.0608, device='cuda:0', grad_fn=<NllLossBackward0>)tensor(4.5708, device='cuda:1', grad_fn=<NllLossBackward0>)

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022635752335190773
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5911750793457031Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4134131669998169
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.22834640741348267

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16586706042289734
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6748766303062439
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02269563637673855
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06794042140245438
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019638072699308395Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6327791810035706

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21852652728557587
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.150067151291296e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00044951881864108145
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.035521749407052994
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012839082046411932Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007171722827479243

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000136308153741993
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00020978430984541774
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001162438071332872
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000301052670693025
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001374333631247282
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022823442122898996
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005011136527173221
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00209313933737576
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003571294655557722
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002215265529230237
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007325906772166491
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00047615758376196027Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029101348482072353
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010036748135462403

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004579243715852499
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015855657402426004
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006371070630848408
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002659401623532176
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012643379159271717
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006998177268542349
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029402656946331263
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013478026958182454
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036176571156829596
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009071834501810372Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021722596138715744

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034342953003942966
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002396642928943038
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011394689790904522
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012664460577070713
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003917241003364325
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007981655071489513
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0046378434635698795
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031476726289838552
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007007395848631859
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008267794037237763
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030667735263705254
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0072380779311060905
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037319331895560026
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010579274967312813
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008051118813455105
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004198247101157904
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025990864261984825
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011884032282978296Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00841091200709343

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006656482350081205
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032274459954351187
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003377823159098625Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006416713818907738

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028312355279922485
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005575251299887896
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017798542976379395Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024381158873438835

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006992996204644442
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002151407301425934
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029803563375025988
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005955030210316181
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017086201114580035
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030508937779814005Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006099715828895569

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017589734634384513
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006694005336612463
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001719506923109293
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003439435036852956
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007627582177519798
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018974578706547618
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0066650803200900555
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05273161455988884
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004538278561085463
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029600870329886675Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.058092713356018066
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1741567850112915

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.038062307983636856
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0238560289144516
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002778151771053672
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04207446426153183
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19684003293514252
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8592932224273682
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6903315186500549
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002374578732997179
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002381061902269721
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002387866610661149
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002344539389014244
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002611369825899601
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029735590796917677
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.042882245033979416
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024971596896648407
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01578761264681816
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012648368254303932
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4363293945789337
 20%|█▉        | 114/584 [12:15<53:29,  6.83s/it] 20%|█▉        | 114/584 [12:09<53:30,  6.83s/it] 20%|█▉        | 114/584 [12:13<53:30,  6.83s/it]Loss Loss Loss tensor(4.1495, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.1445, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.1947, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.33490630984306335
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2299078106880188
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024268297478556633
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.35991910099983215Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.24566379189491272

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07203030586242676
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.040325846523046494
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010235192254185677
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008986111730337143
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10823827236890793
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016123635694384575Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3358379602432251

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00029849683050997555
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.8673322453396395e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004501288931351155
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.363352000946179e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.456815365003422e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006451733643189073
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014852163440082222Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007018490578047931

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011470379104139283
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000906632631085813
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00020647607743740082
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001584557758178562
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009112827247008681
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002557129191700369Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00026968683232553303

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014279998140409589
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000430610787589103
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00028406636556610465
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002721537137404084
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006265290430746973
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014588675694540143
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002778787456918508
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010309192584827542
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001724298927001655
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004093486350029707
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009081929456442595
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023197748232632875
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006948485388420522
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021364260464906693
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001009333529509604
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00041170473559759557Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007215756457298994
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001585602993145585

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031569506973028183
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017476384527981281
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005054098437540233
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003789348527789116
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003110436489805579
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006804433651268482Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004420233424752951
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003375980770215392

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0050987922586500645
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0041266134940087795
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007362525793723762
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018620528280735016
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005190471652895212
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025766296312212944
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0055178077891469
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00584354717284441
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005943172611296177
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011835509212687612Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007634834852069616

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006021520588546991
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004366325680166483
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014526827726513147
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0067322151735424995
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0040586902759969234
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017586867325007915Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006414398085325956

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003675284795463085Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0070169661194086075

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020970278419554234
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007666150573641062
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034013392869383097
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004902881104499102
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009259616024792194
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002689798129722476
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002252817852422595Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04668695107102394

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029349292162805796
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04886450991034508
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024178740568459034Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028928767424076796

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05920126661658287
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003210094291716814
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07147759944200516
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023728813976049423
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9270328283309937
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005544408690184355
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024174910504370928
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.29255104064941406
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002286094706505537
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024297896772623062
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00237927190028131
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3168199062347412
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002740002004429698Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8333731889724731

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031104146037250757
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028806250542402267
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02075173333287239
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03408172354102135
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02525329403579235
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8687789440155029
 20%|█▉        | 115/584 [12:16<53:22,  6.83s/it] 20%|█▉        | 115/584 [12:22<53:21,  6.83s/it] 20%|█▉        | 115/584 [12:20<53:22,  6.83s/it]Loss Loss Loss tensor(3.5279, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(3.8040, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.1762, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14543487131595612
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.487680047750473
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11064483970403671
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5925627946853638Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07426263391971588

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08583879470825195
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021900445222854614
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00044387258822098374
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015948619693517685Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007823184132575989

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001426756352884695
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015257879858836532
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00027688141562975943
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002112563466653228
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005257760058157146Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037378438282757998

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004413769580423832
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008185218903236091
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004953975323587656
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005806971341371536
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013082058867439628
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005432195961475372
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016269281040877104
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005670500453561544
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007130870595574379
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019356190459802747
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007273332681506872
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021730433218181133
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010498720221221447
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021062595769762993
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008554019965231419
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021257451735436916
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007851382717490196
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027702494990080595Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007450790144503117

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006970180664211512
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028308359906077385
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018778899684548378
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038896314799785614Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005852217320352793

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006464269943535328
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003365786513313651
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006591073703020811
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003258316544815898Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007594192400574684

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006653927266597748
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00330895627848804
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007660083472728729
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003152214689180255Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007758644409477711

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011501822620630264
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005263165570795536Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04768970608711243

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05458943173289299
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002707752864807844
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08261467516422272
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002703577047213912
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13581043481826782
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9600830078125
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002624795539304614
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026761216577142477
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024909446947276592
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026700582820922136
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026817067991942167
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033013420179486275
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02845832332968712
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024427233263850212
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03807143121957779
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05297446623444557
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6359692215919495
 20%|█▉        | 116/584 [12:23<53:00,  6.80s/it] 20%|█▉        | 116/584 [12:26<53:00,  6.80s/it]Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02739446423947811
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.24188654124736786
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030556222423911095
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2404121458530426
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.462830813485198e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.200069325743243e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001734855177346617
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00026962108677253127
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004938721540383995
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007685055024921894
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009894249960780144
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001392463454976678
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016038811299949884
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018708717543631792
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00289942161180079
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031859921291470528
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004521070048213005
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004109978210180998
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003981982823461294
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004507721867412329
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00482543371617794
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007990753278136253
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035304375924170017
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031894890125840902
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028240226674824953
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025495137088000774
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020107650198042393
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021031752694398165
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002088327892124653
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002262691967189312
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004529578145593405
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.22515226900577545
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03121885284781456
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.25763818621635437
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8738983869552612
 20%|█▉        | 116/584 [12:29<54:07,  6.94s/it]Loss Loss Loss tensor(4.8701, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.1632, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.4125, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.43167418241500854
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7311512231826782
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.30107003450393677
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.285175621509552
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.048682600259780884
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022152164950966835Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19520984590053558

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00036037451354786754
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04283846169710159
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000569245545193553
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000165336110512726
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009141107439063489
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002718344912864268
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001072391984052956
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00041166521259583533Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016963491216301918

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001875275862403214
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005599847063422203
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026365676894783974
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007432938436977565
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0044951774179935455Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008282882627099752

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002901896135881543Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011770622804760933

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031569802667945623
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016956955660134554
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003983353730291128
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003769166534766555
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012544275959953666
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011491111479699612
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013370149536058307Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004327885340899229

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004639379680156708
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017124551814049482
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004759381990879774
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018140433821827173Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0055493684485554695

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030389782041311264
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005456792190670967
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006010659970343113
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023275171406567097Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006618935149163008

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006180263590067625
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026191899087280035
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007179322652518749
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027758500073105097Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00695535633713007

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007741678971797228
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031774218659847975
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008982826955616474
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01101800985634327
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01032821275293827
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003400919958949089
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0906086340546608
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08735571801662445
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035311223473399878
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07026208192110062
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032832270953804255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06710312515497208
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031860526651144028
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8096648454666138
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031827809289097786
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032695287372916937
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036782214883714914
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004345421679317951
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06987122446298599
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05309244990348816
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0562468022108078
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0365004763007164
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6076798439025879
 20%|██        | 117/584 [12:30<53:58,  6.93s/it] 20%|██        | 117/584 [12:34<53:58,  6.93s/it]Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03447359427809715
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18180102109909058
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018399270251393318
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6944375038146973
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.094461761880666e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011060309043386951
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001781611645128578
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002592685050331056
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00045758733176626265
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006755880312994123
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009952782420441508
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017757421592250466
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011362215736880898
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001158453058451414
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018389439210295677
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019315311219543219
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037584833335131407
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024375636130571365
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022389960940927267
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028666506987065077
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003364344360306859
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01103869080543518
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026990403421223164
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025688549503684044
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023945223074406385
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022230541799217463
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018187320092692971
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020021391101181507
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019720906857401133
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002138212788850069
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005344276316463947
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17004579305648804
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026232820004224777
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20401738584041595
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.641639232635498
 20%|██        | 117/584 [12:36<54:43,  7.03s/it]Loss Loss Loss tensor(3.5736, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(3.9081, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.3071, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11686190217733383
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.32754653692245483
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.32058072090148926
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012229370884597301
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8520923852920532Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07735826075077057
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12332670390605927

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03523711487650871
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017404988408088684Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10629535466432571

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004652483039535582
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15583905577659607
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016103558242321014Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007804696797393262

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.7447541621513665e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010059405030915514
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014306973898783326
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.485190821578726e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001989658223465085
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00018249312415719032
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037117323372513056
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001751556555973366
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004456355236470699
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002850914024747908
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00033218416501767933Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005460630636662245

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005943332798779011
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006611840799450874
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005092178471386433Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009937253780663013

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006975444965064526
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012993778800591826Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008259245660156012
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00768038397654891

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010798754170536995Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016287340549752116

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010497353505343199
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011824509128928185
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019237276865169406
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013711159117519855Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0163591131567955
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002217991976067424

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014838000759482384
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033882225397974253
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013004148378968239
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016230839537456632
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012895936146378517
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037005513440817595
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017296334262937307
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012586429715156555
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005006212275475264
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018825303995981812
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011706506833434105
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004796920344233513
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002720012329518795
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010411215014755726
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004523395095020533
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002958825556561351
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01034222636371851
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005090040620416403
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038258619606494904Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009102750569581985

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005383042152971029
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009111032821238041
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003825149964541197Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005434482824057341

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007918113842606544
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0039379289373755455
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00368367787450552
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007857641205191612
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003586095292121172
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003788870060816407Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009088398888707161

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003250816836953163
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009658027440309525
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037313816137611866Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029667653143405914

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01890602521598339
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002314326586201787
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034487941302359104
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04650481417775154
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024868769105523825
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032536897342652082Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03038644790649414

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002470033708959818
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10173394531011581
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031497569289058447Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9220715761184692
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002606583060696721

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004205870907753706
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025930770207196474
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2195884883403778
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024898569099605083Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018200866878032684

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2200629711151123
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002247818512842059
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9283602833747864
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002124885329976678
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022760869469493628
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002429720712825656
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014911805279552937
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01619984395802021
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008500284515321255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02596307545900345
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.40582266449928284
 20%|██        | 118/584 [12:37<52:55,  6.81s/it] 20%|██        | 118/584 [12:42<52:21,  6.74s/it] 20%|██        | 118/584 [12:40<52:55,  6.81s/it]Loss Loss Loss tensor(4.0052, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.6682, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.4401, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03069443814456463Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6612469553947449

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4478289484977722Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14713427424430847
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3429620563983917

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16058053076267242
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03865677863359451
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8508424162864685Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6958639025688171

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.34471675753593445
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.758571493672207e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012707027606666088Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007061423966661096

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013599105295725167
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011012451723217964
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02345949411392212
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021590250253211707
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016948048723861575
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.697831799509004e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00030338598298840225
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019393771653994918
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014078222739044577Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004884458612650633
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027739480137825012

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006709551089443266
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028816002886742353
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00020821050566155463
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008538367110304534
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037085318472236395
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00027119641890749335
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014726927038282156
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006622202694416046
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000348146801115945
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010339459404349327
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038469904102385044
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00036592717515304685
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010473462752997875
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004715680610388517
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004617786325979978
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016790529480203986
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006350670475512743
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006418790435418487Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018903753953054547

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006401644088327885
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036366707645356655
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021256547421216965
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004565073177218437
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032791458070278168
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007738291751593351
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005536903045140207
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003173168282955885Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009441997855901718

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008613242534920573
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010024827904999256Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003895866684615612

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009734025225043297
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012422874569892883
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004252791870385408
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.047813571989536285
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002180276671424508
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010287665762007236
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010691320523619652
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012795806396752596
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003294808091595769
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011310231871902943
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001685141702182591
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030428755562752485
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010606655851006508
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001758972997777164Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028149597346782684Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01323006208986044


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00259317341260612Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011476236395537853

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020442612003535032
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013582894578576088Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020724348723888397

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004742552526295185Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014078948646783829Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022812813986092806


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021512290462851524
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022756594698876143
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017633178504183888
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13200579583644867
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002412305912002921
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00176024972461164
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15561611950397491
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005565960425883532
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12831144034862518Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15338896214962006

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016248023603111506
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14270754158496857
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02288086712360382
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016118420753628016Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5596134662628174

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18977980315685272
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016720519633963704Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.579115092754364

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017959466204047203
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018762856489047408
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024285640101879835
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03677193447947502
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026548070833086967
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030952293425798416
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019764302298426628
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2670762240886688
 20%|██        | 119/584 [12:44<53:33,  6.91s/it] 20%|██        | 119/584 [12:50<53:09,  6.86s/it] 20%|██        | 119/584 [12:47<53:33,  6.91s/it]Loss Loss tensor(3.8519, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(3.9254, device='cuda:0', grad_fn=<NllLossBackward0>)
Loss tensor(3.6434, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5241458415985107Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01911259815096855Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23350143432617188


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.30734536051750183
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.46920377016067505
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5050265789031982Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01597657799720764
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05487535521388054

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013636314310133457Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.28531691431999207

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15017156302928925
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.4337251640390605e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02305903099477291
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00048467269516550004
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.82367166923359e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013331316586118191Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008271312690339983
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015556956350337714

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014993046643212438
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022835734125692397
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002442787226755172
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001856317394413054
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004201052652206272
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004259214620105922
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030457195825874805
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007202615379355848
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003486955538392067
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009981542825698853
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006045529153198004
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036054851952940226
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001355180749669671
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009212211007252336
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004255456384271383
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014746556989848614
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002961503341794014
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017051594331860542
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010997497010976076
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027042259462177753
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027234377339482307
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036275130696594715
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011753729777410626Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029989995528012514

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003695290768519044
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004246156197041273
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001197944162413478
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008419251069426537
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003999285865575075
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009098517475649714
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003989006858319044
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038946836721152067
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007588923908770084Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004768748302012682

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004752338398247957
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005249635316431522
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010229654144495726
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0055201672948896885
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007181124296039343
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007419280242174864
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00114021310582757
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023826345801353455
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0044266278855502605
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022584612015634775
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009069259278476238
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004181111231446266
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001257918425835669Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00987329613417387

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003938834182918072
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009362872689962387
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016482415376231074Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003674036357551813

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011264834553003311
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00288410484790802
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018512862734496593Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009938349016010761

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003235101466998458
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011572359129786491
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003236994380131364
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002377082360908389
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01196708157658577
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033635336440056562
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005438264459371567
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018227899447083473
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005644169636070728
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002967588836327195Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05730650946497917
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21319063007831573

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04835062846541405
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02578115276992321
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00314909010194242
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.058241382241249084
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2573417127132416
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030871592462062836Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.843120276927948
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07345040887594223

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8266750574111938
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003265748731791973
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031826409976929426
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033159691374748945
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003829739987850189
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004247940611094236
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.031212639063596725
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019662072882056236
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02909986488521099
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020787572488188744
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6831629872322083
 21%|██        | 120/584 [12:54<48:15,  6.24s/it] 21%|██        | 120/584 [12:49<48:32,  6.28s/it] 21%|██        | 120/584 [12:52<48:31,  6.28s/it]Loss Loss Loss tensor(4.2965, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(3.5802, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(3.8485, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.31553342938423157Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13616542518138885
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0225730761885643

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.25087887048721313
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1816154420375824
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6941268444061279Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07640089839696884

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011777627281844616
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04940037056803703Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012437966652214527

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00017733013373799622
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.25057336688041687
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007096152286976576Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003021815500687808

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.7019541196059436e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006140617770142853
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.052822573110461e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.0206002924824134e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008411180460825562
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.15992131922394e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014493662165477872
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002048719208687544
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001739133585942909Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011014801566489041

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002584711881354451
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00018210193957202137
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003272159257903695
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00028187106363475323Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004537812783382833Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002940385602414608


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028386160265654325
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000886285793967545
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00047177920350804925
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030703535303473473
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012747020227834582
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002956466283649206
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007070573046803474Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016459192847833037

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007412020582705736
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018206201493740082
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009299008524976671Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004846209194511175

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019537368789315224
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0066960658878088
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011063599959015846Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029254343826323748

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010302972048521042
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031197674106806517
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010581875685602427
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013867759145796299
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004494447726756334
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010042962385341525Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01638958789408207
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004651322960853577

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01408776268362999
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005077336449176073
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001084966235794127
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013525980524718761
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006406500935554504
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012315760366618633
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010435325093567371
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00702357804402709
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012108208611607552
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008752834983170033
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001707583200186491Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010895986109972
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005255012307316065

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012352853082120419
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004759540781378746
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001717599923722446
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011682126671075821
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0043283430859446526
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027017579413950443
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018143152818083763
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0039114574901759624
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037428438663482666
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021261103451251984
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003000888042151928
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00499529205262661
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0286788959056139
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032510559540241957
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005812016315758228
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07193077355623245
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032752363476902246
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0053252121433615685
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10901882499456406
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033029597252607346
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005290372297167778
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9432601928710938Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005480433814227581

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004878280218690634
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23296689987182617
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.042040929198265076
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004073471296578646
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.39344969391822815
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004259691573679447
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8320552110671997
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0041664899326860905
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00412951223552227
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005279973614960909
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008532971143722534
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011464784853160381
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027791926637291908
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03956807032227516
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6446771025657654
 21%|██        | 121/584 [12:55<48:15,  6.25s/it] 21%|██        | 121/584 [13:01<48:04,  6.23s/it] 21%|██        | 121/584 [12:58<48:16,  6.26s/it]Loss Loss Loss tensor(4.6197, device='cuda:1', grad_fn=<NllLossBackward0>)tensor(3.9027, device='cuda:2', grad_fn=<NllLossBackward0>)

tensor(4.6491, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.38066694140434265Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5283393859863281

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14224106073379517
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7385205626487732Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09434153139591217

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1966448575258255Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01892925053834915

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004568565054796636
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03054709918797016Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007252070936374366

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012057405547238886
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001217948505654931
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00019739795243367553
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001474423217587173
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023872198071330786
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00031240013777278364
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002814185107126832
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034307262394577265
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00043951027328148484
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004910477437078953
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000642862287349999
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004119211342185736
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004782355856150389
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007982149254530668
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006078052334487438
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001059394795447588
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00601610355079174
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013649334432557225Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011484320275485516

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006467605475336313
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013035819865763187
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0061157201416790485
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014723425265401602Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00579496193677187

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006864631082862616
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020028685685247183Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02050897292792797

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006772624794393778
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001974911894649267
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006868691183626652
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002970566041767597
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0064776502549648285
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006945416796952486
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022009010426700115
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0061682965606451035
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006966467015445232
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00221645156852901
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008143976330757141
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021639808546751738
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00839842576533556
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024605898652225733Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06543226540088654

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06839396804571152
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004627631977200508
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05608212947845459
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023998189717531204
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.051361504942178726
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8782151937484741
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002367254113778472
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002096563344821334
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020520268008112907
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018567639635875821
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019232187187299132
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021993513219058514
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023741726763546467
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025630462914705276
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02238108031451702
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018390998244285583
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015086593106389046
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.41512051224708557
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.032199498265981674
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.31280019879341125
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.049193061888217926
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7156842350959778
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.797043458092958e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015366359730251133
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002549056080169976
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00037433914258144796
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006515942513942719
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009327221196144819
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010299711721017957
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016371275996789336
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012409542687237263
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013917186297476292
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002395565388724208
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002906274050474167
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004602524917572737
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004276639316231012
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038265869952738285
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004596105311065912
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0050498745404183865
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010195608250796795
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004069173242896795
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003952599596232176
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038460073992609978
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035958453081548214
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028737615793943405
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033114426769316196
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003438868559896946
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035764274653047323
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006223540753126144
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16399891674518585
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022459091618657112
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20744793117046356
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5618635416030884
 21%|██        | 122/584 [13:01<47:13,  6.13s/it] 21%|██        | 122/584 [13:04<47:13,  6.13s/it] 21%|██        | 122/584 [13:06<47:11,  6.13s/it]Loss Loss Loss tensor(3.9896, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.2595, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.2430, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.46409687399864197Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4073670208454132
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01904386654496193

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.28750887513160706
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3059181272983551
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.764583945274353Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2491532564163208

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06494631618261337
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015191269107162952Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3044036030769348

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004672187496908009
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019572889432311058
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3475876450538635
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007798778242431581
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.639680264517665e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.88133700855542e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013646024744957685

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016705059679225087
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.880799239501357e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.186155173461884e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002841716865077615

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001357451401418075
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033017711248248816
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013714228407479823
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001967097050510347
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038374417927116156
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001930321304826066Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005107598844915628
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003414624370634556

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004720176570117474
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005394602776505053
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000304931279970333
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005873506888747215
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006984117208048701
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003707568976096809
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007712744642049074
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010247222380712628
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00047182824346236885
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008597717620432377
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011589896166697145
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02331949770450592
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005494875367730856
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001493578078225255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005568154738284647Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014529231935739517

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027061435393989086
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02223711647093296
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00062894681468606
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03032301925122738
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003418663516640663
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009388822363689542
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03975016996264458
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005349650979042053
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04531051963567734
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001064153271727264
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006074180360883474
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0434153713285923
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001980396918952465
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007177012041211128
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04325364902615547
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009782548062503338Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018215500749647617
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.039085134863853455

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011461789719760418
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04058295115828514
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003025722224265337
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011079570278525352
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03306790813803673
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037499822210520506Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009512561373412609

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03998145833611488
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00937510747462511Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0388607420027256

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004666205961257219
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04431525245308876Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009277509525418282

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0053980969823896885
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06825529783964157
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008468185551464558
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005107033532112837
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13709419965744019
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006745106540620327
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005227195098996162Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07510130107402802
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0078854039311409

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1659613847732544
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008173595182597637
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004751282744109631Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7217063903808594
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008437112905085087

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012479458004236221
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0042359428480267525
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23096133768558502
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003962439019232988
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027515890076756477
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3066881597042084
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004473411478102207
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7947511672973633
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0043335119262337685
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004935739561915398
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009327998384833336
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023575443774461746
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011625247076153755
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020856350660324097
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.44490545988082886
 21%|██        | 123/584 [13:06<46:19,  6.03s/it] 21%|██        | 123/584 [13:12<46:11,  6.01s/it] 21%|██        | 123/584 [13:10<46:19,  6.03s/it]Loss Loss Loss tensor(4.2939, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.0200, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.5792, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024658353999257088
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.309050977230072
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4366300106048584Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21404437720775604
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18848752975463867

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.033537860959768295Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.35402536392211914
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0858890488743782

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1640869677066803
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4227290749549866Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016666926443576813

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00031648401636630297
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.293131496524438e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026827240362763405
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005130736972205341
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.827188190072775e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.732788410270587e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008692517294548452

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001178639504360035
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00108927336987108
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014799152268096805Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00018221602658741176
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001973171019926667

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003681187517940998
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002115771872922778
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00024519945145584643
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006619315245188773
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002651554299518466
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003566696250345558Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001119600492529571

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003983828704804182
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001774946111254394
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005550037021748722
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003610227955505252
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002022462897002697
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006144677754491568Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004335737321525812

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002273956313729286
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007115243934094906
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007886079838499427
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036350958980619907Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007746445015072823

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010700802085921168
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012275478802621365
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004098127596080303
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010854696156457067
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009676319546997547
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005782690830528736
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009975111111998558Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013471381971612573

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005489095579832792
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009455076418817043
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002445489400997758
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005491739604622126
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009886234998703003
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00271528959274292Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006844948511570692

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014769117347896099
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0075812372379004955
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038667137268930674Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009641168639063835

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009202511981129646
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010257800109684467
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003474381286650896Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005916880909353495

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011057393625378609
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005558454431593418
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037070661783218384
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011196230538189411
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005259556695818901
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010762589052319527
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036411124747246504
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004692874848842621
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01584097556769848
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037757684476673603Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037593869492411613
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013712631538510323

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004149599000811577
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02544158138334751Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00428767642006278

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004396941978484392
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.041961293667554855
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035422425717115402
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004495055880397558
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04682695493102074
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003471211064606905
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.060647152364254
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007053924258798361
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036209425888955593
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06467535346746445
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23575657606124878
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9056875109672546
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003236382734030485Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03053406812250614

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.29994216561317444
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034417524002492428Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7916501760482788

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003936024382710457
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003580627264454961
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0049208300188183784
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01518321968615055
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01638953387737274
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019334327429533005
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015367100946605206
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8256482481956482
 21%|██        | 124/584 [13:13<46:34,  6.07s/it] 21%|██        | 124/584 [13:18<46:28,  6.06s/it] 21%|██        | 124/584 [13:16<46:34,  6.07s/it]Loss Loss Loss tensor(4.0119, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.1550, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.2242, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.44790709018707275Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6989192962646484

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02038688212633133
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14381590485572815
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.882427453994751
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.47098904848098755
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.34764811396598816
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015096780844032764Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09566987305879593

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.434703528881073
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7458196878433228
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006680323858745396
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.685981108807027e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011331087443977594Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01980729028582573

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012296182103455067
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020575670059770346
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.814418207388371e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021324306726455688
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025408496148884296
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.667782822158188e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003033692482858896
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004308665171265602
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014886849385220557Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004859830718487501
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00048506734310649335

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005943288095295429
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006834339583292603
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000214900603168644
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008407308720052242
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009308734443038702
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00033366066054441035
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007134396582841873
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015708275604993105
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003946367942262441
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00838511809706688
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015402889112010598
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005144875030964613
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010939526371657848
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019271158380433917
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006088266964070499
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011605597101151943
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033103988971561193
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000607636640779674Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026922114193439484

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015999337658286095
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038862957153469324
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006700963131152093
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020685434341430664
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005602061282843351
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000977806281298399
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023310597985982895
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004782653413712978
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010464697843417525Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02748052030801773

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004192691762000322
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03713918849825859
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015457072295248508
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00528215104714036
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023504534736275673
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014992104843258858
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0056890151463449
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021974505856633186
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021197788883000612
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01715308055281639
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007189678959548473
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022443169727921486Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017215676605701447

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004364879336208105
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0137472627684474
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025316777173429728Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038612098433077335

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015532689169049263
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00367747456766665
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002964720828458667
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015252207405865192
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032386123202741146
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002170189283788204Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021420488134026527

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025760121643543243
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.053222574293613434
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002004998503252864
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027714744210243225
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05541304871439934
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001569881453178823
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05039697140455246
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002907287096604705
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013239517575129867
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11070387065410614
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002935863798484206
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.391066312789917
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012009532656520605
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00468104612082243
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012312587350606918Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.151370570063591

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020354589447379112
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011916372459381819
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21774941682815552
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3758726418018341
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015019491547718644
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0060263751074671745
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0053472924046218395
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007355459500104189
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008310416713356972
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1408546268939972
 21%|██▏       | 125/584 [13:19<47:20,  6.19s/it] 21%|██▏       | 125/584 [13:25<47:16,  6.18s/it] 21%|██▏       | 125/584 [13:22<47:20,  6.19s/it]Loss Loss Loss tensor(3.6568, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.4722, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.7054, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.42504367232322693Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.038289282470941544

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4289136230945587
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3787146508693695
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.40723294019699097Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.268871009349823
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10860597342252731

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5463112592697144
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.33865290880203247
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8329518437385559Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.83401041594334e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007751867524348199

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015807356976438314
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013247739989310503
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01795574650168419
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024431180208921432
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021446898579597473Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002783598320093006
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003167587798088789

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004011888231616467
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005616316106170416
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.48806560295634e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006528670201078057
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006468469277024269
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013908531400375068
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009482151363044977
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007289703004062176
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002482722047716379
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013094756286591291
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008925335481762886
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003728243173100054
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021920092403888702
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008880902081727982
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006000104476697743
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003078788984566927
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009798633866012096
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007336494163610041
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003930745646357536
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012779737822711468
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009011241490952671
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006337978411465883
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013436349108815193
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023549271747469902
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007011251524090767
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010528643615543842
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016539335250854492
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009352307766675949Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001060684327967465

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019614648073911667
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007838893681764603
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011140870628878474
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023482967168092728
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006495238281786442
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015513172838836908
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027398332953453064
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007626731414347887
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001580396550707519Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029085472226142883
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008201012387871742

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02433367818593979
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012072237208485603
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022778573911637068
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023282354697585106
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006720858626067638
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01945633627474308
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0063080498948693275
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001984881702810526
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02082611434161663
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0061510344967246056
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002524337498471141Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016343995928764343

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005444189999252558Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019670559093356133

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002831237856298685
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0044470252469182014
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020123500376939774
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003140839980915189Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004822754766792059
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023732773959636688

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04378216341137886Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005115367006510496

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003313255263492465
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07807772606611252
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005273755174130201
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09421029686927795
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002740714233368635
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008416703902184963
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1282000094652176
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.22038784623146057
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025927999522536993Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6382758021354675

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04176512733101845
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021960691083222628
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3134709894657135
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018909949576482177Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6287874579429626

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001718182465992868
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018964848713949323
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018199420301243663
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021835544612258673
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005809157155454159
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009776049293577671
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008210922591388226
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014982301741838455
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.37290385365486145
 22%|██▏       | 126/584 [13:28<53:01,  6.95s/it] 22%|██▏       | 126/584 [13:33<52:58,  6.94s/it] 22%|██▏       | 126/584 [13:31<53:01,  6.95s/it]Loss Loss Loss tensor(4.5404, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(3.8979, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(3.7783, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4981996715068817
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016180865466594696
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15573076903820038
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2803318202495575
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.48414722084999084
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.26328855752944946
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09573144465684891
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8459845781326294
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.34296226501464844
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018859902396798134Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5475883483886719

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007115303887985647
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.094068471109495e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023830464109778404
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011945065343752503
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001287727354792878
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.141975947888568e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012714223703369498Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002192179235862568
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002161059295758605

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00031149975256994367
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026725821662694216
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021358983940444887
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004546727053821087
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005240053287707269
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00031082690111361444
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005801981780678034
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008030118769966066
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005026665166951716
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007242122199386358
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009219693602062762
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006913029938004911Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009779208339750767
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001384182833135128

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010320156812667847
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001507147797383368
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009680875227786601
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013333010487258434
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018936482956632972
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012751334579661489
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018824663013219833
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033714063465595245
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013761530863121152Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01965462975203991
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004414004273712635

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028434040024876595
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006712131202220917
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001705522765405476
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02267327718436718
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007287571672350168
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025651606265455484
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022018449380993843
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006839407607913017
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002595981117337942
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022820116952061653
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008030417375266552
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003241564380005002
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02639196440577507
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008273903280496597
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003009576117619872
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0257821474224329
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007895378395915031
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003091685939580202
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024103490635752678
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006295607425272465
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031640941742807627
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022764697670936584
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005945404525846243
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034287134185433388
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01937314122915268
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005680852569639683
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033501668367534876
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018257973715662956
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005059478804469109
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003052512416616082
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014774655923247337
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004148069769144058
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002907827962189913
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016718534752726555
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004584524314850569
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002315726364031434
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017479656264185905
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004892266355454922
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001974091399461031
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022845663130283356
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005103374365717173
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018475123215466738
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03687770292162895
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00784207135438919
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017977245151996613
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0753946304321289
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.22282038629055023
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018944954499602318
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06255444139242172
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024391502141952515
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002138551091775298
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15545982122421265
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.25900202989578247
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003893386572599411Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7052741646766663
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7029547691345215

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013442028313875198
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0139272790402174
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01854499988257885
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21938273310661316
 22%|██▏       | 127/584 [13:33<49:53,  6.55s/it] 22%|██▏       | 127/584 [13:39<49:51,  6.55s/it] 22%|██▏       | 127/584 [13:37<49:53,  6.55s/it]Loss Loss Loss tensor(3.9403, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.0800, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(3.9753, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017682582139968872Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.34955671429634094

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3867875933647156Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17528752982616425
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.28250852227211

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21412502229213715
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04225762188434601
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8824553489685059Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.243771031498909

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.24293698370456696
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.112090053036809e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013066967949271202Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00040125445229932666

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.942920713801868e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006647082045674324
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01626589521765709
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.297977910842746e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011627301573753357
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.014387013739906e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011658512812573463
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014081280678510666

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001979232911253348Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002297717612236738

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.021073543000966e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00031952655990608037
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029128766618669033
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004508103884290904
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034554298035800457
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011531567724887282Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007315028342418373
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0046323370188474655

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008554832311347127
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004437806084752083
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016220736142713577
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010439984034746885
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00556701235473156
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002583727182354778
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017739145550876856
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006831928621977568
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00034996375325135887Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021920332219451666
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007642521057277918

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035494714975357056
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019827362149953842
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004656038072425872
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004509275313466787
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012720337137579918
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0050833821296691895Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005777321639470756
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018927304074168205

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006953611504286528
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02731945738196373
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005819867947138846
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007961188443005085
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03897405043244362
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006553992279805243
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007969343103468418
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04350109398365021
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000910647155251354Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006474427878856659
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04452237859368324

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006200936157256365
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04404984414577484
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009898445568978786
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006014426238834858
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04187287390232086
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017626817570999265
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005334961693733931
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04040283337235451
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001635288936085999
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004341866821050644Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025814941618591547
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03485851362347603

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004826910328119993
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05175246298313141
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033419171813875437
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005073660984635353
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04015118628740311
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004356747027486563Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005346948280930519Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07520370185375214


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07600845396518707
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00794241577386856
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004943631589412689
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12431080639362335
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19610652327537537
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08226288110017776
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02296694926917553
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004764254670590162
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1793961077928543
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2469663769006729
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004771430976688862
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8113495111465454
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8707121014595032
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004379453603178263
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003648053854703903
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003750308183953166
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004500010050833225
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003836390795186162
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005256250500679016
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00682328874245286
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020846469327807426
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012847651727497578
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022423435002565384
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.26430773735046387
 22%|██▏       | 128/584 [13:46<51:07,  6.73s/it] 22%|██▏       | 128/584 [13:41<51:09,  6.73s/it] 22%|██▏       | 128/584 [13:44<51:09,  6.73s/it]Loss Loss Loss tensor(4.0077, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.1387, device='cuda:0', grad_fn=<NllLossBackward0>)tensor(4.5625, device='cuda:1', grad_fn=<NllLossBackward0>)

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2572430670261383Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.25779110193252563
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024582920596003532

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20290443301200867
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1235332265496254
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6569680571556091Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0736391469836235

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025337202474474907
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014881650917232037Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11988499760627747

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20337903499603271
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00045637835864908993
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013042676262557507Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.158903564326465e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007588242879137397
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.028325176681392e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.83459036028944e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001390586607158184

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.772477303864434e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018455703975632787
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001424576184945181
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001322600874118507
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003341288771480322
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00025500613264739513
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002514873631298542
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004067941103130579
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004573274636641145
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00038937939098104835
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005165104288607836
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007357918075285852
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006245413678698242
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007097983732819557
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012103477492928505
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008325136732310057
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007914549671113491
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015112761175259948
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001153585035353899
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009835313074290752
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018298093928024173
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014436213299632072
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015900911530479789Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002934115706011653

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015172048471868038
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032672088127583265
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017610787181183696
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018448486924171448
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00460330443456769
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00215156190097332
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01671568676829338
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004649536218494177
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003255011746659875Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011367022059857845

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004472207278013229
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01101295743137598
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005615904461592436
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032837053295224905
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013325691223144531
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0063569326885044575
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003796897828578949Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0166013203561306
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007698716130107641

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016717715188860893
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0051481532864272594
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035848570987582207
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018333999440073967
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00475784158334136
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002575790509581566Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01987656205892563

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004428211599588394
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020155860111117363
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024618450552225113
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003918153699487448
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018391402438282967
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028246822766959667
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031671389006078243
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025073301047086716
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003404309507459402Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033958961721509695

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020556598901748657
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036109345965087414
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003325878642499447
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.036126647144556046
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038349211681634188
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.056888289749622345
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003361644223332405
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005916574504226446
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07229288667440414
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037235096096992493
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.24226395785808563
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11132057011127472
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033797258511185646
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1653207540512085
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029560210183262825
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034732527565211058Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9047262072563171

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.31822460889816284
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037844509351998568Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8836898803710938

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036760210059583187
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004542743321508169
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00808242429047823
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014213808812201023
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021827898919582367
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.031581178307533264
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7068251967430115
 22%|██▏       | 129/584 [13:46<47:56,  6.32s/it] 22%|██▏       | 129/584 [13:52<47:55,  6.32s/it] 22%|██▏       | 129/584 [13:49<47:56,  6.32s/it]Loss Loss Loss tensor(4.2432, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(3.7096, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.0525, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4591732323169708Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015606745146214962
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.43528327345848083

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3676154911518097
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19209444522857666
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8660517334938049Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05141064152121544
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.30899715423583984

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2996889650821686Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014101231470704079

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2929263114929199
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.571789759211242e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005496273515745997
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.157203071983531e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015431173145771027Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007409107638522983

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001175389188574627
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012821957934647799
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001785129716154188
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.247101242071949e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003389831108506769
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001611783867701888
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005690268590115011
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.679815123789012e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002561297733336687

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008319878834299743
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029960251413285732
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011257315782131627
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001246207277290523
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003185291076079011
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001747572241583839
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014787076506763697
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005186832509934902
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002693712885957211Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001744381501339376

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005211248062551022
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00272188032977283
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002953852235805243Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006980345584452152

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002926188986748457
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009657748974859715
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00030496998806484044
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003999065142124891
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010555975139141083
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00046032643876969814
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037338377442210913
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022528264671564102
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000522464222740382
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003664171788841486
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012831994332373142
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006650945288129151
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004948672838509083
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01659056916832924
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010438170284032822Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005604736972600222

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018477817997336388
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006095075514167547
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00112275336869061
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02252301387488842
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004423058591783047
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017266739159822464
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02664022520184517
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004012819845229387
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014520069817081094
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02322506718337536Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037452143151313066

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002031754469498992
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033251941204071045
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02389385737478733
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00211467151530087
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026343378704041243
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021647876128554344
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023928387090563774
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027789603918790817
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021051578223705292
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026490739546716213
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029638539999723434
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019548486918210983
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002247461350634694Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003149730386212468
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025213779881596565

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004800194874405861
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02361549437046051
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002194118918851018
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1974300593137741
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04001534357666969
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001971958903595805
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018279314041137695
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.045253265649080276
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016187283908948302
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2391330599784851
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05558323115110397
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017185515025630593Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8218173384666443

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09279488027095795
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018393700011074543Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13741233944892883

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7427439093589783
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00180445471778512
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002398111391812563
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003813786432147026
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005594481248408556
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010381435975432396
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013230516575276852
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.195670023560524
 22%|██▏       | 130/584 [13:58<49:02,  6.48s/it] 22%|██▏       | 130/584 [13:53<49:03,  6.48s/it] 22%|██▏       | 130/584 [13:56<49:03,  6.48s/it]Loss Loss Loss tensor(4.3883, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.6636, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(3.5124, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1617816984653473Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029527980834245682Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.27797287702560425


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2975029945373535
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19500088691711426
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6909070611000061Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.045876871794462204
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009678204543888569

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010380195453763008Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05639006942510605
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2434013932943344

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000545394723303616
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.371878432924859e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007904673926532269
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008750168490223587
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.556310785934329e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016292031796183437
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015705268597230315
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001484806416556239
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002045802306383848
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000292751268716529Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002247369848191738

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003748437622562051
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00043412327067926526
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005168602801859379
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0040548453107476234
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007669804035685956
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007857650052756071
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0041856602765619755
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012511304812505841
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013064551167190075Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004790711682289839

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017650170484557748
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004382283892482519
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001505456049926579
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001989745767787099
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0042985971085727215
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015944659244269133
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022354412358254194Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005302824079990387

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017061933176591992
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034250107128173113
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005496809724718332
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015797633677721024
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036969727370887995
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008028639480471611
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014855345943942666Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00502796471118927

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007479348685592413
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004563858266919851
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001751482137478888
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0055088261142373085
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004188033752143383
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017999665578827262
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0064215585589408875
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005354768596589565
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025502333883196115
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00882286299020052
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005979191977530718
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011702267453074455
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025211877655237913Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007901972159743309

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012288181111216545
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0046982900239527225
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019871678669005632Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013215910643339157

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004240360110998154
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013553745113313198
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022380633745342493
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038530961610376835
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013239744119346142
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028873716946691275Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034215550404042006
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012259960174560547

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027485534083098173
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01762184500694275
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003685906995087862
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027934852987527847
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015070542693138123
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036433450877666473Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030423076823353767

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02645781822502613
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003228119807317853
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03256141394376755
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037510464899241924
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0051371012814342976
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.041423577815294266
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038905739784240723
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.257463663816452
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08378954231739044
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003375337226316333Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025525566190481186
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11725227534770966

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9240314364433289
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3039262890815735
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003697637002915144Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8614499568939209

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004201081115752459
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003816968994215131
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005192697513848543
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008842045441269875
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01591382920742035
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02918793261051178
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03506174683570862
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6652844548225403
 22%|██▏       | 131/584 [13:59<47:17,  6.26s/it] 22%|██▏       | 131/584 [14:04<47:17,  6.26s/it] 22%|██▏       | 131/584 [14:02<47:18,  6.26s/it]Loss Loss Loss tensor(4.1476, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(3.6823, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.0622, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.30084362626075745
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.27436912059783936
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.36535635590553284Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12905153632164001

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.893200695514679
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1910492479801178
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011935029178857803Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008074751240201294

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013024061918258667
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016198202967643738
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021709217689931393
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010556585766607895
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026382822543382645
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00018167085363529623
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004561025183647871
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00029511540196835995
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004761056043207645
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004210018669255078
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004789911676198244
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006793412030674517
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005641967989504337
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007634058129042387
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005674412939697504
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008334587910212576
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007087510544806719
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009352611377835274
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010390263982117176
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009567474480718374Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010634328238666058

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013436801731586456
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011530129704624414
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011131513863801956
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00893845222890377
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017860912485048175
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008912147022783756
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017893400508910418
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012574960477650166
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018726296722888947
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020389968995004892
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016165556386113167
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001962510170415044Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016880149021744728

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017340803518891335
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016523129306733608
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016108298674225807
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014603909803554416
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014868763275444508
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0219721756875515
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016325098695233464
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016029026359319687
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021765814162790775
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02248574048280716
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.034547291696071625
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019211735343560576
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.188996359705925
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03259658068418503
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020207453053444624Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.046926580369472504
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0476800762116909

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04192935675382614
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002106437459588051Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3742663860321045

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09212446957826614
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.865929703461006e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016532514709979296
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8734012246131897
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001376592554152012
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00200422084890306
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022345350589603186
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003196318866685033
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021556324791163206
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005603619501926005
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007893175934441388Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017999850679188967

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009554202551953495
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027183026541024446
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001353300642222166
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006013194564729929
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014902130933478475
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001728496397845447
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009108873084187508
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002709203865379095
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007685033604502678
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030014680232852697
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011960449628531933
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004083374049514532
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.260605126619339
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004383130930364132
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004683596082031727
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006110475864261389
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0065237549133598804
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006929393857717514
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0048303138464689255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004337337799370289
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038795368745923042
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003414150793105364
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027422585990279913
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002801819471642375
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030526930931955576
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032556105870753527
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005136227700859308
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2515183091163635
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023231269791722298
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.28843170404434204
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8210734128952026
 23%|██▎       | 132/584 [14:04<44:34,  5.92s/it] 23%|██▎       | 132/584 [14:07<44:35,  5.92s/it] 23%|██▎       | 132/584 [14:09<44:36,  5.92s/it]Loss Loss Loss tensor(4.2038, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(3.9424, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(3.9630, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19394923746585846Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021430302411317825

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20438770949840546
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3376613259315491Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.33409103751182556

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018214737996459007
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19020727276802063Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007916884496808052
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2428518682718277

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.676551907323301e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07545562088489532

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010729766450822353
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.187113078543916e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17784278094768524
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.911737338872626e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006963401683606207
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011651432578219101
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013043567014392465
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001801725011318922
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011042025871574879
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00036871363408863544
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017364562954753637
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00020846654660999775Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006626195972785354

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012251982698217034
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022984440438449383
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003181129286531359
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020074942149221897
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00387751217931509
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00046400493010878563
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024901586584746838
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004361956845968962
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005715593579225242
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002709580585360527
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0058943722397089005
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008230163366533816Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0039865742437541485

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008766239508986473
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004376804456114769
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012247351696714759Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008167916908860207

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006391984410583973
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009239304810762405
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011081837583333254
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006532573141157627
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015449835918843746
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012557700974866748Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005789775401353836

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01665855199098587
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006784945726394653
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020580352284014225Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019065778702497482

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007075373083353043
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012948657386004925
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020931775216013193
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007762226741760969
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014773202128708363
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023706848733127117
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005364338867366314
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016192279756069183
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004792938008904457
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017108552856370807
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018226752057671547
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004268198274075985
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018183744978159666
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021513046696782112
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037914852146059275
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022040007170289755Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031086131930351257
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01784016564488411

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030679316259920597
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017572879791259766
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002432979876175523
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033845079597085714
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019093379378318787
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026682084426283836
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035612634383141994
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020758001133799553
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024295905604958534Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005714107304811478

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019183680415153503
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.32413432002067566
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023334177676588297
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02117224410176277
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026333337649703026
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002432136330753565
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3347263038158417
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028685925528407097
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002464327961206436Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8247246742248535

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029820242896676064
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002337142126634717Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07541019469499588

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09796581417322159Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024860657285898924

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14955388009548187
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029189931228756905
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14752893149852753
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030691446736454964Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.865381121635437

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006116230506449938
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010018417611718178
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019081801176071167
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017316501587629318
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9204845428466797
 23%|██▎       | 133/584 [14:16<46:05,  6.13s/it] 23%|██▎       | 133/584 [14:10<46:06,  6.13s/it] 23%|██▎       | 133/584 [14:14<46:05,  6.13s/it]Loss Loss Loss tensor(4.6890, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.0268, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.5052, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4463653266429901Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015473916195333004
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18632596731185913

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13739439845085144
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.36702293157577515
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7237324118614197Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0287358146160841
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0898049846291542

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2125861644744873
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12675155699253082
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015306616201996803
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00042356032645329833
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.795359953073785e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018477462232112885Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006875591934658587

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.885887730983086e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.909498137654737e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.69496468314901e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012037570122629404
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000156393347424455
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014350542915053666
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015334670897573233
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00027784021222032607
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002807261422276497
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002605498011689633
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00041674869135022163Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033256688620895147

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003965534269809723
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005387082346715033
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0040882909670472145
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006556414300575852
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008008565055206418
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005481494124978781
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008898998494260013Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008504473953507841
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0059873503632843494

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010764445178210735Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007480015978217125

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011452344479039311
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001836958690546453Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01029952708631754

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015193165745586157Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002233299193903804Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010569385252892971


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031018357258290052
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013492818921804428
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016499059274792671Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003133771475404501

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011841323226690292Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030475130770355463

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019795717671513557
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008605759590864182
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004012357909232378
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007226372603327036
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0045181624591350555
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028239074163138866
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006941195577383041
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0055305007845163345
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027734709437936544
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008758668787777424
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003771244315430522
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033657464664429426Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009016472846269608

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035134446807205677
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01077576819807291
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032910360023379326
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003132269252091646Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011186833493411541

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030088466592133045
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011385577730834484
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00238116760738194
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002533675404265523
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010730317793786526
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002065626671537757
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026307692751288414
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014579365029931068
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019345757318660617
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029485058039426804
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01365680992603302
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002238492714241147
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032276709098368883
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02339618280529976
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002249435754492879
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028572358191013336
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005118998233228922
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024223304353654385
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.033411409705877304
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23928961157798767
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09697423875331879
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002496797824278474
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024206288158893585
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10237575322389603
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002270250814035535Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.884398341178894
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.29777178168296814

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.887771725654602
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023450555745512247
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002610832452774048
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002773582935333252
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003439226420596242
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006187925580888987
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008043630048632622
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025207901373505592
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025247549638152122
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.524305522441864
 23%|██▎       | 134/584 [14:16<45:45,  6.10s/it] 23%|██▎       | 134/584 [14:22<45:44,  6.10s/it] 23%|██▎       | 134/584 [14:20<45:45,  6.10s/it]Loss Loss Loss tensor(3.9823, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.4861, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.6489, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.39790937304496765Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018663691356778145

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.27523180842399597
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8973552584648132Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5375159382820129
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07093533873558044

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.22522462904453278
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013010654598474503
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5970659852027893
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2555930018424988
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017152097076177597Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.66212072246708e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.30815955996513367

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010091852163895965
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005673653795383871
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.509764403337613e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007951113511808217
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015563123452011496
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.611108256038278e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013478131731972098
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002268571115564555
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010111676238011569Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004248561162967235
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001608243677765131

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006483425386250019
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023500623647123575
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014747628301847726
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009078418370336294
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031093561556190252
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021935220865998417
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014565680176019669
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004013842903077602
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00028811919037252665Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001462061540223658

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006377951242029667
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013762898743152618
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004150064487475902Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006289229262620211

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023583120200783014
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008949210867285728
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006414646632038057Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029682074673473835

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01347381342202425Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0044159782119095325

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006874801474623382
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0044402191415429115
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013766041956841946
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009684553369879723
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003783215070143342
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021338310092687607
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001591451815329492Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004339978564530611

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012972633354365826
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004387021530419588
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015773996710777283Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011938289739191532

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006591324228793383
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010991114191710949
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019681777339428663
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033684493973851204
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011277668178081512Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029983804561197758
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00157367461360991

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027209697291254997
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018558533862233162
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001542970072478056
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002439206698909402
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008332962170243263
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020329062826931477
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001368214376270771
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007953883148729801
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002018961124122143
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013475475134328008
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007590983062982559
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022449626121670008
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015894012758508325Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008524425327777863

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00236517540179193
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008846567943692207
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0039763376116752625
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010041282512247562
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18680931627750397
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008638625964522362
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008713074494153261
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021413303911685944
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009970862418413162
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008052318589761853
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2118644416332245
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015678593888878822
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6941982507705688
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008135720272548497
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.044810328632593155
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008673724951222539
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07269979268312454
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008514949004165828Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07383953034877777

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08071181178092957
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010239580878987908
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6914564967155457
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011203226167708635
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0052082412876188755
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008907917886972427
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00606260821223259
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0060715451836586
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18907523155212402
 23%|██▎       | 135/584 [14:29<46:35,  6.23s/it] 23%|██▎       | 135/584 [14:23<46:36,  6.23s/it] 23%|██▎       | 135/584 [14:26<46:36,  6.23s/it]Loss Loss Loss tensor(3.9548, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(3.7689, device='cuda:0', grad_fn=<NllLossBackward0>)tensor(4.2639, device='cuda:2', grad_fn=<NllLossBackward0>)

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.22477512061595917Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4793464243412018
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020850740373134613

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.35112282633781433
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2019575536251068
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6917744278907776Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15278062224388123

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06485605239868164
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018322594463825226
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14894065260887146
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.28524672985076904
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000482373870909214
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018250875174999237Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.021430090186186e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000676726340316236
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.210081771016121e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.571938476758078e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012532458640635014

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014924287097528577
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015737691428512335
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001161054169642739
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022427966177929193
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023629365023225546
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000445120211225003
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001960603694897145Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003293791087344289

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006677976925857365
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0044607073068618774
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00029704030021093786
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008822903619147837
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006489998195320368
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00044872902799397707Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001338569913059473

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007244003936648369
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014666486531496048
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006297844811342657Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00931259710341692

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015332234324887395
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012410923838615417
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010065907845273614
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002593817887827754
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011514905840158463Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015410671476274729

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003353134961798787
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013427573256194592
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001692995079793036
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005041820462793112
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009831688366830349
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002094302326440811Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005464008077979088
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008790641091763973

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004754173569381237Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007848734967410564

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002910991432145238
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00542425038293004
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00842233281582594
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002592186676338315
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005560746416449547
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012809151783585548
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003035015659406781
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006987892556935549
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007810748647898436
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002375496318563819
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008293328806757927
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004296609200537205
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00822839979082346Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038014627061784267Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002141665667295456


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009517865255475044
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003419127082452178
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019220802932977676
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008425777778029442
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003087821649387479
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019379182485863566Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009475355967879295
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025900471955537796

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011124510318040848
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026124785654246807
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022668750025331974
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015204022638499737Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029501481913030148

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017397664487361908Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003127242438495159Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0318305678665638


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005461269989609718
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.033366862684488297
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016118730418384075Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2619578242301941
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06834451854228973

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030453458428382874Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09944462031126022

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016277129761874676
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8729331493377686
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.32311195135116577
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8360183238983154
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016996904741972685
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016427265945822
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018139019375666976
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002037538681179285
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022677904926240444
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012916083447635174
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01021329965442419
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01678968220949173
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016231346875429153
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5386135578155518
 23%|██▎       | 136/584 [14:28<43:34,  5.84s/it] 23%|██▎       | 136/584 [14:33<43:34,  5.84s/it] 23%|██▎       | 136/584 [14:31<43:35,  5.84s/it]Loss Loss Loss tensor(4.3239, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(3.8256, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.4523, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4498675465583801Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.49233779311180115
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020551230758428574

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2405409961938858
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.26159054040908813
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8675761818885803Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07192890346050262
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20792819559574127

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013682599179446697Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2838332951068878
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6616821885108948

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005716195446439087
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.724154031369835e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01957818865776062
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009015496470965445
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013235397636890411
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.437258707592264e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001438469160348177
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00020575868256855756
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010648202442098409
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017142482101917267
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000292651035124436
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016282290744129568Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029730757232755423

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005322621436789632
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003244723193347454
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007182876579463482
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022990108118392527
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003991538193076849
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009167864336632192
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003645702381618321Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005696426145732403
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00143184675835073

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0053738756105303764
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001248748041689396
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00042304632370360196
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006862618960440159
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013642186531797051
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005521028651855886Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022915913723409176
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009641584008932114

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028594902250915766
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010161473415791988
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006993182469159365
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004180968273431063Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0180493351072073

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007496992475353181
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012232598848640919Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003816315671429038

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009068177314475179Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012495037168264389Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033140156883746386


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01239543966948986Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00423117121681571

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001373037463054061
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004477553069591522
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01262053195387125
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00724450359120965
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014148677000775933Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02531028538942337

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003561762860044837
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009999974630773067
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019271507626399398
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003136527491733432
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009520882740616798
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017930107424035668Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028424032498151064
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007778910920023918

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025621040258556604
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00777911301702261
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020038115326315165
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002116352552548051
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007139286957681179
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002150299260392785
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019130506552755833Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008260437287390232

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023971046321094036
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008969193324446678
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018820882542058825
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025292809586972
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011670390143990517
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026824248488992453Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00469733402132988
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.057148825377225876

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18099483847618103
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05415957048535347
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014998632250353694
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0251140296459198
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04278278723359108
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013560728402808309Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.24944175779819489

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07035040110349655
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6263425946235657
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7485921382904053
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010781449964269996
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000994415720924735
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009369435720145702
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009442167356610298
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010254152584820986
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011836275225505233
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010362452827394009
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007883060723543167
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006804272066801786
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010021522641181946
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20976534485816956
 23%|██▎       | 137/584 [14:35<46:10,  6.20s/it] 23%|██▎       | 137/584 [14:41<46:10,  6.20s/it] 23%|██▎       | 137/584 [14:38<46:10,  6.20s/it]Loss Loss Loss tensor(3.9791, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.5873, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(3.8564, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014909961260855198
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4932249188423157Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.418015718460083

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.24375386536121368
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2012755423784256
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8931870460510254
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07147499918937683
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.37343478202819824
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013099579140543938Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3587983548641205

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3449884355068207
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.4571068428922445e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00047369851381517947
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013542010448873043Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.864758324809372e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006958530284464359
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.6552203053142875e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011079584510298446
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001232439186424017

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016800788580439985
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001513563096523285
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.071256989846006e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003444798639975488
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002494953805580735
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.410638161469251e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005023733247071505
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003304088255390525
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006592690479010344
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.623148798709735e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00433032400906086

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010723172454163432
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006912978366017342
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015895318938419223
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001114344922825694
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00752602331340313
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002181028394261375Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011640774318948388
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010576906614005566

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016053495928645134
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00033203186467289925Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019042831845581532

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01736254058778286
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024075042456388474
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005173128447495401
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027246752753853798
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003485645866021514
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005992552032694221
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020641891285777092
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032629184424877167
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007999555091373622Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02027084119617939
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003134588012471795

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019032418727874756
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004310965538024902
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013089876156300306
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018323488533496857
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004853712860494852
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013683404540643096Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021477246657013893

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005969807505607605
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014635290950536728
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019332525553181767
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004248577170073986
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01460301224142313
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017329477705061436
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003894245717674494Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013702982105314732

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001849832944571972Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0133266132324934Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036693704314529896


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01273125410079956Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034189033322036266

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017055826028808951Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01705583743751049
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002806337783113122

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016709724441170692
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029710400849580765
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016170799499377608Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023671044036746025

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033533144742250443
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.053686000406742096
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017427961574867368
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003626429010182619
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06753577291965485
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012790936743840575
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0059043229557573795
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07388094812631607
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011576507240533829Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2107880711555481Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14157533645629883


Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6474263668060303
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028011104092001915
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009509798255749047
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3114703893661499
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008756048046052456Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8148791790008545

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008496778318658471
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009242237429134548
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010183306876569986
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011486585717648268
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005354743450880051
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005113017279654741
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00958266481757164
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007953229360282421
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16395941376686096
 24%|██▎       | 138/584 [14:42<48:31,  6.53s/it] 24%|██▎       | 138/584 [14:48<48:32,  6.53s/it] 24%|██▎       | 138/584 [14:45<48:32,  6.53s/it]Loss Loss Loss tensor(4.6481, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.1520, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.7320, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04790995642542839
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7457359433174133Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5285855531692505
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12575861811637878

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2236379235982895
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.44025468826293945Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022155730053782463

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07437063008546829
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8096475601196289
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020736219361424446
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.426202162401751e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04349507763981819
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.47377338889055e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2593352198600769
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000399232842028141
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001362920447718352Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013170599413570017

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006021677399985492
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001772826217347756
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002013574994634837
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000900388928130269
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002655862190295011
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009724589181132615
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002772887528408319Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00038327378570102155

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013459983747452497
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008883979171514511
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000349862442817539
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014510862529277802
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016982449451461434
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004585242422763258Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029019012581557035

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009322277619503438
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005256516858935356
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004807967634405941Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007255112286657095

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025797246489673853
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013571351300925016
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008722911006771028Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030495396349579096

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017059368547052145
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004179161507636309
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014740002807229757
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00392904132604599
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0039502037689089775
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006692063179798424
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002568050054833293
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013838489539921284
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008173234527930617
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023041178938001394Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004923161119222641

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029069501906633377
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012043020687997341Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005657158326357603

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003263642778620124Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004994448274374008

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014347850810736418
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014400772750377655
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005824997555464506
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005525379441678524Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.035385649651288986
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028802487067878246

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006699114106595516
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026546709705144167
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001992549281567335
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007877033203840256
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002454531379044056
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023274922277778387
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00795025285333395
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002261165529489517
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020037898793816566Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009636699222028255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019495089072734118

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009679421782493591
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020442064851522446
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002147726248949766
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010995261371135712
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002304465975612402
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009511656127870083Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013330534100532532
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002487603109329939

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015375176444649696
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0059059783816337585
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024064944591373205
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12613970041275024
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14658984541893005
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002632036805152893
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1392199546098709
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029914941638708115
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026555717922747135Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10882770270109177
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21913602948188782

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5050946474075317
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0835052877664566
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027272384613752365
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7356258034706116
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00279738730750978
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003003084333613515
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035862165968865156
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0043929098173975945
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06299000978469849
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05951576307415962
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.049466829746961594
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03098534792661667
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4864063858985901
 24%|██▍       | 139/584 [14:53<45:33,  6.14s/it] 24%|██▍       | 139/584 [14:47<45:33,  6.14s/it] 24%|██▍       | 139/584 [14:51<45:33,  6.14s/it]Loss Loss Loss tensor(4.1598, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(3.3507, device='cuda:0', grad_fn=<NllLossBackward0>)tensor(3.9992, device='cuda:2', grad_fn=<NllLossBackward0>)

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3545445203781128Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027877449989318848

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2930760383605957
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.24896520376205444
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9041808247566223Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0448286198079586

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3716556131839752
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011941082775592804
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.28422439098358154
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1645582765340805
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00910201296210289
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.8396965717547573e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14455637335777283
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.5293957151006907e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.37634444097057e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000224380346480757
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.8580179534619674e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.172268669819459e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00032708526123315096
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011107473983429372
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.507943180622533e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002461859548930079
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.901128214551136e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006048741634003818
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000435762049164623
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008176513365469873
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015630164125468582Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000759697868488729

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013928321423009038
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00023040150699671358Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001165645895525813

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001308952341787517
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015836810925975442
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00035311156534589827
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001279126270674169
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022192317992448807
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005374799366109073Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021148943342268467

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002597745507955551
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036082505248486996
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004866282979492098
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004136635456234217
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00310261407867074
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006355090881697834
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036206142976880074
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004214099608361721
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011119600385427475Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034076415468007326

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006828575860708952
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0045554437674582005
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012118201702833176
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0050882333889603615
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007500776089727879
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002240267349407077
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008990028873085976
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013043247163295746
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014867122517898679
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004298971965909004
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008404884487390518
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014440263621509075
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003907953388988972
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007896010763943195
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001253496971912682
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003587955143302679
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0068567367270588875
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012092144461348653
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032789474353194237
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007662838324904442
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018990356475114822
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026804301887750626
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01530139148235321
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012008107732981443
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002829815959557891
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001226391876116395Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008612086065113544

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003150536911562085
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009720337577164173
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001258698757737875
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034513636492192745
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010263689793646336
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001250223838724196
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005876206327229738Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012673173332586884
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011259162798523903

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20142750442028046
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001347156590782106Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010641679167747498

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02899480052292347
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01454436406493187
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014162641018629074
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.26213330030441284
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01227949932217598
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017977539682760835
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8485827445983887Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02257501147687435

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008344044908881187
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07565825432538986
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01155473105609417
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0845668837428093
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014784503728151321
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1082511842250824
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013339738361537457
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23642294108867645Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09865383058786392

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8458148837089539
 24%|██▍       | 140/584 [14:58<42:48,  5.79s/it] 24%|██▍       | 140/584 [14:56<42:48,  5.78s/it] 24%|██▍       | 140/584 [14:52<42:49,  5.79s/it]Loss Loss Loss tensor(3.9438, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.0869, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.1669, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04449700564146042
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5408230423927307Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.614264190196991
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09427612274885178

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19548755884170532
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7552387714385986Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0241017434746027

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11128496378660202
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5836989879608154
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020010776817798615
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.384135900181718e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2752983868122101
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021606696769595146Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.299434608081356e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00042377255158498883

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.787099795881659e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006308343727141619
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.423719893675297e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001118094805860892
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014597531117033213
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000188977355719544
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009112616535276175
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00039520071004517376
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000193427040358074Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009871810907498002

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000982010504230857
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001267322339117527
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00023721471370663494Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018081472953781486

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016195786884054542
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014108536997810006
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002697818272281438
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012275931658223271
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033863724675029516
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003324176650494337
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018507519271224737
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006652734242379665
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007006072555668652
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021788987796753645
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0043702395632863045
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004338768310844898
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014096165541559458Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005041114985942841

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033571242820471525
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0075267828069627285
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000994593952782452Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032512058969587088
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007262060418725014

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004342918284237385
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017120977863669395
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011433267500251532
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004937659949064255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009069511666893959
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013386353850364685
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018395533552393317Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008871588855981827

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004264709539711475
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007789296098053455Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019408711232244968

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003934470936655998
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008811474777758121
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0055001587606966496
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036354733165353537
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0389341339468956
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002616142388433218Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033507030457258224

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011613385751843452
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027588140219449997
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024458460975438356Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013676244765520096

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002933058189228177
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014266018755733967
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022659380920231342Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032389468979090452

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015048092231154442
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035930571611970663
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002323742024600506
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006594017613679171
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015609021298587322
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17824548482894897
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007404102943837643Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020124463364481926

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02736940234899521
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01867966167628765
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002780152717605233Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21934689581394196
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030225055292248726

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7528563141822815
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18667343258857727
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002992329653352499
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2046501636505127
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029988670721650124
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19842541217803955
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028757916297763586Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13519184291362762

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5974313020706177
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002931421622633934
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003281419165432453
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033654000144451857
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004551686346530914
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04758021607995033
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.052089035511016846
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04758402332663536
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03425035998225212
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3572625517845154
 24%|██▍       | 141/584 [15:05<44:49,  6.07s/it] 24%|██▍       | 141/584 [14:59<44:49,  6.07s/it] 24%|██▍       | 141/584 [15:02<44:49,  6.07s/it]Loss Loss Loss tensor(3.7046, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(3.6115, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(3.8377, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.40154126286506653Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.508423388004303
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024053122848272324

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.33583834767341614
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2924780249595642
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7990622520446777Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2159414142370224

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07013504952192307
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2820391058921814
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015026194974780083
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009451189544051886
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.41801926493644714
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017704414203763008Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015250269789248705

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010176961950492114
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015813810750842094
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.516166028333828e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026423782110214233

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032795744482427835
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016584362310823053Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002605643530841917

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005863995756953955
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00039186447975225747
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002768085687421262Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006098394747823477
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008110229973681271

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007004660554230213
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010920519707724452
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004180711694061756
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009207898750901222
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014762254431843758
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009702533483505249Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006893747486174107
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023826858960092068

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0109838442876935
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002562406938523054
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000799617962911725
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015011681243777275
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023201487492769957
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009847561595961452
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014759663492441177
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003340642899274826
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012552045518532395
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003927611745893955
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019694453105330467
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005528137553483248
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015261765569448471
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012899342691525817
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005819063633680344
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013101830147206783
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001390601391904056
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005134016275405884
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011280378326773643
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001993705751374364Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0061757927760481834
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011062707751989365

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006653670221567154
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017724255099892616
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018681591609492898
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008530273102223873
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010079494677484035
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022026498336344957Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0056111812591552734Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010264606215059757


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011148952879011631Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005103728733956814

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020816680043935776
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012590463273227215Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004712487105280161

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019100120989605784Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0043644229881465435Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012562112882733345


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035560941323637962
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013593520037829876
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015769116580486298
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037675094790756702
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015116126276552677
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004185430705547333
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014528570463880897Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02839101105928421

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0046303290873765945
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04332985728979111
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016720985295251012
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007796257734298706
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.044088274240493774
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011310280533507466
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2339603304862976
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1322804093360901
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15096145868301392Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03334050625562668
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010556112974882126

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7426863312721252
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.28538084030151367
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011120260460302234
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7722745537757874
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010829956736415625
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012525863712653518
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012053148820996284
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015201892238110304
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001837639370933175
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008580279536545277
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0046660415828228
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014251859858632088
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013927963562309742
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3192565143108368
 24%|██▍       | 142/584 [15:05<45:09,  6.13s/it] 24%|██▍       | 142/584 [15:11<45:09,  6.13s/it] 24%|██▍       | 142/584 [15:09<45:09,  6.13s/it]Loss Loss Loss tensor(4.1877, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(3.4827, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.1007, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0498715378344059
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6293142437934875
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.49992793798446655Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10445816814899445

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2737230658531189
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013111673295497894
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6953533887863159Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06882771104574203

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6410686373710632
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01737004518508911
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.251455826917663e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.34995362162590027
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010738585115177557
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03881515562534332Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007113409228622913

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001575297355884686
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010762456804513931
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00017155997920781374
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002184241748182103
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016005652723833919
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001788309426046908Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00038264249451458454

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002735638408921659
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027781857643276453Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005902639240957797

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003983594651799649Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002902878448367119
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010985488770529628

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004496984649449587
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018368830205872655
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005283025093376637
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007186031900346279
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013684764271602035
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007856140146031976Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036150161176919937
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010337184648960829

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004173631314188242
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015029346104711294
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008397364872507751
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006060760002583265
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017772753490135074
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011081240372732282
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005239104386419058
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038174947258085012
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015691145090386271
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018068429082632065
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002801218070089817
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007735287072136998
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005631399806588888
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027912482619285583
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008515592780895531
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007099388632923365
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003922055009752512
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011964405421167612Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008124359883368015

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004663780797272921
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012248505838215351
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013290680944919586
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001363398157991469
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04579897224903107
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004303140565752983
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005618123337626457
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016452163457870483
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003980756271630526
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015444261953234673
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01803288795053959
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003764802822843194
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01700546219944954
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035736127756536007
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018904785392805934
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019226692616939545
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029926341958343983
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021601698826998472Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016169622540473938
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032616734970360994

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01935727521777153
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036324174143373966
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00306387129239738
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02158036269247532
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004139387514442205
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008826930075883865
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02497965842485428
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007833938114345074
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1671358346939087
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1672547459602356
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037241161335259676
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16787078976631165
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03788486495614052
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004002166911959648
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23462632298469543
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.22613368928432465
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7031958103179932
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20066529512405396
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003765314584597945
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.49447911977767944
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003603277262300253
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033698768820613623
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035993880592286587
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004231393802911043
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005046323873102665
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05214644595980644
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04871357977390289
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06778687238693237
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04621965065598488
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.502652108669281
 24%|██▍       | 143/584 [15:17<45:15,  6.16s/it] 24%|██▍       | 143/584 [15:12<45:15,  6.16s/it] 24%|██▍       | 143/584 [15:15<45:15,  6.16s/it]Loss Loss Loss tensor(3.6885, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.3715, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.6709, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.537075936794281Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.041737720370292664

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1675403118133545
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5983873009681702Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6176849007606506
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029109111055731773

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2502024471759796
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01733771525323391
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6233335137367249
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11362499743700027
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02918281778693199Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.653720917413011e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.29102128744125366
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014663123874925077
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001913743035402149
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009756956715136766
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002288502873852849
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014792123110964894
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00030767786665819585
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003401988069526851
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002374539850279689
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004800496099051088
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006719583761878312
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002753904554992914
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006760241813026369
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000998244620859623
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004543565679341555
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00106810440775007
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014605022734031081
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004633096046745777
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001182620762847364Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022248709574341774
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005228767171502113

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00187980686314404
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007422606460750103
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013499034103006124
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015638284385204315
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005334792658686638
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001591430976986885
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023400988429784775
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006252142135053873
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013325816253200173Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028296473901718855
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008054482750594616

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004475800320506096
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0068297069519758224
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001488863374106586
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004074622876942158
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014868105761706829
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018891929648816586
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003648175857961178
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008204284124076366
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015595918521285057
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004589386750012636
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00817436259239912
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028587181586772203
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005130442325025797
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008809949271380901
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001999392407014966
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01140959095209837
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011034208349883556
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021339664235711098
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004550660960376263
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.033943839371204376
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022161188535392284
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004206531681120396
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011900938116014004
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025835793931037188
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003969836514443159
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012828651815652847
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005285313352942467
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037058028392493725
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012920419685542583
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023862281814217567
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030802995897829533
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01396148931235075
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002473608823493123Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033161265309900045

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035978404339402914
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01391716580837965
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023979772813618183
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004105851519852877
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014918320812284946
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002465838799253106
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0071738846600055695
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018147509545087814
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026340805925428867
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1830863654613495
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020910119637846947
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002687295898795128
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03975841775536537
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.120400570333004
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003284909762442112
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.25045883655548096
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16858428716659546
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036374551709741354
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6946507692337036
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18085798621177673
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025197194889187813
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2107817530632019
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04079967737197876
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5782090425491333
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.035513874143362045
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04038107395172119
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5890690684318542
 25%|██▍       | 144/584 [15:25<47:58,  6.54s/it] 25%|██▍       | 144/584 [15:19<47:58,  6.54s/it] 25%|██▍       | 144/584 [15:22<47:58,  6.54s/it]Loss Loss Loss tensor(3.7112, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.3353, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.0792, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7724698781967163
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.063163161277771
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14040420949459076
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2434762716293335
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.24155904352664948
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04940285533666611
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3362060487270355
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8939540386199951
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008403791580349207
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012470627552829683
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00018782007100526243
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012961596949025989
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018913226667791605
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00028427341021597385
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00227935123257339
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004058072518091649
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00372925098054111
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006825756863690913
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036209053359925747
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010195981012657285
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004446381237357855
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001522015081718564
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007477401755750179
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025255349464714527
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004245753865689039
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018536142306402326
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0043776328675448895
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014234546106308699
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005433280486613512
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002098983386531472Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004808253142982721

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002560065360739827Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019315412268042564

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007373446132987738Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0050416928716003895

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003044452518224716
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010636428371071815
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012016982771456242
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002437259303405881
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030088480561971664Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01413542777299881

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033505763858556747Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03525787591934204

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015091356821358204
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013990324921905994
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003078943118453026
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01424297597259283
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027340897358953953
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012562642805278301
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002555571962147951
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01366537157446146
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023737535811960697
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012096043676137924
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020031146705150604
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013517103157937527
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002095951931551099
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015485476702451706
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002288483316078782
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017393754795193672
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025719834957271814
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15218621492385864
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005590981338173151
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16824908554553986
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09495870769023895
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2138717919588089
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026289917528629303
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10282415896654129
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3169584274291992
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11000753194093704
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3360494077205658
 25%|██▍       | 145/584 [15:26<49:02,  6.70s/it] 25%|██▍       | 145/584 [15:32<49:02,  6.70s/it]Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5254237651824951
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8343461751937866
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016325179487466812
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024221766740083694
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011469213495729491
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00018543015175964683
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002766638353932649
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00039514328818768263
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00055479328148067
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005379571812227368
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006184316007420421
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007792146061547101
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005551028298214078
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00047740040463395417
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006257130298763514
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007191019249148667
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018286998383700848
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013153161853551865
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020777718164026737
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021499653812497854
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023781319614499807
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0039862971752882
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021031773649156094
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020087617449462414
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017239062581211329
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015189283294603229
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014830220025032759
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001482093008235097
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016264645382761955
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002012093784287572
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01778915897011757
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022688329219818115
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021198216825723648
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013092129491269588
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1594599336385727
 25%|██▍       | 145/584 [15:30<49:21,  6.75s/it]Loss Loss Loss tensor(4.0204, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(3.5250, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(5.2100, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7402520775794983
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5111907720565796Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14601537585258484

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17696458101272583
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8406473994255066
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.34289294481277466
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008118478581309319
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013170244172215462
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001242510974407196
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023039307445287704
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010776262934086844
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017970080953091383
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00017225905321538448Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002126394072547555

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033862856216728687
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002540014684200287Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003302417229861021

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004600971005856991
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003592826542444527
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007857652381062508
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00048663062625564635Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004157600458711386

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05878828093409538
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004464306868612766
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004761043528560549
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.25756633281707764
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00582682341337204
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006015875842422247Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024778448045253754

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004869512747973204
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007926971884444356Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.760419487953186

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01979874074459076
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.479725122218952e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004986624117009342
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006220185197889805
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00014291914703790098
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00046599432243965566Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007549874950200319

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021516243577934802
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007095396053045988
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005993607919663191
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00030998195870779455
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008812150917947292
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006499161827377975Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005447520525194705

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04476448893547058
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009040012955665588
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009747452102601528Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00221193116158247

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011090044863522053Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015582663472741842

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009402348659932613
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010854407213628292
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025542525108903646
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011536454549059272Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012667907401919365
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00195889244787395

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012700382620096207
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014543896540999413
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001056581735610962
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01556896511465311
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020515115465968847
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011989386985078454
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01595858857035637
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002526904223486781
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004476758651435375Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022955428808927536

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0048197247087955475
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19359628856182098
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012928895885124803Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003726275870576501

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1978510171175003
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003072823863476515
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001388826291076839Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2615143358707428

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003601250471547246
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12543922662734985
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013925515813753009
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.341398686170578
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003817154560238123
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014118840917944908
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01407713908702135
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014551463536918163
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033103101886808872
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015984688652679324
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030173424165695906
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001694201841019094
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002804557327181101
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022943918593227863
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002554458100348711
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024903807789087296
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021656074095517397
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027918322011828423Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002244275528937578

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023794507142156363Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028829531744122505

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026545424479991198
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01621425710618496
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0056875781156122684
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1695423722267151
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1251133382320404
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02430810034275055
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14015458524227142
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5613160729408264
 25%|██▌       | 146/584 [15:34<51:22,  7.04s/it] 25%|██▌       | 146/584 [15:37<51:17,  7.03s/it] 25%|██▌       | 146/584 [15:40<51:24,  7.04s/it]Loss Loss Loss tensor(3.9503, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(3.7832, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(5.1883, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01928967423737049
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5120999813079834
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3954412639141083Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.27422693371772766
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.186191588640213

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.30834898352622986Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06547903269529343

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9065804481506348Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5287785530090332
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2948155999183655

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005130430799908936Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.321514229057357e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01405978575348854
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007279290584847331
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.786715963855386e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015462517738342285
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011177677661180496
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001525138213764876Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.404190258355811e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012953850673511624
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00023774392320774496
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.583450158359483e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002003744710236788
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005120833520777524
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023586417082697153
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009712846949696541
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.758012311067432e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002765632700175047
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018402280984446406
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004917264450341463
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029540162067860365Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001347614306723699

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035005693789571524
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026216264814138412
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004577839281409979Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021092937095090747
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019102680962532759

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007054486311972141
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026320612523704767
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000248285272391513
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008547958917915821
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034798267297446728
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00027210425469093025
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005358139052987099
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02097245492041111
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005352515261620283
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01315279584378004
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00032027921406552196
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004640664905309677Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01571044884622097

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003277291252743453
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017009204253554344Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00560311134904623

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004325686313677579Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016890792176127434
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005913327913731337

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01995931938290596
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007334290072321892
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000861894921399653Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01394559908658266
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005110165104269981

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013371768407523632
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004638278391212225
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010464077349752188
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010807715356349945
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004408323671668768
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015966524370014668Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011228800751268864
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004048743285238743

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010632687248289585
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034256421495229006
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017610319191589952
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010107133537530899
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00361287547275424
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011943926103413105
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002259186003357172Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038409908302128315

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014881393872201443
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004311902914196253
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002159521449357271Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.032990965992212296

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006989560555666685
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05853547900915146
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002058514393866062Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17131417989730835

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10925957560539246
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002109384397044778
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026044180616736412
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0705934688448906
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19636449217796326
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015418974217027426Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7045743465423584

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7559860348701477
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013895207084715366
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011055163340643048
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001044388860464096
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001068921061232686
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009847985347732902
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001126325805671513
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013044798979535699
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028971550054848194
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005235680378973484
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010093790479004383
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0056582349352538586
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1452367752790451
 25%|██▌       | 147/584 [15:41<50:27,  6.93s/it] 25%|██▌       | 147/584 [15:46<50:27,  6.93s/it] 25%|██▌       | 147/584 [15:44<50:24,  6.92s/it]Loss Loss Loss tensor(3.5738, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.2219, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(3.5966, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021300623193383217Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.48545172810554504
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.37629303336143494

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8638424873352051Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6609941124916077
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10667233914136887

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2540329694747925
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01730944588780403Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7667825222015381

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3538764715194702
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012124466593377292
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02209717035293579
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00018861767603084445
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.401650607585907
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.353383651003242e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007271937793120742

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002977474650833756
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010013571009039879
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000460947398096323Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.221252548741177e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014901066897436976
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009268018184229732
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013038328615948558Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018175678560510278

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013134664914105088
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015452754450961947Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002977705327793956

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00019288438488729298Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025726300664246082Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032271607778966427


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019954985473304987
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00375082204118371
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000284323759842664
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001422228175215423
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006352220196276903
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002961744903586805
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002182744676247239
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005097212269902229
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00032852214644663036Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003189569339156151

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007795753888785839
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0051217349246144295
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004949004505760968Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012883411720395088
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005982753820717335

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005485729780048132Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015097497031092644

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005098958499729633
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007135957013815641
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029715586453676224
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008845305419526994
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007509823888540268
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020627355203032494
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017333307769149542Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009098859503865242

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022342363372445107
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006618746556341648
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019530950812622905Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02434404008090496

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0060848696157336235
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025649288669228554
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002670935122296214
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005863287020474672
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.032845452427864075
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027776360511779785Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005417799577116966

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02179598994553089
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004691334906965494
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031841520685702562
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019971607252955437
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005157534498721361
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030632605776190758
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00548142846673727
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016164083033800125
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029834755696356297
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006378437392413616
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01664407178759575
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031724271830171347
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010847697034478188
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013711279258131981
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002268250100314617
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15972548723220825
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013715911656618118
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020240515004843473
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02665891870856285
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015401351265609264
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1955793797969818Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015566953225061297
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01812729798257351

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4398232102394104
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.079839788377285
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013628574088215828
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08717605471611023
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012858659029006958
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06168803572654724
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012617807369679213Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0915076807141304

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.42284247279167175
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013527850387617946
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015188849065452814
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010377581231296062
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013004523701965809
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008709550835192204
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00897494051605463
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12964966893196106
 25%|██▌       | 148/584 [15:53<50:38,  6.97s/it] 25%|██▌       | 148/584 [15:48<50:38,  6.97s/it] 25%|██▌       | 148/584 [15:51<50:35,  6.96s/it]Loss Loss Loss tensor(4.0905, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.1283, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.2884, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04852386191487312
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4701194763183594
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.40062105655670166
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.306228369474411
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5810478925704956
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.141306072473526
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.324431449174881
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7775365114212036Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6016903519630432
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3138595223426819

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001404833747074008
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007042238139547408
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02368122525513172
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022314013040158898
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009360805852338672
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022419866174459457
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016818078001961112
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003847276675514877Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002099818317219615

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.057420927798375e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037786115426570177Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006688105640932918

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011589482164708897
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0041576591320335865Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016781649319455028

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004622472450137138
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019840896129608154
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001936062762979418
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006596018094569445
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016522016376256943
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00028905528597533703
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006898886989802122
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025606234557926655
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005076997331343591
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010669548995792866Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002061225241050124

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005863505648449063Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018420884385704994

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016343399183824658
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021032176911830902
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027155117131769657
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007211202173493803
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02826886624097824
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003903456963598728
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010220991680398583Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02202709950506687

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005931631661951542
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018112851306796074
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011439197696745396
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005661873146891594
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016054486855864525
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005706145893782377Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0150079857558012

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018631307175382972
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025585152208805084
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008307265117764473
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003412839723750949
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016260677948594093
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009228653274476528
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0173750352114439
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014079269021749496
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036762042436748743
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018092824146151543
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008565356954932213
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0046572876162827015
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01762828417122364
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007934845052659512
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014272869564592838
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004178992938250303
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007633714471012354
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016453413292765617
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037127798423171043Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006967020686715841

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016786575317382812
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005967499688267708
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031463862396776676Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022405995056033134

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00652327248826623
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08316376060247421
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006867173593491316
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028600292280316353
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1060144305229187
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007794315926730633
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003777808975428343
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1315639615058899
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013002555817365646
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025921277701854706
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1543818712234497
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21722953021526337
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024184961803257465Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6448941230773926

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04822913184762001
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2897774279117584
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002211614977568388
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5661863088607788
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018734909826889634
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017908108420670033
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018108778167515993
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019098635530099273
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002358645899221301
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021760908886790276
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0201259795576334
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03042052686214447
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022054599598050117
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23304937779903412
 26%|██▌       | 149/584 [15:53<47:23,  6.54s/it] 26%|██▌       | 149/584 [15:59<47:24,  6.54s/it] 26%|██▌       | 149/584 [15:57<47:22,  6.53s/it]Loss Loss tensor(3.7282, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(3.9841, device='cuda:1', grad_fn=<NllLossBackward0>)
Loss tensor(4.0657, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03711302578449249
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.437579870223999
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2920304238796234
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23816698789596558
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4052072763442993Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07953374087810516
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.43141525983810425

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.37312138080596924
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3418976664543152
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.89657062292099
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013663695426657796
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001594811794348061
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015486018732190132
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002116066316375509
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023604915477335453
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000342287850799039
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01279982179403305Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0039751725271344185
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005070896586403251

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004932429175823927
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008730716072022915
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001235600939253345
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007336207665503025
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001459919847548008
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021689328423235565Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006024501286447048
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002771045546978712

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004464771132916212
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006269779521971941
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00037812028313055634
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038375607691705227
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009205601178109646
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025182045064866543
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0079329339787364
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005531501374207437
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003217098768800497
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008282450027763844
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007178158848546445
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004241433460265398Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012981461361050606

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005672859260812402
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006513315252959728
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015756363049149513
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005291949491947889Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005793818738311529
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027586854994297028

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004753696732223034
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01889812760055065
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007649701437912881Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005556789226830006
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019602984189987183

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005769114010035992
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021091094240546227
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006940157036297023Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009569249115884304

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019879184663295746
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005383775569498539
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02294929511845112
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007473009172827005Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0050003607757389545
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018094947561621666

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004830775782465935Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018121685832738876

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013397226575762033
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01645216904580593
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004505811259150505
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017096467316150665
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003788980422541499
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015555389691144228
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015986958518624306
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004050870425999165
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002363164210692048
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017375988885760307
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0043494440615177155
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020259537268429995Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018825899809598923

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004748777020722628
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026721365749835968
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00788984727114439
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002246927237138152
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06850971281528473
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1792907416820526
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10559568554162979
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03754912316799164
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021621230989694595
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18410296738147736
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23191756010055542
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019963972736150026Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8245531320571899

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12038139998912811
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6148430109024048
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022318570408970118
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016636352520436049
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015299938386306167
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001333383726887405
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001250248053111136
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012475666590034962
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012738548684865236
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013827504590153694
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016136510530486703
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005827245768159628
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010436550714075565
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01299351081252098
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008203946053981781
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17644646763801575
 26%|██▌       | 150/584 [16:05<46:52,  6.48s/it] 26%|██▌       | 150/584 [15:59<46:52,  6.48s/it] 26%|██▌       | 150/584 [16:03<46:52,  6.48s/it]Loss Loss tensor(3.5274, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.6525, device='cuda:1', grad_fn=<NllLossBackward0>)
Loss tensor(4.2173, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02239346317946911
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5074265003204346
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.39485737681388855
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2937016785144806
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6241154074668884Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09646657109260559
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20559851825237274

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5505070686340332
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.26177284121513367
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7453667521476746
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00028320192359387875
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002263323636725545
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021307917311787605Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004428799729794264
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036606627982109785

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007226315792649984Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023828256875276566
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0061447275802493095

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010599371744319797
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007511543110013008
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003413609811104834Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018227758118882775
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012541146948933601

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002271599369123578
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010505505837500095
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006023673340678215
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030827519949525595
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008656580932438374
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010165686253458261Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004291735589504242

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009261230938136578
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003424555528908968
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009918843396008015
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015323281986638904
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023500132374465466
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01159662939608097
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002314383629709482Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003264460014179349

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018859192728996277
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004389108158648014
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02162639982998371
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00210896716453135
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006535009481012821
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027336642146110535
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017371486173942685
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006921055261045694
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024488301947712898
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001682656235061586Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006048389710485935

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017435789108276367
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007521471474319696
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017464907141402364
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013534142635762691
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007754639256745577
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012249188497662544
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021296264603734016
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008692240342497826
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016464587301015854
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037165442481637Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006251034792512655

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01681559532880783
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005526967346668243
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004027985502034426
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020052621141076088
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005052328575402498
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0048670521937310696
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02094399742782116
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00450263312086463
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02088954485952854Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037351467180997133

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004844917915761471
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0039306944236159325
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017911383882164955
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037893871776759624
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004113502334803343
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024385685101151466
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004490431398153305
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029196732211858034Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018893934786319733

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007279660552740097
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.035446662455797195
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023033462930470705Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16913321614265442
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03870179131627083

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029555518180131912
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0533674880862236
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023298803716897964
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19236402213573456
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06534326821565628
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002151406602934003Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6812478303909302
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09190265089273453

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7214275598526001
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00215539732016623
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002315472811460495
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020319924224168062
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021079943981021643
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022493640426546335
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019371174275875092
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002716053044423461
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007176776882261038
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011649633757770061
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012342267669737339
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012887401506304741
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2306584119796753
 26%|██▌       | 151/584 [16:12<48:30,  6.72s/it] 26%|██▌       | 151/584 [16:07<48:30,  6.72s/it] 26%|██▌       | 151/584 [16:10<48:29,  6.72s/it]Loss Loss tensor(4.4868, device='cuda:0', grad_fn=<NllLossBackward0>)tensor(3.9190, device='cuda:2', grad_fn=<NllLossBackward0>)

Loss tensor(3.7624, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3186405897140503Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.301238089799881
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04837969318032265

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3269857168197632
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3902134597301483
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9171853065490723
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20147325098514557
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0375308133661747
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012330395169556141
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.48276641964912415
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18627789616584778
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005270249675959349
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000359164405381307
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025478771422058344
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00023884221445769072Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005603365716524422
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004210741724818945

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00043211737647652626
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007426633033901453
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008973726071417332
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007592430338263512Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009348300285637379

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012581082992255688
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011902940459549427Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01566232368350029

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013583486899733543Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002013967838138342

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001869034837000072
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010861699469387531
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021535539999604225
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018354183994233608
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009170246310532093
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020448502618819475
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015652707079425454Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007389464881271124

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031001963652670383
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005042591597884893
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012018535053357482
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027273583691567183
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005100528243929148
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008940532570704818Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024881078861653805

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010411658324301243
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004154434893280268
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01769755408167839
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005612557870335877
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009377949871122837
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005801010876893997
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00041110400343313813
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011948155239224434
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008453275077044964
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008596114348620176Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012143444269895554

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00762828579172492
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014708043076097965
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016405632486566901Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006445933599025011
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03307177126407623

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00804021954536438Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017662279307842255

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000895604258403182
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01947629079222679
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008767119608819485
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011327724205330014
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017833804711699486
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013859669677913189
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02346910536289215
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012907456839457154Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008428962901234627

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017286384478211403
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007692015264183283
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015227710828185081
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02167787216603756
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007425969000905752
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002630737144500017
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026683945208787918
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006899087689816952
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027790648862719536
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016556563787162304
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005940113216638565
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10188078135251999
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0065435124561190605
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00165320944506675
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10413505136966705
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0070487032644450665
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13992179930210114Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00156493135727942

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00777705293148756
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12656019628047943
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017968674656003714Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013123927637934685

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8144919872283936
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.24130606651306152
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014103049179539084
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04529401659965515
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015814732760190964
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.26834604144096375
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6909724473953247
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017280331812798977
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021234340965747833
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016342589631676674
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013673864305019379
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013942549005150795
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010419188067317009
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23716837167739868
 26%|██▌       | 152/584 [16:13<48:19,  6.71s/it] 26%|██▌       | 152/584 [16:19<48:19,  6.71s/it] 26%|██▌       | 152/584 [16:17<48:18,  6.71s/it]Loss Loss Loss tensor(4.2050, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(3.7779, device='cuda:1', grad_fn=<NllLossBackward0>)tensor(4.5625, device='cuda:2', grad_fn=<NllLossBackward0>)

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4309181869029999
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.39462220668792725
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3386487364768982Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.048254869878292084

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23778142035007477
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10530262440443039
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.664078950881958Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.22191663086414337
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01458987221121788

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004799403250217438Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4016687572002411
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012848535552620888

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007374254637397826
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.370830695028417e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004630690440535545Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.23988375486806e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012616394087672234
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010485478560440242
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001340174931101501
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016151340678334236
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001752095704432577
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021364168787840754
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002887239446863532
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00047397761954925954Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034910673275589943

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00029350470867939293
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004339597187936306
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000976273906417191
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00046529489918611944Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0051425788551568985
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022803498432040215

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00534799974411726Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007426976226270199
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003756301710382104

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006287598051130772
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029661834705621004
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009442641166970134
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009377667680382729
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018634544685482979
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011647662613540888
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010021481662988663
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002334577962756157
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013199589448049664Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015222365036606789
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031108546536415815

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01154432725161314
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005286169704049826
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014150285860523582
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009783461689949036
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005588925443589687
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016318270936608315Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014470481313765049

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004715301562100649
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01960771717131138
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022239473182708025Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005788513459265232

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023556344211101532
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006044602487236261
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0232516098767519Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002207807032391429

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01117203664034605
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025325553491711617
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030404336284846067
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024223685264587402
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005760600324720144
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029576770029962063
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025336124002933502
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0052671730518341064
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002645906526595354Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022986628115177155
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005148993339389563

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0356028750538826
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004856046289205551
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034038119483739138
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026137826964259148
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004263401962816715
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004364310298115015
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04722341150045395
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00472316425293684
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005242565646767616Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06236587092280388

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005251860246062279
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10572829842567444
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004549242556095123Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00582757918164134
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1934647113084793

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14558304846286774
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010217837989330292
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004462543874979019
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7179819345474243
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1874738484621048
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004392176400870085
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04857870936393738
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003982266411185265
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23945243656635284
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004319929052144289
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.827100396156311
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005255494732409716
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005090289283543825
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006163888610899448
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013998446986079216
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03438875079154968
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03773682564496994
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030745258554816246
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.66339510679245
 26%|██▌       | 153/584 [16:19<45:25,  6.32s/it] 26%|██▌       | 153/584 [16:25<45:25,  6.32s/it] 26%|██▌       | 153/584 [16:22<45:24,  6.32s/it]Loss Loss Loss tensor(3.7402, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.0820, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.3462, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4518788456916809Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04332706332206726Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.33133119344711304


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.22426874935626984
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.37888070940971375
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8549339771270752Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024550732225179672
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16748446226119995

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3669736385345459Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015317175537347794
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20515984296798706

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.332565292017534e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005473507335409522
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010580657050013542Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010937891784124076
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008271370898000896

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016230755136348307
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010006430966313928
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013304674066603184Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016594617045484483
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00024518530699424446

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005081340787000954
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017497712979093194
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00026055859052576125
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012572050327435136
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025678719393908978
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026435954496264458
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004269479541108012Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032288755755871534

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037107670214027166
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003637099638581276
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006539141177199781
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030543627217411995
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036146212369203568
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008410878363065422
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033747844863682985
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019351727096363902
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032601396087557077
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002391298534348607
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009025582694448531
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004749090876430273
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031184812542051077
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008393846801482141
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005571360234171152
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005149995908141136
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01252751238644123Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007906521204859018
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0056190164759755135

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008510494604706764Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005295753013342619

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006899974541738629
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0073702372610569
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012760994024574757
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010718908160924911Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0229092575609684Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008290955796837807


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011955113150179386Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03277508169412613

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012958567822352052
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04428970813751221
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008241021074354649
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023939507082104683
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007461706176400185
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04373230040073395
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022058424074202776Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007398925255984068
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.044907182455062866

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006856636144220829
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.044268425554037094
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00340649182908237
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006129206158220768
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04527151212096214
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00670990813523531
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0050353785045444965
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.035694021731615067
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007394998334348202
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006689594127237797
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04618332162499428
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008389373309910297
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008349960669875145Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04730793833732605
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014514945447444916

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05615775287151337
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17631404101848602
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007332842797040939
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12393707782030106Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03358873352408409

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007344766519963741
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21134623885154724
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16717712581157684
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8571025729179382
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00690161157399416Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16845287382602692

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1572045087814331
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0058777290396392345
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6818353533744812
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005796989891678095
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006498789414763451
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006942952983081341
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007941977120935917
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02420194074511528
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05990934371948242
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03936966508626938
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03174611181020737
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.38946378231048584
 26%|██▋       | 154/584 [16:30<43:36,  6.08s/it] 26%|██▋       | 154/584 [16:24<43:36,  6.09s/it] 26%|██▋       | 154/584 [16:28<43:36,  6.08s/it]Loss Loss Loss tensor(3.3460, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.0348, device='cuda:0', grad_fn=<NllLossBackward0>)tensor(3.9442, device='cuda:1', grad_fn=<NllLossBackward0>)

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6069808006286621Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.382318913936615

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.42275694012641907
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8414983749389648Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04628262668848038
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.22182025015354156

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3385634422302246
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014333054423332214Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2697681486606598

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02525537833571434
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022670563776046038
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005797746125608683
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035533253103494644
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4598701000213623
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002711477573029697Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00020056594803463668
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0059791672974824905

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00030441704438999295Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007359079550951719

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004864078655373305
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011456586420536041
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00046895784907974303
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009557298384606838
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000820977205876261Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007605406921356916Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006446723127737641


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010511918924748898
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008852928294800222
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012735318159684539
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009845484979450703
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013219573302194476
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018967508804053068
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006259468384087086
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002464714925736189
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009559170342981815Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017463838448747993
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003380976617336273

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014003022573888302
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002935609081760049
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001330662053078413
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01983402483165264
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002134127076715231Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015188513789325953
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01926007866859436

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02242705412209034
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003063540905714035
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00136280688457191
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025545213371515274
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004064318723976612
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008600467117503285
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022553665563464165
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006619772873818874
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026610272005200386
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013532396405935287Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006621050648391247

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016997475177049637
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0053053442388772964
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018322716932743788
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018631847575306892
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006262404844164848
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028775010723620653
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01987837627530098
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006429535802453756
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01786608248949051
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027939274441450834Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012048500590026379

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02137686125934124
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006101969163864851Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003079429967328906
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023038536310195923

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00560075044631958
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025040382519364357
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003242697101086378
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00547799514606595
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04327753186225891
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026742364279925823Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005088875535875559
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10392717272043228

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004526811186224222Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07229263335466385

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002778860740363598
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1928335577249527
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004874662030488253
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002006079535931349Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13477906584739685
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005431454628705978

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5005959272384644
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005856959614902735
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002018109429627657
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010001988150179386
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002090316964313388
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17613936960697174
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018906488548964262
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0361335389316082
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021489905193448067
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2021999955177307
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7727643251419067
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020139210391789675
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023265578784048557
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031816449481993914
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010303042829036713
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009442934766411781
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0225868858397007
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014402460306882858
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3800637423992157
 27%|██▋       | 155/584 [16:30<43:28,  6.08s/it] 27%|██▋       | 155/584 [16:36<43:29,  6.08s/it] 27%|██▋       | 155/584 [16:34<43:28,  6.08s/it]Loss Loss Loss tensor(3.9943, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(3.7014, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(3.5372, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.034460920840501785
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5729295015335083
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.34139150381088257
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18126624822616577
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5268735289573669Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09493513405323029
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.35500407218933105

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3670147955417633
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3707221448421478
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8202740550041199
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010904068039963022
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008823304087854922
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016473997675348073Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014110227348282933

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019688203930854797
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00024340888194274157
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02414117380976677Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002193156396970153

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003420700377319008
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027192686684429646
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005336858448572457
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010763863247120753
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004122237674891949Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007750365766696632

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001937640190590173
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036972409579902887Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014442262472584844

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020798591431230307Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003874709364026785

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003119745524600148
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017753270221874118
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005089192185550928
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004706301260739565
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012133418349549174
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004120774567127228
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016069430857896805
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004655675962567329
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006742040859535336
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023793247528374195
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004857174586504698
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006395450327545404Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004655611235648394

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008627842180430889
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0068148537538945675
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006016509723849595
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028216931968927383
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008823301643133163
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013152636587619781
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006395008531399071Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016421031206846237

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02220231108367443
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02054821513593197
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000544197391718626Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022494249045848846

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04456181451678276
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020937571302056313
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06370827555656433
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00048683342174626887
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019077202305197716
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0875139981508255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007201816188171506
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019258229061961174
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09124084562063217
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01752573251724243
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09584880620241165
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013070020359009504
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015963103622198105
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09493808448314667
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030662950593978167Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017550064250826836
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0926043763756752

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019457759335637093
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07690064609050751
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00242423452436924
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02119321934878826
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09614469110965729
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03515465557575226
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003874726127833128Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09569606184959412

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11229599267244339
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2238253355026245
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17462065815925598
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04470149055123329
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00586553942412138
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2927658259868622
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2489805519580841
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7867612838745117
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007909828796982765Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12454994767904282

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18337638676166534
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009902951307594776Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3502456247806549

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008878113701939583
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008848581463098526
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008438797667622566
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007022814359515905
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0070844488218426704
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007714445702731609
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008038272149860859
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008821815252304077
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015936587005853653
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06814329326152802
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023312652483582497
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022939985617995262
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20458956062793732
 27%|██▋       | 156/584 [16:43<44:36,  6.25s/it] 27%|██▋       | 156/584 [16:37<44:36,  6.25s/it] 27%|██▋       | 156/584 [16:41<44:36,  6.25s/it]Loss Loss Loss tensor(3.4388, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.3439, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.0742, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.520995020866394
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.34603533148765564Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2737816274166107

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.917747437953949Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19889655709266663

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009938935749232769
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15208271145820618
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005609740503132343
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012695444747805595
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012107560905860737Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019989199936389923

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021876493701711297
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003409481141716242
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00037784044980071485
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004281727131456137
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006051088566891849
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006758090574294329
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006543346680700779
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009312916663475335
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006459174677729607
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009725232375785708
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007364559918642044
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006605530623346567
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008427572902292013
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008069060742855072
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006927556823939085
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01595885306596756
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006517916917800903
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020293843001127243
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026807637885212898
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001101848785765469
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017994416877627373
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021914439275860786
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015968214720487595
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024265956599265337
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030420806258916855
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04361527040600777
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002770856488496065
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.054993174970149994
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023132353089749813
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05648396909236908
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021110540255904198Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.059318751096725464

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.056957852095365524
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031117950566112995
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.057057224214076996
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004227315075695515
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04305700957775116
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004931111354380846Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.057313255965709686

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05288515239953995
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0044274404644966125
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07099628448486328
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00419597327709198
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08604191988706589
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003997409716248512Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1327311396598816

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13082237541675568
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032115497160702944
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10070320218801498
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7101492881774902
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003100816858932376
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003465718124061823
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032647009938955307
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004177785012871027
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008811386302113533
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020308852195739746
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022132383659482002
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010203276760876179
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1912756860256195
 27%|██▋       | 157/584 [16:43<43:59,  6.18s/it] 27%|██▋       | 157/584 [16:47<43:59,  6.18s/it]Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03859788179397583
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.45471426844596863
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03047090396285057
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3407893478870392
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015084298502188176
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022392436221707612
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00033700268249958754
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004456445458345115
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005909080500714481
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007852938142605126
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012584481155499816
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001807989552617073
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017715850844979286
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001572212902829051
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025550061836838722
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00344771146774292
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005407752003520727
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007114516105502844
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006939925253391266
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010344909504055977
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01154693029820919
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012221002951264381
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010084557346999645
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008261178620159626
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007595216855406761
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006756324786692858
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0057318503968417645
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0060546863824129105
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006910043768584728
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007402240298688412
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01278302725404501
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2055961787700653
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.041331417858600616
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.27419885993003845
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7445532083511353
 27%|██▋       | 157/584 [16:49<45:19,  6.37s/it]Loss Loss tensor(3.8245, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.6099, device='cuda:0', grad_fn=<NllLossBackward0>)
Loss tensor(4.7988, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6602988839149475Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030967146158218384
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3655325472354889

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.24374806880950928
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2938878834247589
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5815891623497009Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02551160380244255

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14201632142066956
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017819831147789955Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.24886660277843475

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.651638199808076e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02057524025440216Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1909591257572174

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001285849284613505
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008886001887731254
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001591657637618482
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013704063603654504
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002612553653307259Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00020024263358209282

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025484811048954725
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00029345526127144694
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004612883203662932
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00326451170258224
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004837192827835679
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007311585359275341
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004419663920998573
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007337647257372737
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011508427560329437Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005443538539111614
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014493996277451515

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006120303645730019
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023094406351447105
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016965933609753847
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007135679479688406
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00222221203148365
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002047344110906124
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0056832884438335896
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018155156867578626
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019495091401040554
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004367449786514044
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002528158016502857
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007084693759679794
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013609571615234017
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032711471430957317
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012046976014971733
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009188050753436983Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005074216052889824

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0208686925470829
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00613512983545661
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017776049207895994Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014135089702904224

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006018848158419132
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017708221450448036
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027818954549729824
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008708629757165909
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.034915801137685776
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004488266538828611Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.048116765916347504
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009760469198226929

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.060350023210048676
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010627476498484612
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038725307676941156
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.062459077686071396
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00869713444262743
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06485608965158463
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007227872032672167Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004913377109915018

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0618615485727787
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006794867105782032
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007634689565747976
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06148657947778702
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006135060917586088
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04669033735990524
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009887386113405228Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0052017574198544025

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06111747398972511
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0054788957349956036
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011289706453680992
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05699649080634117
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00637693889439106
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07703982293605804
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006955181248486042
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010165579617023468
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10401415079832077
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01229136623442173
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009818114340305328
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16657325625419617
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.22974631190299988
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00917036086320877Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1316886991262436

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04014510288834572
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.22794948518276215
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007377861067652702Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3099914789199829

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.759057879447937
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8518369793891907
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00715534295886755
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007766127120703459
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007608184590935707
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009699512273073196
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017734043300151825
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.056538332253694534
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05774013325572014
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04807978495955467
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.46356281638145447
 27%|██▋       | 158/584 [16:55<44:27,  6.26s/it] 27%|██▋       | 158/584 [16:50<44:51,  6.32s/it] 27%|██▋       | 158/584 [16:53<44:51,  6.32s/it]Loss Loss Loss tensor(3.7423, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(3.4812, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.2534, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.30774545669555664
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02322484366595745
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.37359705567359924Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5064221024513245
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2022188901901245

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18460173904895782
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05120816454291344
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8794568777084351Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.28265443444252014
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20429839193820953

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000565395166631788
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.923217344796285e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01597106270492077
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008710908587090671
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011548909242264926
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011660494841635227
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012818117393180728
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001657782995607704
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017630443908274174
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.476462971884757e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002453965716995299
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002987476298585534
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001422354980604723Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030799838714301586Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004322565218899399


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004239116329699755
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010500213829800487
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022595346672460437Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00492359371855855

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002864985493943095
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005019654054194689
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038003139197826385
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003621630312409252
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005984581541270018
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034466725774109364
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009519670158624649
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005210409290157259Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025525232776999474

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010625526309013367
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033738359343260527
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005275962175801396
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01582557149231434
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004785117693245411
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006860441062599421Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016535982489585876
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007643647957593203

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015719449147582054
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0074022975750267506
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007776163402013481
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015220442786812782
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006269332021474838
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012458274140954018
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007612333633005619Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008498866809532046

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028540998697280884
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00819578766822815
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011014307383447886
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014349901117384434
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011421185918152332
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01705874688923359
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001882666489109397Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006760322023183107

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019539035856723785
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006035567261278629
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020504535641521215
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01690082810819149
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005605768878012896
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031817578710615635
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017491759732365608
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004876910708844662
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033761977683752775Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022760765627026558

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004090503323823214
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017747454345226288
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004065654706209898
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003404421266168356
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03776216879487038
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004465569742023945
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030391186010092497Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10991741716861725

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004748407751321793
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0721157044172287
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024178458843380213Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008469052612781525

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06996062397956848
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2080298662185669
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003505771979689598Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09466888010501862

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03307535499334335
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7320116758346558
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020951495971530676Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23630200326442719

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8803825974464417
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021392074413597584
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023167163599282503
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018829010659828782
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022163684479892254
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021265645045787096
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022558853961527348
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002935481956228614
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016525547951459885
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016128411516547203
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021365098655223846
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015315674245357513
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.29197993874549866
 27%|██▋       | 159/584 [16:56<43:57,  6.21s/it] 27%|██▋       | 159/584 [17:01<43:40,  6.17s/it] 27%|██▋       | 159/584 [16:59<43:57,  6.21s/it]Loss Loss tensor(3.5520, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.0136, device='cuda:2', grad_fn=<NllLossBackward0>)
Loss tensor(3.9840, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3294089138507843Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.35382279753685Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019501246511936188


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.49847280979156494
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.303771436214447
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9001610279083252
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14901526272296906
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023263517767190933
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010427930392324924Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1871640980243683

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019566137343645096
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2631448209285736
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008236078545451164Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030563906766474247

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00024168702657334507
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022178541985340416
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004896462429314852
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00035089999437332153
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00039629192906431854Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006140534300357103

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005002105026505888
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009542848914861679
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006506633362732828
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006569462711922824
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009293179959058762Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008573709055781364

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010264964075759053
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008774607442319393Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001042146235704422

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015396627131849527Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008335812948644161

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015845020534470677
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0063932351768016815
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021154398564249277
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016936284955590963
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004044221248477697
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022734426893293858
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005394820589572191
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015650063287466764
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002085709711536765
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011483135633170605
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012585746590048075
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029685255140066147
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018895940855145454
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008929868927225471Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038622983265668154

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011223996989428997
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0059280432760715485Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010515703819692135
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005286689265631139

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006733582820743322
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01974637806415558
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007056831964291632
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026824668049812317Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006644056178629398

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001314308843575418
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02992193214595318
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009295373223721981
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002096551237627864
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010184729471802711
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03121657483279705
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017163896700367332Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010503512807190418Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0314696840941906


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0335899256169796
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009038867428898811
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001330202678218484
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03506710007786751
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008206178434193134
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021735692862421274
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02580605447292328Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007985948584973812

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028808102943003178
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03224053606390953Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007096628658473492

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003063676878809929
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006241434253752232
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03818488121032715
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028560366481542587
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006645349785685539
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04747221618890762
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002873277058824897
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007485983427613974
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06623111665248871
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028047796804457903
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008568215183913708
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12770795822143555
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024067943450063467Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014394251629710197

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06361944228410721
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21027061343193054
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002207427751272917
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08748344331979752
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03403802216053009
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024456121027469635Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.723702609539032

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.25184258818626404
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002883676439523697Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8529995083808899

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036945599131286144
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007416216190904379
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02498762495815754
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013272011652588844
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009104670956730843
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2828006148338318
 27%|██▋       | 160/584 [17:03<46:31,  6.58s/it] 27%|██▋       | 160/584 [17:09<46:20,  6.56s/it] 27%|██▋       | 160/584 [17:07<46:31,  6.58s/it]Loss Loss Loss tensor(4.2826, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(3.7723, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(3.9855, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5705536603927612Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02301289699971676

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.757819652557373
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2673511207103729
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.24885942041873932
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.37618282437324524Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1242440715432167

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20288409292697906
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.031000107526779175
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5336064696311951
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.033965032547712326Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.22673429548740387
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012500885350164026

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00017851540178526193
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000787535565905273
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001970578305190429
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011298303725197911Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00024351265165023506

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00030266359681263566
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00032657221890985966
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016581994714215398
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004416425945237279Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000469562946818769

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002045834669843316
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008783517405390739
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030829445458948612
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006393896182999015
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001711036660708487
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003415375715121627
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002588515868410468
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009214251185767353
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004354191944003105
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023470865562558174
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009480603039264679
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006239633075892925
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001843553502112627
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011354205198585987
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00657144607976079Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025674914941191673

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015713138272985816Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008231512270867825Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037441146560013294


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006167637649923563
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014671173878014088
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017106800805777311
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006684461142867804
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020130468532443047
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028695794753730297Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0064107151702046394

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03048611618578434
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010401482693850994
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.032664310187101364
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00605551153421402
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022099114954471588
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01322917640209198
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014015953987836838Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007549418602138758
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017714405432343483

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014971831813454628Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012289858423173428

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01139593031257391
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011026998050510883
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02128201350569725
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010676991194486618
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024877827614545822
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013459633104503155
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009275807999074459
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029057538136839867
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010044025257229805
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008122581988573074
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03654085844755173Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007197961211204529

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008479888550937176
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03514029085636139
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005063157062977552Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030215587466955185
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009368565864861012

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04358133301138878
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010361390188336372
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005134321749210358
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03572751209139824Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016616379842162132

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005082796327769756Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.25026237964630127

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07158976793289185
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04207500442862511
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08347027748823166
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005212550517171621
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.31909582018852234
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10125956684350967
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6781385540962219
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006496401969343424Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08435631543397903

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07278886437416077
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005278749391436577
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.47331809997558594
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005553898401558399
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006509759929031134
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005586171988397837
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00930227804929018
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011189977638423443
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030220620334148407
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012501268647611141
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016815895214676857
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.726926326751709
 28%|██▊       | 161/584 [17:17<49:59,  7.09s/it] 28%|██▊       | 161/584 [17:12<50:07,  7.11s/it] 28%|██▊       | 161/584 [17:15<50:07,  7.11s/it]Loss Loss tensor(3.5870, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.0687, device='cuda:2', grad_fn=<NllLossBackward0>)
Loss tensor(3.8919, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03502040356397629Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.47569891810417175
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6395682692527771

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21700800955295563
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.36899030208587646
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.82807856798172Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03416740521788597
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15321846306324005

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6413598656654358
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013493303209543228
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3057192862033844
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00010134714102605358Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02090713195502758

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009659263887442648
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001482498919358477
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001234802621183917
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014181460719555616
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021206788369454443
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00019456214795354754
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002804803370963782
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002456762595102191
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003940994502045214
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029360027983784676
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003086744691245258Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006703390972688794

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037666871212422848
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015904407482594252
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004328293725848198
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0047545903362333775
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002370087895542383
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006231223233044147Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005856480449438095
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001960187219083309

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006756894290447235
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016759330173954368
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009645269601605833Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004377108067274094
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022935091983526945

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003991089761257172
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029448848217725754
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012934746919199824
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006188948173075914
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005111682694405317
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012536366702988744Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00947055034339428

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0054537514224648476
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019238920882344246
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0047606294974684715
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007862286292947829
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0091632641851902
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005618665367364883
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012131882831454277
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005810941103845835
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005856526549905539
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01433861069381237
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011506237089633942
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013386111706495285
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00081705889897421Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004980653524398804

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.043266694992780685
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004442505072802305
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012348619056865573Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010497611947357655

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004216340836137533
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011184806004166603
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003661494702100754
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002837359206750989
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014020814560353756
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00315889623016119
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001686803181655705
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01442661788314581
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031822884920984507
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012242655269801617
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035879858769476414Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002263197908177972

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01417379081249237
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003987189847975969
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002365893218666315Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018621079623699188

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007897702045738697
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01918381080031395
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18732739984989166
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021019745618104935
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15591052174568176
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03343646228313446
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004528815392404795
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13720177114009857
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.24402664601802826
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6655220985412598
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1720409393310547
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013379929587244987
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10149203985929489
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.49996545910835266
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013502839719876647
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001507149776443839
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014770424459129572
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014390695141628385
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015158223686739802
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001967427786439657
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002247606636956334
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022877294570207596
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026179689913988113
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02217726968228817
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015483791939914227
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.292165607213974
 28%|██▊       | 162/584 [17:22<45:45,  6.51s/it] 28%|██▊       | 162/584 [17:17<45:51,  6.52s/it] 28%|██▊       | 162/584 [17:20<45:51,  6.52s/it]Loss Loss Loss tensor(3.9932, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(4.4999, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(3.3615, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.549849271774292Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02177315577864647Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.31714993715286255


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.29501697421073914
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4815481901168823
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6628915071487427Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05882016569375992
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15501928329467773

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3449302613735199
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020648356527090073Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13886882364749908

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00024845474399626255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017394975293427706
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003465646004769951Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002582065062597394

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021182682365179062
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036755807232111692
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00044780111056752503
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00047375421854667366
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004961197264492512
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000576745776925236
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007559264078736305
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008341121138073504Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007413579733110964

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006249874830245972
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001031438005156815
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00131127517670393Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0052370913326740265

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021866357419639826
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005660408642143011
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003132403129711747
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020564335864037275
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005036566872149706
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002872255863621831
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003916130401194096
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002847840543836355
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002099790843203664
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005500842351466417
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024017479736357927
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027180423494428396Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0075640189461410046

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016912694554775953Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038847560063004494Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014812936075031757


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006848112214356661Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01670871302485466

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016732425428926945
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008017952553927898
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018051674589514732
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015469539212062955
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0068121301010251045
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018159961327910423
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012698385398834944
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00790855847299099
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013522597961127758
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002138171810656786
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007904384285211563
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01001986674964428
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026807982940226793
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008790065534412861
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008113628253340721
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005136209074407816
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009063334204256535
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006117816083133221
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006051742937415838
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01037483662366867Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005343740340322256

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006493027321994305
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011771885678172112
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004945699125528336
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0057668741792440414
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009599147364497185
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004298946354538202
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0040615759789943695
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010990608483552933
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035764852073043585
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029252427630126476
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01337491162121296
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003509214846417308
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021901174914091825
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01731293648481369
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003970226738601923
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002131089335307479
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027736080810427666
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00427590124309063
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002237125067040324
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.031352099031209946
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0072271679528057575
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022148326970636845
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06190452352166176
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.24166621267795563
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024173706769943237
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0558910146355629
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030374573543667793
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002346573630347848
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7827182412147522
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2846479117870331
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029442862141877413
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8056501150131226
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032779499888420105
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007609291467815638
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013673770241439342
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017483258619904518
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01886773109436035
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5061653852462769
 28%|██▊       | 163/584 [17:23<45:08,  6.43s/it] 28%|██▊       | 163/584 [17:29<45:04,  6.42s/it] 28%|██▊       | 163/584 [17:26<45:08,  6.43s/it]Loss Loss Loss tensor(3.9588, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(3.8302, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(3.5957, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.031890276819467545
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.39303892850875854Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6996435523033142
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.29086339473724365

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.43548351526260376
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06514376401901245
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9121224880218506Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2802791893482208

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7859949469566345
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012052883394062519
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.32862982153892517
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00024182363995350897
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016943208174780011Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003361381241120398

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013234937563538551
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025979052297770977
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00043195075704716146
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015549328236375004
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005400074878707528
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036341820377856493
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00026858298224397004Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007008864195086062

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004478875547647476
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010753195965662599
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006912616081535816
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004052242438774556
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002187705133110285
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006377899553626776
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005962180439382792Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027052750810980797

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006846162024885416
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020269849337637424
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008375712786801159
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007658332120627165
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001564031932502985
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008003534749150276Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006914578378200531

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021608741953969
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005401476286351681
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007915928144939244Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003062303178012371

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005187097936868668
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005302200559526682
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007294711540453136
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0055938586592674255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003944142255932093
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007007458480075002
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017253320664167404Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003821594873443246

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004911196301691234Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007514089345932007
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005404801573604345

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009492040611803532
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005965812131762505
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004663430736400187
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013232526369392872
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009900307282805443
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005078030517324805Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01623048633337021

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0050911810249090195
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025138171389698982
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0045477887615561485
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012653629528358579
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004274850245565176
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016722658649086952
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008489593747071922
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036966283805668354Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016852127388119698

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001129757845774293Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031762283761054277Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015279307961463928


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014932685531675816Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003179060062393546

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001297647599130869
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01184104010462761Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003554134862497449

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014865790726616979
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004008279647678137
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014850150793790817
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019298960687592626Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013857088051736355
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0070345401763916016

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13270269334316254Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02308529242873192

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012763015693053603
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09203838557004929
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023177316412329674
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00123202009126544
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10015677660703659
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16310080885887146
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.49715951085090637
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010853874264284968Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0952204167842865

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06217134743928909
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009182858630083501Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3144383132457733

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008229060913436115
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008924208232201636
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000891244737431407
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012832131469622254
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005085369106382132
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010364280082285404
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007882713340222836
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005476241931319237
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11394120007753372
 28%|██▊       | 164/584 [17:34<43:39,  6.24s/it] 28%|██▊       | 164/584 [17:29<43:42,  6.24s/it] 28%|██▊       | 164/584 [17:32<43:42,  6.24s/it]Loss Loss Loss tensor(3.7055, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(3.8962, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(3.9795, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7792726159095764
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.36842888593673706
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23389610648155212
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028887322172522545Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.29768699407577515
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9201040863990784

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3253086805343628
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01213212963193655
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.35731595754623413
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06135650724172592
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013206961564719677
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012897526612505317
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7894474267959595
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00196772045455873
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001129920274252072Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001821374025894329

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027431536000221968
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002518041292205453
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001927890843944624
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033846294973045588
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003262246900703758
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002876660437323153Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0053712292574346066
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004195159417577088

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005176421720534563
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005935358349233866
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004240738635417074
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0060702115297317505
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010401702020317316
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005978873814456165
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007076858542859554
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002136313123628497
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005906355800107121Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006155042909085751

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002515458967536688
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005004643928259611
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006295467610470951Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001802304876036942

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0046934885904192924
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001327571109868586
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006283558905124664
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005119025707244873
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001964668510481715
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01825588569045067
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005913686472922564
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00331499963067472
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0077098337933421135
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004277340485714376
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006342621985822916
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010080703534185886
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00038596719969063997Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004242700524628162

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014309307560324669
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004206845071166754
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004517394700087607
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016651375219225883
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005912517663091421
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012686675181612372Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03396904841065407Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006110604852437973


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015460020862519741
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009630290791392326
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000815630191937089
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015149914659559727
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0049714152701199055
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011152017395943403Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013394665904343128

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0044059306383132935
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012806670740246773
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004063533153384924
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013020633487030864
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010660819709300995
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035674222745001316
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014541295822709799
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013147038407623768
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003079709131270647
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002332218922674656
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012249808758497238
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003073694184422493
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020366491749882698
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011582124279811978Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034783591981977224

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09055236726999283
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003937319852411747
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00108232197817415Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08169831335544586

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007437830325216055
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05518369749188423
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009434217936359346
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13681627810001373
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06251321732997894
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007911409484222531Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.30957138538360596

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027309216558933258
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007285866304300725Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1855127364397049

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.46045583486557007
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007974437321536243
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008062506094574928
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011587782064452767
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009593862108886242
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010219729505479336
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005477061960846186
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006039001047611237
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13061988353729248
 28%|██▊       | 165/584 [17:35<44:39,  6.39s/it] 28%|██▊       | 165/584 [17:41<44:37,  6.39s/it] 28%|██▊       | 165/584 [17:39<44:39,  6.39s/it]Loss Loss Loss tensor(4.0726, device='cuda:0', grad_fn=<NllLossBackward0>)tensor(4.0258, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(3.9041, device='cuda:1', grad_fn=<NllLossBackward0>)

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019754881039261818
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6078717708587646
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23288023471832275
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.29476770758628845
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.44607120752334595Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.039550598710775375

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11493463814258575
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.378374308347702
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6655578017234802Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.92216815170832e-05

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23281076550483704
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011396069749025628
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013952246867120266
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010897654574364424
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015757088840473443
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016297573456540704
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017612967640161514Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022231842740438879

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025088891852647066
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00038701508310623467
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001638413086766377
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030229866970330477
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008385868277400732
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00026979760150425136Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004731560591608286

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018396498635411263
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00518493028357625
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002351446310058236
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004058634222019464
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006427423562854528
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002100863493978977
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007509798742830753
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000583713932428509Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007370623294264078
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015343076083809137

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009315287694334984Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019851098768413067

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008742994978092611Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014651150442659855

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028068104293197393
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01584622636437416
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005152843426913023
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010272895451635122
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01816469058394432
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007606753148138523
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01599559560418129Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00703545194119215

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001168490038253367
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015790723264217377
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00883979257196188
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013860558392480016
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023810647428035736
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008855698630213737
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02658514305949211Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009317643009126186

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001455069170333445
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027933752164244652
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006742298137396574
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001982959685847163
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020252957940101624
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005845495965331793
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032032786402851343
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005218865349888802
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020004471763968468
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0045353714376688Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01924053207039833

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031771203503012657
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037885140627622604Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016555411741137505

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003488415852189064
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036655771546065807
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015577580779790878
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034132245928049088Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004197480157017708
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019093800336122513

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00467560812830925
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01953042671084404
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028374611865729094
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007903383113443851
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03108682855963707
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.24177733063697815
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00374378589913249
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07509133964776993
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.032343752682209015
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0677899569272995
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004083713982254267
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.28865402936935425
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1546960324048996
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0039713503792881966Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8106531500816345

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14135347306728363
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002973852911964059
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6441848874092102
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027485715691000223
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002585004549473524
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021124070044606924
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020688604563474655
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022534432355314493
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00240952312014997
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003463760018348694
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006700829137116671
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012101545929908752
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016190852969884872
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01952742412686348
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5971166491508484
 28%|██▊       | 166/584 [17:47<43:42,  6.27s/it] 28%|██▊       | 166/584 [17:41<43:43,  6.28s/it] 28%|██▊       | 166/584 [17:45<43:44,  6.28s/it]Loss Loss Loss tensor(3.2267, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(3.9922, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.7734, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.49435174465179443
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03277081623673439
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5313467383384705
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20759432017803192
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4897376000881195Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06734731793403625
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011258645914494991

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18304966390132904
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.48919257521629333
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6295663714408875
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025337371043860912
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002808056306093931
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013467052020132542
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038420804776251316
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003910191881004721
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005536632612347603
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019186779856681824
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005196795100346208
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007276961579918861
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007609247695654631
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006731695029884577
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011800861917436123
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009513296536169946
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013247833121567965Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009744218550622463

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013391085667535663
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007968124933540821
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002052056835964322
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026594859082251787
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007452406454831362
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031373235397040844
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003727325703948736
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005485531408339739
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035846319515258074
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004175423178821802Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004489894025027752

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025765702594071627
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007439074106514454
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004252515733242035
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003172133583575487
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010629835538566113
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004320284351706505
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016610050573945045
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031801587902009487
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0073041184805333614
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01157623901963234
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00233661662787199
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007134741172194481
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01265803910791874
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006454745773226023
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017515865620225668Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014606627635657787

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008390803821384907
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019552364945411682
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001346703851595521
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008792500011622906
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03380002826452255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002237428445369005
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012071670964360237
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02329559437930584
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002971330191940069
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006751216482371092
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02383449673652649
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005058868322521448
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005944924894720316
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022572111338377
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00378037360496819Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005278956610709429
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021946746855974197

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004554730374366045
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01861243136227131
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0042940545827150345
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038015947211533785
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021903177723288536
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004727947060018778Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003588802879676223

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02203211560845375
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004016102757304907
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03707220032811165
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005377012304961681Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004380316007882357
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10475731641054153

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00737305311486125
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10821085423231125
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007791436277329922
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2108648121356964
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10023009032011032
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0052775973454117775
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02948836423456669
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07949789613485336
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005097764078527689
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6232365965843201
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.22883445024490356
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7860896587371826
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00461364584043622
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036694162990897894
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004290089942514896
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004165198188275099
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003932102117687464
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005887514911592007
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02296496368944645
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03137395903468132
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02334021031856537
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021877411752939224
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6002373695373535
 29%|██▊       | 167/584 [17:48<44:03,  6.34s/it] 29%|██▊       | 167/584 [17:54<44:02,  6.34s/it] 29%|██▊       | 167/584 [17:51<44:03,  6.34s/it]Loss Loss tensor(3.9473, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(3.8290, device='cuda:1', grad_fn=<NllLossBackward0>)
Loss tensor(3.9081, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030339177697896957
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3101937472820282
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.22321227192878723
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5301501154899597
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8909680843353271Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026621675118803978

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3704659342765808
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011926579289138317
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3581293821334839
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19614653289318085
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021984991326462477
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2103150635957718
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004759317729622126Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003094336425419897

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017943952698260546
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004190976032987237
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022265866573434323
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002747546648606658
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005366363911889493
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007677447283640504
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003923431213479489
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004226375836879015
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001114966464228928
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024699249770492315
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005449521355330944
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006318101659417152Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00419847946614027

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008973885327577591
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004307148512452841
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00098646420519799Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008225610479712486

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031405570916831493
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008118484169244766
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003577561816200614
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014820614596828818
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004690023139119148
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008508379571139812
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016578815411776304
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00773452315479517
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006427982822060585
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015443847514688969Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008962309919297695

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0053238533437252045
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008669625036418438
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013034718576818705Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010549214668571949

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011524293571710587
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014425098896026611
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009382728603668511Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011469701305031776

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012665946036577225
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01695721410214901
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007106995908543468
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00828890223056078
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010947701521217823
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012053742539137602Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007129232864826918

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017636889591813087
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00621041189879179
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015080489683896303Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026676062494516373

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005392204504460096
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03251979872584343Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018046798650175333

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004464769270271063
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.032997097820043564
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001533419475890696Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004173255525529385

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02940296195447445
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004726211540400982
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002581838984042406Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028973747044801712

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005183912813663483
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02429117076098919
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003324518445879221Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008995778858661652
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020436696708202362

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2663425803184509
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017857611179351807
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003738998668268323
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0456780269742012
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01986500807106495
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003612288273870945
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3091398775577545
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020647574216127396
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029707893263548613
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8066064119338989
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.031437311321496964
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028388393111526966
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05616924166679382
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024301274679601192
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06533344089984894
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11510515213012695Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001963874790817499

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12660053372383118
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019004357745870948Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6731556057929993

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018003213917836547
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019220721442252398
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024239346385002136
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009284399449825287
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01161646842956543
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010495328344404697
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01654943637549877
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3302673399448395
 29%|██▉       | 168/584 [18:00<44:13,  6.38s/it] 29%|██▉       | 168/584 [17:54<44:14,  6.38s/it] 29%|██▉       | 168/584 [17:58<44:14,  6.38s/it]Loss Loss Loss tensor(3.5292, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(3.9400, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(3.5460, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7204201221466064Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029604746028780937

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17943748831748962
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5790150165557861
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5558937788009644Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04787391424179077

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.30720505118370056
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017176447436213493
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4970756769180298
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15496866405010223
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004235443484503776
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021917235106229782
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3501736521720886
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005980149726383388
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000621640298049897Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004345996305346489

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008067837334237993Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006703034043312073

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010939196217805147
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009959853487089276
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010321121662855148
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017544172005727887
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013163858093321323
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01297400426119566Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00155805388931185Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026901355013251305


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022868032101541758
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0041287802159786224Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021740365773439407

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035183147992938757
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020161708816885948
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004583093803375959
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038051882293075323
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017983723431825638
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031849252991378307
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0041479081846773624Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01622193492949009

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00425009336322546
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01261309813708067
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032166496384888887
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005681038834154606
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0073755704797804356
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002293600933626294Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008514288812875748

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010334933176636696
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008219374343752861
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001258936943486333
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007313060108572245Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020671986043453217

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00887941475957632
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012893097009509802Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03199444338679314

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008585953153669834
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0157539751380682
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023634948302060366Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012879774905741215

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00642505194991827
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01713598519563675
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037245070561766624
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005561080761253834
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01668119616806507
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004990975838154554
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002316915662959218Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018172910436987877

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004514521919190884
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.049480944871902466
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022759861312806606
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003683203598484397
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014300161972641945
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023654925171285868Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003476041601970792

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004137909039855003Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01243964396417141

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002538683358579874
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01194342877715826
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004404470790177584
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008872313424944878
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013233386911451817
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00508526898920536
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.26005294919013977
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013035710901021957
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001982708228752017
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03875933960080147
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013997269794344902
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001748485490679741Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.30233657360076904

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02674938552081585
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7457500696182251
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016323162708431482Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02014007978141308

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17752781510353088
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015386948361992836
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1065421923995018
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001525169238448143
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1749333143234253
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001568527426570654
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16741453111171722
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002252796897664666
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5593690872192383
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027214116416871548
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0271376334130764
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018322819843888283
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022816820070147514
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023278161883354187
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.41095468401908875
 29%|██▉       | 169/584 [18:07<44:24,  6.42s/it] 29%|██▉       | 169/584 [18:01<44:25,  6.42s/it] 29%|██▉       | 169/584 [18:04<44:25,  6.42s/it]Loss Loss Loss tensor(3.6106, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.0705, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(3.3994, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.48180875182151794Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7874729037284851
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05431518703699112

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3322030007839203
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5432931780815125
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.525888204574585Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19007538259029388

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028568992391228676
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09087076783180237
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02875203639268875
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017875977791845798
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3135514557361603
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010117417201399803
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002749748295173049
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002375653275521472
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00045268077519722283
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00033977802377194166
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004663954954594374
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007851412519812584
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00557300029322505
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004915267927572131
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013113816967234015
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009547913447022438
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006296579376794398
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010160403326153755
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019993807654827833Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000934167648665607

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009442981332540512
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013332292437553406
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033333897590637207
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009482030756771564Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0042288475669920444
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002413689624518156

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008367999456822872
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027986466884613037
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004041082691401243
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006201636511832476
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028268112801015377
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035167918540537357
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006808237638324499
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021552378311753273
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028490324039012194
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007636113092303276Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002463293494656682

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020159713458269835Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011239935643970966
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030978210270404816

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008157478645443916
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0051171137019991875
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020129873882979155
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006956315599381924
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004680143669247627
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017122705467045307
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008735287934541702
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037491268012672663
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020830146968364716
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011688897386193275
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004854898899793625
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023711510002613068
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018368784338235855
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0051993741653859615
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024392507039010525
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01458391360938549
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008497330360114574
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002653948962688446
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015605890192091465
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004496576264500618
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034016466233879328
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015610934235155582
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004004410468041897
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0041422066278755665
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015775179490447044
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037171724252402782
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0033819994423538446
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017759984359145164
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034034820273518562
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003279464552178979
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003053088206797838
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019364066421985626
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031643002294003963
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029919706284999847
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02098761685192585
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029841437935829163Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035437429323792458
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027661750093102455

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038500798400491476
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07136298716068268
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035764893982559443
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006899299565702677
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07952355593442917
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003501732600852847
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1527799665927887
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06188376620411873
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004106826614588499
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029794247820973396
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06810374557971954
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004708864726126194
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7674264311790466
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18232609331607819
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026181301102042198
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.738169252872467
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025988701730966568
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021687934175133705
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01748739555478096
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3162616491317749
 29%|██▉       | 170/584 [18:07<43:59,  6.37s/it] 29%|██▉       | 170/584 [18:13<43:59,  6.37s/it] 29%|██▉       | 170/584 [18:11<43:58,  6.37s/it]Loss Loss Loss tensor(4.6650, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(3.6286, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(3.9104, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.49748653173446655Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6396387815475464Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04449274018406868


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.34854841232299805
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2197238951921463
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7667933702468872Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.057975850999355316
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025142023339867592

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012767128646373749Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2105199098587036
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6932576894760132

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001237792894244194
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00015348989109043032
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019828587770462036
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018863696604967117Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022030457330401987

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002940613485407084
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003096654254477471
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030587213113904
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00041630747728049755
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000493611500132829Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036790058948099613
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006715429481118917
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006227830424904823

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000983700854703784
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006250861566513777
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007963922107592225
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016961193177849054
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006109970156103373
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001210035290569067Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002399636432528496

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007050805725157261
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002062681131064892
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019692403730005026Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004845309071242809

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015722635434940457
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004116717725992203
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002421220298856497Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002119496464729309

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006366722285747528
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003128704382106662
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022897920571267605
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009436898864805698
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005902438890188932
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020356858149170876Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017801469191908836

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006393273826688528
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009464572183787823
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005993503611534834
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014274297282099724
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010578485205769539
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007876341231167316
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011265062494203448Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013517080806195736Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007971731014549732


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015466162003576756Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013160524889826775

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001667385222390294
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0387376993894577
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006348563823848963
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002163426950573921
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017163408920168877
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00546989543363452
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01784135401248932Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004256053827702999Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004980020225048065


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004459124989807606
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016749102622270584
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037498208694159985
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026536511722952127Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01468002237379551

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034877199213951826Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022781151346862316
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01443548034876585

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004053255543112755
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0176287479698658
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029083536937832832
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004590868018567562
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01814752258360386
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008583007380366325
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003296757349744439Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030002176761627197

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21101471781730652
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12489882856607437
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006608292460441589
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03818229213356972
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13526062667369843
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032137271482497454Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.258899450302124

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11301041394472122
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5956467390060425
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1582280844449997
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031909970566630363
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5867977738380432
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030475144740194082
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023647649213671684
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002531240927055478
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0026327534578740597
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027355020865797997
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00396606232970953
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03181682899594307
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03876578435301781
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03976520523428917
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.037564437836408615
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.39783602952957153
 29%|██▉       | 171/584 [18:18<40:41,  5.91s/it] 29%|██▉       | 171/584 [18:12<40:41,  5.91s/it] 29%|██▉       | 171/584 [18:15<40:42,  5.91s/it]Loss Loss Loss tensor(3.6494, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(3.4844, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(3.9596, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0327034555375576Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.435832142829895
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.30646970868110657

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5193328857421875
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4471171200275421
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8827764987945557Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2019788920879364Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06301265209913254


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21800701320171356
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3755422830581665
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012327582575380802
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006852780934423208
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.552508709020913e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01018044538795948Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00013709465565625578
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009909060318022966

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.7986653953557834e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021522435417864472
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001881041331216693
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.537149213021621e-05Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003400858258828521

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002319546416401863
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006873934762552381
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00011817416088888422
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029756389558315277
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008464190759696066
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004103327635675669
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00016752812371123582Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015403289580717683

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005632069893181324
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021180168259888887
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00022601587988901883
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008097562938928604
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018305754056200385
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003975070430897176Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0090766791254282

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014853733591735363
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012481500394642353
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006935176206752658Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00220714183524251
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019511405378580093

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031655358616262674
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02000107429921627
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010323968017473817
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005175258498638868
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021697640419006348
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005459208507090807
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011013619368895888
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011773492209613323
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004696143325418234
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001372632454149425
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010335467755794525
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005779675208032131
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01272523682564497
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002008766634389758Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005922021809965372

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014070776291191578
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009971489198505878
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001821651472710073
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021708574146032333
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005129445344209671
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018476832192391157Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011121069081127644

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004487283993512392
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011198777705430984
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009862490696832538Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004227847326546907

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011335160583257675Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038297586143016815

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008531794883310795
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010830661281943321
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003273959504440427
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011728218756616116
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003032093867659569
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010152183240279555
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012105374597012997
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036000097170472145
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011203414760529995Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01561105065047741
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003987445496022701

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022033045068383217
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007284045685082674
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014811846194788814
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06962522864341736
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17495985329151154
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008596318657509983
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.059397242963314056
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.037066373974084854
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008184140897355974
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08726640790700912
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2243787795305252
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7081202268600464
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09753470122814178
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008072496275417507
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7668943405151367
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006844369345344603
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007755481055937707
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007299851858988404
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008860004018060863
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011175043182447553
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007371058221906424
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0069841439835727215
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009646784514188766
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008089485578238964
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1738135814666748
 29%|██▉       | 172/584 [18:24<41:35,  6.06s/it] 29%|██▉       | 172/584 [18:18<41:35,  6.06s/it] 29%|██▉       | 172/584 [18:22<41:35,  6.06s/it]Loss Loss Loss tensor(4.1175, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(3.5225, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.4595, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7800472378730774Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025820031762123108

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.38727906346321106
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5222960114479065
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5143626928329468Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.39399901032447815

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02761945314705372
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20484530925750732
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027161099016666412Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.34580543637275696

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002546814503148198
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014217053540050983Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14743760228157043

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00037031242391094565
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002275923267006874
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0004161579126957804
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035003095399588346
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005425415583886206
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007096888730302453
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007507115951739252
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011912159388884902Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0060386136174201965

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012323693372309208
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0072434744797647
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018641295609995723
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014529775362461805
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012166141532361507
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017732561100274324
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003227431094273925
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012906047515571117
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002448169980198145
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004159306176006794
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012874683365225792
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023313569836318493
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004214471206068993Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013275254517793655
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0017678573494777083

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011510146781802177Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0023973698262125254

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038616755045950413
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003369576297700405Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01189096737653017

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030966054182499647Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005042714532464743
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014871153049170971

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004907256457954645
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012206091545522213
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028100053314119577
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004366220906376839
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012214254587888718
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031826994381844997
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005321213975548744
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01017079595476389
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002292088931426406
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005291180685162544
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013848038390278816
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022801344748586416
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00860921572893858
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017973998561501503
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002173237269744277
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004283071495592594
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016732295975089073
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028546275570988655Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003830753033980727
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01500600017607212

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003502342849969864
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009260118007659912
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032238818239420652Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031194346956908703

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008918198756873608
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002637486672028899
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028644693084061146
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010286546312272549
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024436062667518854
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002463436219841242
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010029872879385948
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002817537635564804
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016594675835222006Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010664246045053005
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003158355364575982

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005402739159762859Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010968128219246864

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0014761964557692409
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14212897419929504
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013260938227176666
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016282984288409352Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02938426099717617
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018704941496253014

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17461040616035461
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06955775618553162
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015694283647462726Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7445061206817627

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.059646692126989365
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016860973555594683
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13084636628627777
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016903056530281901
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07714835554361343
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0021105518098920584Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.771880567073822

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024619849864393473
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011253605596721172
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012018132954835892
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018660007044672966
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014274751767516136
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.35359087586402893
 30%|██▉       | 173/584 [18:31<43:15,  6.32s/it] 30%|██▉       | 173/584 [18:25<43:16,  6.32s/it] 30%|██▉       | 173/584 [18:29<43:16,  6.32s/it]Loss Loss Loss tensor(4.1777, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(4.2405, device='cuda:0', grad_fn=<NllLossBackward0>)tensor(3.6580, device='cuda:2', grad_fn=<NllLossBackward0>)

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5006939172744751Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03752293065190315
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3022840619087219

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.25147175788879395
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4986967444419861
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8235543370246887Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06325691938400269

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1629694700241089
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016899224370718002
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3952620029449463
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016992688179016113Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1684713065624237

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012345463619567454
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009860499994829297
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001795345888240263
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021204931545071304
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013869748217985034
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000255702092545107
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00032450203434564173Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0003828955232165754

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0022128650452941656
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006987258093431592
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005132615915499628Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027806602884083986
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011672681430354714

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00413693580776453
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001884487341158092
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007781577878631651
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004147465340793133
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002274789847433567
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013550472212955356
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003803806146606803
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018450673669576645
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004892696626484394Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001728722476400435
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013106722617521882

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034146918915212154Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015413459623232484

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0015302652027457952
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038392727728933096
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002119086217135191
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0013035773299634457
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005895409267395735
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004618029110133648
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009546468034386635Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008116503595374525
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005339726340025663

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01888824999332428
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005064297001808882
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008219057926908135Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017346229404211044

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006925832014530897
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013754994608461857
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007214200682938099
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016576170455664396
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013575299642980099
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011481931433081627
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024120763409882784
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012860782444477081
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006172495428472757
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004362483508884907Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01674846187233925
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005399889312684536

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010836412198841572
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004984820261597633
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0049515157006680965
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009611639194190502
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00453579518944025
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004250876605510712
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0038726096972823143
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009645219892263412
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036162452306598425Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0035135014913976192
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010322810150682926

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004030351527035236
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010015462525188923
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032356525771319866
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004698692820966244
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010135478340089321
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034604212269186974Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007988467812538147
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014467679895460606

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18732966482639313
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015913087874650955
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002357698045670986Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07977823913097382
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03494562953710556

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10790179669857025
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23242437839508057
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020169576164335012Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8271719217300415

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17639969289302826
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10735207051038742
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019056493183597922
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7358955144882202
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018994613783434033
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019636815413832664
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019956212490797043
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027679321356117725
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031715792138129473
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009885032661259174
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0212322399020195
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024693377315998077
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02125605009496212
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2621445655822754
 30%|██▉       | 174/584 [18:37<41:34,  6.08s/it] 30%|██▉       | 174/584 [18:31<41:34,  6.08s/it] 30%|██▉       | 174/584 [18:34<41:34,  6.08s/it]Loss Loss Loss tensor(2.9169, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(3.6465, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(3.6675, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.48894307017326355Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8026232719421387
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030029740184545517

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.32444867491722107
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.47462359070777893
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5292961597442627Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.22714751958847046
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06437582522630692

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02566859871149063Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.28816086053848267
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.30886000394821167

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003755454905331135
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00035827350802719593
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025634028017520905
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005675559397786856
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005165356560610235
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0006217744085006416Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.009251506999135017

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007503135711885989
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011137142777442932
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001031569205224514
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010960346553474665
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01827428489923477
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019054142758250237
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016741250874474645Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016692643985152245

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002557890024036169
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014219379983842373
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0025928320828825235Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.001740358187817037
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013620434328913689

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002050963696092367Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011195161379873753

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004400553181767464
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01115330308675766
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019369071815162897
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005040792748332024
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013777113519608974
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016033222200348973
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004356428515166044Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014317985624074936

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018338172230869532
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016692854464054108
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0036489879712462425
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002362580969929695
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010055151768028736
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0027138148434460163
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014237192459404469
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00388170313090086
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002442772965878248
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0225873701274395
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004642943851649761
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003012963104993105Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027937591075897217

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004276111721992493
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03585202991962433
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0024985603522509336
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006220267154276371
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0365857295691967
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0019426586804911494Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0073454794473946095

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0374143086373806
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010229270905256271
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016730115748941898
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03625517711043358
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007606707513332367
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002554187783971429Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03208014369010925

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0071712215431034565
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03289277106523514
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003731677308678627
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006976443808525801
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.038750581443309784
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004530875477939844
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0061365580186247826
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03038511425256729
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005180560052394867
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005599881988018751
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0807650089263916
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005048380699008703Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08304893970489502Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004620803520083427


Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12539759278297424
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005688866134732962
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004522270988672972
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12798362970352173
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006958862766623497
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004318919964134693
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19917675852775574
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01145569235086441
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031869234517216682Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6497614979743958

Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1669698804616928
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003920233808457851
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0417046919465065
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003986711613833904Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21527044475078583

Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7730334997177124
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0034868575166910887
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006421763449907303
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010337273590266705
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03293651342391968
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02211115136742592
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03118119388818741
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.26706933975219727
 30%|██▉       | 175/584 [18:36<39:34,  5.81s/it] 30%|██▉       | 175/584 [18:42<39:34,  5.81s/it]REMOVE TEST?! 0 0 0.6027397260273972
 30%|██▉       | 175/584 [18:39<39:34,  5.81s/it]Before Process
B-INPUTREMOVE TEST?! 0 0 2.1095890410958904
 tensor([    1,   415,  5971,  7826, 28594,  5876,  1287,   298,  6722,   369,
         1567,   575,   438,  2125, 28723, 28705,  1263,  1012,  5344,   298,
          316, 28725,   736,   460, 28705, 28750, 28782,  9060,   298,  6722,
        28725,   304,   624, 28733,   364,  4136,   302,   272,  9060,   298,
         6722,   460, 20958, 28723, 28705,  1047,   736,   460, 28705, 28782,
        28734, 20958,  9060,   298,  6722,   660,   264,   961, 28725,   910,
         1287,  5344,   298,  6722,   460,   736,   660,   264,   961, 28804,
        28705,     2,  1047,   736,   460, 28705, 28782, 28734, 20958,  9060,
          298,  6722,   660,   264,   961, 28725,   304,   456, 10651,   624,
        28733,   364,  4136,   302,   272,  9060,   298,  6722, 28725,   868,
          736,   460, 28705, 28782, 28734, 28736, 28781, 28746,  5275, 28782,
        28734, 28736, 28781, 28746, 28750, 28734, 28734,  4060, 28750, 28734,
        28734,  9060,   298,  6722,   660,   264,   961, 28723,  1047,   354,
         1012, 28705, 28750, 28782,  9060,   298,  6722,   736,   349,   624,
         5344,   298,   316, 28725,   868,   736,   460, 28705, 28750, 28734,
        28734, 28748, 28750, 28782, 28746,  5275, 28750, 28734, 28734, 28748,
        28750, 28782, 28746, 28783,  4060, 28783,  5344,   298,  6722,   660,
          264,   961, 28723, 28705,     2,  2476, 28783, 28705,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2], device='cuda:0')
B-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  1047,   736,   460, 28705, 28782, 28734, 20958,  9060,
          298,  6722,   660,   264,   961, 28725,   304,   456, 10651,   624,
        28733,   364,  4136,   302,   272,  9060,   298,  6722, 28725,   868,
          736,   460, 28705, 28782, 28734, 28736, 28781, 28746,  5275, 28782,
        28734, 28736, 28781, 28746, 28750, 28734, 28734,  4060, 28750, 28734,
        28734,  9060,   298,  6722,   660,   264,   961, 28723,  1047,   354,
         1012, 28705, 28750, 28782,  9060,   298,  6722,   736,   349,   624,
         5344,   298,   316, 28725,   868,   736,   460, 28705, 28750, 28734,
        28734, 28748, 28750, 28782, 28746,  5275, 28750, 28734, 28734, 28748,
        28750, 28782, 28746, 28783,  4060, 28783,  5344,   298,  6722,   660,
          264,   961, 28723, 28705,     2,  2476, 28783, 28705,     2,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100], device='cuda:0')
[tensor([[ 1047,   736,   460, 28705, 28782, 28734, 20958,  9060,   298,  6722,
           660,   264,   961, 28725,   304,   456, 10651,   624, 28733,   364,
          4136,   302,   272,  9060,   298,  6722, 28725,   868,   736,   460,
         28705, 28782, 28734, 28736, 28781, 28746,  5275, 28782, 28734, 28736,
         28781, 28746, 28750, 28734, 28734,  4060, 28750, 28734, 28734,  9060,
           298,  6722,   660,   264,   961, 28723]], device='cuda:0'), tensor([[ 1047,   354,  1012, 28705, 28750, 28782,  9060,   298,  6722,   736,
           349,   624,  5344,   298,   316, 28725,   868,   736,   460, 28705,
         28750, 28734, 28734, 28748, 28750, 28782, 28746,  5275, 28750, 28734,
         28734, 28748, 28750, 28782, 28746, 28783,  4060, 28783,  5344,   298,
          6722,   660,   264,   961, 28723, 28705,     2]], device='cuda:0')]
REMOVE TEST?! 0 0 0.6027397260273972
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3733, 35.7085, 35.3007, 35.2254, 34.1884, 34.1401, 34.3297, 33.4586,
          5.7150]], device='cuda:1')
tensor([[10.3732, 36.7630, 36.4504, 36.0885, 35.9700, 35.6068, 35.7192, 35.0870,
          5.5292]], device='cuda:2')
tensor([[10.3732, 38.3823, 38.1159, 38.0628, 38.6702, 39.2096, 39.4756, 38.6623,
          5.8270]], device='cuda:0')
REMOVE TEST?! 1 0 REMOVE TEST?!2.1095890410958904 
1 0 0.6027397260273972
[0]
REMOVE TEST?! 0 0 1.506849315068493
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3733, 33.2911, 32.7662, 32.5532, 31.8732, 31.6026, 31.8174, 30.7977,
          5.1229]], device='cuda:1')
tensor([[10.3732, 36.3074, 35.9978, 35.8689, 36.0435, 35.8443, 36.1160, 35.4576,
          5.3906]], device='cuda:2')
[]
tensor([[10.3732, 40.1745, 39.9363, 39.5377, 37.9991, 36.5822, 36.2395, 35.4621,
          6.3161]], device='cuda:0')
REMOVE TEST?! 2 0 2.1095890410958904
REMOVE TEST?! 1 0 1.506849315068493
REMOVE TEST?! 0 0 0.6027397260273972
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3731, 35.5511, 35.2292, 34.4108, 32.1611, 31.3651, 31.3829, 30.5804,
          5.4720]], device='cuda:1')
REMOVE TEST?! 1 0 0.6027397260273972
tensor([[10.3732, 35.4052, 35.0366, 35.2282, 35.6195, 35.6475, 36.0606, 35.3707,
          5.2533]], device='cuda:2')
tensor([[10.3732, 38.6660, 38.3094, 38.0939, 36.8399, 35.6153, 35.3836, 34.5724,
          5.9541]], device='cuda:0')
REMOVE TEST?! 3 1 2.1095890410958904
REMOVE TEST?! 2 0 1.506849315068493
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3731, 33.2622, 32.9017, 32.0942, 29.9198, 29.4005, 29.6676, 28.8660,
          5.0977]], device='cuda:1')
[]
tensor([[10.3732, 35.5641, 35.2391, 35.0335, 35.6300, 35.3570, 35.6530, 35.0486,
          5.3236]], device='cuda:2')
tensor([[10.3732, 37.6283, 37.2096, 37.0096, 35.7617, 34.7178, 34.5220, 33.6812,
          5.6488]], device='cuda:0')
REMOVE TEST?! 4 2 2.1095890410958904
REMOVE TEST?! 3 0 1.506849315068493
REMOVE TEST?! 0 0 1.8082191780821917
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3732, 38.4420, 38.1979, 37.7860, 36.5434, 35.9278, 35.9441, 35.2415,
          6.0965]], device='cuda:1')
tensor([[10.3732, 34.6051, 34.1548, 33.9816, 34.1675, 34.0207, 34.3391, 33.6188,
          5.0895]], device='cuda:2')
REMOVE TEST?! 1 0 1.8082191780821917
REMOVE TEST?! 5 2 2.1095890410958904
tensor([[10.3732, 36.5358, 36.0821, 35.8431, 34.4910, 33.5351, 33.3725, 32.5165,
          5.4468]], device='cuda:0')
REMOVE TEST?! 4 0 1.506849315068493
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3732, 33.0062, 32.4532, 32.1672, 32.0420, 31.8746, 32.1889, 31.4224,
          4.7103]], device='cuda:2')
tensor([[10.3731, 36.1350, 35.7486, 35.3396, 34.1459, 33.5377, 33.5466, 32.7950,
          5.6766]], device='cuda:1')
REMOVE TEST?! 6 2 2.1095890410958904
REMOVE TEST?! 2 0 1.8082191780821917
tensor([[10.3732, 35.5865, 35.1154, 34.8081, 33.2870, 32.4775, 32.3764, 31.5323,
          5.2544]], device='cuda:0')
[]
REMOVE TEST?! 0 0 0.6027397260273972
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3733, 35.2069, 34.8708, 34.2215, 35.1293, 35.7152, 35.8372, 34.8917,
          5.6419]], device='cuda:0')
tensor([[10.3732, 35.1238, 34.7040, 34.2554, 32.9751, 32.4338, 32.5080, 31.7745,
          5.5149]], device='cuda:1')
[0]tensor([[10.3732, 32.4766, 31.9056, 31.6064, 31.2957, 31.0197, 31.3252, 30.4891,
          4.5786]], device='cuda:2')

REMOVE TEST?! 3 0 1.8082191780821917
[2, 3]
REMOVE TEST?! 0 0 0.9041095890410958
REMOVE TEST?! 0 0 0.3013698630136986
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3731, 38.9174, 38.6358, 38.1793, 36.4209, 35.2470, 35.0814, 34.1040,
          5.6785]], device='cuda:0')
tensor([[10.3730, 27.7471, 27.2357, 26.1767, 23.9994, 24.9795, 25.0159, 24.0329,
          3.8209]], device='cuda:2')
REMOVE TEST?! 1 0 0.9041095890410958
[]
REMOVE TEST?! 0 0 0.9041095890410958
tensor([[10.3731, 34.8451, 34.4154, 33.9599, 32.6752, 32.1312, 32.2375, 31.4641,
          5.4159]], device='cuda:1')
REMOVE TEST?! 4 0 1.8082191780821917
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3731, 34.7898, 34.4241, 33.8061, 36.7014, 37.8338, 38.0539, 37.2771,
          6.2930]], device='cuda:2')
[0]
tensor([[10.3731, 36.7711, 36.4063, 35.9654, 34.0173, 33.3235, 33.2953, 32.0907,
          5.1564]], device='cuda:0')
REMOVE TEST?! 2 0 0.9041095890410958
REMOVE TEST?! 0 0 2.1095890410958904
tensor([[10.3731, 34.5569, 34.0987, 33.6790, 32.7733, 32.3372, 32.4277, 31.6471,
          5.4006]], device='cuda:1')
REMOVE TEST?! 5 0 1.8082191780821917
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3731, 35.2181, 34.8639, 34.2151, 32.4427, 31.9798, 32.2593, 31.1255,
          5.4177]], device='cuda:2')
REMOVE TEST?! 1 0 2.1095890410958904
tensor([[10.3731, 35.2569, 34.9085, 34.3547, 32.2463, 31.5694, 31.5920, 30.3241,
          4.9222]], device='cuda:0')
[]
After Process
A-INPUT tensor([    1,   415,  5971,  7826, 28594,  5876,  1287,   298,  6722,   369,
         1567,   575,   438,  2125, 28723, 28705,  1263,  1012,  5344,   298,
          316, 28725,   736,   460, 28705, 28750, 28782,  9060,   298,  6722,
        28725,   304,   624, 28733,   364,  4136,   302,   272,  9060,   298,
         6722,   460, 20958, 28723, 28705,  1047,   736,   460, 28705, 28782,
        28734, 20958,  9060,   298,  6722,   660,   264,   961, 28725,   910,
         1287,  5344,   298,  6722,   460,   736,   660,   264,   961, 28804,
        28705,     2,  1047,   354,  1012, 28705, 28750, 28782,  9060,   298,
         6722,   736,   349,   624,  5344,   298,   316, 28725,   868,   736,
          460, 28705, 28750, 28734, 28734, 28748, 28750, 28782, 28746,  5275,
        28750, 28734, 28734, 28748, 28750, 28782, 28746, 28783,  4060, 28783,
         5344,   298,  6722,   660,   264,   961, 28723, 28705,     2,  2476,
        28783, 28705,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2], device='cuda:0')
A-LABEL tensor([[10.3731, 34.0073, 33.5252, 33.0756, 32.1100, 31.6768, 31.7932, 30.9905,
          5.3031]], device='cuda:1')
tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  1047,   354,  1012, 28705, 28750, 28782,  9060,   298,
         6722,   736,   349,   624,  5344,   298,   316, 28725,   868,   736,
          460, 28705, 28750, 28734, 28734, 28748, 28750, 28782, 28746,  5275,
        28750, 28734, 28734, 28748, 28750, 28782, 28746, 28783,  4060, 28783,
         5344,   298,  6722,   660,   264,   961, 28723, 28705,     2,  2476,
        28783, 28705,     2,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100], device='cuda:0')
[]
REMOVE TEST?! 0 0 0.9041095890410958
Cross Entropy List Cross Entropy List Loss tensor([[10.3733, 34.5466, 34.0454, 33.4850, 32.3280, 32.4005, 32.8046, 32.0805,
          5.7184]], device='cuda:1')
REMOVE TEST?! 1 0 0.9041095890410958
tensor([[10.3731, 33.8301, 33.3933, 32.7814, 31.0656, 30.7439, 31.1635, 30.0342,
          5.1443]], device='cuda:2')
REMOVE TEST?! 2 0 2.1095890410958904
tensor(3.9724, device='cuda:0', grad_fn=<NllLossBackward0>)
Cross Entropy List Cross Entropy List tensor([[10.3733, 10.4193, 10.5302,  8.6922,  9.3755, 11.3550, 10.6417,  9.8530,
         15.7097]], device='cuda:1')
[1]
tensor([[10.3733, 10.4150, 10.4918,  8.6953, 10.5810, 12.2812, 10.3516,  8.5445,
         12.8621]], device='cuda:2')
REMOVE TEST?! 3 1 2.1095890410958904
Loss Cross Entropy List tensor([[10.3733, 10.4454, 10.5839,  8.4555, 12.5371, 11.3500, 10.5062, 10.0272,
         18.2134]], device='cuda:2')
REMOVE TEST?! 4 2 2.1095890410958904
tensor(18.8675, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3692225217819214
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6738446354866028
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12069672346115112
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11642882972955704
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11313726007938385
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11093789339065552
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11038142442703247
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11026790738105774
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11314542591571808
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11344990879297256
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11324930191040039
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11274918913841248
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11153712868690491
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11050522327423096
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10844514518976212
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10775488615036011
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1101979911327362
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11223030835390091
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10733118653297424
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1180076003074646
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11456746608018875
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1119847521185875
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11018102616071701
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11045720428228378
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1121240109205246
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11359391361474991
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11274658888578415
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11390557885169983
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11185004562139511
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11090899258852005
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10939902812242508
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10850948095321655
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10905414819717407
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11111538857221603
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09302617609500885
 30%|███       | 176/584 [18:44<36:32,  5.37s/it]Before Process
B-INPUT tensor([    1,   524,  2013, 28724,  2897, 28705, 28750, 28782,   297, 28705,
        28740, 28774, 28774, 28774, 28723, 28705,  2584,  6402,  5668,   403,
         5381, 28705, 28770,  1267,  1159,   524,  2013, 28724, 28723, 28705,
          661, 28742, 28713,  5489, 28705, 28750, 28734, 28750, 28740, 28723,
        28705,  1602,  1571,   349,   524,  2013, 28724, 28742, 28713,  6402,
         5668, 28804, 28705,     2,   524,  2013, 28724,  2897, 28705, 28750,
        28782,   297, 28705, 28740, 28774, 28774, 28774,   579,   630,   403,
         5381,   297, 28705, 28740, 28774, 28774, 28774, 28733, 28750, 28782,
          327,  2087, 28740, 28774, 28787, 28781, 28746, 28740, 28774, 28787,
        28781,  4060, 28740, 28774, 28787, 28781,   524,  2013, 28724, 28742,
        28713,  5668,   349,  6402,   486, 28705, 28770,  1267,   579,   630,
          403,  5381,   297, 28705, 28740, 28774, 28787, 28781, 28733, 28770,
          327,  2087, 28740, 28774, 28787, 28781, 28733, 28770, 28746, 28740,
        28774, 28787, 28740,  4060, 28740, 28774, 28787, 28740,   661, 28742,
        28713,  5489, 28705, 28750, 28734, 28750, 28740,   304,   524,  2013,
        28724, 28742, 28713,  5668,   403,  5381,   297, 28705, 28740, 28774,
        28787, 28740,   579,   630,   349, 28705, 28750, 28734, 28750, 28740,
        28733, 28740, 28774, 28787, 28740,   327,  2087, 28750, 28734, 28750,
        28740, 28733, 28740, 28774, 28787, 28740, 28746, 28782, 28734,  4060,
        28782, 28734,  1267,  1571, 28705,     2,  2476, 28782, 28734, 28705,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2], device='cuda:0')
B-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,   524,  2013, 28724,  2897, 28705, 28750,
        28782,   297, 28705, 28740, 28774, 28774, 28774,   579,   630,   403,
         5381,   297, 28705, 28740, 28774, 28774, 28774, 28733, 28750, 28782,
          327,  2087, 28740, 28774, 28787, 28781, 28746, 28740, 28774, 28787,
        28781,  4060, 28740, 28774, 28787, 28781,   524,  2013, 28724, 28742,
        28713,  5668,   349,  6402,   486, 28705, 28770,  1267,   579,   630,
          403,  5381,   297, 28705, 28740, 28774, 28787, 28781, 28733, 28770,
          327,  2087, 28740, 28774, 28787, 28781, 28733, 28770, 28746, 28740,
        28774, 28787, 28740,  4060, 28740, 28774, 28787, 28740,   661, 28742,
        28713,  5489, 28705, 28750, 28734, 28750, 28740,   304,   524,  2013,
        28724, 28742, 28713,  5668,   403,  5381,   297, 28705, 28740, 28774,
        28787, 28740,   579,   630,   349, 28705, 28750, 28734, 28750, 28740,
        28733, 28740, 28774, 28787, 28740,   327,  2087, 28750, 28734, 28750,
        28740, 28733, 28740, 28774, 28787, 28740, 28746, 28782, 28734,  4060,
        28782, 28734,  1267,  1571, 28705,     2,  2476, 28782, 28734, 28705,
            2,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100], device='cuda:0')
[tensor([[  524,  2013, 28724,  2897, 28705, 28750, 28782,   297, 28705, 28740,
         28774, 28774, 28774,   579,   630,   403,  5381,   297, 28705, 28740,
         28774, 28774, 28774, 28733, 28750, 28782,   327,  2087, 28740, 28774,
         28787, 28781, 28746, 28740, 28774, 28787, 28781,  4060, 28740, 28774,
         28787, 28781,   524,  2013, 28724, 28742, 28713,  5668,   349,  6402,
           486, 28705, 28770,  1267,   579,   630,   403,  5381,   297, 28705,
         28740, 28774, 28787, 28781, 28733, 28770,   327,  2087, 28740, 28774,
         28787, 28781, 28733, 28770, 28746, 28740, 28774, 28787, 28740,  4060,
         28740, 28774, 28787, 28740,   661, 28742, 28713,  5489, 28705, 28750,
         28734, 28750, 28740,   304,   524,  2013, 28724, 28742, 28713,  5668,
           403,  5381,   297, 28705, 28740, 28774, 28787, 28740,   579,   630,
           349, 28705, 28750, 28734, 28750, 28740, 28733, 28740, 28774, 28787,
         28740,   327,  2087, 28750, 28734, 28750, 28740, 28733, 28740, 28774,
         28787, 28740, 28746, 28782, 28734,  4060, 28782, 28734,  1267,  1571,
         28705,     2]], device='cuda:0')]
REMOVE TEST?! 0 0 0.3030821917808219
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.4325, 10.7007,  9.8182,  9.3585, 10.5572, 10.0418, 11.9052,
         10.2947]], device='cuda:2')
REMOVE TEST?! 5 2 2.1095890410958904
Cross Entropy List tensor([[10.3720, 10.3912, 10.4112, 10.3612, 10.3611, 10.3612, 10.3611, 10.3611,
         10.3733]], device='cuda:0')
[]
REMOVE TEST?! 0 0 0.6061643835616438
Cross Entropy List tensor([[10.3738, 10.4664, 10.6293,  9.7399,  9.9133, 10.8262, 10.5489, 10.1343,
          9.9637]], device='cuda:2')
REMOVE TEST?! 6 2 2.1095890410958904
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9382479786872864
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11073143035173416
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07689140737056732
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05593714863061905
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.044059284031391144
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04079440236091614
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03538244217634201
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.031927432864904404
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03824466094374657
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03442421182990074
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.047280412167310715
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03633184731006622
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.055203843861818314
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.034807611256837845
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04859340190887451
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03439810872077942
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.048399440944194794
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03711158409714699
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06020215153694153
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04315396398305893
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07085024565458298
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.051394976675510406
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1014542505145073
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06230878084897995
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11364846676588058
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.057390518486499786
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10987290740013123
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05833405256271362
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08179710060358047
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04123300313949585
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05526897683739662
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03571299463510513
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.037981994450092316
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03047141432762146
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026175348088145256
 30%|███       | 176/584 [18:43<41:18,  6.07s/it]REMOVE TEST?! 0 0 0.3030821917808219
Cross Entropy List tensor([[10.3733, 10.3721, 10.4047, 10.2988, 10.2988, 10.2988, 10.2988, 10.2988,
         10.3732]], device='cuda:0')
REMOVE TEST?! 1 0 0.6061643835616438
Cross Entropy List Cross Entropy List tensor([[10.3736, 10.5549, 10.5149, 10.5433, 10.6799, 10.6769, 10.6325, 10.4717,
          9.9565]], device='cuda:2')
[2, 3, 6]
tensor([[10.3733, 10.3894, 10.4581, 10.2939, 10.2938, 10.2938, 10.2938, 10.2938,
         10.3734]], device='cuda:0')
tensor([[10.3736, 10.3736, 10.3736, 10.4118, 11.2612, 10.1299, 10.1085, 10.1085,
         10.3734]], device='cuda:1')
[]
[]
REMOVE TEST?! 0 0 1.2123287671232876
REMOVE TEST?! 0 0 1.5154109589041096
Loss Cross Entropy List Cross Entropy List tensor(23.9388, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor([[10.3736, 10.3736, 10.3736, 10.3745, 10.7759, 10.1405, 10.3642, 10.3642,
         10.3735]], device='cuda:1')
REMOVE TEST?! 1 0 1.2123287671232876
tensor([[10.3731, 10.3701, 10.3510, 10.2586, 10.2586, 10.2586, 10.2586, 10.2586,
         10.3735]], device='cuda:0')
REMOVE TEST?! 1 0 1.5154109589041096
Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3167, 11.3961, 13.9572, 10.9665, 10.9665,
         10.3732]], device='cuda:1')
REMOVE TEST?! 2 1 1.2123287671232876
tensor([[10.3732, 10.3683, 10.3961, 10.4162, 10.4163, 10.4161, 10.4162, 10.4162,
         10.3734]], device='cuda:0')
REMOVE TEST?! 2 1 1.5154109589041096
Cross Entropy List Cross Entropy List Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.517794132232666
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.43025636672973633
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.39598754048347473
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1611272692680359
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07544312626123428
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06884805113077164
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07097271829843521
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07410772144794464
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07339797168970108
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07469629496335983
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07655371725559235
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0945867970585823
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09434906393289566
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12437957525253296
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16717711091041565
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10633430629968643
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1542997658252716
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08600351959466934
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08394934982061386
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17108939588069916
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08230035752058029
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09402502328157425
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09721653163433075
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.105785071849823
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10983792692422867
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10764937102794647
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12596353888511658
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13012254238128662
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1271858960390091
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12452712655067444
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13329514861106873
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12242098897695541
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13756193220615387
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07659300416707993
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06465180963277817
 30%|███       | 176/584 [18:49<43:09,  6.35s/it]REMOVE TEST?! 0 0 0.3030821917808219
tensor([[10.3735, 10.3735, 10.3735, 10.3671, 10.2976, 10.2413, 10.2765, 10.2765,
         10.3735]], device='cuda:1')
REMOVE TEST?! 3 1 1.2123287671232876
tensor([[10.3732, 10.3816, 10.3981, 10.3382, 10.3382, 10.3385, 10.3385, 10.3385,
         10.3733]], device='cuda:0')
[1, 2]
REMOVE TEST?! 0 0 0.6061643835616438
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.1191, 11.4241,
         10.9769]], device='cuda:2')
tensor([[10.3734, 10.3851, 10.3855, 10.3637, 10.3637, 10.3638, 10.3637, 10.3637,
         10.3735]], device='cuda:0')[]

tensor([[10.3734, 10.3734, 10.3734, 10.3571, 10.6197, 10.1692, 10.2511, 10.2511,
         10.3733]], device='cuda:1')
REMOVE TEST?! 1 [1]
0 0.6061643835616438
REMOVE TEST?! 0 0 0.3030821917808219
REMOVE TEST?! 0 0 1.5154109589041096
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3734, 23.5306, 23.5689, 23.7372, 23.7371, 23.7372, 23.7372, 23.7371,
         10.3736]], device='cuda:0')
[1]
tensor([[10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.9111, 21.0012,
         20.7291]], device='cuda:2')
After Process
A-INPUTtensor([[ 10.3736,  10.3736,  10.3736,  10.3138,  85.8296, 106.2052, 106.2825,
         106.2824,  10.3733]], device='cuda:1')
 REMOVE TEST?! 1 1 1.5154109589041096
[0]
tensor([    1,   524,  2013, 28724,  2897, 28705, 28750, 28782,   297, 28705,
        28740, 28774, 28774, 28774, 28723, 28705,  2584,  6402,  5668,   403,
         5381, 28705, 28770,  1267,  1159,   524,  2013, 28724, 28723, 28705,
          661, 28742, 28713,  5489, 28705, 28750, 28734, 28750, 28740, 28723,
        28705,  1602,  1571,   349,   524,  2013, 28724, 28742, 28713,  6402,
         5668, 28804, 28705,     2,   524,  2013, 28724,  2897, 28705, 28750,
        28782,   297, 28705, 28740, 28774, 28774, 28774,   579,   630,   403,
         5381,   297, 28705, 28740, 28774, 28774, 28774, 28733, 28750, 28782,
          327,  2087, 28740, 28774, 28787, 28781, 28746, 28740, 28774, 28787,
        28781,  4060, 28740, 28774, 28787, 28781,   524,  2013, 28724, 28742,
        28713,  5668,   349,  6402,   486, 28705, 28770,  1267,   579,   630,
          403,  5381,   297, 28705, 28740, 28774, 28787, 28781, 28733, 28770,
          327,  2087, 28740, 28774, 28787, 28781, 28733, 28770, 28746, 28740,
        28774, 28787, 28740,  4060, 28740, 28774, 28787, 28740,   661, 28742,
        28713,  5489, 28705, 28750, 28734, 28750, 28740,   304,   524,  2013,
        28724, 28742, 28713,  5668,   403,  5381,   297, 28705, 28740, 28774,
        28787, 28740,   579,   630,   349, 28705, 28750, 28734, 28750, 28740,
        28733, 28740, 28774, 28787, 28740,   327,  2087, 28750, 28734, 28750,
        28740, 28733, 28740, 28774, 28787, 28740, 28746, 28782, 28734,  4060,
        28782, 28734,  1267,  1571, 28705,     2,  2476, 28782, 28734, 28705,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2], device='cuda:0')
A-LABEL REMOVE TEST?! 0 0 0.3030821917808219
tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,   524,  2013, 28724,  2897, 28705, 28750,
        28782,   297, 28705, 28740, 28774, 28774, 28774,   579,   630,   403,
         5381,   297, 28705, 28740, 28774, 28774, 28774, 28733, 28750, 28782,
          327,  2087, 28740, 28774, 28787, 28781, 28746, 28740, 28774, 28787,
        28781,  4060, 28740, 28774, 28787, 28781,   524,  2013, 28724, 28742,
        28713,  5668,   349,  6402,   486, 28705, 28770,  1267,   579,   630,
          403,  5381,   297, 28705, 28740, 28774, 28787, 28781, 28733, 28770,
          327,  2087, 28740, 28774, 28787, 28781, 28733, 28770, 28746, 28740,
        28774, 28787, 28740,  4060, 28740, 28774, 28787, 28740,   661, 28742,
        28713,  5489, 28705, 28750, 28734, 28750, 28740,   304,   524,  2013,
        28724, 28742, 28713,  5668,   403,  5381,   297, 28705, 28740, 28774,
        28787, 28740,   579,   630,   349, 28705, 28750, 28734, 28750, 28740,
        28733, 28740, 28774, 28787, 28740,   327,  2087, 28750, 28734, 28750,
        28740, 28733, 28740, 28774, 28787, 28740, 28746, 28782, 28734,  4060,
        28782, 28734,  1267,  1571, 28705,     2,  2476, 28782, 28734, 28705,
            2,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100], device='cuda:0')
Cross Entropy List Cross Entropy List Loss tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.8763, 20.8085,
         21.0527]], device='cuda:2')
[0, 1]
tensor([[ 10.3736,  10.3736,  10.3736,  10.1876, 101.0106, 122.9977, 123.1953,
         123.1951,  10.3733]], device='cuda:1')
[0]
REMOVE TEST?! 0 0 0.3030821917808219
tensor(10.3735, device='cuda:0', grad_fn=<NllLossBackward0>)
Cross Entropy List Loss tensor(10.3737, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.1227, 12.8319,
         16.6123]], device='cuda:2')
[0]
REMOVE TEST?! 0 0 0.9092465753424657
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3395, 10.1370,
         16.5505]], device='cuda:2')
REMOVE TEST?! 1 0 0.9092465753424657
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.352173775434494
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 6.128224413259886e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17320924997329712
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15969331562519073
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16059742867946625
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16078802943229675
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.160413920879364
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15874065458774567
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15604132413864136
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15637049078941345
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15632401406764984
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15600985288619995
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15680262446403503
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15852239727973938
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15984666347503662
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16222712397575378
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1644376665353775
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16703379154205322
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07005897909402847
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18044938147068024
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.175190269947052
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17124207317829132
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16848501563072205
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16890732944011688
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1714550107717514
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1737019121646881
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17240650951862335
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17417843639850616
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17103514075279236
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16959770023822784
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16728943586349487
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1659289002418518
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16676044464111328
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1699124127626419
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13980332016944885
 30%|███       | 177/584 [18:48<34:22,  5.07s/it]Before Process
B-INPUT tensor([    1,  1387,   460, 28705, 28740, 28750,  8743, 16983,   304, 28705,
        28781,   979,  2815,   297,   272,  5045, 11359, 28723,   415,  2760,
        11359,  8288,  2795,   390,  1287, 21566,   390,   272,  5045, 11359,
        28723,  1602,  1287, 21566,   460,   297,   272,  2760, 11359, 28804,
        28705,     2,   560,   272,  5045, 11359, 28725,   736,   460, 28705,
        28740, 28750,  8743, 16983,   648, 28705, 28781,   979,  2815,   327,
         2087, 28740, 28750, 28806, 28781, 28746, 28740, 28784,  4060, 28740,
        28784, 21566, 28723,   415,  2760, 11359,  8288,  2795,   302,   456,
          579,   736,   460, 28705, 28740, 28784, 21566,   297,   272,  5045,
        11359,   732, 28705, 28750,   327,  2087, 28740, 28784, 28748, 28750,
        28746, 28783,  4060, 28783, 21566,   297,   272,  2760, 11359, 28723,
        28705,     2,  2476, 28783, 28705,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2], device='cuda:0')
B-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,   560,   272,  5045, 11359, 28725,   736,   460, 28705,
        28740, 28750,  8743, 16983,   648, 28705, 28781,   979,  2815,   327,
         2087, 28740, 28750, 28806, 28781, 28746, 28740, 28784,  4060, 28740,
        28784, 21566, 28723,   415,  2760, 11359,  8288,  2795,   302,   456,
          579,   736,   460, 28705, 28740, 28784, 21566,   297,   272,  5045,
        11359,   732, 28705, 28750,   327,  2087, 28740, 28784, 28748, 28750,
        28746, 28783,  4060, 28783, 21566,   297,   272,  2760, 11359, 28723,
        28705,     2,  2476, 28783, 28705,     2,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100], device='cuda:0')
[tensor([[  560,   272,  5045, 11359, 28725,   736,   460, 28705, 28740, 28750,
          8743, 16983,   648, 28705, 28781,   979,  2815,   327,  2087, 28740,
         28750, 28806, 28781, 28746, 28740, 28784,  4060, 28740, 28784, 21566,
         28723]], device='cuda:0'), tensor([[  415,  2760, 11359,  8288,  2795,   302,   456,   579,   736,   460,
         28705, 28740, 28784, 21566,   297,   272,  5045, 11359,   732, 28705,
         28750,   327,  2087, 28740, 28784, 28748, 28750, 28746, 28783,  4060,
         28783, 21566,   297,   272,  2760, 11359, 28723, 28705,     2]],
       device='cuda:0')]
REMOVE TEST?! 0 0 0.6095890410958904
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.4805, 11.1447,
         17.2727]], device='cuda:2')
[1]
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4272320866584778
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13048502802848816
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15626025199890137
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1620914340019226
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1597592681646347
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15668714046478271
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15554922819137573
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.155070960521698
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15762624144554138
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15826357901096344
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15796294808387756
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15747042000293732
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15567658841609955
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15489085018634796
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15251602232456207
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15190449357032776
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15551871061325073
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15668585896492004
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1516702026128769
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1624356210231781
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16117943823337555
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1581355333328247
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1554477959871292
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15536998212337494
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15697261691093445
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1579526662826538
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1573800891637802
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15845747292041779
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15602631866931915
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15503397583961487
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15356425940990448
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15278369188308716
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15386906266212463
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15615233778953552
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13033898174762726
 30%|███       | 177/584 [18:45<33:35,  4.95s/it]REMOVE TEST?! 0 0 0.3047945205479452
Loss tensor([[10.3732, 10.3892, 10.3922, 10.2688, 10.2688, 10.2688, 10.2688, 10.2688,
         10.3732]], device='cuda:0')
REMOVE TEST?! 1 0 0.6095890410958904
Cross Entropy List Cross Entropy List tensor(12.9514, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor([[10.3731, 10.3846, 10.3941, 10.3065, 10.3065, 10.3065, 10.3065, 10.3065,
         10.3733]], device='cuda:0')
[]
tensor([[10.3736, 10.3736, 10.3736, 10.3875, 10.1672, 10.8451, 11.5674, 11.5674,
         10.3735]], device='cuda:1')
[]
REMOVE TEST?! 0 0REMOVE TEST?!  0 0 0.3047945205479452
1.523972602739726
Cross Entropy List Cross Entropy List tensor([[10.3733, 10.3645, 10.4262, 10.4375, 10.4375, 10.4375, 10.4375, 10.4375,
         10.3734]], device='cuda:0')
REMOVE TEST?! 1tensor([[10.3734, 10.3734, 10.3734, 10.3254, 10.8307, 10.6977, 10.8518, 10.8518,
         10.3736]], device='cuda:1')
 1 1.523972602739726
[0]
REMOVE TEST?! 0 0 0.3047945205479452
Cross Entropy List Cross Entropy List Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9425860643386841
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.032369326800107956
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02478380687534809
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024433115497231483
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02485016919672489
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025196393951773643
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02553822658956051
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025365449488162994
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02449592389166355
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02461535669863224
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021044669672846794
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02656782604753971
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026467544957995415
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026558391749858856
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026701193302869797
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026426304131746292
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025980424135923386
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02549850009381771
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02520080842077732
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024499552324414253
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024640677496790886
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025035832077264786
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02550472505390644
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.27726253867149353
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09467903524637222
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05950948968529701
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.035407934337854385
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.032406315207481384
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0311441533267498
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03053933009505272
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028952181339263916
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02722056210041046
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02661728486418724
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025702014565467834
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023933948948979378
 30%|███       | 177/584 [18:51<34:26,  5.08s/it]REMOVE TEST?! 0 0 0.9143835616438356
tensor([[10.3734, 10.3765, 10.3837, 10.3543, 10.3543, 10.3543, 10.3543, 10.3543,
         10.3733]], device='cuda:0')
tensor([[10.3735, 10.3735, 10.3735, 10.3657, 11.2267, 10.3024, 10.4237, 10.4236,
         10.3736]], device='cuda:1')
REMOVE TEST?! 2[0]
 1 1.523972602739726
REMOVE TEST?! 0 0 1.523972602739726
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3737, 10.3737, 10.3738, 10.3737, 10.3737, 10.3737, 10.4709, 12.0402,
         22.9732]], device='cuda:2')
tensor([[10.3734, 10.3734, 10.3734, 10.3883, 10.6583, 10.1979, 10.3096, 10.3095,
         10.3735]], device='cuda:1')
tensor([[10.3733, 10.3910, 10.3887, 10.3661, 10.3661, 10.3661, 10.3661, 10.3661,
         10.3733]], device='cuda:0')
[0]
REMOVE TEST?! 1 1 1.523972602739726
REMOVE TEST?! 3 1 1.523972602739726
REMOVE TEST?! 0 0 2.133561643835616
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[ 10.3734,  10.3734,  10.3735,  10.2034, 100.1080, 121.3850, 121.4682,
         121.4681,  10.3733]], device='cuda:1')
tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 11.1982, 25.7383,
         21.7726]], device='cuda:2')
tensor([[10.3735, 24.6264, 24.6566, 24.9423, 24.9423, 24.9423, 24.9423, 24.9422,
         10.3735]], device='cuda:0')
[0, 1]
REMOVE TEST?! 1 1 2.133561643835616[0, 3]

REMOVE TEST?! 0 0 1.2191780821917808
Cross Entropy List Cross Entropy List Loss tensor([[10.3733, 23.6849, 23.7108, 23.9342, 23.9342, 23.9342, 23.9342, 23.9341,
         10.3735]], device='cuda:0')
tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 11.1065, 25.8005,
         21.9757]], device='cuda:2')
REMOVE TEST?! 1 1REMOVE TEST?! 2 2 2.133561643835616
 1.2191780821917808
tensor(10.3735, device='cuda:1', grad_fn=<NllLossBackward0>)
Cross Entropy ListCross Entropy List  tensor([[10.3732, 10.3853, 10.3826, 10.3144, 10.3144, 10.3144, 10.3144, 10.3143,
         10.3734]], device='cuda:0')
tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3343, 11.2802,
         29.4356]], device='cuda:2')
REMOVE TEST?! 2 1 [0, 1, 2]
1.2191780821917808
REMOVE TEST?! 0 0 0.3047945205479452
Cross Entropy List Cross Entropy List tensor([[10.3733, 10.3765, 10.3796, 10.3577, 10.3577, 10.3577, 10.3577, 10.3577,
         10.3734]], device='cuda:0')
REMOVE TEST?! 3 1 1.2191780821917808
tensor([[10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.3733,  9.9939, 10.8105,
         13.3390]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.9143835616438356
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.42724910378456116
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13035085797309875
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15578392148017883
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16208073496818542
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15974844992160797
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15667767822742462
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15553691983222961
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15504854917526245
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15762226283550262
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15826129913330078
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15796321630477905
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15746714174747467
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15567418932914734
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15489043295383453
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15251857042312622
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15191012620925903
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1555209755897522
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1566755473613739
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1516801118850708
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1625351458787918
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16133445501327515
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15830357372760773
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15545342862606049
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15540871024131775
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15692010521888733
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1579446792602539
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15732625126838684
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15854427218437195
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15605519711971283
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1550471931695938
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15366415679454803
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15288616716861725
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15378107130527496
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15614771842956543
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13035085797309875
 30%|███       | 178/584 [18:47<27:04,  4.00s/it]REMOVE TEST?! 0 0 0.9195205479452055
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3732, 10.3732, 10.3732, 10.3732, 10.3732, 10.3732, 10.3101, 10.3168,
         13.0381]], device='cuda:2')
REMOVE TEST?! 1 0 0.9143835616438356
tensor([[10.3733, 10.3773, 10.3728, 10.3151, 10.3151, 10.3151, 10.3151, 10.3151,
         10.3737]], device='cuda:0')
[0]
REMOVE TEST?! 0 0 1.8287671232876712
Cross Entropy List Cross Entropy List tensor([[10.3733, 10.3733, 10.3733, 10.3586, 10.2460, 11.6787, 11.1896, 11.1896,
         10.3737]], device='cuda:1')
[0]
REMOVE TEST?! 0 0 0.3065068493150685
Cross Entropy List tensor([[10.3735, 10.3752, 10.3549, 10.3210, 10.3209, 10.3209, 10.3209, 10.3209,
         10.3735]], device='cuda:0')
REMOVE TEST?! 1 0 1.8287671232876712
tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  9.9825,  9.8210,
         13.2229]], device='cuda:2')
REMOVE TEST?! 2 0 0.9143835616438356
Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3815, 10.2455, 10.3868, 10.6219, 10.6219,
         10.3734]], device='cuda:1')
[0]
REMOVE TEST?! 0 0 0.3065068493150685
Cross Entropy List tensor([[10.3735, 10.3726, 10.3964, 10.2802, 10.2802, 10.2802, 10.2802, 10.2802,
         10.3735]], device='cuda:0')
REMOVE TEST?! 2 0 1.8287671232876712
tensor([[10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.3733,  9.9475, 10.0173,
         13.9309]], device='cuda:2')
[]
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.4141, 10.2049, 10.5099, 10.6990, 10.6990,
         10.3734]], device='cuda:1')
[0]
REMOVE TEST?! 0 0 0.3065068493150685
Loss Cross Entropy List tensor([[10.3735, 10.3733, 10.3988, 10.2670, 10.2670, 10.2670, 10.2670, 10.2670,
         10.3735]], device='cuda:0')
REMOVE TEST?! 3 0 1.8287671232876712
tensor(14.1332, device='cuda:2', grad_fn=<NllLossBackward0>)
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.4120, 10.2335, 10.5109, 10.5898, 10.5898,
         10.3735]], device='cuda:1')
[0]
Loss tensor([[10.3735, 10.3916, 10.4631, 10.3082, 10.3082, 10.3082, 10.3082, 10.3081,
         10.3733]], device='cuda:0')
REMOVE TEST?! 4 0 1.8287671232876712
Cross Entropy List tensor(10.3737, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor([[10.3735, 10.3918, 10.4627, 10.3118, 10.3118, 10.3118, 10.3118, 10.3118,
         10.3732]], device='cuda:0')
REMOVE TEST?! 5 1 1.8287671232876712
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8487460017204285
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2730221450328827
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.046662379056215286
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.044295500963926315
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04464248567819595
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.044794097542762756
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04464280232787132
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.044463951140642166
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.043316446244716644
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04269886761903763
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.041717950254678726
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04104893282055855
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04174960404634476
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.042331282049417496
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04290557652711868
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04261530190706253
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04115445539355278
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04135510325431824
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.035356082022190094
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0446351058781147
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04446651414036751
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04461930692195892
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04485919326543808
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.28055113554000854
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1046215146780014
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15074175596237183
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16372936964035034
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10379981994628906
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06370159238576889
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05079648271203041
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.048353131860494614
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04591299220919609
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04557272419333458
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.041415371000766754
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03464937210083008
 30%|███       | 178/584 [18:54<28:36,  4.23s/it]REMOVE TEST?! 0 0 0.3065068493150685
Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3925, 10.4705, 10.3388, 10.3388, 10.3388, 10.3388, 10.3388,
         10.3733]], device='cuda:0')
[4]
After Process
A-INPUT tensor([    1,  1387,   460, 28705, 28740, 28750,  8743, 16983,   304, 28705,
        28781,   979,  2815,   297,   272,  5045, 11359, 28723,   415,  2760,
        11359,  8288,  2795,   390,  1287, 21566,   390,   272,  5045, 11359,
        28723,  1602,  1287, 21566,   460,   297,   272,  2760, 11359, 28804,
        28705,     2,   560,   272,  5045, 11359, 28725,   736,   460, 28705,
        28740, 28750,  8743, 16983,   648, 28705, 28781,   979,  2815,   327,
         2087, 28740, 28750, 28806, 28781, 28746, 28740, 28784,  4060, 28740,
        28784, 21566, 28723,   415,  2760, 11359,  8288,  2795,   302,   456,
          579,   736,   460, 28705, 28740, 28784, 21566,   297,   272,  5045,
        11359,   732, 28705, 28750,   327,  2087, 28740, 28784, 28748, 28750,
        28746, 28783,  4060, 28783, 21566,   297,   272,  2760, 11359, 28723,
        28705,     2,  2476, 28783, 28705,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2],
       device='cuda:0')
A-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,   560,   272,  5045, 11359, 28725,   736,   460, 28705,
        28740, 28750,  8743, 16983,   648, 28705, 28781,   979,  2815,   327,
         2087, 28740, 28750, 28806, 28781, 28746, 28740, 28784,  4060, 28740,
        28784, 21566, 28723,   415,  2760, 11359,  8288,  2795,   302,   456,
          579,   736,   460, 28705, 28740, 28784, 21566,   297,   272,  5045,
        11359,   732, 28705, 28750,   327,  2087, 28740, 28784, 28748, 28750,
        28746, 28783,  4060, 28783, 21566,   297,   272,  2760, 11359, 28723,
        28705,     2,  2476, 28783, 28705,     2,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],
       device='cuda:0')
Loss tensor([[10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.3733,  9.9400,  7.9898,
          8.6469]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.3065068493150685
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07802314311265945
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02380453236401081
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04138940945267677
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029690492898225784
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029467400163412094
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028917590156197548
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02839779481291771
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028389550745487213
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028664058074355125
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0288471058011055
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028738515451550484
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028959333896636963
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028508534654974937
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028321214020252228
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028069354593753815
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02793250046670437
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028092028573155403
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02852477878332138
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028584420680999756
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5510014295578003
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.527226448059082
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5013788342475891
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3686024844646454
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03406194597482681
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030215607956051826
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027859708294272423
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04960552230477333
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024442192167043686
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02531806379556656
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025385718792676926
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025283208116889
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025247592478990555
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024907326325774193
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024584118276834488
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 4.129756689508213e-06
 31%|███       | 179/584 [18:48<22:10,  3.29s/it]REMOVE TEST?! 0 0 0.6164383561643836
Cross Entropy List tensor(10.3732, device='cuda:0', grad_fn=<NllLossBackward0>)
Cross Entropy List tensor([[10.3732, 10.3732, 10.3732, 10.3732, 10.3732, 10.3732,  9.9641, 15.1799,
         20.6036]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.3065068493150685
Cross Entropy List tensor([[10.3722, 10.3722, 10.3722, 10.3939, 10.3272, 10.5251, 10.8594, 10.8594,
         10.3736]], device='cuda:1')
[0]
REMOVE TEST?! 0 0 0.6164383561643836
tensor([[10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.3733,  9.8841, 13.2153,
         17.1833]], device='cuda:2')
[]
REMOVE TEST?! 0 0 1.839041095890411
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.4300, 10.5374, 10.0770, 10.4933, 10.4933,
         10.3734]], device='cuda:1')
[0]
REMOVE TEST?! 0 0 0.3082191780821918
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4191926419734955
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13645410537719727
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1512402445077896
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1632155179977417
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15842409431934357
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15487608313560486
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1523667573928833
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15271233022212982
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15506680309772491
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15708503127098083
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15593209862709045
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15752363204956055
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15468382835388184
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15338736772537231
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15130756795406342
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15008705854415894
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1508384793996811
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15367600321769714
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15820981562137604
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21333347260951996
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16225089132785797
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15743692219257355
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15417054295539856
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1524983048439026
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1526380032300949
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15577664971351624
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1569782793521881
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15622514486312866
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15677818655967712
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15449286997318268
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15309958159923553
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15066926181316376
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14956368505954742
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1516328901052475
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13486811518669128
 30%|███       | 178/584 [18:53<33:48,  5.00s/it]Before Process
B-INPUT tensor([    1,   320,  5973,   271,   349,  5489, 28705, 28740, 28740,  1267,
         1571,   304,   516,  6402,  5510,   349, 28705, 28750, 28734,  1267,
         1571, 28723,  1602,  1571,   622,   320,  5973,   271,   347,   739,
          516,  6402,  5510,   349,  1712,  2421,   390,  1571,   390,   320,
         5973,   271,   349,  1055, 28804, 28705,     2,  1684,   320,  5973,
          271,   349, 28705, 28740, 28740, 28725,   516,  6402,  5510,   622,
          347, 28705, 28740, 28740,  1318, 28705, 28770,   327,  2087, 28740,
        28740, 28736, 28770, 28746, 28770, 28770,  4060, 28770, 28770,  1267,
         1571, 28723,   320,  5973,   271, 28809, 28713,  6402,  5510,   349,
        28705, 28750, 28734,   387, 28705, 28740, 28740,   327,  2087, 28750,
        28734, 28733, 28740, 28740, 28746, 28774,  4060, 28774,  1267,  6402,
          821,   320,  5973,   271, 28723,  4577,   320,  5973,   271,   349,
        28705, 28774,  1267,  9729, 28725,   320,  5973,   271,   622,   347,
        28705, 28770, 28770,   387, 28705, 28774,   327,  2087, 28770, 28770,
        28733, 28774, 28746, 28750, 28781,  4060, 28750, 28781,  1267,  1571,
        28723, 28705,     2,  2476, 28750, 28781, 28705,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2],
       device='cuda:0')
B-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  1684,   320,  5973,
          271,   349, 28705, 28740, 28740, 28725,   516,  6402,  5510,   622,
          347, 28705, 28740, 28740,  1318, 28705, 28770,   327,  2087, 28740,
        28740, 28736, 28770, 28746, 28770, 28770,  4060, 28770, 28770,  1267,
         1571, 28723,   320,  5973,   271, 28809, 28713,  6402,  5510,   349,
        28705, 28750, 28734,   387, 28705, 28740, 28740,   327,  2087, 28750,
        28734, 28733, 28740, 28740, 28746, 28774,  4060, 28774,  1267,  6402,
          821,   320,  5973,   271, 28723,  4577,   320,  5973,   271,   349,
        28705, 28774,  1267,  9729, 28725,   320,  5973,   271,   622,   347,
        28705, 28770, 28770,   387, 28705, 28774,   327,  2087, 28770, 28770,
        28733, 28774, 28746, 28750, 28781,  4060, 28750, 28781,  1267,  1571,
        28723, 28705,     2,  2476, 28750, 28781, 28705,     2,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],
       device='cuda:0')
[tensor([[ 1684,   320,  5973,   271,   349, 28705, 28740, 28740, 28725,   516,
          6402,  5510,   622,   347, 28705, 28740, 28740,  1318, 28705, 28770,
           327,  2087, 28740, 28740, 28736, 28770, 28746, 28770, 28770,  4060,
         28770, 28770,  1267,  1571, 28723]], device='cuda:0'), tensor([[  320,  5973,   271, 28809, 28713,  6402,  5510,   349, 28705, 28750,
         28734,   387, 28705, 28740, 28740,   327,  2087, 28750, 28734, 28733,
         28740, 28740, 28746, 28774,  4060, 28774,  1267,  6402,   821,   320,
          5973,   271, 28723]], device='cuda:0'), tensor([[ 4577,   320,  5973,   271,   349, 28705, 28774,  1267,  9729, 28725,
           320,  5973,   271,   622,   347, 28705, 28770, 28770,   387, 28705,
         28774,   327,  2087, 28770, 28770, 28733, 28774, 28746, 28750, 28781,
          4060, 28750, 28781,  1267,  1571, 28723, 28705,     2]],
       device='cuda:0')]
REMOVE TEST?! 0 0 0.9195205479452055
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.9770, 21.1340,
         20.0757]], device='cuda:2')
REMOVE TEST?! 1 1 1.839041095890411
Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.4132, 10.4409, 10.9792, 11.7681, 11.7681,
         10.3734]], device='cuda:1')
[0]
REMOVE TEST?! 0 0 0.3082191780821918
Cross Entropy List tensor([[10.3708, 10.3790, 10.3933, 10.2898, 10.2898, 10.2898, 10.2898, 10.2898,
         10.3736]], device='cuda:0')
tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 11.0262, 21.2636,
         27.5487]], device='cuda:2')
REMOVE TEST?! 1[0, 1]
 0 0.9195205479452055
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3898, 10.5665, 10.2583, 10.1981, 10.1981,
         10.3734]], device='cuda:1')
[]
Loss Loss tensor([[10.3734, 10.3678, 10.4205, 10.2482, 10.2482, 10.2482, 10.2482, 10.2482,
         10.3735]], device='cuda:0')
REMOVE TEST?! 2 0 0.9195205479452055
tensor(10.0219, device='cuda:2', grad_fn=<NllLossBackward0>)
Cross Entropy List tensor(10.3735, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor([[10.3733, 10.3867, 10.4546, 10.2680, 10.2680, 10.2680, 10.2680, 10.2680,
         10.3736]], device='cuda:0')
[]
REMOVE TEST?! 0 0 1.5325342465753424
Cross Entropy List tensor([[10.3733, 10.3807, 10.3604, 10.3099, 10.3099, 10.3100, 10.3100, 10.3100,
         10.3735]], device='cuda:0')
REMOVE TEST?! 1 0 1.5325342465753424
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.38671964406967163
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09993480145931244
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14855410158634186
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14150631427764893
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14261400699615479
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14309847354888916
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14261537790298462
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14204467833042145
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13837940990924835
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13640591502189636
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13321177661418915
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13113684952259064
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13337457180023193
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13523223996162415
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13706758618354797
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1361396163702011
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13147422671318054
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13211464881896973
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11295580118894577
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14259067177772522
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1420527696609497
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1425403654575348
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.143306165933609
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14337585866451263
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1406618356704712
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13925819098949432
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14551980793476105
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14757318794727325
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15261487662792206
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1608126163482666
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1723148226737976
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15679249167442322
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14563511312007904
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13320843875408173
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4438529908657074
 31%|███       | 179/584 [18:58<28:07,  4.17s/it]REMOVE TEST?! 0 0 0.9246575342465754
Cross Entropy List Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1336645483970642
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04232494905591011
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9836716055870056
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.058760978281497955
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05719006806612015
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05768290534615517
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02384774200618267
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00030750682344660163
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00032482051756232977
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00033635771251283586
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012657635379582644
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.442853610153179e-08
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.8416397728724405e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.724196398659842e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.320457719586557e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.9206491944933077e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.182916760939406e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.809296003964846e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.934912006618106e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.424021431579604e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.9379748411884066e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.762236246984685e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.864932295982726e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.49163926139018e-12
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.9006710228207666e-12
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.620505636576127e-08
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.024452433289526e-12
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.5464879770814575e-12
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.965512421355015e-08
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.043988889075977e-12
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.275285838521551e-12
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011532844044268131
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006894033867865801
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01258895918726921
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0420939065515995
 31%|███       | 180/584 [18:52<23:07,  3.43s/it]REMOVE TEST?! 0 0 0.3099315068493151
Cross Entropy List tensor([[10.3733, 10.3818, 10.3755, 10.2881, 10.2881, 10.2881, 10.2882, 10.2882,
         10.3736]], device='cuda:0')
REMOVE TEST?! 2 1 1.5325342465753424
Cross Entropy List Cross Entropy List tensor([[10.3732, 10.3732, 10.3732, 10.3732, 10.3732, 10.3732,  9.8637,  8.4521,
          8.7772]], device='cuda:2')
REMOVE TEST?! 1 0 0.9246575342465754
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3952, 10.2909, 10.2303, 10.2109, 10.2109,
         10.3734]], device='cuda:1')
[]
REMOVE TEST?! 0 0 0.6198630136986302
tensor([[10.3733, 10.3786, 10.3658, 10.3013, 10.3013, 10.3013, 10.3013, 10.3013,
         10.3736]], device='cuda:0')
REMOVE TEST?! 3 1 1.5325342465753424
Cross Entropy List Cross Entropy List tensor([[10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.6568, 17.8584,
         18.0317]], device='cuda:2')
REMOVE TEST?! 2 0 0.9246575342465754
Cross Entropy List tensor([[10.3737, 10.3737, 10.3737, 10.3817, 10.2693, 10.5361, 20.3718, 20.3717,
         10.3735]], device='cuda:1')
REMOVE TEST?! 1 0 0.6198630136986302
tensor([[10.3733, 10.3808, 10.3677, 10.3016, 10.3016, 10.3017, 10.3017, 10.3017,
         10.3736]], device='cuda:0')
REMOVE TEST?! 4 1 1.5325342465753424
Cross Entropy List Cross Entropy List tensor([[10.3732, 10.3732, 10.3732, 10.3732, 10.3732, 10.3732, 10.6257, 18.4523,
         18.4589]], device='cuda:2')
[2]
REMOVE TEST?! 0 0 0.3082191780821918
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3816, 10.2646, 10.4586, 17.7771, 17.7770,
         10.3735]], device='cuda:1')
[]
REMOVE TEST?! 0 0 1.5496575342465755
tensor([[10.3733, 10.3828, 10.3821, 10.3004, 10.3004, 10.3004, 10.3004, 10.3004,
         10.3735]], device='cuda:0')
[1, 4]
REMOVE TEST?! 0 0 0.3065068493150685
Cross Entropy List Cross Entropy List tensor([[10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.4382, 16.6302,
         16.6703]], device='cuda:2')
[0]
REMOVE TEST?! 0 0 1.541095890410959
Cross Entropy List tensor([[10.3737, 10.3737, 10.3737, 10.4010, 10.5457, 19.1514, 48.5891, 48.5888,
         10.3735]], device='cuda:1')
REMOVE TEST?! 1 1 1.5496575342465755
tensor([[10.3734, 10.3914, 10.4290, 10.2914, 10.2914, 10.2914, 10.2914, 10.2914,
         10.3737]], device='cuda:0')
[]
REMOVE TEST?! 0 0 0.3065068493150685
Cross Entropy List Cross Entropy List tensor([[10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.8902, 19.4678,
         19.5775]], device='cuda:2')
REMOVE TEST?! 1 1 1.541095890410959
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.4019, 10.5508, 19.2479, 48.7230, 48.7226,
         10.3736]], device='cuda:1')
[0, 1]
REMOVE TEST?! 0 0 0.3099315068493151
tensor([[10.3735, 10.3972, 10.4475, 10.2898, 10.2898, 10.2898, 10.2898, 10.2898,
         10.3739]], device='cuda:0')
[]
After Process
A-INPUT tensor([    1,   320,  5973,   271,   349,  5489, 28705, 28740, 28740,  1267,
         1571,   304,   516,  6402,  5510,   349, 28705, 28750, 28734,  1267,
         1571, 28723,  1602,  1571,   622,   320,  5973,   271,   347,   739,
          516,  6402,  5510,   349,  1712,  2421,   390,  1571,   390,   320,
         5973,   271,   349,  1055, 28804, 28705,     2,  1684,   320,  5973,
          271,   349, 28705, 28740, 28740, 28725,   516,  6402,  5510,   622,
          347, 28705, 28740, 28740,  1318, 28705, 28770,   327,  2087, 28740,
        28740, 28736, 28770, 28746, 28770, 28770,  4060, 28770, 28770,  1267,
         1571, 28723,   320,  5973,   271, 28809, 28713,  6402,  5510,   349,
        28705, 28750, 28734,   387, 28705, 28740, 28740,   327,  2087, 28750,
        28734, 28733, 28740, 28740, 28746, 28774,  4060, 28774,  1267,  6402,
          821,   320,  5973,   271, 28723,  4577,   320,  5973,   271,   349,
        28705, 28774,  1267,  9729, 28725,   320,  5973,   271,   622,   347,
        28705, 28770, 28770,   387, 28705, 28774,   327,  2087, 28770, 28770,
        28733, 28774, 28746, 28750, 28781,  4060, 28750, 28781,  1267,  1571,
        28723, 28705,     2,  2476, 28750, 28781, 28705,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2], device='cuda:0')
A-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  1684,   320,  5973,
          271,   349, 28705, 28740, 28740, 28725,   516,  6402,  5510,   622,
          347, 28705, 28740, 28740,  1318, 28705, 28770,   327,  2087, 28740,
        28740, 28736, 28770, 28746, 28770, 28770,  4060, 28770, 28770,  1267,
         1571, 28723,   320,  5973,   271, 28809, 28713,  6402,  5510,   349,
        28705, 28750, 28734,   387, 28705, 28740, 28740,   327,  2087, 28750,
        28734, 28733, 28740, 28740, 28746, 28774,  4060, 28774,  1267,  6402,
          821,   320,  5973,   271, 28723,  4577,   320,  5973,   271,   349,
        28705, 28774,  1267,  9729, 28725,   320,  5973,   271,   622,   347,
        28705, 28770, 28770,   387, 28705, 28774,   327,  2087, 28770, 28770,
        28733, 28774, 28746, 28750, 28781,  4060, 28750, 28781,  1267,  1571,
        28723, 28705,     2,  2476, 28750, 28781, 28705,     2,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100], device='cuda:0')
Cross Entropy List tensor([[10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.8750, 19.3398,
         19.4533]], device='cuda:2')
[0, 1]
REMOVE TEST?! 0 0 0.3082191780821918
Loss Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3811, 10.6525, 21.8477, 49.3565, 49.3562,
         10.3732]], device='cuda:1')
[0]
tensor(10.3737, device='cuda:0', grad_fn=<NllLossBackward0>)
Loss tensor([[10.3731, 10.3731, 10.3731, 10.3731, 10.3731, 10.3731, 10.0111, 10.4958,
         10.8617]], device='cuda:2')
[0]
Loss tensor(10.3733, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(16.4536, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9585391879081726
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04965453967452049
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03139316663146019
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02285286784172058
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.8556237364464323e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01870611123740673
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.6747928788827267e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019064025953412056
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.3576136502233567e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030497515108436346
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012224947102367878
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.806321496493183e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.3321471530047813e-11
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.228093841898481e-11
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.2191010353990173e-11
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.2381842946773691e-11
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.2422843136128403e-11
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.46605956541368e-11
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07227503508329391
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07199783623218536
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06939732283353806
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06746724992990494
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06625612825155258
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06611189246177673
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.066277414560318
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06787140667438507
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0678902119398117
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0679362416267395
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0672716349363327
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06674126535654068
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06600116938352585
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06487426906824112
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06463532894849777
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06620986014604568
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05908945947885513
 31%|███       | 179/584 [18:57<32:07,  4.76s/it]Before Process
B-INPUT tensor([    1,  2984,  8830,   304,  1972,  3679,  1105,  1430,   506, 28705,
        28783,   680,  2609,  2040,   821,  4790,   562,   865,  3359,  2108,
          821, 15281, 28723,  1047, 15281,   659, 28705, 28770, 28734,  2609,
         2040, 28725, 13911,   272,  3102,  1474,   302,  2609,  2040,   369,
          272,  2308,   506, 28804, 28705,     2,  1047, 15281,   659, 28705,
        28770, 28734,  2609,  2040, 28725,   868,  1560,  1972,  3679,  1105,
          304,  2984,  8830,  1430,   506, 28705, 28770, 28734, 28733, 28782,
          327,  2087, 28770, 28734, 28733, 28782, 28746, 28750, 28782,  4060,
        28750, 28782,  2609,  2040, 28723,   415,  3102,  1474,   302,  2609,
         2040,   369,  1972,  3679,  1105,   304,  2984,  8830,   506,   349,
        28705, 28750, 28782, 28806, 28750, 28782,   327,  2087, 28750, 28782,
        28806, 28750, 28782, 28746, 28782, 28734,  4060, 28782, 28734, 21583,
        28725,  1972,  3679,  1105, 28725,  2984,  8830, 28725,   304, 15281,
          506, 28705, 28782, 28734, 28806, 28770, 28734,   327,  2087, 28782,
        28734, 28806, 28770, 28734, 28746, 28783, 28734,  4060, 28783, 28734,
         2609,  2040, 28723,  4577,  2984,  8830,   304,  1972,  3679,  1105,
         1430,   506, 28705, 28783,   680,  2609,  2040,   821,  4790, 28725,
          868,  4790,   659, 28705, 28750, 28782, 28733, 28783,   327,  2087,
        28750, 28782, 28733, 28783, 28746, 28740, 28787,  4060, 28740, 28787,
         2609,  2040, 28723, 16589, 11553, 28725,   272,  2308,   506, 28705,
        28740, 28787, 28806, 28783, 28734,   327,  2087, 28740, 28787, 28806,
        28783, 28734, 28746, 28774, 28787,  4060, 28774, 28787,  2609,  2040,
        28723, 28705,     2,  2476, 28774, 28787, 28705,     2],
       device='cuda:0')
B-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  1047, 15281,   659, 28705,
        28770, 28734,  2609,  2040, 28725,   868,  1560,  1972,  3679,  1105,
          304,  2984,  8830,  1430,   506, 28705, 28770, 28734, 28733, 28782,
          327,  2087, 28770, 28734, 28733, 28782, 28746, 28750, 28782,  4060,
        28750, 28782,  2609,  2040, 28723,   415,  3102,  1474,   302,  2609,
         2040,   369,  1972,  3679,  1105,   304,  2984,  8830,   506,   349,
        28705, 28750, 28782, 28806, 28750, 28782,   327,  2087, 28750, 28782,
        28806, 28750, 28782, 28746, 28782, 28734,  4060, 28782, 28734, 21583,
        28725,  1972,  3679,  1105, 28725,  2984,  8830, 28725,   304, 15281,
          506, 28705, 28782, 28734, 28806, 28770, 28734,   327,  2087, 28782,
        28734, 28806, 28770, 28734, 28746, 28783, 28734,  4060, 28783, 28734,
         2609,  2040, 28723,  4577,  2984,  8830,   304,  1972,  3679,  1105,
         1430,   506, 28705, 28783,   680,  2609,  2040,   821,  4790, 28725,
          868,  4790,   659, 28705, 28750, 28782, 28733, 28783,   327,  2087,
        28750, 28782, 28733, 28783, 28746, 28740, 28787,  4060, 28740, 28787,
         2609,  2040, 28723, 16589, 11553, 28725,   272,  2308,   506, 28705,
        28740, 28787, 28806, 28783, 28734,   327,  2087, 28740, 28787, 28806,
        28783, 28734, 28746, 28774, 28787,  4060, 28774, 28787,  2609,  2040,
        28723, 28705,     2,  2476, 28774, 28787, 28705,     2],
       device='cuda:0')
[tensor([[ 1047, 15281,   659, 28705, 28770, 28734,  2609,  2040, 28725,   868,
          1560,  1972,  3679,  1105,   304,  2984,  8830,  1430,   506, 28705,
         28770, 28734, 28733, 28782,   327,  2087, 28770, 28734, 28733, 28782,
         28746, 28750, 28782,  4060, 28750, 28782,  2609,  2040, 28723]],
       device='cuda:0'), tensor([[  415,  3102,  1474,   302,  2609,  2040,   369,  1972,  3679,  1105,
           304,  2984,  8830,   506,   349, 28705, 28750, 28782, 28806, 28750,
         28782,   327,  2087, 28750, 28782, 28806, 28750, 28782, 28746, 28782,
         28734,  4060, 28782, 28734, 21583, 28725,  1972,  3679,  1105, 28725,
          2984,  8830, 28725,   304, 15281,   506, 28705, 28782, 28734, 28806,
         28770, 28734,   327,  2087, 28782, 28734, 28806, 28770, 28734, 28746,
         28783, 28734,  4060, 28783, 28734,  2609,  2040, 28723]],
       device='cuda:0'), tensor([[ 4577,  2984,  8830,   304,  1972,  3679,  1105,  1430,   506, 28705,
         28783,   680,  2609,  2040,   821,  4790, 28725,   868,  4790,   659,
         28705, 28750, 28782, 28733, 28783,   327,  2087, 28750, 28782, 28733,
         28783, 28746, 28740, 28787,  4060, 28740, 28787,  2609,  2040, 28723]],
       device='cuda:0'), tensor([[16589, 11553, 28725,   272,  2308,   506, 28705, 28740, 28787, 28806,
         28783, 28734,   327,  2087, 28740, 28787, 28806, 28783, 28734, 28746,
         28774, 28787,  4060, 28774, 28787,  2609,  2040, 28723, 28705,     2]],
       device='cuda:0')]
REMOVE TEST?! 0 0 1.2328767123287672
Cross Entropy List Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2843453288078308
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002098463592119515
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13783307373523712
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.128746896982193
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12973541021347046
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12990280985832214
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13036908209323883
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13073131442070007
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13176476955413818
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13282401859760284
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13236209750175476
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1317957192659378
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13263645768165588
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1323152631521225
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13214890658855438
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5935624241828918
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12984278798103333
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13895606994628906
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13032668828964233
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13199391961097717
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13105086982250214
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13434948027133942
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13364161550998688
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13663887977600098
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13576413691043854
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13638591766357422
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.053506117314100266
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.147044375538826
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14595672488212585
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14321649074554443
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14063434302806854
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14059072732925415
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1419767290353775
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14290271699428558
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1233823373913765
 31%|███       | 181/584 [18:54<19:59,  2.98s/it]REMOVE TEST?! 0 0 0.3116438356164384
tensor([[10.3733, 10.3817, 10.4106, 10.2451, 10.2451, 10.2451, 10.2451, 10.2451,
         10.3736]], device='cuda:0')
REMOVE TEST?! 1 1 1.2328767123287672
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5930851697921753
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3253481388092041
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05970935896039009
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0486271008849144
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04844381660223007
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.048609938472509384
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04887109249830246
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.048368390649557114
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.047550953924655914
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04667101055383682
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.046177659183740616
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.044886406511068344
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04513174295425415
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.045850981026887894
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0467037633061409
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04643407091498375
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04547103866934776
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04471312835812569
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04512223228812218
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3736579120159149
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.30742818117141724
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.24496352672576904
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07520943135023117
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4339614808559418
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.7229143622898846e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04212750494480133
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.58350814874575e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.048161882907152176
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.040436357259750366
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04868790879845619
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03963315114378929
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04534890130162239
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0403410866856575
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04115712270140648
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02642584964632988
 31%|███       | 180/584 [19:02<28:21,  4.21s/it]REMOVE TEST?! 0 0 0.3099315068493151
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.4039, 10.5410, 10.3403, 10.3247, 10.3247,
         10.3734]], device='cuda:1')
[]
REMOVE TEST?! 0 0 1.558219178082192
tensor([[10.3733, 10.3816, 10.4163, 10.2925, 10.2925, 10.2925, 10.2925, 10.2925,
         10.3735]], device='cuda:0')
[0, 1]
REMOVE TEST?! 0 0 0.6164383561643836
Cross Entropy List Cross Entropy List tensor([[10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.1642, 10.0243,
         13.0519]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.9297945205479452
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.4199, 18.4573, 10.1946, 10.1956, 10.1956,
         10.3738]], device='cuda:1')
REMOVE TEST?! 1 0 1.558219178082192
tensor([[10.3733, 10.3863, 10.3813, 10.2112, 10.2112, 10.2112, 10.2112, 10.2112,
         10.3735]], device='cuda:0')
REMOVE TEST?! 1 0 0.6164383561643836
Cross Entropy List Cross Entropy List tensor([[10.3732, 10.3732, 10.3732, 10.3732, 10.3732, 10.3732,  9.7653,  9.1439,
         10.6815]], device='cuda:2')
[0]
REMOVE TEST?! 0 0 0.3099315068493151
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.4361, 21.3507, 12.5822, 24.9498, 24.9497,
         10.3736]], device='cuda:1')
REMOVE TEST?! 2 1 1.558219178082192
tensor([[10.3734, 10.3895, 10.4133, 10.2205, 10.2205, 10.2205, 10.2205, 10.2205,
         10.3735]], device='cuda:0')
[1]
REMOVE TEST?! 0 0 0.6164383561643836
Cross Entropy List Cross Entropy List tensor([[10.3732, 10.3732, 10.3732, 10.3732, 10.3732, 10.3732, 10.1968,  9.4447,
         11.3258]], device='cuda:2')
[0]
REMOVE TEST?! 0 0 0.3099315068493151
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.4361, 21.4291, 12.7211, 25.6255, 25.6254,
         10.3736]], device='cuda:1')
[1, 2]
REMOVE TEST?! 0 0 1.2465753424657535
tensor([[10.3732, 10.3884, 10.4040, 10.1348, 10.1348, 10.1348, 10.1348, 10.1348,
         10.3735]], device='cuda:0')
REMOVE TEST?! 1 0 0.6164383561643836
Cross Entropy List Cross Entropy List tensor([[10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.3733,  9.9180,  9.4590,
         10.9184]], device='cuda:2')
[0]
tensor([[10.3735, 10.3735, 10.3735, 10.4427, 27.3441, 10.1455, 10.8306, 10.8305,
         10.3736]], device='cuda:1')
REMOVE TEST?! 1 1 1.2465753424657535
Loss tensor([[10.3733, 10.3891, 10.4335, 10.1610, 10.1610, 10.1610, 10.1610, 10.1610,
         10.3735]], device='cuda:0')
[]
REMOVE TEST?! 0 0 0.9246575342465754
Cross Entropy List Cross Entropy List tensor(11.3347, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor([[10.3735, 10.3734, 10.3734, 10.4415, 27.2588, 10.1568, 11.4355, 11.4353,
         10.3735]], device='cuda:1')
[0, 1]
REMOVE TEST?! 0 0 0.6232876712328768
tensor([[10.3733, 10.3879, 10.4672, 10.2346, 10.2346, 10.2346, 10.2346, 10.2346,
         10.3735]], device='cuda:0')
[0]
After Process
A-INPUT tensor([    1,  2984,  8830,   304,  1972,  3679,  1105,  1430,   506, 28705,
        28783,   680,  2609,  2040,   821,  4790,   562,   865,  3359,  2108,
          821, 15281, 28723,  1047, 15281,   659, 28705, 28770, 28734,  2609,
         2040, 28725, 13911,   272,  3102,  1474,   302,  2609,  2040,   369,
          272,  2308,   506, 28804, 28705,     2,  4577,  2984,  8830,   304,
         1972,  3679,  1105,  1430,   506, 28705, 28783,   680,  2609,  2040,
          821,  4790, 28725,   868,  4790,   659, 28705, 28750, 28782, 28733,
        28783,   327,  2087, 28750, 28782, 28733, 28783, 28746, 28740, 28787,
         4060, 28740, 28787,  2609,  2040, 28723, 16589, 11553, 28725,   272,
         2308,   506, 28705, 28740, 28787, 28806, 28783, 28734,   327,  2087,
        28740, 28787, 28806, 28783, 28734, 28746, 28774, 28787,  4060, 28774,
        28787,  2609,  2040, 28723, 28705,     2,  2476, 28774, 28787, 28705,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2], device='cuda:0')
A-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  4577,  2984,  8830,   304,
         1972,  3679,  1105,  1430,   506, 28705, 28783,   680,  2609,  2040,
          821,  4790, 28725,   868,  4790,   659, 28705, 28750, 28782, 28733,
        28783,   327,  2087, 28750, 28782, 28733, 28783, 28746, 28740, 28787,
         4060, 28740, 28787,  2609,  2040, 28723, 16589, 11553, 28725,   272,
         2308,   506, 28705, 28740, 28787, 28806, 28783, 28734,   327,  2087,
        28740, 28787, 28806, 28783, 28734, 28746, 28774, 28787,  4060, 28774,
        28787,  2609,  2040, 28723, 28705,     2,  2476, 28774, 28787, 28705,
            2,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100], device='cuda:0')
Cross Entropy List Loss tensor([[10.3735, 10.3735, 10.3735, 10.4440, 26.5496, 10.1114, 10.2189, 10.2189,
         10.3738]], device='cuda:1')
REMOVE TEST?! 1 0 0.6232876712328768
tensor(10.3732, device='cuda:0', grad_fn=<NllLossBackward0>)
Cross Entropy List Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9226555824279785
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06214893236756325
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02370256371796131
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03408275544643402
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.033981725573539734
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03381313383579254
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03384359925985336
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03361750394105911
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03345267102122307
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06539366394281387
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.061343416571617126
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06278848648071289
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06328017264604568
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06349470466375351
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06328058987855911
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06302722543478012
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06140105798840523
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06052581965923309
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05910290777683258
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05818129703402519
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05917409434914589
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05999830365180969
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06081337481737137
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2018333226442337
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0739026740193367
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.061990175396203995
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.052457425743341446
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06452278792858124
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06409681588411331
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06425556540489197
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06436087936162949
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06361398845911026
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.062266070395708084
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06070219352841377
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05812152847647667
 31%|███       | 181/584 [19:04<23:29,  3.50s/it]REMOVE TEST?! 0 0 0.6232876712328768
tensor([[10.3736, 10.3735, 10.3735, 10.4425, 31.1920, 10.1592, 12.4791, 12.4791,
         10.3739]], device='cuda:1')
[1]
Cross Entropy List Loss tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  9.7066,  8.4638,
          9.0391]], device='cuda:2')
[0]
REMOVE TEST?! 0 0 0.9349315068493151
tensor(10.3736, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.33447954058647156
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14348408579826355
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07686451822519302
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1622915267944336
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15763883292675018
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15408337116241455
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1517486572265625
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15206003189086914
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15453752875328064
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15636089444160461
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1553800255060196
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15676283836364746
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15396760404109955
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15268221497535706
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15067800879478455
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14938457310199738
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1503509283065796
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15317068994045258
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15688101947307587
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1652538776397705
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1596072018146515
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15516850352287292
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1523832082748413
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21350567042827606
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23387154936790466
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2347991019487381
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.21107634902000427
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1562328040599823
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15464428067207336
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1533959060907364
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1516912281513214
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14923889935016632
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14880236983299255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15233628451824188
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13510377705097198
 31%|███       | 180/584 [19:02<32:18,  4.80s/it]Before Process
B-INPUT tensor([    1,  4121,   659,   429, 28750, 28734, 28734, 28734,   354,   516,
         1955,  6933,  6966, 28723,   650,  8636, 11282,   477,   516, 25877,
          304, 13883,   706,   264,   997,  1011,   354,   429, 28784, 28734,
        28734, 28723,  2354, 10953,   271, 12429,   713,   429, 28783, 28734,
        28734,   477,   272, 25596,   590,   553,  1269,   356,  6183, 28723,
         2964, 28723,  4121,   868, 24928,   298,   511,  7108, 12364,   304,
          668,  2827,   429, 28740, 28750, 28734, 28734,   356,   272,  2894,
         5225, 28723,  1602,  1188,  2445,   349,  2964, 28723,  4121,  8409,
          395, 28804, 28705,     2,  1684,  2964, 28723,  4121, 13883,   272,
          997,  1011, 28725,   400,  7520,   395,   429, 28750, 28734, 28734,
        28734, 15191, 28784, 28734, 28734,   327,   429,  5275, 28750, 28734,
        28734, 28734, 28733, 28784, 28734, 28734, 28746, 28740, 28781, 28734,
        28734,  4060, 28740, 28781, 28734, 28734,  2354, 10953,   271, 12429,
          713,   429, 28783, 28734, 28734, 28725,  6488,   516,  5225,  5565,
          298,   429, 28740, 28781, 28734, 28734, 28806, 28776, 28783, 28734,
        28734,   327,   429,  5275, 28740, 28781, 28734, 28734, 28806, 28783,
        28734, 28734, 28746, 28750, 28750, 28734, 28734,  4060, 28750, 28750,
        28734, 28734,   650,   668,  2827,   429, 28740, 28750, 28734, 28734,
        28725,  8409,   429, 28750, 28750, 28734, 28734, 15191, 28740, 28750,
        28734, 28734,   327,   429, 28740, 28734, 28734, 28734,   354,  1955,
         6933,  2434,  1024, 12364, 28723, 28705,     2,  2476, 28740, 28734,
        28734, 28734, 28705,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2], device='cuda:0')
B-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  1684,  2964, 28723,  4121, 13883,   272,
          997,  1011, 28725,   400,  7520,   395,   429, 28750, 28734, 28734,
        28734, 15191, 28784, 28734, 28734,   327,   429,  5275, 28750, 28734,
        28734, 28734, 28733, 28784, 28734, 28734, 28746, 28740, 28781, 28734,
        28734,  4060, 28740, 28781, 28734, 28734,  2354, 10953,   271, 12429,
          713,   429, 28783, 28734, 28734, 28725,  6488,   516,  5225,  5565,
          298,   429, 28740, 28781, 28734, 28734, 28806, 28776, 28783, 28734,
        28734,   327,   429,  5275, 28740, 28781, 28734, 28734, 28806, 28783,
        28734, 28734, 28746, 28750, 28750, 28734, 28734,  4060, 28750, 28750,
        28734, 28734,   650,   668,  2827,   429, 28740, 28750, 28734, 28734,
        28725,  8409,   429, 28750, 28750, 28734, 28734, 15191, 28740, 28750,
        28734, 28734,   327,   429, 28740, 28734, 28734, 28734,   354,  1955,
         6933,  2434,  1024, 12364, 28723, 28705,     2,  2476, 28740, 28734,
        28734, 28734, 28705,     2,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100], device='cuda:0')
[tensor([[ 1684,  2964, 28723]], device='cuda:0'), tensor([[ 4121, 13883,   272,   997,  1011, 28725,   400,  7520,   395,   429,
         28750, 28734, 28734, 28734, 15191, 28784, 28734, 28734,   327,   429,
          5275, 28750, 28734, 28734, 28734, 28733, 28784, 28734, 28734, 28746,
         28740, 28781, 28734, 28734,  4060, 28740, 28781, 28734, 28734,  2354,
         10953,   271, 12429,   713,   429, 28783, 28734, 28734, 28725,  6488,
           516,  5225,  5565,   298,   429, 28740, 28781, 28734, 28734, 28806,
         28776, 28783, 28734, 28734,   327,   429,  5275, 28740, 28781, 28734,
         28734, 28806, 28783, 28734, 28734, 28746, 28750, 28750, 28734, 28734,
          4060, 28750, 28750, 28734, 28734,   650,   668,  2827,   429, 28740,
         28750, 28734, 28734, 28725,  8409,   429, 28750, 28750, 28734, 28734,
         15191, 28740, 28750, 28734, 28734,   327,   429, 28740, 28734, 28734,
         28734,   354,  1955,  6933,  2434,  1024, 12364, 28723, 28705,     2]],
       device='cuda:0')]
REMOVE TEST?! 0 0 0.6198630136986302
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.0297,  9.3014,
          9.3005]], device='cuda:2')
[0]
REMOVE TEST?! 0 0 0.9349315068493151
Cross Entropy List tensor([[10.3711, 10.3777, 10.3983, 10.2194, 10.2194, 10.2194, 10.2194, 10.2194,
         10.3731]], device='cuda:0')
REMOVE TEST?! 1 0 0.6198630136986302
Cross Entropy List tensor([[10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.3733,  9.8478,  8.9991,
         11.2878]], device='cuda:2')
[0]
REMOVE TEST?! 0 0 0.9349315068493151
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.42721429467201233
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13042369484901428
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15576601028442383
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16210554540157318
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1597859412431717
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15671822428703308
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15556858479976654
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15504774451255798
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15764369070529938
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15829966962337494
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15789486467838287
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15746566653251648
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15567614138126373
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15489408373832703
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15252552926540375
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15190252661705017
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15550920367240906
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1566600799560547
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15175098180770874
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1625145524740219
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16131214797496796
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15828478336334229
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1554146260023117
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15536703169345856
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.156917542219162
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15794366598129272
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1573234647512436
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15854144096374512
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15605805814266205
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15504984557628632
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15366330742835999
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15287666022777557
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15377084910869598
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1561347246170044
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13042369484901428
 31%|███       | 182/584 [18:59<24:17,  3.62s/it]REMOVE TEST?! 0 0 0.3133561643835616
Cross Entropy List tensor([[10.3735, 10.3868, 10.4793, 10.2681, 10.2681, 10.2681, 10.2681, 10.2681,
         10.3730]], device='cuda:0')
[]
REMOVE TEST?! 0 0 3.409246575342466
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 11.6360, 20.5961,
         16.2139]], device='cuda:2')
[0]
tensor([[10.3735, 10.3735, 10.3735, 10.3816, 10.1074, 13.6828, 11.7314, 11.7314,
         10.3732]], device='cuda:1')
[0]
Loss REMOVE TEST?! 0 0 0.3133561643835616
tensor([[10.3734, 10.3884, 10.3690, 10.1277, 10.1277, 10.1277, 10.1277, 10.1277,
         10.3730]], device='cuda:0')
REMOVE TEST?! 1 0 3.409246575342466
Cross Entropy List Cross Entropy List tensor(14.2982, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor([[10.3736, 10.3736, 10.3736, 10.4291, 10.4053, 10.1970, 10.1998, 10.1999,
         10.3732]], device='cuda:1')
[]
REMOVE TEST?! 0 0 0.3133561643835616
tensor([[10.3734, 10.3885, 10.4191, 10.1777, 10.1777, 10.1777, 10.1777, 10.1777,
         10.3730]], device='cuda:0')
REMOVE TEST?! 2 0 3.409246575342466
Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.4031, 10.3507, 10.1731, 10.1625, 10.1625,
         10.3733]], device='cuda:1')
[]
REMOVE TEST?! 0 0 0.3133561643835616
tensor([[10.3733, 10.3922, 10.4744, 10.2145, 10.2145, 10.2145, 10.2145, 10.2145,
         10.3730]], device='cuda:0')
REMOVE TEST?! 3 0 3.409246575342466
Cross Entropy List Cross Entropy List Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5442963242530823
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19977688789367676
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13386155664920807
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13402418792247772
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.136405810713768
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1385505348443985
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.138658806681633
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13635312020778656
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13326483964920044
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13555294275283813
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14579369127750397
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14384864270687103
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1449749618768692
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14546748995780945
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14497293531894684
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14439347386360168
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14067348837852478
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.138667032122612
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13541261851787567
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1333022564649582
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13557519018650055
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13746203482151031
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1393248289823532
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1909143626689911
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14040270447731018
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13668370246887207
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11914883553981781
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1497584879398346
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14897435903549194
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1501118540763855
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1509876698255539
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14896006882190704
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14665307104587555
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13912183046340942
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1278511881828308
 31%|███       | 182/584 [19:06<20:21,  3.04s/it]REMOVE TEST?! 0 0 0.6267123287671232
tensor([[10.3736, 10.3736, 10.3736, 10.4366, 10.2562, 10.1164, 10.1188, 10.1188,
         10.3730]], device='cuda:1')
[]
tensor([[10.3734, 10.3906, 10.4345, 10.1737, 10.1737, 10.1737, 10.1737, 10.1737,
         10.3731]], device='cuda:0')
REMOVE TEST?! 4 0 3.409246575342466
Cross Entropy List Cross Entropy List Loss tensor([[10.3737, 10.3737, 10.3737, 10.3737, 10.3737, 10.3737, 10.4033, 16.8265,
          9.8821]], device='cuda:2')
[0]
REMOVE TEST?! 0 0 0.3133561643835616
tensor(10.3732, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor([[10.3734, 10.3897, 10.4261, 10.1717, 10.1717, 10.1717, 10.1717, 10.1717,
         10.3730]], device='cuda:0')
REMOVE TEST?! 5 0 3.409246575342466
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.0333, 10.7584,
         49.1129]], device='cuda:2')
[0]
REMOVE TEST?! 0 0 0.6267123287671232
tensor([[10.3733, 10.3894, 10.4413, 10.1885, 10.1885, 10.1885, 10.1885, 10.1885,
         10.3730]], device='cuda:0')
REMOVE TEST?! 6 0 3.409246575342466
Cross Entropy List Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.0487, 10.7410,
         39.8779]], device='cuda:2')
REMOVE TEST?! 1 0 0.6267123287671232
tensor([[10.3733, 10.3913, 10.4389, 10.1848, 10.1848, 10.1848, 10.1848, 10.1848,
         10.3730]], device='cuda:0')
REMOVE TEST?! 7 0 3.409246575342466
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4271220266819
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13038180768489838
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15575769543647766
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16208936274051666
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1597706824541092
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15670451521873474
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15555371344089508
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15501640737056732
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15763363242149353
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1582888960838318
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15797466039657593
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15751470625400543
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15570518374443054
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1549401879310608
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15253755450248718
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15190231800079346
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15551580488681793
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15658612549304962
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1517016589641571
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1625010073184967
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16134211421012878
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15832874178886414
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1554567515850067
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1553858071565628
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1569378674030304
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15796194970607758
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15735770761966705
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15856704115867615
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15610428154468536
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15507909655570984
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15369142591953278
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15289682149887085
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15376950800418854
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15613485872745514
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1303817629814148
 31%|███▏      | 183/584 [19:02<22:16,  3.33s/it]REMOVE TEST?! 0 0 0.6301369863013698
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.1401, 10.8521,
         45.8006]], device='cuda:2')
[]
REMOVE TEST?! 0 0 1.8801369863013697
tensor([[10.3734, 10.3922, 10.4562, 10.2132, 10.2132, 10.2132, 10.2132, 10.2132,
         10.3731]], device='cuda:0')
REMOVE TEST?! 8 0 3.409246575342466
Cross Entropy List Cross Entropy List tensor([[10.3733, 10.3733, 10.3733, 10.3841, 10.2589, 10.6646, 11.0479, 11.0479,
         10.3733]], device='cuda:1')
[0]
REMOVE TEST?! 0 0 1.5753424657534245
Cross Entropy List tensor([[10.3737, 10.3737, 10.3737, 10.3737, 10.3737, 10.3737,  9.9244, 10.4320,
         30.5683]], device='cuda:2')
REMOVE TEST?! 1 1 1.8801369863013697
tensor([[10.3733, 10.3870, 10.4396, 10.1951, 10.1951, 10.1951, 10.1951, 10.1951,
         10.3730]], device='cuda:0')
REMOVE TEST?! 9 0 3.409246575342466
Cross Entropy List Cross Entropy List tensor([[10.3733, 10.3733, 10.3733, 10.4235, 10.1091, 10.4068, 10.2202, 10.2202,
         10.3733]], device='cuda:1')
REMOVE TEST?! 1 0 1.5753424657534245
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.0327, 10.6143,
         35.8549]], device='cuda:2')
[0, 1]
tensor([[10.3733, 10.3891, 10.4362, 10.1816, 10.1816, 10.1816, 10.1816, 10.1816,
         10.3729]], device='cuda:0')
REMOVE TEST?! 10 0 3.409246575342466
Cross Entropy List tensor([[10.3734, 10.3734, 10.3733, 10.4254, 10.1009, 10.4034, 10.2195, 10.2195,
         10.3733]], device='cuda:1')
REMOVE TEST?! 2 0 1.5753424657534245
Loss Cross Entropy List tensor(36.9608, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor([[10.3733, 10.3903, 10.4443, 10.1861, 10.1861, 10.1861, 10.1861, 10.1861,
         10.3729]], device='cuda:0')
[]
REMOVE TEST?! 0 0 1.2397260273972603
Cross Entropy List tensor([[10.3733, 10.3733, 10.3733, 10.4260, 10.0902, 10.3727, 10.2007, 10.2007,
         10.3734]], device='cuda:1')
REMOVE TEST?! 3 0 1.5753424657534245
Cross Entropy List tensor([[10.3733, 10.3823, 10.4195, 10.2441, 10.2441, 10.2441, 10.2441, 10.2441,
         10.3730]], device='cuda:0')
REMOVE TEST?! 1 0 1.2397260273972603
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.5088, 10.3079, 10.3591, 10.2446, 10.2446,
         10.3733]], device='cuda:1')
REMOVE TEST?! 4 0 1.5753424657534245
Cross Entropy List tensor([[10.3733, 10.3865, 10.4505, 10.2073, 10.2073, 10.2073, 10.2073, 10.2073,
         10.3729]], device='cuda:0')
REMOVE TEST?! 2 0 1.2397260273972603
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8911560773849487
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2809510827064514
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01279654260724783
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012651199474930763
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012711788527667522
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012772786431014538
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012627857737243176
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012516754679381847
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012225647456943989
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012086820788681507
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011742517352104187
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011741489171981812
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011967561207711697
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012151808477938175
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01216297596693039
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011977707035839558
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01169118843972683
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01187902595847845
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012776738032698631
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012617223896086216
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012716014869511127
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012759215198457241
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01271583791822195
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.31847086548805237
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08143484592437744
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07604742795228958
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07730365544557571
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04104801267385483
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02049923874437809
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.017134683206677437
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016669675707817078
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.018446898087859154
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.020545700564980507
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016855159774422646
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012842525728046894
 31%|███▏      | 183/584 [19:11<23:41,  3.54s/it]REMOVE TEST?! 0 0 1.2602739726027397
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.4554, 10.1645, 10.2790, 10.2124, 10.2125,
         10.3733]], device='cuda:1')
[]
REMOVE TEST?! 0 0 2.835616438356164
Cross Entropy List Cross Entropy List tensor([[10.3733, 10.3708, 10.4035, 10.3875, 10.3875, 10.3875, 10.3875, 10.3875,
         10.3735]], device='cuda:0')
REMOVE TEST?! 3 1 1.2397260273972603
Cross Entropy List tensor([[10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.3072,  9.5773,
         10.8470]], device='cuda:2')
tensor([[10.3733, 10.3733, 10.3733, 10.4523, 10.1522, 10.2616, 10.1798, 10.1798,
         10.3733]], device='cuda:1')
REMOVE TEST?! 1 0 1.2602739726027397
REMOVE TEST?! 1 0 2.835616438356164
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3879, 10.4481, 10.2174, 10.2174, 10.2174, 10.2174, 10.2174,
         10.3730]], device='cuda:0')
[2]
REMOVE TEST?! 0 0 1.2397260273972603
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.4067, 10.2240, 10.5686, 10.8549, 10.8549,
         10.3734]], device='cuda:1')tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  9.6758,  9.1707,
         10.7551]], device='cuda:2')

REMOVE TEST?! 2 0 2.835616438356164
REMOVE TEST?! 2 1 1.2602739726027397
Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3797, 10.4536, 10.2379, 10.2379, 10.2379, 10.2379, 10.2379,
         10.3730]], device='cuda:0')
REMOVE TEST?! 1 0 1.2397260273972603
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3735,  9.6936,  9.1837,
         10.7311]], device='cuda:2')
tensor([[10.3735, 10.3735, 10.3735, 10.4074, 10.2157, 10.5910, 10.8859, 10.8859,
         10.3733]], device='cuda:1')
REMOVE TEST?! 3 0 2.835616438356164
[1, 2]
REMOVE TEST?! 0 0 0.6301369863013698
Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3834, 10.4803, 10.2418, 10.2418, 10.2418, 10.2418, 10.2418,
         10.3730]], device='cuda:0')
REMOVE TEST?! 2 0 1.2397260273972603
Cross Entropy List tensor([[10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.3733,  9.9047,  9.5799,
         10.7605]], device='cuda:2')
REMOVE TEST?! 1 0 0.6301369863013698
tensor([[10.3735, 10.3735, 10.3735, 10.4072, 10.2093, 10.6157, 10.9181, 10.9181,
         10.3733]], device='cuda:1')
REMOVE TEST?! 4 0 2.835616438356164
Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3863, 10.4973, 10.2492, 10.2492, 10.2492, 10.2492, 10.2492,
         10.3730]], device='cuda:0')
REMOVE TEST?! 3 0 1.2397260273972603
Cross Entropy List tensor([[10.3735, 10.3735, 10.3734, 10.4070, 10.1995, 10.6556, 10.9745, 10.9745,
         10.3733]], device='cuda:1')
tensor([[10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.3733,  9.6675,  9.1070,
         11.0315]], device='cuda:2')
REMOVE TEST?! 5 0 2.835616438356164
[]
REMOVE TEST?! 0 0 0.6301369863013698
Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3890, 10.5134, 10.2558, 10.2558, 10.2558, 10.2558, 10.2558,
         10.3730]], device='cuda:0')
[]
After Process
A-INPUT tensor([    1,  4121,   659,   429, 28750, 28734, 28734, 28734,   354,   516,
         1955,  6933,  6966, 28723,   650,  8636, 11282,   477,   516, 25877,
          304, 13883,   706,   264,   997,  1011,   354,   429, 28784, 28734,
        28734, 28723,  2354, 10953,   271, 12429,   713,   429, 28783, 28734,
        28734,   477,   272, 25596,   590,   553,  1269,   356,  6183, 28723,
         2964, 28723,  4121,   868, 24928,   298,   511,  7108, 12364,   304,
          668,  2827,   429, 28740, 28750, 28734, 28734,   356,   272,  2894,
         5225, 28723,  1602,  1188,  2445,   349,  2964, 28723,  4121,  8409,
          395, 28804, 28705,     2,  1684,  2964, 28723,  4121, 13883,   272,
          997,  1011, 28725,   400,  7520,   395,   429, 28750, 28734, 28734,
        28734, 15191, 28784, 28734, 28734,   327,   429,  5275, 28750, 28734,
        28734, 28734, 28733, 28784, 28734, 28734, 28746, 28740, 28781, 28734,
        28734,  4060, 28740, 28781, 28734, 28734,  2354, 10953,   271, 12429,
          713,   429, 28783, 28734, 28734, 28725,  6488,   516,  5225,  5565,
          298,   429, 28740, 28781, 28734, 28734, 28806, 28776, 28783, 28734,
        28734,   327,   429,  5275, 28740, 28781, 28734, 28734, 28806, 28783,
        28734, 28734, 28746, 28750, 28750, 28734, 28734,  4060, 28750, 28750,
        28734, 28734,   650,   668,  2827,   429, 28740, 28750, 28734, 28734,
        28725,  8409,   429, 28750, 28750, 28734, 28734, 15191, 28740, 28750,
        28734, 28734,   327,   429, 28740, 28734, 28734, 28734,   354,  1955,
         6933,  2434,  1024, 12364, 28723, 28705,     2,  2476, 28740, 28734,
        28734, 28734, 28705,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2], device='cuda:0')
A-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  1684,  2964, 28723,  4121, 13883,   272,
          997,  1011, 28725,   400,  7520,   395,   429, 28750, 28734, 28734,
        28734, 15191, 28784, 28734, 28734,   327,   429,  5275, 28750, 28734,
        28734, 28734, 28733, 28784, 28734, 28734, 28746, 28740, 28781, 28734,
        28734,  4060, 28740, 28781, 28734, 28734,  2354, 10953,   271, 12429,
          713,   429, 28783, 28734, 28734, 28725,  6488,   516,  5225,  5565,
          298,   429, 28740, 28781, 28734, 28734, 28806, 28776, 28783, 28734,
        28734,   327,   429,  5275, 28740, 28781, 28734, 28734, 28806, 28783,
        28734, 28734, 28746, 28750, 28750, 28734, 28734,  4060, 28750, 28750,
        28734, 28734,   650,   668,  2827,   429, 28740, 28750, 28734, 28734,
        28725,  8409,   429, 28750, 28750, 28734, 28734, 15191, 28740, 28750,
        28734, 28734,   327,   429, 28740, 28734, 28734, 28734,   354,  1955,
         6933,  2434,  1024, 12364, 28723, 28705,     2,  2476, 28740, 28734,
        28734, 28734, 28705,     2,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100], device='cuda:0')
tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735,  9.5912,  9.0883,
         10.6938]], device='cuda:2')
REMOVE TEST?! 1 0 0.6301369863013698
tensor([[10.3734, 10.3734, 10.3734, 10.4074, 10.1794, 10.6785, 11.0164, 11.0164,
         10.3732]], device='cuda:1')
REMOVE TEST?! 6 1 2.835616438356164
Loss Cross Entropy List Cross Entropy List tensor(10.3730, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  9.4717,  8.9497,
         10.6845]], device='cuda:2')
[]
tensor([[10.3735, 10.3735, 10.3735, 10.4059, 10.1589, 10.6355, 11.0149, 11.0149,
         10.3732]], device='cuda:1')
REMOVE TEST?! 7 2 2.835616438356164
REMOVE TEST?! 0 0 0.3150684931506849
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  9.7245,  9.0741,
         10.6490]], device='cuda:2')
tensor([[10.3736, 10.3736, 10.3736, 10.3498, 10.1908, 10.9437, 11.2472, 11.2472,
         10.3732]], device='cuda:1')
[]
REMOVE TEST?! 8 2 2.835616438356164
Loss Cross Entropy List Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4290642738342285
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13597925007343292
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15713085234165192
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15857316553592682
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1557239145040512
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15442515909671783
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15250347554683685
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15112312138080597
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15188170969486237
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15473423898220062
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15926755964756012
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16737844049930573
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16134677827358246
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15687303245067596
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15405844151973724
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15372607111930847
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15411052107810974
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15780240297317505
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15785858035087585
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15796098113059998
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1564214676618576
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15519443154335022
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1534951776266098
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15087054669857025
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.150320366024971
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1539597064256668
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15717625617980957
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15631094574928284
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16333244740962982
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15848498046398163
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15520736575126648
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15351073443889618
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15366286039352417
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15683504939079285
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13597926497459412
 31%|███       | 181/584 [19:10<38:14,  5.69s/it]Before Process
B-INPUT tensor([    1,  4696,   473, 19085, 28705, 28740, 28781, 28734,  8251,   298,
          771,  1430,  1370, 28723,  1047,   630,  1235,   459,   576,   298,
          771, 28705, 28770,  2202,  1012,  1819, 28725,  1300,   272,  3102,
         5328,   630, 19085,   298,   771,   354, 28705, 28781,  4587,   297,
        22230,  2612, 28723, 28705,     2,  1387,   460, 28705, 28787,  2202,
          297,   264,  1819, 28725,   579,   513,   400,  2368, 28742, 28707,
          576,   298,   771,   354, 28705, 28770,  2202, 28725,   400,  4859,
        28705, 28787, 28733, 28770,   327,  2087, 28787, 28733, 28770, 28746,
        28781,  4060, 28781,  2202,  1012,  1819,   650, 27651, 28705, 28740,
        28781, 28734,  8251,  1430,  1370,   354,   264, 16496,  3102,   302,
        28705, 28740, 28781, 28734, 28736, 28781,   327,  2087, 28740, 28781,
        28734, 28736, 28781, 28746, 28782, 28784, 28734,  4060, 28782, 28784,
        28734,  8251,   560, 28705, 28781,  4587,   400,   622,  4530,   264,
         3102,   302, 28705, 28781, 28736, 28782, 28784, 28734,   327,  2087,
        28781, 28736, 28782, 28784, 28734, 28746, 28750, 28750, 28781, 28734,
         4060, 28750, 28750, 28781, 28734,  8251, 28705,     2,  2476, 28750,
        28750, 28781, 28734, 28705,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2],
       device='cuda:0')
B-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  1387,   460, 28705, 28787,  2202,
          297,   264,  1819, 28725,   579,   513,   400,  2368, 28742, 28707,
          576,   298,   771,   354, 28705, 28770,  2202, 28725,   400,  4859,
        28705, 28787, 28733, 28770,   327,  2087, 28787, 28733, 28770, 28746,
        28781,  4060, 28781,  2202,  1012,  1819,   650, 27651, 28705, 28740,
        28781, 28734,  8251,  1430,  1370,   354,   264, 16496,  3102,   302,
        28705, 28740, 28781, 28734, 28736, 28781,   327,  2087, 28740, 28781,
        28734, 28736, 28781, 28746, 28782, 28784, 28734,  4060, 28782, 28784,
        28734,  8251,   560, 28705, 28781,  4587,   400,   622,  4530,   264,
         3102,   302, 28705, 28781, 28736, 28782, 28784, 28734,   327,  2087,
        28781, 28736, 28782, 28784, 28734, 28746, 28750, 28750, 28781, 28734,
         4060, 28750, 28750, 28781, 28734,  8251, 28705,     2,  2476, 28750,
        28750, 28781, 28734, 28705,     2,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],
       device='cuda:0')
[tensor([[ 1387,   460, 28705, 28787,  2202,   297,   264,  1819, 28725,   579,
           513,   400,  2368, 28742, 28707,   576,   298,   771,   354, 28705,
         28770,  2202, 28725,   400,  4859, 28705, 28787, 28733, 28770,   327,
          2087, 28787, 28733, 28770, 28746, 28781,  4060, 28781,  2202,  1012,
          1819,   650, 27651, 28705, 28740, 28781, 28734,  8251,  1430,  1370,
           354,   264, 16496,  3102,   302, 28705, 28740, 28781, 28734, 28736,
         28781,   327,  2087, 28740, 28781, 28734, 28736, 28781, 28746, 28782,
         28784, 28734,  4060, 28782, 28784, 28734,  8251,   560, 28705, 28781,
          4587,   400,   622,  4530,   264,  3102,   302, 28705, 28781, 28736,
         28782, 28784, 28734,   327,  2087, 28781, 28736, 28782, 28784, 28734,
         28746, 28750, 28750, 28781, 28734,  4060, 28750, 28750, 28781, 28734,
          8251, 28705,     2]], device='cuda:0')]
REMOVE TEST?! 0 0 0.3116438356164384
tensor([[10.3736, 10.3736, 10.3736, 10.4468, 11.4725, 10.3230, 10.6896, 10.6896,
         10.3734]], device='cuda:1')
[5, 6, 8]
tensor(19.2818, device='cuda:2', grad_fn=<NllLossBackward0>)
REMOVE TEST?! 0 0 1.8904109589041096
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3910, 10.3909, 10.3155, 10.4309, 10.4309,
         10.3735]], device='cuda:1')
REMOVE TEST?! 1 1 1.8904109589041096
tensor([[10.3734, 10.4202, 10.4880, 10.4809, 10.4809, 10.4809, 10.4809, 10.4809,
         10.3735]], device='cuda:0')
[0]
REMOVE TEST?! 0 0 0.3116438356164384
Cross Entropy List Cross Entropy List tensor([[10.3733, 10.3733, 10.3733, 10.4276, 10.9665, 10.0780, 10.1177, 10.1177,
         10.3733]], device='cuda:1')
[0, 1]
tensor([[10.3734, 10.3902, 10.4415, 10.2004, 10.2004, 10.2005, 10.2004, 10.2004,
         10.3734]], device='cuda:0')
[]
REMOVE TEST?! 0 0 0.9349315068493151
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9874269366264343
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15234173834323883
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031576231122016907
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003121790708974004
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031367200426757336
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031518004834651947
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003115988103672862
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030886305030435324
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030167761724442244
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029825454112142324
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028995925094932318
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0029008304700255394
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00295233610086143
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00299876369535923
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003001077100634575
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002951208269223571
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0028843602631241083
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002933894982561469
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037907836958765984
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031372150406241417
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003125420305877924
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031361225992441177
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031529171392321587
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0031204817350953817
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030678827315568924
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0030111658852547407
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.004221748095005751
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0118727907538414
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.016247479245066643
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.015052366070449352
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012186910025775433
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01550794392824173
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019206741824746132
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0032977862283587456
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011582712642848492
 32%|███▏      | 184/584 [19:13<21:00,  3.15s/it]REMOVE TEST?! 0 0 0.6335616438356164
Cross Entropy List Loss Cross Entropy List tensor(10.3735, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor([[10.3733, 10.6123, 11.4218, 11.4321, 11.4321, 11.4321, 11.4321, 11.4321,
         10.3735]], device='cuda:0')
[0]
REMOVE TEST?! 0 0 0.3116438356164384
Cross Entropy List tensor([[10.3731, 10.3731, 10.3731, 10.3732, 10.3731, 10.3731,  9.9441,  9.2026,
          9.6049]], device='cuda:2')
REMOVE TEST?! 1 0 0.6335616438356164
Cross Entropy List tensor([[10.3734, 10.3897, 10.4524, 10.2125, 10.2125, 10.2125, 10.2125, 10.2125,
         10.3735]], device='cuda:0')
[]
After Process
A-INPUT tensor([    1,  4696,   473, 19085, 28705, 28740, 28781, 28734,  8251,   298,
          771,  1430,  1370, 28723,  1047,   630,  1235,   459,   576,   298,
          771, 28705, 28770,  2202,  1012,  1819, 28725,  1300,   272,  3102,
         5328,   630, 19085,   298,   771,   354, 28705, 28781,  4587,   297,
        22230,  2612, 28723, 28705,     2,  2476, 28750, 28750, 28781, 28734,
        28705,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2],
       device='cuda:0')
A-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  2476, 28750, 28750, 28781, 28734,
        28705,     2,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],
       device='cuda:0')
Loss tensor([[10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.3733,  9.7118,  8.1165,
          9.8130]], device='cuda:2')
[]
REMOVE TEST?! 0 0 1.2671232876712328
Cross Entropy List tensor(10.3734, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.42688098549842834
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13389576971530914
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1560005247592926
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15540753304958344
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15362563729286194
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15286864340305328
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15050475299358368
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14987842738628387
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15344251692295074
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15449553728103638
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14995643496513367
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16039003431797028
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15916351974010468
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15619827806949615
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15339307487010956
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1533440351486206
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1548958718776703
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1558837890625
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15522198379039764
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15644574165344238
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15402065217494965
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1530095487833023
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15163980424404144
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15085835754871368
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15172119438648224
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15405160188674927
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15436352789402008
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20663459599018097
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1601228415966034
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1582566350698471
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1552422195672989
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.153270423412323
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15302832424640656
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1551119089126587
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.134506493806839
 32%|███▏      | 184/584 [19:10<31:41,  4.75s/it]REMOVE TEST?! 0 0 1.2671232876712328
tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  9.2761,  8.1380,
          9.3433]], device='cuda:2')
REMOVE TEST?! 1 0 1.2671232876712328
Cross Entropy List Cross Entropy List tensor([[10.3727, 10.3727, 10.3727, 10.4349, 10.8454, 10.8581, 11.1598, 11.1599,
         10.3735]], device='cuda:1')
tensor([[10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.3733,  9.5503,  7.9613,
          7.9320]], device='cuda:2')
REMOVE TEST?! 1 1 1.2671232876712328
REMOVE TEST?! 2 0 1.2671232876712328
Cross Entropy List Cross Entropy List Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15465718507766724
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04901381954550743
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05663822591304779
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05715776979923248
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05613114312291145
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05566311255097389
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.054970722645521164
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05447316914796829
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.054746612906455994
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.055774666368961334
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.057408109307289124
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07734731584787369
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.058887455612421036
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05712384358048439
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.055943336337804794
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.055333979427814484
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.055405084043741226
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05653443932533264
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05697743222117424
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05669187009334564
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.056892797350883484
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.056066423654556274
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.055562879890203476
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0547269731760025
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05428663641214371
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05503762885928154
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05604492127895355
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.055921927094459534
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5669176578521729
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5073360800743103
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.42760589718818665
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.35719937086105347
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.7619710206417949e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.8407328070679796e-06
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 1.4987920621933881e-05
 31%|███       | 182/584 [19:14<35:00,  5.22s/it]Before Process
B-INPUT tensor([    1,  7066,  3500,   302,   264, 28705, 28770,   268,  1932, 13164,
          659, 28705, 28783, 24903,  3822,   272,  4850,   302,   272,  3500,
          304, 28705, 28750, 28734, 24903,  3822,   272,  5110,   302,   272,
         3500, 28723, 28705,  1602,  1287, 24903,   460,   297,   272, 13164,
        28804, 28705,     2,  1387,   460, 28705, 28783, 24903,  2267,   272,
         4850,   304, 28705, 28750, 28734, 24903,  2267,   272,  5110,   354,
          264,  3102,   302, 28705, 28783, 28736, 28750, 28734,   327,  2087,
        28783, 28736, 28750, 28734, 28746, 28740, 28784, 28734,  4060, 28740,
        28784, 28734, 24903,  7066,  3500,   659, 28705, 28740, 28784, 28734,
        24903,   304,   736,   460, 28705, 28770,  8133,   579,   736,   460,
        28705, 28740, 28784, 28734, 28736, 28770,   327,  2087, 28740, 28784,
        28734, 28736, 28770, 28746, 28781, 28783, 28734,  4060, 28781, 28783,
        28734, 24903,   297,   272, 13164, 28705,     2,  2476, 28781, 28783,
        28734, 28705,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2],
       device='cuda:0')
B-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  1387,   460, 28705, 28783, 24903,  2267,   272,
         4850,   304, 28705, 28750, 28734, 24903,  2267,   272,  5110,   354,
          264,  3102,   302, 28705, 28783, 28736, 28750, 28734,   327,  2087,
        28783, 28736, 28750, 28734, 28746, 28740, 28784, 28734,  4060, 28740,
        28784, 28734, 24903,  7066,  3500,   659, 28705, 28740, 28784, 28734,
        24903,   304,   736,   460, 28705, 28770,  8133,   579,   736,   460,
        28705, 28740, 28784, 28734, 28736, 28770,   327,  2087, 28740, 28784,
        28734, 28736, 28770, 28746, 28781, 28783, 28734,  4060, 28781, 28783,
        28734, 24903,   297,   272, 13164, 28705,     2,  2476, 28781, 28783,
        28734, 28705,     2,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],
       device='cuda:0')
[tensor([[ 1387,   460, 28705, 28783, 24903,  2267,   272,  4850,   304, 28705,
         28750, 28734, 24903,  2267,   272,  5110,   354,   264,  3102,   302,
         28705, 28783, 28736, 28750, 28734,   327,  2087, 28783, 28736, 28750,
         28734, 28746, 28740, 28784, 28734,  4060, 28740, 28784, 28734, 24903,
          7066,  3500,   659, 28705, 28740, 28784, 28734, 24903,   304,   736,
           460, 28705, 28770,  8133,   579,   736,   460, 28705, 28740, 28784,
         28734, 28736, 28770,   327,  2087, 28740, 28784, 28734, 28736, 28770,
         28746, 28781, 28783, 28734,  4060, 28781, 28783, 28734, 24903,   297,
           272, 13164, 28705,     2]], device='cuda:0')]
REMOVE TEST?! 0 0 0.3133561643835616
tensor([[10.3735, 10.3735, 10.3735, 10.5508, 10.6174, 10.1322, 10.1357, 10.1357,
         10.3735]], device='cuda:1')
REMOVE TEST?! 2 1 1.2671232876712328
tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  9.0357,  7.9950,
          9.8138]], device='cuda:2')
REMOVE TEST?! 3 0 1.2671232876712328
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.1631, 38.1691, 58.2314, 59.6429, 59.6430,
         10.3734]], device='cuda:1')
tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.4341, 15.3520,
          8.4723]], device='cuda:2')
[0, 2]
[]
REMOVE TEST?! 0 0 0.3167808219178082
REMOVE TEST?! 0 0 0.6335616438356164
tensor([[10.3722, 23.5343, 23.5788, 23.7405, 23.7405, 23.7405, 23.7405, 23.7405,
         10.3736]], device='cuda:0')
[0]
REMOVE TEST?! 0 0 0.6267123287671232
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3721, 10.3721, 10.3721, 10.3721, 10.3721, 10.3721, 10.3143, 10.3258,
          9.3599]], device='cuda:2')
tensor([[10.3730, 10.3730, 10.3730, 10.3415, 10.1232, 11.5489, 11.0329, 11.0329,
         10.3735]], device='cuda:1')
REMOVE TEST?! 1 0 0.6335616438356164
[0]
REMOVE TEST?! 0 0 0.9503424657534246
tensor([[10.3733, 10.3906, 10.4027, 10.2448, 10.2447, 10.2447, 10.2447, 10.2447,
         10.3733]], device='cuda:0')
REMOVE TEST?! 1 0 0.6267123287671232
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3739, 10.3739, 10.3739, 10.3973, 10.0852, 12.6798, 12.5037, 12.5036,
         10.3735]], device='cuda:1')
tensor([[10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.3736,  9.4481,  8.9899,
         10.2034]], device='cuda:2')
[0]
[]
REMOVE TEST?! 0 0 0.9503424657534246
REMOVE TEST?! 0 0 0.9503424657534246
tensor([[10.3734, 10.4025, 10.4799, 10.2824, 10.2824, 10.2824, 10.2824, 10.2824,
         10.3734]], device='cuda:0')
[]
REMOVE TEST?! 0 0 0.6267123287671232
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3657, 10.1473, 11.5984, 11.3979, 11.3979,
         10.3735]], device='cuda:1')
tensor([[10.3738, 10.3738, 10.3738, 10.3738, 10.3738, 10.3738,  9.7096,  9.5439,
         10.2417]], device='cuda:2')
[0]
REMOVE TEST?! 1 0 0.9503424657534246
tensor([[10.3733, 10.3908, 10.3941, 10.1701, 10.1701, 10.1701, 10.1701, 10.1701,
         10.3734]], device='cuda:0')
REMOVE TEST?! 1 0 0.6267123287671232
Cross Entropy List Cross Entropy List Loss tensor([[10.3737, 10.3737, 10.3737, 10.3737, 10.3737, 10.3737,  9.6583,  9.4281,
         10.2409]], device='cuda:2')
REMOVE TEST?! 2 0 0.9503424657534246
tensor(10.3735, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor([[10.3733, 10.3958, 10.4430, 10.1974, 10.1974, 10.1974, 10.1974, 10.1974,
         10.3734]], device='cuda:0')
[]
REMOVE TEST?! 0 0 3.7602739726027394
Cross Entropy List Cross Entropy List tensor([[10.3737, 10.3737, 10.3737, 10.3737, 10.3737, 10.3737, 10.1195,  9.1675,
         10.1201]], device='cuda:2')
[]
tensor([[10.3732, 10.3938, 10.4680, 10.2324, 10.2324, 10.2324, 10.2324, 10.2324,
         10.3734]], device='cuda:0')
REMOVE TEST?! 1 0 3.7602739726027394
Loss Cross Entropy List tensor(9.5146, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor([[10.3732, 10.3980, 10.4730, 10.2320, 10.2320, 10.2320, 10.2320, 10.2320,
         10.3734]], device='cuda:0')
REMOVE TEST?! 2 0 3.7602739726027394
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3526637554168701
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005077993497252464
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16291773319244385
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16951033473014832
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16707995533943176
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1638738065958023
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16269634664058685
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16212093830108643
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16488896310329437
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16557279229164124
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1651940494775772
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16471946239471436
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16283079981803894
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1620284467935562
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1595229059457779
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1588590443134308
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16263669729232788
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16375280916690826
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15864937007427216
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16995149850845337
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16871926188468933
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1655682921409607
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16259215772151947
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1625184267759323
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16416311264038086
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16523227095603943
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16452279686927795
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16581986844539642
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16324947774410248
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16217778623104095
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16072598099708557
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15989769995212555
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16081222891807556
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16328227519989014
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1363539695739746
 32%|███▏      | 185/584 [19:12<26:57,  4.05s/it]REMOVE TEST?! 0 0 3.5034246575342465
Cross Entropy List Cross Entropy List tensor([[10.3733, 10.4012, 10.5014, 10.2702, 10.2702, 10.2702, 10.2702, 10.2702,
         10.3732]], device='cuda:0')
REMOVE TEST?! 3 0 3.7602739726027394
Cross Entropy List tensor([[10.3733, 10.3733, 10.3733, 10.4087, 10.1134, 12.3829, 11.8916, 11.8917,
         10.3735]], device='cuda:1')
REMOVE TEST?! 1 1 3.5034246575342465
Cross Entropy List tensor([[10.3732, 10.4021, 10.5073, 10.2586, 10.2586, 10.2586, 10.2586, 10.2586,
         10.3735]], device='cuda:0')
REMOVE TEST?! 4 0 3.7602739726027394
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4545908272266388
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17149744927883148
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15826855599880219
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15648327767848969
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15723706781864166
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15799115598201752
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1561979502439499
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.154825359582901
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15122546255588531
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14950984716415405
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1452522575855255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14528179168701172
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14809061586856842
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15040232241153717
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15045972168445587
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1481815129518509
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1446433961391449
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1469743549823761
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1580199897289276
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15605857968330383
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15719732642173767
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15792419016361237
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15726441144943237
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16833484172821045
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1536099761724472
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15048110485076904
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14710994064807892
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14470700919628143
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.147256001830101
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14916276931762695
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15125726163387299
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15019378066062927
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1451519876718521
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14573967456817627
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15716849267482758
 32%|███▏      | 185/584 [19:19<26:24,  3.97s/it]REMOVE TEST?! 0 0 0.9554794520547945
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.4167, 10.0916, 11.3745, 11.1929, 11.1929,
         10.3735]], device='cuda:1')
REMOVE TEST?! 2 2 3.5034246575342465
Cross Entropy List Cross Entropy List tensor([[10.3732, 10.4027, 10.4991, 10.3087, 10.3087, 10.3087, 10.3087, 10.3087,
         10.3735]], device='cuda:0')
REMOVE TEST?! 5 0 3.7602739726027394
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3965, 10.4730, 12.0591, 11.9230, 11.9229,
         10.3735]], device='cuda:1')
tensor([[10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.0132,  8.5784,
          9.0049]], device='cuda:2')
REMOVE TEST?! 3 3 3.5034246575342465
[0]
REMOVE TEST?! 0 0 0.9554794520547945
Cross Entropy List tensor([[10.3732, 10.3940, 10.4680, 10.2474, 10.2474, 10.2474, 10.2474, 10.2474,
         10.3733]], device='cuda:0')
REMOVE TEST?! 6 0 3.7602739726027394
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.4075, 10.2705, 10.6643, 11.0137, 11.0137,
         10.3735]], device='cuda:1')
tensor([[10.3732, 10.3732, 10.3732, 10.3732, 10.3732, 10.3732,  9.4006,  9.2035,
          9.0078]], device='cuda:2')
[0, 1, 2, 3]
REMOVE TEST?! 1 0 0.9554794520547945
REMOVE TEST?! 0 0 0.3184931506849315
Cross Entropy List Cross Entropy List tensor([[10.3732, 10.3998, 10.5130, 10.2664, 10.2664, 10.2664, 10.2664, 10.2664,
         10.3734]], device='cuda:0')
REMOVE TEST?! 7 0 3.7602739726027394
Cross Entropy List tensor([[10.3732, 10.3732, 10.3732, 10.3732, 10.3732, 10.3732,  9.2444,  8.6755,
          8.7641]], device='cuda:2')
REMOVE TEST?! 2 0 0.9554794520547945
tensor([[10.3736, 10.3736, 10.3736, 10.3956, 10.1674, 10.3529, 10.4381, 10.4381,
         10.3735]], device='cuda:1')
[]
REMOVE TEST?! 0 0 2.2294520547945207
Cross Entropy List Cross Entropy List tensor([[10.3732, 10.4011, 10.5225, 10.2733, 10.2733, 10.2733, 10.2733, 10.2733,
         10.3734]], device='cuda:0')
REMOVE TEST?! 8 0 3.7602739726027394
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3853, 10.2152, 10.3944, 10.6723, 10.6723,
         10.3735]], device='cuda:1')
REMOVE TEST?! 1 1 2.2294520547945207
tensor([[10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.3733,  9.0950,  8.2685,
          8.6729]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.3184931506849315
Cross Entropy List Cross Entropy List tensor([[10.3732, 10.4024, 10.5284, 10.2803, 10.2803, 10.2803, 10.2803, 10.2803,
         10.3734]], device='cuda:0')
REMOVE TEST?! 9 0 3.7602739726027394
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3830, 10.2238, 10.3918, 10.6722, 10.6722,
         10.3735]], device='cuda:1')
REMOVE TEST?! 2 2 2.2294520547945207
tensor([[10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.3733,  9.0380,  7.0790,
          8.7395]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.9554794520547945
Cross Entropy List Cross Entropy List tensor([[10.3732, 10.4033, 10.5321, 10.2837, 10.2837, 10.2837, 10.2837, 10.2837,
         10.3734]], device='cuda:0')
REMOVE TEST?! 10 0 3.7602739726027394
Cross Entropy List tensor([[10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.3733,  9.2859,  7.8465,
          8.7742]], device='cuda:2')
tensor([[10.3734, 10.3734, 10.3734, 10.3882, 10.2301, 10.3993, 10.6738, 10.6738,
         10.3735]], device='cuda:1')
REMOVE TEST?! 1 0 0.9554794520547945
[0, 1, 2]
REMOVE TEST?! 0 0 1.273972602739726
Cross Entropy List Cross Entropy List tensor([[10.3732, 10.4053, 10.5389, 10.2869, 10.2869, 10.2869, 10.2869, 10.2869,
         10.3734]], device='cuda:0')
REMOVE TEST?! 11 0 3.7602739726027394
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.4370, 10.2293, 10.2246, 10.2353, 10.2353,
         10.3735]], device='cuda:1')
REMOVE TEST?! 1 0 1.273972602739726
tensor([[10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.3733,  9.1423,  7.5086,
          8.6185]], device='cuda:2')
REMOVE TEST?! 2 0 0.9554794520547945
Cross Entropy List Cross Entropy List tensor([[10.3732, 10.4064, 10.5459, 10.2926, 10.2926, 10.2926, 10.2926, 10.2926,
         10.3734]], device='cuda:0')
[]
After Process
A-INPUT tensor([    1,  7066,  3500,   302,   264, 28705, 28770,   268,  1932, 13164,
          659, 28705, 28783, 24903,  3822,   272,  4850,   302,   272,  3500,
          304, 28705, 28750, 28734, 24903,  3822,   272,  5110,   302,   272,
         3500, 28723, 28705,  1602,  1287, 24903,   460,   297,   272, 13164,
        28804, 28705,     2,  2476, 28781, 28783, 28734, 28705,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2],
       device='cuda:0')
A-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  2476, 28781, 28783, 28734, 28705,     2,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],
       device='cuda:0')
tensor([[10.3736, 10.3736, 10.3736, 10.4370, 10.2136, 10.2170, 10.2251, 10.2251,
         10.3735]], device='cuda:1')
tensor([[10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.3733,  9.0821,  7.4303,
          8.5591]], device='cuda:2')
REMOVE TEST?! 2 0 1.273972602739726
[]
Loss Cross Entropy List Loss tensor(10.3734, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(8.5235, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor([[10.3736, 10.3736, 10.3736, 10.4365, 10.2034, 10.2096, 10.2125, 10.2125,
         10.3735]], device='cuda:1')
REMOVE TEST?! 3 0 1.273972602739726
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3350, 10.2860, 10.9118, 11.5120, 11.5120,
         10.3735]], device='cuda:1')
[3]
Loss Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4284674823284149
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13568423688411713
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15701831877231598
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15822526812553406
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1554192453622818
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15413157641887665
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1522047072649002
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1508316844701767
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15180200338363647
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15461918711662292
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15831582248210907
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16709157824516296
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16108065843582153
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15662455558776855
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1538180559873581
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15593934059143066
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1559264361858368
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15808257460594177
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15795482695102692
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15789467096328735
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15638171136379242
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15517567098140717
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15360140800476074
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15141203999519348
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.150919109582901
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15376585721969604
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15692363679409027
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15879012644290924
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16304701566696167
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1582184135913849
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1549534648656845
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1532624065876007
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15341345965862274
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1565718799829483
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1357669085264206
 31%|███▏      | 183/584 [19:18<33:04,  4.95s/it]Before Process
B-INPUT tensor([    1,  1794,   272, 26103,  1905, 12191, 13229, 28725,   590,   506,
        28705, 28782, 28734, 28734,  8300,   354,  7796, 28723, 28705,  1047,
          590,   506, 28705, 28740, 28734,  6292, 12749, 28725,   304,  1430,
         6292,  9701,  6112, 28713, 28705, 28740, 28734,  8300,   660,  2102,
        28725,   910,  1287,  3370,   622,   378,  1388,   354,   706,   298,
         6112,   544,   302,   272,  8300, 28804, 28705,     2,  1047, 28705,
        28740, 28734,  6292, 12749,  1430,  6112, 28705, 28740, 28734,  8300,
          660,  2102, 28725,   868,   590,  6112,   264,  9837, 28705, 28740,
        28734, 28736, 28740, 28734, 28746,  5275, 28740, 28734, 28736, 28740,
        28734, 28746, 28740, 28734, 28734,  4060, 28740, 28734, 28734,  8300,
          660,  2102, 28723,  1047,   272,  4143,   659, 28705, 28782, 28734,
        28734,  8300, 28725,   868,   378,   622,  1388,   272,  6292,  1918,
        28705, 28782, 28734, 28734, 28748, 28740, 28734, 28734, 28746,  5275,
        28782, 28734, 28734, 28748, 28740, 28734, 28734, 28746, 28782,  4060,
        28782,  3370,   298,  6112,   544,   302,   272,  8300, 28723, 28705,
            2,  2476, 28782, 28705,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2],
       device='cuda:0')
B-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  1047, 28705,
        28740, 28734,  6292, 12749,  1430,  6112, 28705, 28740, 28734,  8300,
          660,  2102, 28725,   868,   590,  6112,   264,  9837, 28705, 28740,
        28734, 28736, 28740, 28734, 28746,  5275, 28740, 28734, 28736, 28740,
        28734, 28746, 28740, 28734, 28734,  4060, 28740, 28734, 28734,  8300,
          660,  2102, 28723,  1047,   272,  4143,   659, 28705, 28782, 28734,
        28734,  8300, 28725,   868,   378,   622,  1388,   272,  6292,  1918,
        28705, 28782, 28734, 28734, 28748, 28740, 28734, 28734, 28746,  5275,
        28782, 28734, 28734, 28748, 28740, 28734, 28734, 28746, 28782,  4060,
        28782,  3370,   298,  6112,   544,   302,   272,  8300, 28723, 28705,
            2,  2476, 28782, 28705,     2,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],
       device='cuda:0')
[tensor([[ 1047, 28705, 28740, 28734,  6292, 12749,  1430,  6112, 28705, 28740,
         28734,  8300,   660,  2102, 28725,   868,   590,  6112,   264,  9837,
         28705, 28740, 28734, 28736, 28740, 28734, 28746,  5275, 28740, 28734,
         28736, 28740, 28734, 28746, 28740, 28734, 28734,  4060, 28740, 28734,
         28734,  8300,   660,  2102, 28723]], device='cuda:0'), tensor([[ 1047,   272,  4143,   659, 28705, 28782, 28734, 28734,  8300, 28725,
           868,   378,   622,  1388,   272,  6292,  1918, 28705, 28782, 28734,
         28734, 28748, 28740, 28734, 28734, 28746,  5275, 28782, 28734, 28734,
         28748, 28740, 28734, 28734, 28746, 28782,  4060, 28782,  3370,   298,
          6112,   544,   302,   272,  8300, 28723, 28705,     2]],
       device='cuda:0')]
REMOVE TEST?! 0 0 0.6301369863013698
tensor(10.3735, device='cuda:1', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.22773030400276184
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05742034688591957
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.49742239713668823
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5680294036865234
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.44186097383499146
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20111894607543945
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.2336811866807693e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.495383111840056e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.680032480384398e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.162844207821763e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05698007345199585
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07455066591501236
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07377772033214569
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0730884000658989
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07314569503068924
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07446101307868958
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07587236911058426
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07592243701219559
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07645050436258316
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07633870095014572
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07548516243696213
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07491788268089294
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07447652518749237
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08096547424793243
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07520043104887009
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07516590505838394
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07450556010007858
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07603690028190613
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07626304030418396
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07656039297580719
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07728446274995804
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0780395045876503
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07938888669013977
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07904849946498871
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.055188097059726715
 32%|███▏      | 186/584 [19:21<22:45,  3.43s/it]REMOVE TEST?! 0 0 0.3202054794520548
Cross Entropy List Cross Entropy List tensor([[10.3733, 10.3992, 10.5542, 10.2803, 10.2803, 10.2803, 10.2803, 10.2803,
         10.3735]], device='cuda:0')
REMOVE TEST?! 1 0 0.6301369863013698
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735,  9.3219, 12.7294,
          9.7747]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.3202054794520548
Cross Entropy List tensor([[10.3734, 10.3967, 10.5363, 10.2445, 10.2445, 10.2445, 10.2445, 10.2445,
         10.3735]], device='cuda:0')
[]
REMOVE TEST?! 0 0 1.5753424657534245
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09216416627168655
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028910119086503983
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03369035944342613
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03356755152344704
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03317883238196373
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03301536664366722
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03250303864479065
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03236722573637962
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03314010426402092
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03336752951145172
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.032410845160484314
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.033448949456214905
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.034474536776542664
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03390704467892647
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.033256590366363525
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03311733901500702
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0330805741250515
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03360891714692116
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.033679522573947906
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.033705778419971466
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.033459652215242386
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.033123355358839035
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03294166177511215
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03247500956058502
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.032420795410871506
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.033224884420633316
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03342036157846451
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6669968366622925
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4386788010597229
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4254041016101837
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.38047295808792114
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0012352591147646308
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0011573144001886249
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0010672240750864148
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00350207625888288
 32%|███▏      | 186/584 [19:17<28:17,  4.27s/it]REMOVE TEST?! 0 0 0.3202054794520548
Cross Entropy List tensor([[10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.3733,  8.5687,  9.9627,
          8.6950]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.6404109589041096
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3893, 10.4123, 10.2654, 10.2653, 10.2654, 10.2654, 10.2654,
         10.3735]], device='cuda:0')
REMOVE TEST?! 1 0 1.5753424657534245
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.4263, 10.0692, 11.5268, 10.5002, 10.5002,
         10.3730]], device='cuda:1')
[0]
tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  9.8984, 10.9747,
          9.2566]], device='cuda:2')
REMOVE TEST?! 1 0 0.6404109589041096
REMOVE TEST?! 0 0 4.803082191780822
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3923, 10.4609, 10.2071, 10.2071, 10.2071, 10.2071, 10.2071,
         10.3735]], device='cuda:0')
REMOVE TEST?! 2 0 1.5753424657534245
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3625, 10.2506, 10.6228, 10.8532, 10.8532,
         10.3733]], device='cuda:1')
REMOVE TEST?! 1 0 4.803082191780822
tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  9.1775, 10.9971,
          8.6299]], device='cuda:2')
[]
REMOVE TEST?! 0 0 1.2808219178082192
Cross Entropy List Cross Entropy List tensor([[10.3733, 10.3896, 10.4681, 10.2170, 10.2170, 10.2170, 10.2170, 10.2170,
         10.3735]], device='cuda:0')
REMOVE TEST?! 3 0 1.5753424657534245
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  9.3622, 11.5159,
          9.0843]], device='cuda:2')
tensor([[10.3735, 10.3735, 10.3735, 10.3620, 10.2412, 10.6293, 10.8475, 10.8476,
         10.3733]], device='cuda:1')
REMOVE TEST?! 1 0 1.2808219178082192
REMOVE TEST?! 2 0 4.803082191780822
Cross Entropy List Cross Entropy List tensor([[10.3733, 10.3931, 10.5029, 10.2346, 10.2346, 10.2346, 10.2346, 10.2346,
         10.3735]], device='cuda:0')
REMOVE TEST?! 4 0 1.5753424657534245
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3618, 10.2422, 10.6335, 10.8498, 10.8498,
         10.3733]], device='cuda:1')
tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  9.1647, 10.9364,
          8.7321]], device='cuda:2')
REMOVE TEST?! 3 0 4.803082191780822
REMOVE TEST?! 2 1 1.2808219178082192
Cross Entropy List Cross Entropy List tensor([[10.3733, 10.3961, 10.5259, 10.2472, 10.2472, 10.2472, 10.2472, 10.2472,
         10.3735]], device='cuda:0')
[]
REMOVE TEST?! 0 0 1.5753424657534245
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3613, 10.2292, 10.6095, 10.8208, 10.8209,
         10.3733]], device='cuda:1')
tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  9.1628, 10.9429,
          8.7113]], device='cuda:2')
REMOVE TEST?! 4 0 4.803082191780822
[1, 2]
Cross Entropy List tensor([[10.3709, 10.3804, 10.4623, 10.2029, 10.2029, 10.2029, 10.2029, 10.2029,
         10.3735]], device='cuda:0')
REMOVE TEST?! 1 0 1.5753424657534245
Loss Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3605, 10.2280, 10.6042, 10.8101, 10.8101,
         10.3733]], device='cuda:1')
REMOVE TEST?! 5 0 4.803082191780822
tensor(7.6785, device='cuda:2', grad_fn=<NllLossBackward0>)
Cross Entropy List tensor([[10.3708, 10.3837, 10.5031, 10.2237, 10.2237, 10.2237, 10.2237, 10.2237,
         10.3735]], device='cuda:0')
REMOVE TEST?! 2 0 1.5753424657534245
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.4049, 10.4074, 11.4763, 11.1937, 11.1937,
         10.3734]], device='cuda:1')
REMOVE TEST?! 6 1 4.803082191780822
Cross Entropy List tensor([[10.3734, 10.3941, 10.5367, 10.2369, 10.2369, 10.2369, 10.2369, 10.2369,
         10.3735]], device='cuda:0')
REMOVE TEST?! 3 0 1.5753424657534245
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3922, 10.1036, 10.5986, 10.5285, 10.5286,
         10.3730]], device='cuda:1')
REMOVE TEST?! 7 2 4.803082191780822
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.43142804503440857
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12880398333072662
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14868737757205963
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1505151242017746
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15285199880599976
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15536874532699585
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15428416430950165
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15023908019065857
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14899370074272156
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14204363524913788
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16364626586437225
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16082434356212616
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16159868240356445
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16237281262874603
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16052938997745514
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1591213494539261
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15542356669902802
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15366129577159882
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14928798377513885
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1492767482995987
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15214718878269196
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15453195571899414
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15469233691692352
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1525619775056839
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14880812168121338
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15120398998260498
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16253608465194702
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16053828597068787
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1618598997592926
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16247093677520752
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16194254159927368
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16118735074996948
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15714102983474731
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15463553369045258
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15123680233955383
 32%|███▏      | 187/584 [19:24<22:47,  3.44s/it]REMOVE TEST?! 0 0 0.6438356164383562
Cross Entropy List tensor([[10.3734, 10.3934, 10.5585, 10.2513, 10.2513, 10.2513, 10.2513, 10.2513,
         10.3735]], device='cuda:0')
REMOVE TEST?! 4 0 1.5753424657534245
Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3959, 10.5062, 10.3322, 10.4668, 10.4668,
         10.3736]], device='cuda:1')
REMOVE TEST?! 8 3 4.803082191780822
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735,  9.2601, 12.7512,
         11.5179]], device='cuda:2')
REMOVE TEST?! 1 0 0.6438356164383562
tensor([[10.3734, 10.3948, 10.5549, 10.2453, 10.2453, 10.2453, 10.2453, 10.2453,
         10.3735]], device='cuda:0')
[]
REMOVE TEST?! 0 0 0.3150684931506849
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3831, 10.1275, 10.3423, 10.4508, 10.4508,
         10.3734]], device='cuda:1')
REMOVE TEST?! 9 3 4.803082191780822
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  8.9042, 15.0658,
         11.1105]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.3219178082191781
tensor([[10.3733, 10.3881, 10.4408, 10.2304, 10.2304, 10.2304, 10.2304, 10.2304,
         10.3735]], device='cuda:0')
[]
After Process
A-INPUT tensor([    1,  1794,   272, 26103,  1905, 12191, 13229, 28725,   590,   506,
        28705, 28782, 28734, 28734,  8300,   354,  7796, 28723, 28705,  1047,
          590,   506, 28705, 28740, 28734,  6292, 12749, 28725,   304,  1430,
         6292,  9701,  6112, 28713, 28705, 28740, 28734,  8300,   660,  2102,
        28725,   910,  1287,  3370,   622,   378,  1388,   354,   706,   298,
         6112,   544,   302,   272,  8300, 28804, 28705,     2,  1047, 28705,
        28740, 28734,  6292, 12749,  1430,  6112, 28705, 28740, 28734,  8300,
          660,  2102, 28725,   868,   590,  6112,   264,  9837, 28705, 28740,
        28734, 28736, 28740, 28734, 28746,  5275, 28740, 28734, 28736, 28740,
        28734, 28746, 28740, 28734, 28734,  4060, 28740, 28734, 28734,  8300,
          660,  2102, 28723,  1047,   272,  4143,   659, 28705, 28782, 28734,
        28734,  8300, 28725,   868,   378,   622,  1388,   272,  6292,  1918,
        28705, 28782, 28734, 28734, 28748, 28740, 28734, 28734, 28746,  5275,
        28782, 28734, 28734, 28748, 28740, 28734, 28734, 28746, 28782,  4060,
        28782,  3370,   298,  6112,   544,   302,   272,  8300, 28723, 28705,
            2,  2476, 28782, 28705,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2],
       device='cuda:0')
A-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  1047, 28705,
        28740, 28734,  6292, 12749,  1430,  6112, 28705, 28740, 28734,  8300,
          660,  2102, 28725,   868,   590,  6112,   264,  9837, 28705, 28740,
        28734, 28736, 28740, 28734, 28746,  5275, 28740, 28734, 28736, 28740,
        28734, 28746, 28740, 28734, 28734,  4060, 28740, 28734, 28734,  8300,
          660,  2102, 28723,  1047,   272,  4143,   659, 28705, 28782, 28734,
        28734,  8300, 28725,   868,   378,   622,  1388,   272,  6292,  1918,
        28705, 28782, 28734, 28734, 28748, 28740, 28734, 28734, 28746,  5275,
        28782, 28734, 28734, 28748, 28740, 28734, 28734, 28746, 28782,  4060,
        28782,  3370,   298,  6112,   544,   302,   272,  8300, 28723, 28705,
            2,  2476, 28782, 28705,     2,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],
       device='cuda:0')
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.4054, 10.1686, 12.0073, 11.6039, 11.6039,
         10.3733]], device='cuda:1')
REMOVE TEST?! 10 4 4.803082191780822
Loss Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.3736,  9.6279, 14.7178,
         13.9271]], device='cuda:2')
[]
REMOVE TEST?! 0 0 1.2876712328767124
tensor(10.3735, device='cuda:0', grad_fn=<NllLossBackward0>)
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.4031, 10.1771, 12.1743, 11.7600, 11.7599,
         10.3733]], device='cuda:1')
[5, 6, 7, 9, 10]
REMOVE TEST?! 0 0 0.9606164383561644
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.2280, 14.1479,
         14.9504]], device='cuda:2')
REMOVE TEST?! 1 0 1.2876712328767124
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.4122, 10.2141, 10.1762, 10.2087, 10.2087,
         10.3735]], device='cuda:1')
REMOVE TEST?! 1 0 0.9606164383561644
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735,  9.3637, 16.4450,
         10.1004]], device='cuda:2')
REMOVE TEST?! 2 0 1.2876712328767124
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4290549159049988
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13598673045635223
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15713363885879517
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15848171710968018
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1556720733642578
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15438289940357208
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1524956226348877
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15112097561359406
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15209247171878815
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15491318702697754
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1586134433746338
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.167347714304924
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16133105754852295
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1568789929151535
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15406917035579681
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15373967587947845
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15412330627441406
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1578044295310974
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15787078440189362
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.158101886510849
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15636475384235382
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1551131159067154
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15343239903450012
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15098270773887634
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15054766833782196
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15408577024936676
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15740738809108734
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15621715784072876
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16329903900623322
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15847459435462952
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15520703792572021
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1535124033689499
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15366333723068237
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1568259447813034
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13598673045635223
 32%|███▏      | 184/584 [19:23<32:52,  4.93s/it]Before Process
B-INPUT tensor([    1,   330,   686,  3464,   659, 28705, 28783,   940,   311,  1074,
        28723,   661, 28705, 28770,  2421,   272,  1474,   302,  2502,  1593,
          821,   940,   311,  1074,   304, 28705, 28750,  2421,   272,  1474,
          302,  1326,  6798,   821,  2502,  1593, 28723,   415,  1474,   302,
         5939,   721,  1549,   349,  2795,   272,  1474,   302,   940,   311,
         1074,   304,  2502,  1593,  3886,   582, 28725,   304,   736,   460,
        28705, 28770, 16130,   686,  1169,  5895,   821,  5939,   721,  1549,
        28723,  1824,   349,   272,  5133,   297,  1474,  1444,   272,   686,
         1169,  5895,   304,   272,  1326,  6798, 28804, 28705,     2,   415,
          686,  3464,   659, 28705, 28783,  1318, 28705, 28770,   327,  2087,
        28783, 28736, 28770, 28746, 28750, 28781,  4060, 28750, 28781,  2502,
         1593, 28723,   661,   659, 28705, 28750, 28781,  1318, 28705, 28750,
          327,  2087, 28750, 28781, 28736, 28750, 28746, 28781, 28783,  4060,
        28781, 28783,  1326,  6798, 28723,   415,  1474,   302,   940,   311,
         1074,   304,  2502,  1593,  3886,   582,   349, 28705, 28783,   648,
        28705, 28750, 28781,   327,  2087, 28783, 28806, 28750, 28781, 28746,
        28770, 28750,  4060, 28770, 28750,  1387,   460, 28705, 28770, 28750,
        28748, 28750,   327,  2087, 28770, 28750, 28748, 28750, 28746, 28740,
        28784,  4060, 28740, 28784,  5939,   721,  1549, 28723,  1387,   460,
        28705, 28740, 28784,   387, 28705, 28770,   327,  2087, 28740, 28784,
        28733, 28770, 28746, 28740, 28770,  4060, 28740, 28770,   686,  1169,
         5895, 28723,   415,  5133,  1444,   686,  1169,  5895,   304,  1326,
         6798,   349, 28705, 28781, 28783,   387, 28705, 28740, 28770,   327,
         2087, 28781, 28783, 28733, 28740, 28770, 28746, 28770, 28782,  4060,
        28770, 28782, 28705,     2,  2476, 28770, 28782, 28705,     2],
       device='cuda:0')
B-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,   415,
          686,  3464,   659, 28705, 28783,  1318, 28705, 28770,   327,  2087,
        28783, 28736, 28770, 28746, 28750, 28781,  4060, 28750, 28781,  2502,
         1593, 28723,   661,   659, 28705, 28750, 28781,  1318, 28705, 28750,
          327,  2087, 28750, 28781, 28736, 28750, 28746, 28781, 28783,  4060,
        28781, 28783,  1326,  6798, 28723,   415,  1474,   302,   940,   311,
         1074,   304,  2502,  1593,  3886,   582,   349, 28705, 28783,   648,
        28705, 28750, 28781,   327,  2087, 28783, 28806, 28750, 28781, 28746,
        28770, 28750,  4060, 28770, 28750,  1387,   460, 28705, 28770, 28750,
        28748, 28750,   327,  2087, 28770, 28750, 28748, 28750, 28746, 28740,
        28784,  4060, 28740, 28784,  5939,   721,  1549, 28723,  1387,   460,
        28705, 28740, 28784,   387, 28705, 28770,   327,  2087, 28740, 28784,
        28733, 28770, 28746, 28740, 28770,  4060, 28740, 28770,   686,  1169,
         5895, 28723,   415,  5133,  1444,   686,  1169,  5895,   304,  1326,
         6798,   349, 28705, 28781, 28783,   387, 28705, 28740, 28770,   327,
         2087, 28781, 28783, 28733, 28740, 28770, 28746, 28770, 28782,  4060,
        28770, 28782, 28705,     2,  2476, 28770, 28782, 28705,     2],
       device='cuda:0')
[tensor([[  415,   686,  3464,   659, 28705, 28783,  1318, 28705, 28770,   327,
          2087, 28783, 28736, 28770, 28746, 28750, 28781,  4060, 28750, 28781,
          2502,  1593, 28723]], device='cuda:0'), tensor([[  661,   659, 28705, 28750, 28781,  1318, 28705, 28750,   327,  2087,
         28750, 28781, 28736, 28750, 28746, 28781, 28783,  4060, 28781, 28783,
          1326,  6798, 28723]], device='cuda:0'), tensor([[  415,  1474,   302,   940,   311,  1074,   304,  2502,  1593,  3886,
           582,   349, 28705, 28783,   648, 28705, 28750, 28781,   327,  2087,
         28783, 28806, 28750, 28781, 28746, 28770, 28750,  4060, 28770, 28750,
          1387,   460, 28705, 28770, 28750, 28748, 28750,   327,  2087, 28770,
         28750, 28748, 28750, 28746, 28740, 28784,  4060, 28740, 28784,  5939,
           721,  1549, 28723]], device='cuda:0'), tensor([[ 1387,   460, 28705, 28740, 28784,   387, 28705, 28770,   327,  2087,
         28740, 28784, 28733, 28770, 28746, 28740, 28770,  4060, 28740, 28770,
           686,  1169,  5895, 28723,   415,  5133,  1444,   686,  1169,  5895,
           304,  1326,  6798,   349, 28705, 28781, 28783,   387, 28705, 28740,
         28770,   327,  2087, 28781, 28783, 28733, 28740, 28770, 28746, 28770,
         28782,  4060, 28770, 28782, 28705,     2]], device='cuda:0')]
REMOVE TEST?! 0 0 1.2671232876712328
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.4799, 12.1084, 10.1691, 10.1545, 10.1545,
         10.3737]], device='cuda:1')
REMOVE TEST?! 2 0 0.9606164383561644
Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735,  9.2901, 24.5740,
         11.6460]], device='cuda:2')
REMOVE TEST?! 3 0 1.2876712328767124
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3917, 10.3474, 10.1508, 10.3029, 10.3029,
         10.3738]], device='cuda:1')
[]
REMOVE TEST?! 0 0 1.601027397260274
tensor([[10.3733, 10.3743, 10.3517, 10.3500, 10.3500, 10.3500, 10.3500, 10.3500,
         10.3738]], device='cuda:0')
REMOVE TEST?! 1 0 1.2671232876712328
Cross Entropy List Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.3736,  9.5240, 25.2010,
         10.1717]], device='cuda:2')
[3]
REMOVE TEST?! 0 0 0.9657534246575343
Cross Entropy List tensor([[10.3730, 10.3730, 10.3730, 10.3742, 10.5736, 10.1590, 10.2148, 10.2148,
         10.3737]], device='cuda:1')
REMOVE TEST?! 1 1 1.601027397260274
tensor([[10.3733, 10.3842, 10.4215, 10.1477, 10.1477, 10.1477, 10.1477, 10.1477,
         10.3731]], device='cuda:0')
REMOVE TEST?! 2 0 1.2671232876712328
Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735,  9.6143, 27.2298,
         11.6971]], device='cuda:2')
[0]
tensor([[10.3737, 10.3737, 10.3737, 10.4299, 10.9103, 10.1461, 10.1637, 10.1637,
         10.3738]], device='cuda:1')
REMOVE TEST?! 2 1 1.601027397260274
tensor([[10.3733, 10.3880, 10.4527, 10.1687, 10.1687, 10.1687, 10.1687, 10.1687,
         10.3732]], device='cuda:0')
REMOVE TEST?! 3 0 1.2671232876712328
Cross Entropy List Cross Entropy List Loss tensor(8.8025, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor([[10.3737, 10.3737, 10.3736, 10.4266, 10.9408, 10.1541, 10.1676, 10.1676,
         10.3738]], device='cuda:1')
REMOVE TEST?! 3 1 1.601027397260274
tensor([[10.3733, 10.3877, 10.4673, 10.1814, 10.1814, 10.1814, 10.1814, 10.1814,
         10.3732]], device='cuda:0')
[]
REMOVE TEST?! 0 0 0.9503424657534246
Cross Entropy List Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.4602, 10.6937, 10.1646, 10.1809, 10.1809,
         10.3737]], device='cuda:1')
REMOVE TEST?! 4 1 1.601027397260274
tensor([[10.3734, 10.3857, 10.4469, 10.2724, 10.2723, 10.2723, 10.2723, 10.2723,
         10.3735]], device='cuda:0')
REMOVE TEST?! 1 0 0.9503424657534246
Cross Entropy List Cross Entropy List Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5606706738471985
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17423394322395325
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1305081993341446
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13218334317207336
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13419915735721588
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13648664951324463
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13541674613952637
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13174916803836823
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13081951439380646
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12304258346557617
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14354589581489563
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14107327163219452
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14175216853618622
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1424298733472824
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14081276953220367
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13958077132701874
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13634023070335388
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13479596376419067
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1310541331768036
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1311107575893402
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13343504071235657
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13559341430664062
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13572292029857635
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20325002074241638
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13377170264720917
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13472606241703033
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14491362869739532
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14496786892414093
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14836566150188446
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15189863741397858
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15338367223739624
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1516132354736328
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15502889454364777
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1369091421365738
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1285194307565689
 32%|███▏      | 188/584 [19:27<20:58,  3.18s/it]REMOVE TEST?! 0 0 1.618150684931507
tensor([[10.3735, 10.3735, 10.3735, 10.4297, 10.8267, 10.1590, 10.1855, 10.1855,
         10.3737]], device='cuda:1')
[0, 4]
tensor([[10.3735, 10.3968, 10.4959, 10.2328, 10.2328, 10.2328, 10.2328, 10.2328,
         10.3734]], device='cuda:0')
REMOVE TEST?! 2 0 0.9503424657534246
Cross Entropy List Cross Entropy List Loss tensor([[10.3737, 10.3737, 10.3737, 10.3737, 10.3737, 10.3737, 10.4048, 12.7885,
         25.4270]], device='cuda:2')
REMOVE TEST?! 1 0 1.618150684931507
tensor(10.3736, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor([[10.3735, 10.3927, 10.4841, 10.2352, 10.2352, 10.2352, 10.2352, 10.2352,
         10.3734]], device='cuda:0')
[]
REMOVE TEST?! 0 0 0.3167808219178082
Cross Entropy List Cross Entropy List tensor([[10.3737, 10.3737, 10.3737, 10.3737, 10.3737, 10.3737,  9.9852,  9.4381,
         16.9598]], device='cuda:2')
REMOVE TEST?! 2 1 1.618150684931507
tensor([[10.3733, 10.3900, 10.4536, 10.1560, 10.1560, 10.1560, 10.1560, 10.1560,
         10.3734]], device='cuda:0')
[]
REMOVE TEST?! 0 0 0.6335616438356164
Cross Entropy List Cross Entropy List tensor([[10.3737, 10.3737, 10.3737, 10.3737, 10.3737, 10.3737, 10.3359, 13.8549,
         26.8296]], device='cuda:2')
[1, 2]
REMOVE TEST?! 0 0 0.3236301369863014
tensor([[10.3734, 10.3812, 10.3698, 10.2006, 10.2006, 10.2006, 10.2006, 10.2006,
         10.3733]], device='cuda:0')
REMOVE TEST?! 1 0 0.6335616438356164
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.42555439472198486
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13476528227329254
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15259340405464172
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16237860918045044
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1611402928829193
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15814074873924255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15534734725952148
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1552385538816452
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15683704614639282
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1578349769115448
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1571602076292038
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15841913223266602
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15596990287303925
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15494604408740997
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15358512103557587
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15272626280784607
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15362615883350372
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15599095821380615
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15634572505950928
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15685391426086426
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16175851225852966
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1591060906648636
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15608763694763184
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15541036427021027
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15525178611278534
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1577000617980957
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15799260139465332
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15810927748680115
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15693004429340363
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15536701679229736
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15451112389564514
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15232758224010468
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1520809382200241
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15583814680576324
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13476522266864777
 32%|███▏      | 187/584 [19:23<30:20,  4.59s/it]REMOVE TEST?! 0 0 0.3219178082191781
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.0567, 11.2455,
         25.9335]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.9708904109589042
tensor([[10.3733, 10.3853, 10.4413, 10.2294, 10.2294, 10.2294, 10.2294, 10.2294,
         10.3733]], device='cuda:0')
[]
After Process
A-INPUT tensor([    1,   330,   686,  3464,   659, 28705, 28783,   940,   311,  1074,
        28723,   661, 28705, 28770,  2421,   272,  1474,   302,  2502,  1593,
          821,   940,   311,  1074,   304, 28705, 28750,  2421,   272,  1474,
          302,  1326,  6798,   821,  2502,  1593, 28723,   415,  1474,   302,
         5939,   721,  1549,   349,  2795,   272,  1474,   302,   940,   311,
         1074,   304,  2502,  1593,  3886,   582, 28725,   304,   736,   460,
        28705, 28770, 16130,   686,  1169,  5895,   821,  5939,   721,  1549,
        28723,  1824,   349,   272,  5133,   297,  1474,  1444,   272,   686,
         1169,  5895,   304,   272,  1326,  6798, 28804, 28705,     2,   415,
          686,  3464,   659, 28705, 28783,  1318, 28705, 28770,   327,  2087,
        28783, 28736, 28770, 28746, 28750, 28781,  4060, 28750, 28781,  2502,
         1593, 28723,   661,   659, 28705, 28750, 28781,  1318, 28705, 28750,
          327,  2087, 28750, 28781, 28736, 28750, 28746, 28781, 28783,  4060,
        28781, 28783,  1326,  6798, 28723,   415,  1474,   302,   940,   311,
         1074,   304,  2502,  1593,  3886,   582,   349, 28705, 28783,   648,
        28705, 28750, 28781,   327,  2087, 28783, 28806, 28750, 28781, 28746,
        28770, 28750,  4060, 28770, 28750,  1387,   460, 28705, 28770, 28750,
        28748, 28750,   327,  2087, 28770, 28750, 28748, 28750, 28746, 28740,
        28784,  4060, 28740, 28784,  5939,   721,  1549, 28723,  1387,   460,
        28705, 28740, 28784,   387, 28705, 28770,   327,  2087, 28740, 28784,
        28733, 28770, 28746, 28740, 28770,  4060, 28740, 28770,   686,  1169,
         5895, 28723,   415,  5133,  1444,   686,  1169,  5895,   304,  1326,
         6798,   349, 28705, 28781, 28783,   387, 28705, 28740, 28770,   327,
         2087, 28781, 28783, 28733, 28740, 28770, 28746, 28770, 28782,  4060,
        28770, 28782, 28705,     2,  2476, 28770, 28782, 28705,     2],
       device='cuda:0')
A-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,   415,
          686,  3464,   659, 28705, 28783,  1318, 28705, 28770,   327,  2087,
        28783, 28736, 28770, 28746, 28750, 28781,  4060, 28750, 28781,  2502,
         1593, 28723,   661,   659, 28705, 28750, 28781,  1318, 28705, 28750,
          327,  2087, 28750, 28781, 28736, 28750, 28746, 28781, 28783,  4060,
        28781, 28783,  1326,  6798, 28723,   415,  1474,   302,   940,   311,
         1074,   304,  2502,  1593,  3886,   582,   349, 28705, 28783,   648,
        28705, 28750, 28781,   327,  2087, 28783, 28806, 28750, 28781, 28746,
        28770, 28750,  4060, 28770, 28750,  1387,   460, 28705, 28770, 28750,
        28748, 28750,   327,  2087, 28770, 28750, 28748, 28750, 28746, 28740,
        28784,  4060, 28740, 28784,  5939,   721,  1549, 28723,  1387,   460,
        28705, 28740, 28784,   387, 28705, 28770,   327,  2087, 28740, 28784,
        28733, 28770, 28746, 28740, 28770,  4060, 28740, 28770,   686,  1169,
         5895, 28723,   415,  5133,  1444,   686,  1169,  5895,   304,  1326,
         6798,   349, 28705, 28781, 28783,   387, 28705, 28740, 28770,   327,
         2087, 28781, 28783, 28733, 28740, 28770, 28746, 28770, 28782,  4060,
        28770, 28782, 28705,     2,  2476, 28770, 28782, 28705,     2],
       device='cuda:0')
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3755, 10.0619, 11.5420, 10.4915, 10.4915,
         10.3724]], device='cuda:1')
[0]
REMOVE TEST?! 0 0 0.9657534246575343
Loss Cross Entropy List tensor([[10.3738, 10.3738, 10.3738, 10.3738, 10.3738, 10.3738, 10.4442, 15.1035,
         26.8016]], device='cuda:2')
[0]
REMOVE TEST?! 0 0 2.2654109589041096
tensor(10.3734, device='cuda:0', grad_fn=<NllLossBackward0>)
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.4323, 10.1649, 10.7441, 10.4149, 10.4149,
         10.3730]], device='cuda:1')
REMOVE TEST?! 1 0 0.9657534246575343
Cross Entropy List tensor([[10.3737, 10.3737, 10.3737, 10.3737, 10.3737, 10.3737, 10.5726, 10.0262,
          9.3494]], device='cuda:2')
REMOVE TEST?! 1 1 2.2654109589041096
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3668, 10.5503, 11.1468, 12.6275, 12.6275,
         10.3734]], device='cuda:1')
REMOVE TEST?! 2 0 0.9657534246575343
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.0161, 10.4911,
         23.9357]], device='cuda:2')
REMOVE TEST?! 2 2 2.2654109589041096
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4290107488632202
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.135981947183609
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15715378522872925
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15849615633487701
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15568779408931732
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15439940989017487
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15251578390598297
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15114811062812805
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15211839973926544
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15493790805339813
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15863588452339172
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1673274040222168
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16131310164928436
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15686289966106415
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15405374765396118
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15372419357299805
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1541074812412262
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15778808295726776
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1578618288040161
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1581166386604309
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1563800424337387
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15512853860855103
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15344959497451782
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1510103940963745
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15057557821273804
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15411168336868286
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1574310064315796
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15622325241565704
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16328047215938568
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1584574580192566
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15519091486930847
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15349754691123962
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15364748239517212
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15680967271327972
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1359819620847702
 32%|███▏      | 185/584 [19:27<30:18,  4.56s/it]Before Process
B-INPUT tensor([    1, 12040,   659,   264,  9783, 17961,  1344,   304, 24928,   298,
         3848,   741,  3358, 20430,   404,   477,   272,  4143, 28723, 28705,
          650, 23380,   582,   264, 10859,   302, 28705, 28782, 28734, 19436,
          304,  4347,   706,  1611, 28723, 28705,   650,  4347, 28705, 28750,
        19436,  1430,  1370,  1712,  2421,   264,  1370,   354,   272,   907,
        28705, 28750,  2202, 28725,  1159, 12164,   456,  3558,   297,  2795,
          354,   272,  1679, 28705, 28770,  2202, 28723, 28705,  1418,   272,
        20865,  1370, 28725,   400,  4347,   264,  1480, 28705, 28750, 19436,
          297,   272,  3970,   304,  9675,   582,  4622,  1873, 28723, 28705,
         1602,  1287, 19436,   460,  1749,   297,   272, 10859, 28804, 28705,
            2, 12040,  8383,   395, 28705, 28782, 28734, 19436,   304,  4347,
        28705, 28750, 19436,  1430, 28705, 28770,  2421,   264,  1370, 28725,
         5746,   400,  4347, 28705, 28750, 28736, 28770, 28746, 28784, 19436,
          297,  3102, 28723, 12040,  5683,  1449,   456,  1759,   354,   989,
         2202,   297,  3102, 28725,  5746,   754,  1395,   989,  2202,   400,
         4347, 28705, 28750, 28736, 28784, 28746,  2087, 28750, 28736, 28784,
        28746, 28740, 28750,  4060, 28740, 28750, 19436, 12040,   868, 15981,
         1060,   516, 10837, 11753,   297,  2795, 28725,  5746,   400, 28742,
        28713,  1055,  3344, 28705, 28784, 28748, 28750, 28746,  2087, 28784,
        28748, 28750, 28746, 28770,  4060, 28770, 19436,   264,  1370, 28723,
         4577,   400,  5683,  1449,   456,  1759,   354,  1712,  2202, 28725,
          369,  2825,   400,  4347, 28705, 28770, 28736, 28770, 28746,  2087,
        28770, 28736, 28770, 28746, 28774,  4060, 28774, 19436,   354,   369,
         3216, 28723,  3301,   288,   297,   272,   989, 19436, 12040,  2056,
          356,   272,  1480,  1370, 28725,   369,  2825,   400,  2056, 28705,
        28740, 28750, 28806, 28774, 28806, 28750, 28746,  5275, 28740, 28750,
        28806, 28774, 28806, 28750, 28746, 28750, 28770,  4060, 28750, 28770,
        19436, 28723,  4577,   736,   654, 28705, 28782, 28734, 19436,   297,
          272, 10859,   298,  2839,   395, 28725,   456,  2825, 12040,   659,
        28705, 28782, 28734, 28733, 28750, 28770, 28746,  5275, 28782, 28734,
        28733, 28750, 28770, 28746, 28750, 28787,  4060, 28750, 28787, 19436,
         8409, 28723, 28705,     2,  2476, 28750, 28787, 28705,     2],
       device='cuda:0')
B-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100, 12040,  8383,   395, 28705, 28782, 28734, 19436,   304,  4347,
        28705, 28750, 19436,  1430, 28705, 28770,  2421,   264,  1370, 28725,
         5746,   400,  4347, 28705, 28750, 28736, 28770, 28746, 28784, 19436,
          297,  3102, 28723, 12040,  5683,  1449,   456,  1759,   354,   989,
         2202,   297,  3102, 28725,  5746,   754,  1395,   989,  2202,   400,
         4347, 28705, 28750, 28736, 28784, 28746,  2087, 28750, 28736, 28784,
        28746, 28740, 28750,  4060, 28740, 28750, 19436, 12040,   868, 15981,
         1060,   516, 10837, 11753,   297,  2795, 28725,  5746,   400, 28742,
        28713,  1055,  3344, 28705, 28784, 28748, 28750, 28746,  2087, 28784,
        28748, 28750, 28746, 28770,  4060, 28770, 19436,   264,  1370, 28723,
         4577,   400,  5683,  1449,   456,  1759,   354,  1712,  2202, 28725,
          369,  2825,   400,  4347, 28705, 28770, 28736, 28770, 28746,  2087,
        28770, 28736, 28770, 28746, 28774,  4060, 28774, 19436,   354,   369,
         3216, 28723,  3301,   288,   297,   272,   989, 19436, 12040,  2056,
          356,   272,  1480,  1370, 28725,   369,  2825,   400,  2056, 28705,
        28740, 28750, 28806, 28774, 28806, 28750, 28746,  5275, 28740, 28750,
        28806, 28774, 28806, 28750, 28746, 28750, 28770,  4060, 28750, 28770,
        19436, 28723,  4577,   736,   654, 28705, 28782, 28734, 19436,   297,
          272, 10859,   298,  2839,   395, 28725,   456,  2825, 12040,   659,
        28705, 28782, 28734, 28733, 28750, 28770, 28746,  5275, 28782, 28734,
        28733, 28750, 28770, 28746, 28750, 28787,  4060, 28750, 28787, 19436,
         8409, 28723, 28705,     2,  2476, 28750, 28787, 28705,     2],
       device='cuda:0')
[tensor([[12040,  8383,   395, 28705, 28782, 28734, 19436,   304,  4347, 28705,
         28750, 19436,  1430, 28705, 28770,  2421,   264,  1370, 28725,  5746,
           400,  4347, 28705, 28750, 28736, 28770, 28746, 28784, 19436,   297,
          3102, 28723]], device='cuda:0'), tensor([[12040,  5683,  1449,   456,  1759,   354,   989,  2202,   297,  3102,
         28725,  5746,   754,  1395,   989,  2202,   400,  4347, 28705, 28750,
         28736, 28784, 28746,  2087, 28750, 28736, 28784, 28746, 28740, 28750,
          4060, 28740, 28750, 19436, 12040,   868, 15981,  1060,   516, 10837,
         11753,   297,  2795, 28725,  5746,   400, 28742, 28713,  1055,  3344,
         28705, 28784, 28748, 28750, 28746,  2087, 28784, 28748, 28750, 28746,
         28770,  4060, 28770, 19436,   264,  1370, 28723]], device='cuda:0'), tensor([[ 4577,   400,  5683,  1449,   456,  1759,   354,  1712,  2202, 28725,
           369,  2825,   400,  4347, 28705, 28770, 28736, 28770, 28746,  2087,
         28770, 28736, 28770, 28746, 28774,  4060, 28774, 19436,   354,   369,
          3216, 28723]], device='cuda:0'), tensor([[ 3301,   288,   297,   272,   989, 19436, 12040,  2056,   356,   272,
          1480,  1370, 28725,   369,  2825,   400,  2056, 28705, 28740, 28750,
         28806, 28774, 28806, 28750, 28746,  5275, 28740, 28750, 28806, 28774,
         28806, 28750, 28746, 28750, 28770,  4060, 28750, 28770, 19436, 28723]],
       device='cuda:0'), tensor([[ 4577,   736,   654, 28705, 28782, 28734, 19436,   297,   272, 10859,
           298,  2839,   395, 28725,   456,  2825, 12040,   659, 28705, 28782,
         28734, 28733, 28750, 28770, 28746,  5275, 28782, 28734, 28733, 28750,
         28770, 28746, 28750, 28787,  4060, 28750, 28787, 19436,  8409, 28723,
         28705,     2]], device='cuda:0')]
REMOVE TEST?! 0 0 1.5924657534246576
Cross Entropy List tensor([[10.3735, 10.3734, 10.3734, 10.5092, 11.6252, 10.2103, 10.1966, 10.1966,
         10.3735]], device='cuda:1')
[]
REMOVE TEST?! 0 0 0.9657534246575343
Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.1267,  9.6616,
          9.4328]], device='cuda:2')
REMOVE TEST?! 3 2 2.2654109589041096
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3873, 10.2979, 10.1411, 10.3029, 10.3029,
         10.3727]], device='cuda:1')
[0]
REMOVE TEST?! 0 0 0.6438356164383562
tensor([[10.3734, 10.4032, 10.3918, 10.3824, 10.3824, 10.3824, 10.3824, 10.3824,
         10.3741]], device='cuda:0')
REMOVE TEST?! 1 1 1.5924657534246576
Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 12.6300, 14.8447,
         15.1155]], device='cuda:2')
[0, 1, 3]
tensor([[10.3731, 10.3731, 10.3731, 10.3824, 10.8577, 10.0554, 10.0821, 10.0821,
         10.3732]], device='cuda:1')
[0]
Loss tensor([[10.3732, 10.3879, 10.4253, 10.1496, 10.1496, 10.1496, 10.1496, 10.1496,
         10.3733]], device='cuda:0')
REMOVE TEST?! 2 1 1.5924657534246576
Cross Entropy List Loss tensor(24.2640, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(10.3729, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor([[10.3732, 10.3882, 10.4355, 10.1570, 10.1570, 10.1570, 10.1570, 10.1570,
         10.3733]], device='cuda:0')
REMOVE TEST?! 3 1 1.5924657534246576
Cross Entropy List tensor([[10.3733, 10.3949, 10.4724, 10.1799, 10.1799, 10.1800, 10.1800, 10.1799,
         10.3733]], device='cuda:0')
REMOVE TEST?! 4 1 1.5924657534246576
Cross Entropy List Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.46865275502204895
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13747066259384155
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1432606279850006
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1450166255235672
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1472625732421875
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14972779154777527
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14868570864200592
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14480093121528625
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14360496401786804
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13696011900901794
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1576346457004547
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15492337942123413
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15566806495189667
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15641063451766968
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1546355038881302
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15328654646873474
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14973251521587372
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14803928136825562
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14393575489521027
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14399883151054382
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14654764533042908
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1489381194114685
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1490887999534607
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15806211531162262
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14461715519428253
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14721904695034027
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15845800936222076
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1584755778312683
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.160798117518425
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16312532126903534
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16393034160137177
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16234946250915527
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1599702388048172
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14959856867790222
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15893791615962982
 32%|███▏      | 189/584 [19:30<21:16,  3.23s/it]REMOVE TEST?! 0 0 1.6267123287671235
tensor([[10.3733, 10.3948, 10.4648, 10.1859, 10.1859, 10.1859, 10.1859, 10.1859,
         10.3733]], device='cuda:0')
[0]
REMOVE TEST?! 0 0 1.910958904109589
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.25449123978614807
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08112625777721405
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09251006692647934
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11463870108127594
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10754672437906265
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10803376883268356
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8515103459358215
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0040113674476742744
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003770916722714901
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.003741833148524165
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007089680060744286
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08023287355899811
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08306553959846497
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08322097361087799
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08291454613208771
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08275274187326431
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08164283633232117
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08056926727294922
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08119863271713257
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08092918992042542
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08164927363395691
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.082274429500103
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08234906941652298
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08263348042964935
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08289030939340591
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08353880047798157
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08418667316436768
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08397717028856277
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08350396156311035
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08406627923250198
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08386477828025818
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09033487737178802
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0836617574095726
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.082603819668293
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.013199908658862114
 32%|███▏      | 188/584 [19:25<25:38,  3.89s/it]REMOVE TEST?! 0 0 0.3236301369863014
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.0871,  9.8032,
         10.3071]], device='cuda:2')
REMOVE TEST?! 1 0 1.6267123287671235
tensor([[10.3734, 10.3984, 10.4782, 10.1952, 10.1952, 10.1952, 10.1952, 10.1952,
         10.3733]], device='cuda:0')
REMOVE TEST?! 1 0 1.910958904109589
Cross Entropy List Cross Entropy List tensor([[10.3738, 10.3738, 10.3738, 10.3850, 10.0434, 11.4449, 11.0367, 11.0366,
         10.3735]], device='cuda:1')
[]
REMOVE TEST?! 0 0 1.618150684931507
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.2255, 10.5576,
         24.3442]], device='cuda:2')
REMOVE TEST?! 2 1 1.6267123287671235
tensor([[10.3733, 10.3984, 10.4920, 10.1704, 10.1704, 10.1704, 10.1704, 10.1704,
         10.3733]], device='cuda:0')
REMOVE TEST?! 2 0 1.910958904109589
Cross Entropy List Cross Entropy List tensor([[10.3732, 10.3732, 10.3732, 10.4101, 10.1094, 10.3284, 10.1975, 10.1975,
         10.3734]], device='cuda:1')
REMOVE TEST?! 1 0 1.618150684931507
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.2008, 10.4866,
         24.2515]], device='cuda:2')
[1, 2]
REMOVE TEST?! 0 0 0.6506849315068494
tensor([[10.3733, 10.3938, 10.4823, 10.1809, 10.1809, 10.1809, 10.1809, 10.1809,
         10.3734]], device='cuda:0')
REMOVE TEST?! 3 0 1.910958904109589
Cross Entropy List Cross Entropy List tensor([[10.3733, 10.3733, 10.3733, 10.4137, 10.1011, 10.3253, 10.2070, 10.2071,
         10.3734]], device='cuda:1')
REMOVE TEST?! 2 0 1.618150684931507
Cross Entropy List tensor([[10.3737, 10.3737, 10.3737, 10.3737, 10.3737, 10.3737, 10.2030, 10.2813,
         25.9047]], device='cuda:2')
REMOVE TEST?! 1 0 0.6506849315068494
tensor([[10.3734, 10.3954, 10.4990, 10.1970, 10.1970, 10.1970, 10.1970, 10.1970,
         10.3734]], device='cuda:0')
REMOVE TEST?! 4 0 1.910958904109589
Cross Entropy List Cross Entropy List tensor([[10.3733, 10.3733, 10.3733, 10.4162, 10.1084, 10.3365, 10.2222, 10.2222,
         10.3734]], device='cuda:1')
REMOVE TEST?! 3 0 1.618150684931507
Cross Entropy List tensor([[10.3737, 10.3737, 10.3737, 10.3737, 10.3737, 10.3737, 10.1461, 10.1095,
         25.3379]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.6506849315068494
tensor([[10.3734, 10.3973, 10.5106, 10.2012, 10.2012, 10.2012, 10.2012, 10.2012,
         10.3735]], device='cuda:0')
REMOVE TEST?! 5 0 1.910958904109589
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.4169, 10.1117, 10.3359, 10.2220, 10.2220,
         10.3734]], device='cuda:1')
REMOVE TEST?! 4 0 1.618150684931507
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.1159,  9.9625,
         24.7297]], device='cuda:2')
REMOVE TEST?! 1 0 0.6506849315068494
tensor([[10.3734, 10.3976, 10.5165, 10.2053, 10.2053, 10.2053, 10.2053, 10.2053,
         10.3735]], device='cuda:0')
[]
REMOVE TEST?! 0 0 0.636986301369863
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.4158, 10.1001, 10.3274, 10.2146, 10.2146,
         10.3734]], device='cuda:1')
[]
REMOVE TEST?! 0 0 0.3236301369863014
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.0093,  9.7167,
         24.2112]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.3253424657534247
tensor([[10.3733, 10.3897, 10.3840, 10.1727, 10.1727, 10.1727, 10.1727, 10.1727,
         10.3732]], device='cuda:0')
[0]
REMOVE TEST?! 0 0 1.273972602739726
Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3734, 10.3734, 10.3756, 10.1010, 10.3215, 10.2195, 10.2195,
         10.3734]], device='cuda:1')
[]
REMOVE TEST?! 0 0 0.3236301369863014
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.0383, 10.0159,
         23.3749]], device='cuda:2')
[]
tensor([[10.3732, 10.3841, 10.4136, 10.1857, 10.1857, 10.1857, 10.1857, 10.1857,
         10.3734]], device='cuda:0')
REMOVE TEST?! 1 0 1.273972602739726
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3573, 10.1162, 10.5032, 10.3817, 10.3817,
         10.3735]], device='cuda:1')
[]
Loss Loss tensor(23.7552, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor([[10.3732, 10.3862, 10.4374, 10.1974, 10.1974, 10.1974, 10.1974, 10.1974,
         10.3734]], device='cuda:0')
REMOVE TEST?! 2 0 1.273972602739726
Cross Entropy List tensor(10.3735, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor([[10.3731, 10.3895, 10.4726, 10.2171, 10.2171, 10.2171, 10.2171, 10.2171,
         10.3734]], device='cuda:0')
REMOVE TEST?! 3 0 1.273972602739726
Cross Entropy List tensor([[10.3732, 10.3943, 10.4951, 10.1919, 10.1919, 10.1919, 10.1919, 10.1919,
         10.3733]], device='cuda:0')
[]
After Process
A-INPUT tensor([    1, 12040,   659,   264,  9783, 17961,  1344,   304, 24928,   298,
         3848,   741,  3358, 20430,   404,   477,   272,  4143, 28723, 28705,
          650, 23380,   582,   264, 10859,   302, 28705, 28782, 28734, 19436,
          304,  4347,   706,  1611, 28723, 28705,   650,  4347, 28705, 28750,
        19436,  1430,  1370,  1712,  2421,   264,  1370,   354,   272,   907,
        28705, 28750,  2202, 28725,  1159, 12164,   456,  3558,   297,  2795,
          354,   272,  1679, 28705, 28770,  2202, 28723, 28705,  1418,   272,
        20865,  1370, 28725,   400,  4347,   264,  1480, 28705, 28750, 19436,
          297,   272,  3970,   304,  9675,   582,  4622,  1873, 28723, 28705,
         1602,  1287, 19436,   460,  1749,   297,   272, 10859, 28804, 28705,
            2, 12040,  5683,  1449,   456,  1759,   354,   989,  2202,   297,
         3102, 28725,  5746,   754,  1395,   989,  2202,   400,  4347, 28705,
        28750, 28736, 28784, 28746,  2087, 28750, 28736, 28784, 28746, 28740,
        28750,  4060, 28740, 28750, 19436, 12040,   868, 15981,  1060,   516,
        10837, 11753,   297,  2795, 28725,  5746,   400, 28742, 28713,  1055,
         3344, 28705, 28784, 28748, 28750, 28746,  2087, 28784, 28748, 28750,
        28746, 28770,  4060, 28770, 19436,   264,  1370, 28723,  4577,   400,
         5683,  1449,   456,  1759,   354,  1712,  2202, 28725,   369,  2825,
          400,  4347, 28705, 28770, 28736, 28770, 28746,  2087, 28770, 28736,
        28770, 28746, 28774,  4060, 28774, 19436,   354,   369,  3216, 28723,
         3301,   288,   297,   272,   989, 19436, 12040,  2056,   356,   272,
         1480,  1370, 28725,   369,  2825,   400,  2056, 28705, 28740, 28750,
        28806, 28774, 28806, 28750, 28746,  5275, 28740, 28750, 28806, 28774,
        28806, 28750, 28746, 28750, 28770,  4060, 28750, 28770, 19436, 28723,
         4577,   736,   654, 28705, 28782, 28734, 19436,   297,   272, 10859,
          298,  2839,   395, 28725,   456,  2825, 12040,   659, 28705, 28782,
        28734, 28733, 28750, 28770, 28746,  5275, 28782, 28734, 28733, 28750,
        28770, 28746, 28750, 28787,  4060, 28750, 28787, 19436,  8409, 28723,
        28705,     2,  2476, 28750, 28787, 28705,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2], device='cuda:0')
A-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100, 12040,  5683,  1449,   456,  1759,   354,   989,  2202,   297,
         3102, 28725,  5746,   754,  1395,   989,  2202,   400,  4347, 28705,
        28750, 28736, 28784, 28746,  2087, 28750, 28736, 28784, 28746, 28740,
        28750,  4060, 28740, 28750, 19436, 12040,   868, 15981,  1060,   516,
        10837, 11753,   297,  2795, 28725,  5746,   400, 28742, 28713,  1055,
         3344, 28705, 28784, 28748, 28750, 28746,  2087, 28784, 28748, 28750,
        28746, 28770,  4060, 28770, 19436,   264,  1370, 28723,  4577,   400,
         5683,  1449,   456,  1759,   354,  1712,  2202, 28725,   369,  2825,
          400,  4347, 28705, 28770, 28736, 28770, 28746,  2087, 28770, 28736,
        28770, 28746, 28774,  4060, 28774, 19436,   354,   369,  3216, 28723,
         3301,   288,   297,   272,   989, 19436, 12040,  2056,   356,   272,
         1480,  1370, 28725,   369,  2825,   400,  2056, 28705, 28740, 28750,
        28806, 28774, 28806, 28750, 28746,  5275, 28740, 28750, 28806, 28774,
        28806, 28750, 28746, 28750, 28770,  4060, 28750, 28770, 19436, 28723,
         4577,   736,   654, 28705, 28782, 28734, 19436,   297,   272, 10859,
          298,  2839,   395, 28725,   456,  2825, 12040,   659, 28705, 28782,
        28734, 28733, 28750, 28770, 28746,  5275, 28782, 28734, 28733, 28750,
        28770, 28746, 28750, 28787,  4060, 28750, 28787, 19436,  8409, 28723,
        28705,     2,  2476, 28750, 28787, 28705,     2,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100], device='cuda:0')
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8618011474609375
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1348118633031845
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026839029043912888
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0269082672894001
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027049388736486435
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02706102281808853
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02684168517589569
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026243386790156364
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025873010978102684
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02533327415585518
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024830279871821404
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025127118453383446
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025516264140605927
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025943420827388763
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02576286531984806
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025089746341109276
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024882519617676735
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023731164634227753
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02731345035135746
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026843668892979622
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026972699910402298
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027101365849375725
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.026793789118528366
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4144119322299957
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09969661384820938
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0915980264544487
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07429691404104233
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08383813500404358
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09036751836538315
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.054906465113162994
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05713709443807602
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05601757392287254
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.051226504147052765
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.033959075808525085
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.028721241280436516
 33%|███▎      | 190/584 [19:33<19:23,  2.95s/it]REMOVE TEST?! 0 0 0.3270547945205479
Loss Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09388096630573273
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029924292117357254
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03414700925350189
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4708656072616577
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4505195617675781
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.42853856086730957
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.38490593433380127
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06398051232099533
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05950357764959335
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06142616271972656
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05045007914304733
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029615173116326332
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030659379437565804
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03071601130068302
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030602952465415
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03054347261786461
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030134303495287895
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02973846159875393
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029952723532915115
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029842710122466087
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030114779248833656
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03034241497516632
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03037004917860031
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030473126098513603
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030563825741410255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03080836310982704
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03107289969921112
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030995547771453857
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.030820637941360474
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.031028276309370995
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03095402754843235
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.42708516120910645
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07935748994350433
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06386273354291916
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08570493012666702
 32%|███▏      | 189/584 [19:27<22:40,  3.45s/it]REMOVE TEST?! 0 0 0.6506849315068494
Cross Entropy List tensor(10.3734, device='cuda:0', grad_fn=<NllLossBackward0>)
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  9.8924, 10.1084,
          9.3735]], device='cuda:2')
[]
REMOVE TEST?! 0 0 5.886986301369863
Cross Entropy List tensor([[10.3733, 10.3733, 10.3733, 10.3115, 10.0764, 11.5471, 11.3605, 11.3605,
         10.3735]], device='cuda:1')
REMOVE TEST?! 1 0 0.6506849315068494
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735,  9.7394,  9.3045,
         10.4503]], device='cuda:2')
REMOVE TEST?! 1 1 5.886986301369863
Cross Entropy List tensor([[10.3733, 10.3733, 10.3733, 10.3872, 13.0262, 15.9653, 18.5576, 18.5577,
         10.3736]], device='cuda:1')
[1]
REMOVE TEST?! 0 0 3.253424657534247
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4191899299621582
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13550995290279388
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15599088370800018
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16664403676986694
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16066153347492218
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1562235802412033
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1534755527973175
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15309308469295502
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15347537398338318
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.157138392329216
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15720795094966888
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1574881672859192
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15574780106544495
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15450331568717957
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15281054377555847
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1503496915102005
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14993800222873688
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15349741280078888
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15679343044757843
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19479644298553467
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16496330499649048
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1595178246498108
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15566350519657135
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15308399498462677
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1529727429151535
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1545458883047104
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15728871524333954
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15676186978816986
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15771394968032837
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15540623664855957
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15403462946414948
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15224632620811462
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15044336020946503
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15076738595962524
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13402794301509857
 32%|███▏      | 186/584 [19:31<30:05,  4.54s/it]Before Process
B-INPUT tensor([    1, 23119,  2662, 28705, 28784, 28782,  7769,   302,  9636,   356,
         9262, 28725, 28705, 28740, 28734,   680,  7769,   302,  9636,   356,
        11187,   821,   356,  9262, 28725, 28705, 28782, 16130,   356, 11463,
          821,   356, 11187, 28725,   304, 28705, 28740, 28782,   680,  7769,
          302,  9636,   356, 10983,   821,   356, 11463, 28723,  1602,  1287,
         7769,   302,  9636,   863, 23119,  4080, 28804, 28705,     2, 23119,
         2662, 28705, 28784, 28782,   648, 28705, 28740, 28734,   327,  2087,
        28784, 28782, 28806, 28740, 28734, 28746, 28787, 28782,  4060, 28787,
        28782,  7769,   302,  9636,   356, 11187, 28723,   650,  2662, 28705,
        28787, 28782,   387, 28705, 28782,   327,  2087, 28787, 28782, 28733,
        28782, 28746, 28787, 28734,  4060, 28787, 28734,  7769,   302,  9636,
          356, 11463, 28723,  1015,  2662, 28705, 28787, 28734,   648, 28705,
        28740, 28782,   327,  2087, 28787, 28734, 28806, 28740, 28782, 28746,
        28783, 28782,  4060, 28783, 28782,  7769,   302,  9636,   356, 10983,
        28723,  8469, 28725,   400,  2662, 28705, 28784, 28782,   648, 28705,
        28787, 28782,   648, 28705, 28787, 28734,   648, 28705, 28783, 28782,
          327,  2087, 28784, 28782, 28806, 28787, 28782, 28806, 28787, 28734,
        28806, 28783, 28782, 28746, 28750, 28774, 28782,  4060, 28750, 28774,
        28782,  7769,   302,  9636, 28723, 28705,     2,  2476, 28750, 28774,
        28782, 28705,     2], device='cuda:0')
B-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100, 23119,
         2662, 28705, 28784, 28782,   648, 28705, 28740, 28734,   327,  2087,
        28784, 28782, 28806, 28740, 28734, 28746, 28787, 28782,  4060, 28787,
        28782,  7769,   302,  9636,   356, 11187, 28723,   650,  2662, 28705,
        28787, 28782,   387, 28705, 28782,   327,  2087, 28787, 28782, 28733,
        28782, 28746, 28787, 28734,  4060, 28787, 28734,  7769,   302,  9636,
          356, 11463, 28723,  1015,  2662, 28705, 28787, 28734,   648, 28705,
        28740, 28782,   327,  2087, 28787, 28734, 28806, 28740, 28782, 28746,
        28783, 28782,  4060, 28783, 28782,  7769,   302,  9636,   356, 10983,
        28723,  8469, 28725,   400,  2662, 28705, 28784, 28782,   648, 28705,
        28787, 28782,   648, 28705, 28787, 28734,   648, 28705, 28783, 28782,
          327,  2087, 28784, 28782, 28806, 28787, 28782, 28806, 28787, 28734,
        28806, 28783, 28782, 28746, 28750, 28774, 28782,  4060, 28750, 28774,
        28782,  7769,   302,  9636, 28723, 28705,     2,  2476, 28750, 28774,
        28782, 28705,     2], device='cuda:0')
[tensor([[23119,  2662, 28705, 28784, 28782,   648, 28705, 28740, 28734,   327,
          2087, 28784, 28782, 28806, 28740, 28734, 28746, 28787, 28782,  4060,
         28787, 28782,  7769,   302,  9636,   356, 11187, 28723]],
       device='cuda:0'), tensor([[  650,  2662, 28705, 28787, 28782,   387, 28705, 28782,   327,  2087,
         28787, 28782, 28733, 28782, 28746, 28787, 28734,  4060, 28787, 28734,
          7769,   302,  9636,   356, 11463, 28723]], device='cuda:0'), tensor([[ 1015,  2662, 28705, 28787, 28734,   648, 28705, 28740, 28782,   327,
          2087, 28787, 28734, 28806, 28740, 28782, 28746, 28783, 28782,  4060,
         28783, 28782,  7769,   302,  9636,   356, 10983, 28723]],
       device='cuda:0'), tensor([[ 8469, 28725,   400,  2662, 28705, 28784, 28782,   648, 28705, 28787,
         28782,   648, 28705, 28787, 28734,   648, 28705, 28783, 28782,   327,
          2087, 28784, 28782, 28806, 28787, 28782, 28806, 28787, 28734, 28806,
         28783, 28782, 28746, 28750, 28774, 28782,  4060, 28750, 28774, 28782,
          7769,   302,  9636, 28723, 28705,     2]], device='cuda:0')]
REMOVE TEST?! 0 0 1.2808219178082192
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  9.5144,  9.6547,
         10.0492]], device='cuda:2')
REMOVE TEST?! 2 1 5.886986301369863
Cross Entropy List Cross Entropy List tensor([[10.3733, 10.3733, 10.3733, 10.3387, 10.1530, 11.2974, 11.0322, 11.0322,
         10.3735]], device='cuda:1')
REMOVE TEST?! 1 1 3.253424657534247
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.8925, 10.8590,
          8.9899]], device='cuda:2')
REMOVE TEST?! 3 2 5.886986301369863
tensor([[10.3735, 10.3847, 10.4170, 10.1888, 10.1888, 10.1888, 10.1888, 10.1888,
         10.3733]], device='cuda:0')
REMOVE TEST?! 1 0 1.2808219178082192
Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.2929, 10.0201, 11.0672, 10.8831, 10.8831,
         10.3734]], device='cuda:1')
REMOVE TEST?! 2 1 3.253424657534247
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735,  9.2087,  8.3355,
          9.4619]], device='cuda:2')
REMOVE TEST?! 4 2 5.886986301369863
tensor([[10.3734, 10.3899, 10.4363, 10.1815, 10.1815, 10.1815, 10.1815, 10.1815,
         10.3733]], device='cuda:0')
REMOVE TEST?! 2 1 1.2808219178082192
Cross Entropy List Cross Entropy List tensor([[10.3733, 10.3733, 10.3733, 10.3025, 11.0090, 10.3487, 10.6354, 10.6354,
         10.3732]], device='cuda:1')
REMOVE TEST?! 3 1 3.253424657534247
Cross Entropy List tensor([[10.3737, 10.3737, 10.3737, 10.3737, 10.3737, 10.3737,  9.1299,  8.2915,
          9.4024]], device='cuda:2')
REMOVE TEST?! 5 2 5.886986301369863
tensor([[10.3735, 10.3906, 10.4436, 10.1927, 10.1927, 10.1927, 10.1927, 10.1927,
         10.3733]], device='cuda:0')
REMOVE TEST?! 3 1 1.2808219178082192
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3034, 10.9809, 10.3427, 10.6249, 10.6249,
         10.3732]], device='cuda:1')
REMOVE TEST?! 4 1 3.253424657534247
Cross Entropy List tensor([[10.3737, 10.3737, 10.3737, 10.3737, 10.3737, 10.3737,  9.0193,  8.0009,
          9.3232]], device='cuda:2')
REMOVE TEST?! 6 2 5.886986301369863
tensor([[10.3735, 10.3923, 10.4662, 10.2064, 10.2064, 10.2064, 10.2064, 10.2064,
         10.3733]], device='cuda:0')
[1]
REMOVE TEST?! 0 0 0.6404109589041096
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3030, 10.9577, 10.3278, 10.6056, 10.6056,
         10.3732]], device='cuda:1')
REMOVE TEST?! 5 1 3.253424657534247
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.3736,  8.9331,  7.7607,
          9.2569]], device='cuda:2')
REMOVE TEST?! 7 2 5.886986301369863
tensor([[10.3732, 10.3848, 10.4277, 10.2240, 10.2240, 10.2240, 10.2240, 10.2240,
         10.3734]], device='cuda:0')
REMOVE TEST?! 1 0 0.6404109589041096
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3022, 10.9382, 10.3151, 10.5900, 10.5900,
         10.3732]], device='cuda:1')
REMOVE TEST?! 6 1 3.253424657534247
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.3736,  8.8804,  7.6307,
          9.2198]], device='cuda:2')
REMOVE TEST?! 8 2 5.886986301369863
tensor([[10.3733, 10.3851, 10.4423, 10.2210, 10.2210, 10.2210, 10.2210, 10.2210,
         10.3735]], device='cuda:0')
[]
REMOVE TEST?! 0 0 1.601027397260274
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3026, 10.9266, 10.3125, 10.5819, 10.5819,
         10.3732]], device='cuda:1')
REMOVE TEST?! 7 1 3.253424657534247
Cross Entropy List tensor([[10.3737, 10.3737, 10.3737, 10.3737, 10.3737, 10.3737,  8.9138,  7.7768,
          9.2650]], device='cuda:2')
REMOVE TEST?! 9 2 5.886986301369863
tensor([[10.3735, 10.3870, 10.3844, 10.1516, 10.1516, 10.1516, 10.1516, 10.1516,
         10.3733]], device='cuda:0')
REMOVE TEST?! 1 0 1.601027397260274
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3033, 10.9208, 10.3127, 10.5785, 10.5785,
         10.3732]], device='cuda:1')
REMOVE TEST?! 8 1 3.253424657534247
Cross Entropy List tensor([[10.3737, 10.3737, 10.3737, 10.3737, 10.3737, 10.3737,  8.8776,  7.6952,
          9.2408]], device='cuda:2')
REMOVE TEST?! 10 2 5.886986301369863
tensor([[10.3736, 10.3872, 10.3893, 10.1536, 10.1536, 10.1536, 10.1536, 10.1536,
         10.3733]], device='cuda:0')
REMOVE TEST?! 2 0 1.601027397260274
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3034, 10.8969, 10.3065, 10.5642, 10.5642,
         10.3732]], device='cuda:1')
REMOVE TEST?! 9 1 3.253424657534247
Cross Entropy List tensor([[10.3737, 10.3737, 10.3737, 10.3736, 10.3737, 10.3736,  8.8219,  7.5905,
          9.2302]], device='cuda:2')
REMOVE TEST?! 11 2 5.886986301369863
tensor([[10.3736, 10.3880, 10.4010, 10.1621, 10.1621, 10.1620, 10.1620, 10.1620,
         10.3733]], device='cuda:0')
REMOVE TEST?! 3 0 1.601027397260274
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3065, 10.8338, 10.2916, 10.5253, 10.5253,
         10.3732]], device='cuda:1')
[0]
REMOVE TEST?! 0 0 1.952054794520548
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.3736,  8.7755,  7.4850,
          9.2118]], device='cuda:2')
REMOVE TEST?! 12 2 5.886986301369863
tensor([[10.3736, 10.3870, 10.4029, 10.1643, 10.1643, 10.1642, 10.1642, 10.1642,
         10.3733]], device='cuda:0')
REMOVE TEST?! 4 0 1.601027397260274
Cross Entropy List Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.4307, 11.8697, 10.2572, 10.2544, 10.2543,
         10.3733]], device='cuda:1')
REMOVE TEST?! 1 0 1.952054794520548
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.3736,  8.7330,  7.3762,
          9.1781]], device='cuda:2')
REMOVE TEST?! 13 2 5.886986301369863
tensor([[10.3735, 10.3879, 10.4118, 10.1517, 10.1517, 10.1517, 10.1517, 10.1517,
         10.3733]], device='cuda:0')
[]
REMOVE TEST?! 0 0 0.3202054794520548
Cross Entropy List Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.4263, 11.7372, 10.2123, 10.2166, 10.2166,
         10.3732]], device='cuda:1')
REMOVE TEST?! 2 0 1.952054794520548
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.3736,  8.7026,  7.3070,
          9.1495]], device='cuda:2')
REMOVE TEST?! 14 2 5.886986301369863
tensor([[10.3734, 10.3834, 10.4928, 10.2576, 10.2576, 10.2576, 10.2576, 10.2576,
         10.3734]], device='cuda:0')
[]
After Process
A-INPUT tensor([    1, 23119,  2662, 28705, 28784, 28782,  7769,   302,  9636,   356,
         9262, 28725, 28705, 28740, 28734,   680,  7769,   302,  9636,   356,
        11187,   821,   356,  9262, 28725, 28705, 28782, 16130,   356, 11463,
          821,   356, 11187, 28725,   304, 28705, 28740, 28782,   680,  7769,
          302,  9636,   356, 10983,   821,   356, 11463, 28723,  1602,  1287,
         7769,   302,  9636,   863, 23119,  4080, 28804, 28705,     2, 23119,
         2662, 28705, 28784, 28782,   648, 28705, 28740, 28734,   327,  2087,
        28784, 28782, 28806, 28740, 28734, 28746, 28787, 28782,  4060, 28787,
        28782,  7769,   302,  9636,   356, 11187, 28723,  1015,  2662, 28705,
        28787, 28734,   648, 28705, 28740, 28782,   327,  2087, 28787, 28734,
        28806, 28740, 28782, 28746, 28783, 28782,  4060, 28783, 28782,  7769,
          302,  9636,   356, 10983, 28723,  8469, 28725,   400,  2662, 28705,
        28784, 28782,   648, 28705, 28787, 28782,   648, 28705, 28787, 28734,
          648, 28705, 28783, 28782,   327,  2087, 28784, 28782, 28806, 28787,
        28782, 28806, 28787, 28734, 28806, 28783, 28782, 28746, 28750, 28774,
        28782,  4060, 28750, 28774, 28782,  7769,   302,  9636, 28723, 28705,
            2,  2476, 28750, 28774, 28782, 28705,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2], device='cuda:0')
A-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100, 23119,
         2662, 28705, 28784, 28782,   648, 28705, 28740, 28734,   327,  2087,
        28784, 28782, 28806, 28740, 28734, 28746, 28787, 28782,  4060, 28787,
        28782,  7769,   302,  9636,   356, 11187, 28723,  1015,  2662, 28705,
        28787, 28734,   648, 28705, 28740, 28782,   327,  2087, 28787, 28734,
        28806, 28740, 28782, 28746, 28783, 28782,  4060, 28783, 28782,  7769,
          302,  9636,   356, 10983, 28723,  8469, 28725,   400,  2662, 28705,
        28784, 28782,   648, 28705, 28787, 28782,   648, 28705, 28787, 28734,
          648, 28705, 28783, 28782,   327,  2087, 28784, 28782, 28806, 28787,
        28782, 28806, 28787, 28734, 28806, 28783, 28782, 28746, 28750, 28774,
        28782,  4060, 28750, 28774, 28782,  7769,   302,  9636, 28723, 28705,
            2,  2476, 28750, 28774, 28782, 28705,     2,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100], device='cuda:0')
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.4231, 11.6185, 10.1690, 10.1756, 10.1756,
         10.3733]], device='cuda:1')
REMOVE TEST?! 3 0 1.952054794520548
Loss Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.3736,  8.7559,  7.4718,
          9.1802]], device='cuda:2')
REMOVE TEST?! 15 2 5.886986301369863
tensor(10.3734, device='cuda:0', grad_fn=<NllLossBackward0>)
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.4205, 11.5347, 10.1588, 10.1689, 10.1689,
         10.3732]], device='cuda:1')
REMOVE TEST?! 4 0 1.952054794520548
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.3736,  9.3643,  7.7966,
         10.0240]], device='cuda:2')
REMOVE TEST?! 16 2 5.886986301369863
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3486, 10.0545, 10.0394, 10.1087, 10.1087,
         10.3733]], device='cuda:1')
REMOVE TEST?! 5 0 1.952054794520548
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  9.2265,  8.8868,
          9.2495]], device='cuda:2')
REMOVE TEST?! 17 2 5.886986301369863
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4290001690387726
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13597005605697632
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15715156495571136
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15850745141506195
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1556953340768814
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15440957248210907
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15245705842971802
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15110453963279724
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15213632583618164
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15495264530181885
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15864518284797668
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16732822358608246
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16132116317749023
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15686500072479248
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15410567820072174
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1537216603755951
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15410549938678741
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15778356790542603
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1578533947467804
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15813477337360382
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15638725459575653
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15513765811920166
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15343792736530304
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15096698701381683
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1505535989999771
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15412762761116028
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15743717551231384
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1562425047159195
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16328474879264832
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15845730900764465
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15523004531860352
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15349464118480682
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15364545583724976
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1568061262369156
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13597005605697632
 32%|███▏      | 187/584 [19:34<25:43,  3.89s/it]Before Process
B-INPUT tensor([    1,  4797, 24928,   298,  3848,   264,  3687,  2003,   808, 28723,
        28705,   415,  7786,  2434,   429, 28750, 28782, 28734, 28734,   304,
          272,  4211,   282,  2434,   429, 28770, 28782, 28734, 28734,   304,
         2905,  1112,   659,   264,  9837,  2434,   302,   429, 28750, 28734,
        28734, 28734, 28723, 28705,   650,  4739,   264, 28705, 28740, 28734,
        28823, 12711,   356,  2905, 28723, 28705,  1602,  1188,   863,   400,
         2136, 28804, 28705,     2,   415,  9837,  2434,   302,  2905,   403,
        28705, 28750, 28782, 28734, 28734, 28806, 28770, 28782, 28734, 28734,
        28806, 28750, 28734, 28734, 28734,  8991,  5275, 28750, 28782, 28734,
        28734, 28806, 28770, 28782, 28734, 28734, 28806, 28750, 28734, 28734,
        28734, 28746, 28783, 28734, 28734, 28734,  4060, 28783, 28734, 28734,
        28734,  1537,   400,  4739,   396, 28705, 28783, 28734, 28734, 28734,
         2414, 28740,  8991,  5275, 28783, 28734, 28734, 28734,  2414, 28740,
        28746, 28783, 28734, 28734,  4060, 28783, 28734, 28734, 12711,  1725,
         2825,   400, 12429, 28705, 28783, 28734, 28734, 28734, 28733, 28783,
        28734, 28734,  8991,  5275, 28783, 28734, 28734, 28734, 28733, 28783,
        28734, 28734, 28746, 28787, 28750, 28734, 28734,  4060, 28787, 28750,
        28734, 28734, 28705,     2,  2476, 28787, 28750, 28734, 28734, 28705,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2], device='cuda:0')
B-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,   415,  9837,  2434,   302,  2905,   403,
        28705, 28750, 28782, 28734, 28734, 28806, 28770, 28782, 28734, 28734,
        28806, 28750, 28734, 28734, 28734,  8991,  5275, 28750, 28782, 28734,
        28734, 28806, 28770, 28782, 28734, 28734, 28806, 28750, 28734, 28734,
        28734, 28746, 28783, 28734, 28734, 28734,  4060, 28783, 28734, 28734,
        28734,  1537,   400,  4739,   396, 28705, 28783, 28734, 28734, 28734,
         2414, 28740,  8991,  5275, 28783, 28734, 28734, 28734,  2414, 28740,
        28746, 28783, 28734, 28734,  4060, 28783, 28734, 28734, 12711,  1725,
         2825,   400, 12429, 28705, 28783, 28734, 28734, 28734, 28733, 28783,
        28734, 28734,  8991,  5275, 28783, 28734, 28734, 28734, 28733, 28783,
        28734, 28734, 28746, 28787, 28750, 28734, 28734,  4060, 28787, 28750,
        28734, 28734, 28705,     2,  2476, 28787, 28750, 28734, 28734, 28705,
            2,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100], device='cuda:0')
[tensor([[  415,  9837,  2434,   302,  2905,   403, 28705, 28750, 28782, 28734,
         28734, 28806, 28770, 28782, 28734, 28734, 28806, 28750, 28734, 28734,
         28734,  8991,  5275, 28750, 28782, 28734, 28734, 28806, 28770, 28782,
         28734, 28734, 28806, 28750, 28734, 28734, 28734, 28746, 28783, 28734,
         28734, 28734,  4060, 28783, 28734, 28734, 28734,  1537,   400,  4739,
           396, 28705, 28783, 28734, 28734, 28734,  2414, 28740,  8991,  5275,
         28783, 28734, 28734, 28734,  2414, 28740, 28746, 28783, 28734, 28734,
          4060, 28783, 28734, 28734, 12711,  1725,  2825,   400, 12429, 28705,
         28783, 28734, 28734, 28734, 28733, 28783, 28734, 28734,  8991,  5275,
         28783, 28734, 28734, 28734, 28733, 28783, 28734, 28734, 28746, 28787,
         28750, 28734, 28734,  4060, 28787, 28750, 28734, 28734, 28705,     2]],
       device='cuda:0')]
REMOVE TEST?! 0 0 0.3219178082191781
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3806, 10.0366, 11.6813, 11.5129, 11.5129,
         10.3736]], device='cuda:1')
[5]
REMOVE TEST?! 0 0 0.3253424657534247
Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735,  9.0778,  7.7393,
         10.2355]], device='cuda:2')
[0, 2]
REMOVE TEST?! 0 0 0.9811643835616437
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3863, 10.4346, 10.2215, 10.6449, 10.6449,
         10.3736]], device='cuda:1')
[0]
tensor([[10.3664, 10.3608, 10.3486, 10.3452, 10.3452, 10.3452, 10.3452, 10.3452,
         10.3737]], device='cuda:0')
[]
REMOVE TEST?! 0 0 0.6438356164383562
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.4115,  8.7869,
         10.1733]], device='cuda:2')
[0]
REMOVE TEST?! 0 0 1.3082191780821917
Loss Cross Entropy List tensor(10.3736, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor([[10.3732, 10.3764, 10.4105, 10.2065, 10.2065, 10.2065, 10.2065, 10.2065,
         10.3733]], device='cuda:0')
REMOVE TEST?! 1 0 0.6438356164383562
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  9.7518,  9.2350,
         10.6110]], device='cuda:2')
REMOVE TEST?! 1 1 1.3082191780821917
Cross Entropy List tensor([[10.3732, 10.3799, 10.4467, 10.2203, 10.2203, 10.2203, 10.2203, 10.2203,
         10.3734]], device='cuda:0')
[]
REMOVE TEST?! 0 0 1.9315068493150687
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  9.9253,  9.9475,
         11.2912]], device='cuda:2')
[0, 1]
Loss tensor([[10.3733, 10.3930, 10.4273, 10.2320, 10.2320, 10.2320, 10.2320, 10.2320,
         10.3733]], device='cuda:0')
REMOVE TEST?! 1 0 1.9315068493150687
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.43097227811813354
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.135199636220932
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15755337476730347
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15698018670082092
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.155168816447258
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15440592169761658
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15199488401412964
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15136191248893738
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15496966242790222
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1560276746749878
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15158164501190186
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16191110014915466
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1606801301240921
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1576935052871704
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15491138398647308
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15480366349220276
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15639954805374146
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1573936939239502
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15673291683197021
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15800225734710693
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1555631160736084
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15453965961933136
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1531815379858017
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15235470235347748
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15322527289390564
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1555887907743454
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15591119229793549
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15641476213932037
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1612945944070816
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1586548089981079
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15564970672130585
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1549740880727768
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15480491518974304
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1572592556476593
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13519951701164246
 33%|███▎      | 190/584 [19:31<24:02,  3.66s/it]REMOVE TEST?! 0 0 1.6352739726027397
Cross Entropy List tensor(8.7295, device='cuda:2', grad_fn=<NllLossBackward0>)
Cross Entropy List tensor([[10.3734, 10.3948, 10.4394, 10.2178, 10.2178, 10.2178, 10.2178, 10.2178,
         10.3732]], device='cuda:0')
REMOVE TEST?! 2 0 1.9315068493150687
Cross Entropy List tensor([[10.3732, 10.3732, 10.3732, 10.3846, 10.0743, 12.7753, 12.1987, 12.1986,
         10.3732]], device='cuda:1')
REMOVE TEST?! 1 1 1.6352739726027397
Cross Entropy List tensor([[10.3734, 10.3963, 10.4636, 10.2341, 10.2341, 10.2341, 10.2341, 10.2341,
         10.3733]], device='cuda:0')
REMOVE TEST?! 3 0 1.9315068493150687
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.4254, 10.0697, 10.4066, 10.2048, 10.2048,
         10.3734]], device='cuda:1')
[0, 1]
REMOVE TEST?! 0 0 0.3270547945205479
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4704436659812927
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12971481680870056
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13683930039405823
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1385115683078766
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1406528502702713
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14302349090576172
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14203214645385742
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1383310854434967
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13719066977500916
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13087311387062073
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1505381315946579
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14795450866222382
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14866401255130768
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1493709832429886
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14767864346504211
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14639395475387573
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14300614595413208
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14139236509799957
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13738654553890228
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13741682469844818
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1400601863861084
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1423162817955017
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1423952281475067
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1402561217546463
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1369306743144989
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13911136984825134
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.30954307317733765
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14792269468307495
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1522977650165558
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15038126707077026
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15457312762737274
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14950893819332123
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14880907535552979
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14309841394424438
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16657912731170654
 33%|███▎      | 191/584 [19:38<23:40,  3.61s/it]REMOVE TEST?! 0 0 0.3287671232876712
Cross Entropy List tensor([[10.3734, 10.3959, 10.4682, 10.2387, 10.2387, 10.2387, 10.2387, 10.2387,
         10.3734]], device='cuda:0')
REMOVE TEST?! 4 0 1.9315068493150687
Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3916, 10.3874, 10.3991, 10.4580, 10.4580,
         10.3735]], device='cuda:1')
[0]
REMOVE TEST?! 0 0 1.6352739726027397
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.3735,  9.3339,  8.5735,
          8.2064]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.3287671232876712
tensor([[10.3734, 10.3920, 10.4644, 10.2412, 10.2412, 10.2412, 10.2412, 10.2412,
         10.3733]], device='cuda:0')
REMOVE TEST?! 5 0 1.9315068493150687
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.4436, 10.1699, 10.2466, 10.2170, 10.2170,
         10.3735]], device='cuda:1')
REMOVE TEST?! 1 0 1.6352739726027397
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.3736,  9.3356, 10.1141,
          9.5979]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.3287671232876712
tensor([[10.3734, 10.3955, 10.4726, 10.2379, 10.2379, 10.2379, 10.2379, 10.2379,
         10.3733]], device='cuda:0')
[]
REMOVE TEST?! 0 0 0.3219178082191781
Cross Entropy List Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.4074, 10.1238, 10.5511, 10.2932, 10.2932,
         10.3732]], device='cuda:1')
REMOVE TEST?! 2 0 1.6352739726027397
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735,  8.7150,  7.8872,
          8.5911]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.9863013698630136
tensor([[10.3734, 10.3991, 10.5384, 10.2490, 10.2490, 10.2490, 10.2490, 10.2490,
         10.3735]], device='cuda:0')
[]
After Process
A-INPUT tensor([    1,  4797, 24928,   298,  3848,   264,  3687,  2003,   808, 28723,
        28705,   415,  7786,  2434,   429, 28750, 28782, 28734, 28734,   304,
          272,  4211,   282,  2434,   429, 28770, 28782, 28734, 28734,   304,
         2905,  1112,   659,   264,  9837,  2434,   302,   429, 28750, 28734,
        28734, 28734, 28723, 28705,   650,  4739,   264, 28705, 28740, 28734,
        28823, 12711,   356,  2905, 28723, 28705,  1602,  1188,   863,   400,
         2136, 28804, 28705,     2,   415,  9837,  2434,   302,  2905,   403,
        28705, 28750, 28782, 28734, 28734, 28806, 28770, 28782, 28734, 28734,
        28806, 28750, 28734, 28734, 28734,  8991,  5275, 28750, 28782, 28734,
        28734, 28806, 28770, 28782, 28734, 28734, 28806, 28750, 28734, 28734,
        28734, 28746, 28783, 28734, 28734, 28734,  4060, 28783, 28734, 28734,
        28734,  1537,   400,  4739,   396, 28705, 28783, 28734, 28734, 28734,
         2414, 28740,  8991,  5275, 28783, 28734, 28734, 28734,  2414, 28740,
        28746, 28783, 28734, 28734,  4060, 28783, 28734, 28734, 12711,  1725,
         2825,   400, 12429, 28705, 28783, 28734, 28734, 28734, 28733, 28783,
        28734, 28734,  8991,  5275, 28783, 28734, 28734, 28734, 28733, 28783,
        28734, 28734, 28746, 28787, 28750, 28734, 28734,  4060, 28787, 28750,
        28734, 28734, 28705,     2,  2476, 28787, 28750, 28734, 28734, 28705,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2], device='cuda:0')
A-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,   415,  9837,  2434,   302,  2905,   403,
        28705, 28750, 28782, 28734, 28734, 28806, 28770, 28782, 28734, 28734,
        28806, 28750, 28734, 28734, 28734,  8991,  5275, 28750, 28782, 28734,
        28734, 28806, 28770, 28782, 28734, 28734, 28806, 28750, 28734, 28734,
        28734, 28746, 28783, 28734, 28734, 28734,  4060, 28783, 28734, 28734,
        28734,  1537,   400,  4739,   396, 28705, 28783, 28734, 28734, 28734,
         2414, 28740,  8991,  5275, 28783, 28734, 28734, 28734,  2414, 28740,
        28746, 28783, 28734, 28734,  4060, 28783, 28734, 28734, 12711,  1725,
         2825,   400, 12429, 28705, 28783, 28734, 28734, 28734, 28733, 28783,
        28734, 28734,  8991,  5275, 28783, 28734, 28734, 28734, 28733, 28783,
        28734, 28734, 28746, 28787, 28750, 28734, 28734,  4060, 28787, 28750,
        28734, 28734, 28705,     2,  2476, 28787, 28750, 28734, 28734, 28705,
            2,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100], device='cuda:0')
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.4041, 10.1186, 10.5077, 10.2611, 10.2610,
         10.3732]], device='cuda:1')
REMOVE TEST?! 3 0 1.6352739726027397
Loss Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.3736,  9.1535,  8.8713,
          9.0872]], device='cuda:2')
REMOVE TEST?! 1 0 0.9863013698630136
tensor(10.3734, device='cuda:0', grad_fn=<NllLossBackward0>)
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.4004, 10.1177, 10.4926, 10.2546, 10.2546,
         10.3732]], device='cuda:1')
REMOVE TEST?! 4 0 1.6352739726027397
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735,  9.4180,  8.4265,
          9.5203]], device='cuda:2')
REMOVE TEST?! 2 0 0.9863013698630136
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3395, 10.2305, 10.1531, 10.1735, 10.1735,
         10.3738]], device='cuda:1')
[]
REMOVE TEST?! 0 0 2.2893835616438354
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  9.1315,  8.2673,
          8.5124]], device='cuda:2')
[]
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4289935231208801
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13596634566783905
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1571487933397293
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1585029810667038
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15569345653057098
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15440864861011505
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15249906480312347
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1511480212211609
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15217864513397217
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15499208867549896
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.158680260181427
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16727881133556366
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16127504408359528
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15682187676429749
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1540726125240326
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15372127294540405
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15410424768924713
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15777945518493652
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15784896910190582
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.158130943775177
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1563846617937088
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15513519942760468
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15344928205013275
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15101060271263123
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1505974680185318
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15416742861270905
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15747356414794922
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1562449187040329
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16323748230934143
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15841349959373474
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1551876962184906
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15349268913269043
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1536443829536438
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15680253505706787
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13596636056900024
 32%|███▏      | 188/584 [19:37<24:04,  3.65s/it]Before Process
B-INPUT tensor([    1,  6213,   272, 26402,  9119, 20021, 28725, 13589,  1419, 28705,
        28782, 14636, 28725,  8500,  4255,  1419, 28705, 28740, 28770, 14636,
        28725,  5163,  1419, 28705, 28774,   304, 12913,  2951,  1419, 28705,
        28782, 28784, 28723, 28705,  1602,  1287,   680, 14636,   863, 12913,
         2951,  1300,   821,   272,   799,  1712,  2436,  1419, 28804, 28705,
            2,   816,   873,   369, 13589,  1419, 28705, 28782, 28725,  8500,
         4255,  1419, 28705, 28740, 28770,   304,  5163,  1419, 28705, 28774,
          579, 28705, 28782, 28806, 28740, 28770, 28806, 28774,   327,  2087,
        28782, 28806, 28740, 28770, 28806, 28774, 28746, 28750, 28787,  4060,
        28750, 28787, 12913,  2951,  1419, 28705, 28782, 28784, 14636,  1312,
          272,  2663,  1419, 28705, 28750, 28787, 14636,   579, 28705, 28782,
        28784, 28733, 28750, 28787,   327,  2087, 28782, 28784, 28733, 28750,
        28787, 28746, 28750, 28774,  4060, 28750, 28774,   680, 14636, 28705,
            2,  2476, 28750, 28774, 28705,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2],
       device='cuda:0')
B-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,   816,   873,   369, 13589,  1419, 28705, 28782, 28725,  8500,
         4255,  1419, 28705, 28740, 28770,   304,  5163,  1419, 28705, 28774,
          579, 28705, 28782, 28806, 28740, 28770, 28806, 28774,   327,  2087,
        28782, 28806, 28740, 28770, 28806, 28774, 28746, 28750, 28787,  4060,
        28750, 28787, 12913,  2951,  1419, 28705, 28782, 28784, 14636,  1312,
          272,  2663,  1419, 28705, 28750, 28787, 14636,   579, 28705, 28782,
        28784, 28733, 28750, 28787,   327,  2087, 28782, 28784, 28733, 28750,
        28787, 28746, 28750, 28774,  4060, 28750, 28774,   680, 14636, 28705,
            2,  2476, 28750, 28774, 28705,     2,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],
       device='cuda:0')
[tensor([[  816,   873,   369, 13589,  1419, 28705, 28782, 28725,  8500,  4255,
          1419, 28705, 28740, 28770,   304,  5163,  1419, 28705, 28774,   579,
         28705, 28782, 28806, 28740, 28770, 28806, 28774,   327,  2087, 28782,
         28806, 28740, 28770, 28806, 28774, 28746, 28750, 28787,  4060, 28750,
         28787, 12913,  2951,  1419, 28705, 28782, 28784, 14636,  1312,   272,
          2663,  1419, 28705, 28750, 28787, 14636,   579, 28705, 28782, 28784,
         28733, 28750, 28787,   327,  2087, 28782, 28784, 28733, 28750, 28787,
         28746, 28750, 28774,  4060, 28750, 28774,   680, 14636, 28705,     2]],
       device='cuda:0')]
REMOVE TEST?! 0 0 0.3236301369863014
Loss tensor([[10.3735, 10.3735, 10.3735, 10.4588, 11.7156, 10.0986, 10.0975, 10.0975,
         10.3736]], device='cuda:1')
REMOVE TEST?! 1 1 2.2893835616438354
Cross Entropy List Cross Entropy List tensor(9.4088, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor([[10.3736, 10.3736, 10.3736, 10.4025, 10.3636, 10.2953, 10.7475, 10.7475,
         10.3737]], device='cuda:1')
REMOVE TEST?! 2 2 2.2893835616438354
tensor([[10.3734, 10.3695, 10.3649, 10.3572, 10.3572, 10.3572, 10.3572, 10.3572,
         10.3740]], device='cuda:0')
[]
REMOVE TEST?! 0 0 0.9708904109589042
Cross Entropy List Cross Entropy List tensor([[10.3731, 10.3731, 10.3731, 10.3673, 10.9571, 10.0698, 10.0891, 10.0891,
         10.3736]], device='cuda:1')
REMOVE TEST?! 3 2 2.2893835616438354
tensor([[10.3731, 10.3796, 10.4268, 10.2510, 10.2510, 10.2510, 10.2510, 10.2510,
         10.3733]], device='cuda:0')
REMOVE TEST?! 1 0 0.9708904109589042
Cross Entropy List Cross Entropy List Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.44153299927711487
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12996907532215118
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1467035710811615
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1485724151134491
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15082427859306335
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1534774899482727
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1522873193025589
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14819492399692535
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14715465903282166
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13846859335899353
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16126656532287598
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15850523114204407
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1592639684677124
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16001860797405243
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15820807218551636
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15683674812316895
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15321509540081024
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1514894664287567
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.147309347987175
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14737509191036224
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14997340738773346
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15245631337165833
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.152626171708107
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15808942914009094
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1471388041973114
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14941555261611938
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19244004786014557
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16021357476711273
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15960320830345154
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16003035008907318
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1604509949684143
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15872249007225037
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1561584770679474
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15292146801948547
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1421779990196228
 33%|███▎      | 192/584 [19:40<20:42,  3.17s/it]REMOVE TEST?! 0 0 0.3304794520547945
tensor([[10.3737, 10.3737, 10.3737, 10.4357, 10.3237, 10.2784, 10.6957, 10.6957,
         10.3737]], device='cuda:1')
REMOVE TEST?! 4 2 2.2893835616438354
tensor([[10.3732, 10.3873, 10.4682, 10.2505, 10.2505, 10.2505, 10.2505, 10.2505,
         10.3734]], device='cuda:0')
REMOVE TEST?! 2 0 0.9708904109589042
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  9.8573,  8.6864,
          8.9491]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.9914383561643836
tensor([[10.3736, 10.3736, 10.3736, 10.4417, 10.4676, 10.2224, 10.2523, 10.2522,
         10.3736]], device='cuda:1')
REMOVE TEST?! 5 2 2.2893835616438354
tensor([[10.3733, 10.3879, 10.4672, 10.2476, 10.2475, 10.2476, 10.2475, 10.2476,
         10.3734]], device='cuda:0')
[]
REMOVE TEST?! 0 0 1.2945205479452055
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3736, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735,  9.9636,  9.1920,
          9.1432]], device='cuda:2')
REMOVE TEST?! 1 0 0.9914383561643836
tensor([[10.3736, 10.3736, 10.3736, 10.4383, 10.9538, 10.1305, 10.1713, 10.1713,
         10.3736]], device='cuda:1')
REMOVE TEST?! 6 2 2.2893835616438354
tensor([[10.3733, 10.3870, 10.3801, 10.1745, 10.1744, 10.1744, 10.1744, 10.1744,
         10.3733]], device='cuda:0')
REMOVE TEST?! 1 0 1.2945205479452055
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.3736,  9.9324,  8.7998,
          8.8956]], device='cuda:2')
REMOVE TEST?! 2 0 0.9914383561643836
tensor([[10.3736, 10.3736, 10.3736, 10.4324, 10.9932, 10.1400, 10.1796, 10.1796,
         10.3736]], device='cuda:1')
[0, 1, 6]
tensor([[10.3733, 10.3892, 10.4105, 10.1869, 10.1869, 10.1869, 10.1869, 10.1869,
         10.3733]], device='cuda:0')
REMOVE TEST?! 2 0 1.2945205479452055
Cross Entropy List Cross Entropy List Loss tensor([[10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.3736,  9.8923,  8.4108,
          8.6289]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.9914383561643836
tensor(10.3735, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor([[10.3733, 10.3907, 10.4284, 10.1969, 10.1969, 10.1969, 10.1969, 10.1969,
         10.3734]], device='cuda:0')
REMOVE TEST?! 3 0 1.2945205479452055
Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735,  9.0482,  9.6477,
          8.2348]], device='cuda:2')
REMOVE TEST?! 1 0 0.9914383561643836
tensor([[10.3733, 10.3930, 10.4568, 10.2104, 10.2104, 10.2104, 10.2104, 10.2104,
         10.3734]], device='cuda:0')
[]
REMOVE TEST?! 0 0 0.6472602739726028
Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735,  8.9203,  8.9244,
          7.8589]], device='cuda:2')
REMOVE TEST?! 2 0 0.9914383561643836
tensor([[10.3733, 10.3844, 10.3603, 10.1582, 10.1581, 10.1581, 10.1581, 10.1581,
         10.3734]], device='cuda:0')
REMOVE TEST?! 1 0 0.6472602739726028
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4256119728088379
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13479380309581757
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15262845158576965
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16226492822170258
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16103477776050568
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15805061161518097
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15521836280822754
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15524084866046906
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15684354305267334
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15783654153347015
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15718261897563934
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15844690799713135
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15600904822349548
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15498439967632294
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15363748371601105
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15276920795440674
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15366452932357788
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15601472556591034
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1563793420791626
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15677756071090698
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16164982318878174
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15901130437850952
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1560133844614029
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15541209280490875
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15521609783172607
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15770220756530762
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15800708532333374
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15813599526882172
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15696439146995544
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15540724992752075
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15455688536167145
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15236835181713104
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15212583541870117
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1558636724948883
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13479378819465637
 33%|███▎      | 191/584 [19:36<25:33,  3.90s/it]REMOVE TEST?! 0 0 0.3287671232876712
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735,  8.8374,  8.4040,
          7.5961]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.9914383561643836
tensor([[10.3733, 10.3853, 10.3929, 10.1691, 10.1690, 10.1690, 10.1690, 10.1690,
         10.3733]], device='cuda:0')
[]
After Process
A-INPUT tensor([    1,  6213,   272, 26402,  9119, 20021, 28725, 13589,  1419, 28705,
        28782, 14636, 28725,  8500,  4255,  1419, 28705, 28740, 28770, 14636,
        28725,  5163,  1419, 28705, 28774,   304, 12913,  2951,  1419, 28705,
        28782, 28784, 28723, 28705,  1602,  1287,   680, 14636,   863, 12913,
         2951,  1300,   821,   272,   799,  1712,  2436,  1419, 28804, 28705,
            2,   816,   873,   369, 13589,  1419, 28705, 28782, 28725,  8500,
         4255,  1419, 28705, 28740, 28770,   304,  5163,  1419, 28705, 28774,
          579, 28705, 28782, 28806, 28740, 28770, 28806, 28774,   327,  2087,
        28782, 28806, 28740, 28770, 28806, 28774, 28746, 28750, 28787,  4060,
        28750, 28787, 12913,  2951,  1419, 28705, 28782, 28784, 14636,  1312,
          272,  2663,  1419, 28705, 28750, 28787, 14636,   579, 28705, 28782,
        28784, 28733, 28750, 28787,   327,  2087, 28782, 28784, 28733, 28750,
        28787, 28746, 28750, 28774,  4060, 28750, 28774,   680, 14636, 28705,
            2,  2476, 28750, 28774, 28705,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2],
       device='cuda:0')
A-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,   816,   873,   369, 13589,  1419, 28705, 28782, 28725,  8500,
         4255,  1419, 28705, 28740, 28770,   304,  5163,  1419, 28705, 28774,
          579, 28705, 28782, 28806, 28740, 28770, 28806, 28774,   327,  2087,
        28782, 28806, 28740, 28770, 28806, 28774, 28746, 28750, 28787,  4060,
        28750, 28787, 12913,  2951,  1419, 28705, 28782, 28784, 14636,  1312,
          272,  2663,  1419, 28705, 28750, 28787, 14636,   579, 28705, 28782,
        28784, 28733, 28750, 28787,   327,  2087, 28782, 28784, 28733, 28750,
        28787, 28746, 28750, 28774,  4060, 28750, 28774,   680, 14636, 28705,
            2,  2476, 28750, 28774, 28705,     2,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],
       device='cuda:0')
Cross Entropy List tensor([[10.3687, 10.3687, 10.3687, 10.3629, 10.0854, 11.6295, 10.6795, 10.6795,
         10.3723]], device='cuda:1')
[0]
REMOVE TEST?! 0 0 0.6575342465753424
Loss Cross Entropy List tensor([[10.3738, 10.3738, 10.3738, 10.3738, 10.3738, 10.3738,  9.7354, 13.6027,
         10.3328]], device='cuda:2')
REMOVE TEST?! 1 0 0.9914383561643836
tensor(10.3734, device='cuda:0', grad_fn=<NllLossBackward0>)
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3909, 10.0819, 10.7466, 10.3824, 10.3824,
         10.3724]], device='cuda:1')
[0]
REMOVE TEST?! 0 0 0.3287671232876712
Cross Entropy List tensor([[10.3739, 10.3739, 10.3739, 10.3739, 10.3739, 10.3739,  9.8397, 11.5882,
         10.1133]], device='cuda:2')
REMOVE TEST?! 2 0 0.9914383561643836
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3797, 12.4158, 12.0708, 13.7768, 13.7769,
         10.3731]], device='cuda:1')
[0]
REMOVE TEST?! 0 0 0.6575342465753424
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735,  8.9542,  8.2015,
          8.6855]], device='cuda:2')
[]
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.42894622683525085
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13595962524414062
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15716537833213806
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1585136502981186
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15570656955242157
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15442340075969696
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.152518630027771
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1511746644973755
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15220460295677185
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1550152599811554
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15869836509227753
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16725097596645355
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16125266253948212
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1568036824464798
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15410350263118744
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15370525419712067
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1540881097316742
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.157760888338089
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15783780813217163
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15814195573329926
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15639691054821014
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15514828264713287
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15346530079841614
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15103814005851746
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15062542259693146
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15419217944145203
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15749409794807434
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1562482714653015
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1632136106491089
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15839344263076782
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15520532429218292
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1534772515296936
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1536281406879425
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15678466856479645
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13595964014530182
 32%|███▏      | 189/584 [19:40<23:24,  3.55s/it]Before Process
B-INPUT tensor([    1,  4797,   659, 28705, 28740, 28783, 14403, 13529,   298,  6112,
          354,   272, 10923,  1918, 28723,   650,  3910, 28705, 28782,  1432,
         1819,   304, 28705, 28787,   456,  1819, 28723,  1602,  1287,   680,
        14403, 13529,  1235,   400,   927,   298,  6112, 28804, 28705,     2,
          650,   659,  3910,   264,  3102,   302, 28705, 28782,   648, 28705,
        28787,   327,  2087, 28782, 28806, 28787, 28746, 28740, 28750,  4060,
        28740, 28750, 14403, 13529,   579,  2082, 28723,  4797,  3208,   298,
         6112, 28705, 28740, 28783,   387, 28705, 28740, 28750,   327,  2087,
        28740, 28783, 28733, 28740, 28750, 28746, 28784,  4060, 28784,   680,
        14403, 13529, 28723, 28705,     2,  2476, 28784, 28705,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2], device='cuda:0')
B-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          650,   659,  3910,   264,  3102,   302, 28705, 28782,   648, 28705,
        28787,   327,  2087, 28782, 28806, 28787, 28746, 28740, 28750,  4060,
        28740, 28750, 14403, 13529,   579,  2082, 28723,  4797,  3208,   298,
         6112, 28705, 28740, 28783,   387, 28705, 28740, 28750,   327,  2087,
        28740, 28783, 28733, 28740, 28750, 28746, 28784,  4060, 28784,   680,
        14403, 13529, 28723, 28705,     2,  2476, 28784, 28705,     2,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100], device='cuda:0')
[tensor([[  650,   659,  3910,   264,  3102,   302, 28705, 28782,   648, 28705,
         28787,   327,  2087, 28782, 28806, 28787, 28746, 28740, 28750,  4060,
         28740, 28750, 14403, 13529,   579,  2082, 28723]], device='cuda:0'), tensor([[ 4797,  3208,   298,  6112, 28705, 28740, 28783,   387, 28705, 28740,
         28750,   327,  2087, 28740, 28783, 28733, 28740, 28750, 28746, 28784,
          4060, 28784,   680, 14403, 13529, 28723, 28705,     2]],
       device='cuda:0')]
REMOVE TEST?! 0 0 0.6506849315068494
Loss tensor([[10.3736, 10.3736, 10.3736, 10.4030, 14.0289, 10.3966, 10.3582, 10.3582,
         10.3733]], device='cuda:1')
[0]
Cross Entropy List Loss tensor(6.9901, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(10.3725, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor([[10.3733, 10.3776, 10.3538, 10.3369, 10.3369, 10.3369, 10.3369, 10.3369,
         10.3740]], device='cuda:0')
REMOVE TEST?! 1 0 0.6506849315068494
Cross Entropy List tensor([[10.3733, 10.3932, 10.4779, 10.1851, 10.1851, 10.1851, 10.1851, 10.1851,
         10.3734]], device='cuda:0')
[]
REMOVE TEST?! 0 0 0.976027397260274
Cross Entropy List Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4290449321269989
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.128231480717659
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14808471500873566
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14988389611244202
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1521894782781601
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15478697419166565
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15372119843959808
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14974066615104675
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14851316809654236
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1417473703622818
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1628294736146927
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16004882752895355
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16081340610980988
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16157227754592896
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15974734723567963
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15836822986602783
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15472042560577393
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15298213064670563
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14877337217330933
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14883916079998016
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15145738422870636
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15398140251636505
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1541605144739151
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15165741741657257
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14825955033302307
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1507757008075714
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1940741240978241
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16103550791740417
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16053909063339233
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16110065579414368
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16180898249149323
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1601908653974533
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15764522552490234
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15441679954528809
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13944555819034576
 33%|███▎      | 193/584 [19:43<21:04,  3.23s/it]REMOVE TEST?! 0 0 0.6643835616438356
tensor([[10.3733, 10.3848, 10.3880, 10.1846, 10.1846, 10.1846, 10.1846, 10.1846,
         10.3733]], device='cuda:0')
REMOVE TEST?! 1 0 0.976027397260274
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.25538498163223267
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08141130954027176
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09285940229892731
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11488009244203568
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10781064629554749
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10827778279781342
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8514439463615417
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.939324470702559e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.991313759703189e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.324181544594467e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00012761075049638748
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08048148453235626
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08330483734607697
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08345199376344681
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0831451267004013
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08298584073781967
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08187870681285858
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08080700039863586
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08144614100456238
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08117452263832092
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08189579844474792
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08251815289258957
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08259082585573196
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0828772708773613
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0831327810883522
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08377967029809952
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08442611247301102
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08421534299850464
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08373762667179108
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0842960998415947
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0840955600142479
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08401044458150864
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08356939256191254
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08246497809886932
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0008079790859483182
 33%|███▎      | 192/584 [19:38<21:37,  3.31s/it]REMOVE TEST?! 0 0 0.660958904109589
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735,  8.9098,  8.3042,
          8.1774]], device='cuda:2')
REMOVE TEST?! 1 0 0.6643835616438356
tensor([[10.3733, 10.3878, 10.4316, 10.2317, 10.2317, 10.2317, 10.2317, 10.2317,
         10.3733]], device='cuda:0')
REMOVE TEST?! 2 0 0.976027397260274
Cross Entropy List Cross Entropy List tensor([[10.3733, 10.3734, 10.3733, 10.3774, 10.1105, 10.9626, 10.5081, 10.5081,
         10.3735]], device='cuda:1')
[0]
REMOVE TEST?! 0 0 0.660958904109589
Cross Entropy List tensor([[10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.3733,  8.2221,  9.1733,
          7.4950]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.3321917808219178
tensor([[10.3733, 10.3907, 10.4631, 10.2133, 10.2133, 10.2133, 10.2133, 10.2133,
         10.3734]], device='cuda:0')
[]
REMOVE TEST?! 0 0 0.3253424657534247
Cross Entropy List Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.4171, 10.1682, 10.5923, 10.2914, 10.2914,
         10.3736]], device='cuda:1')
REMOVE TEST?! 1 0 0.660958904109589
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.3736,  9.1845, 10.7434,
          8.7403]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.3321917808219178
tensor([[10.3733, 10.3929, 10.4801, 10.2035, 10.2035, 10.2035, 10.2035, 10.2035,
         10.3734]], device='cuda:0')
[]
REMOVE TEST?! 0 0 1.3013698630136987
Cross Entropy List Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.4172, 10.1670, 10.4690, 10.2663, 10.2663,
         10.3736]], device='cuda:1')
[]
REMOVE TEST?! 0 0 0.9914383561643836
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735,  7.7480,  7.7226,
          6.5583]], device='cuda:2')
[]
REMOVE TEST?! 0 0 1.3287671232876712
tensor([[10.3733, 10.3810, 10.4265, 10.2459, 10.2459, 10.2459, 10.2459, 10.2459,
         10.3734]], device='cuda:0')
REMOVE TEST?! 1 0 1.3013698630136987
Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3679, 10.1161, 10.1794, 10.0941, 10.0941,
         10.3732]], device='cuda:1')
REMOVE TEST?! 1 0 0.9914383561643836
Cross Entropy List tensor([[10.3737, 10.3737, 10.3737, 10.3737, 10.3737, 10.3737,  9.1953, 10.7868,
          8.6802]], device='cuda:2')
REMOVE TEST?! 1 0 1.3287671232876712
tensor([[10.3733, 10.3826, 10.4462, 10.2347, 10.2347, 10.2347, 10.2347, 10.2347,
         10.3734]], device='cuda:0')
REMOVE TEST?! 2 0 1.3013698630136987
Cross Entropy List Cross Entropy Listtensor([[10.3735, 10.3735, 10.3735, 10.3690, 10.1140, 10.1769, 10.1021, 10.1021,
         10.3733]], device='cuda:1')
 REMOVE TEST?! 2 0 0.9914383561643836
Cross Entropy List tensor([[10.3737, 10.3737, 10.3737, 10.3737, 10.3737, 10.3737,  8.9681, 10.1772,
          8.2718]], device='cuda:2')
REMOVE TEST?! 2 0 1.3287671232876712
tensor([[10.3733, 10.3838, 10.4589, 10.2300, 10.2300, 10.2300, 10.2300, 10.2300,
         10.3734]], device='cuda:0')
REMOVE TEST?! 3 0 1.3013698630136987
Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3695, 10.1114, 10.1707, 10.0975, 10.0975,
         10.3733]], device='cuda:1')
[]
REMOVE TEST?! 0 0 0.3304794520547945
Cross Entropy List tensor([[10.3737, 10.3737, 10.3737, 10.3737, 10.3737, 10.3737,  8.8202,  9.8528,
          8.0416]], device='cuda:2')
REMOVE TEST?! 3 0 1.3287671232876712
tensor([[10.3733, 10.3867, 10.4791, 10.2359, 10.2359, 10.2359, 10.2359, 10.2359,
         10.3735]], device='cuda:0')
[]
After Process
A-INPUT tensor([    1,  4797,   659, 28705, 28740, 28783, 14403, 13529,   298,  6112,
          354,   272, 10923,  1918, 28723,   650,  3910, 28705, 28782,  1432,
         1819,   304, 28705, 28787,   456,  1819, 28723,  1602,  1287,   680,
        14403, 13529,  1235,   400,   927,   298,  6112, 28804, 28705,     2,
          650,   659,  3910,   264,  3102,   302, 28705, 28782,   648, 28705,
        28787,   327,  2087, 28782, 28806, 28787, 28746, 28740, 28750,  4060,
        28740, 28750, 14403, 13529,   579,  2082, 28723,  4797,  3208,   298,
         6112, 28705, 28740, 28783,   387, 28705, 28740, 28750,   327,  2087,
        28740, 28783, 28733, 28740, 28750, 28746, 28784,  4060, 28784,   680,
        14403, 13529, 28723, 28705,     2,  2476, 28784, 28705,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2], device='cuda:0')
A-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          650,   659,  3910,   264,  3102,   302, 28705, 28782,   648, 28705,
        28787,   327,  2087, 28782, 28806, 28787, 28746, 28740, 28750,  4060,
        28740, 28750, 14403, 13529,   579,  2082, 28723,  4797,  3208,   298,
         6112, 28705, 28740, 28783,   387, 28705, 28740, 28750,   327,  2087,
        28740, 28783, 28733, 28740, 28750, 28746, 28784,  4060, 28784,   680,
        14403, 13529, 28723, 28705,     2,  2476, 28784, 28705,     2,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100], device='cuda:0')
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3752, 10.1609, 10.4761, 10.2541, 10.2541,
         10.3734]], device='cuda:1')
Loss[]
 tensor([[10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.3736,  8.6198,  9.3380,
          7.7366]], device='cuda:2')
[]
Loss tensor(10.3734, device='cuda:0', grad_fn=<NllLossBackward0>)
Loss tensor(10.3734, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(6.8743, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.34291520714759827
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11473877727985382
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1325567364692688
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15503853559494019
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1568365842103958
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15814661979675293
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15873344242572784
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16056828200817108
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16013406217098236
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16102270781993866
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16295279562473297
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16215626895427704
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16139085590839386
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1624547243118286
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16251078248023987
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16211678087711334
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1603827029466629
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1577974557876587
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1579742133617401
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1543741226196289
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15033107995986938
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15132996439933777
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15272118151187897
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1539953351020813
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1562252640724182
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1585964858531952
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1913655698299408
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12711559236049652
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1892329603433609
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18364708125591278
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17999589443206787
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.17794546484947205
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1781209111213684
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18177779018878937
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1576208770275116
 33%|███▎      | 190/584 [19:43<22:09,  3.37s/it]Before Process
B-INPUT tensor([    1, 24728,  3208,   298, 13045, 28705, 28740, 28734,  6052,   298,
          625,  1611, 28723, 28705,   985,   541, 13045, 28705, 28770,   290,
          721,   354,   989,  3316,  1159,   630,  4739, 10272, 28725,   304,
          630,   541, 13045, 28705, 28740,   290,   721,  1996,   630,  4739,
         1611, 28723, 28705,  1602,  1043,   622,   378,  1388, 24728,   298,
          625,  1611, 28804, 28705,     2,   560,   272,   907,   744,   302,
          559,  6596, 28725, 24728,   622,  2796, 28705, 28750,  3316,   398,
        28705, 28770,   290,   721,   327,  2087, 28750, 28736, 28770, 28746,
        28784,  4060, 28784,  6052, 28723,   560,   272,  1676,   744,   302,
          559,  6596, 28725, 24728,   622,   927,   298,  2796,   396,  4870,
        28705, 28740, 28734,  6052,   387, 28705, 28784,  6052,   327,  2087,
        28740, 28734, 28733, 28784, 28746, 28781,  4060, 28781,  6052, 28723,
         1791,  2796, 28705, 28781,  6052,   398, 28705, 28740,   290,   721,
          327,   622,  1388, 24728,  2087, 28781, 28736, 28740, 28746, 28781,
         4060, 28781,  3316, 28723, 10711,   287, 16040,   727,   298,   625,
         1611,   354, 24728,   622,   347, 28705, 28750,  3316,   648, 28705,
        28781,  3316,   327,  2087, 28750, 28806, 28781, 28746, 28784,  4060,
        28784,  3316, 28723, 28705,     2,  2476, 28784, 28705,     2],
       device='cuda:0')
B-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,   560,   272,   907,   744,   302,
          559,  6596, 28725, 24728,   622,  2796, 28705, 28750,  3316,   398,
        28705, 28770,   290,   721,   327,  2087, 28750, 28736, 28770, 28746,
        28784,  4060, 28784,  6052, 28723,   560,   272,  1676,   744,   302,
          559,  6596, 28725, 24728,   622,   927,   298,  2796,   396,  4870,
        28705, 28740, 28734,  6052,   387, 28705, 28784,  6052,   327,  2087,
        28740, 28734, 28733, 28784, 28746, 28781,  4060, 28781,  6052, 28723,
         1791,  2796, 28705, 28781,  6052,   398, 28705, 28740,   290,   721,
          327,   622,  1388, 24728,  2087, 28781, 28736, 28740, 28746, 28781,
         4060, 28781,  3316, 28723, 10711,   287, 16040,   727,   298,   625,
         1611,   354, 24728,   622,   347, 28705, 28750,  3316,   648, 28705,
        28781,  3316,   327,  2087, 28750, 28806, 28781, 28746, 28784,  4060,
        28784,  3316, 28723, 28705,     2,  2476, 28784, 28705,     2],
       device='cuda:0')
[tensor([[  560,   272,   907,   744,   302,   559,  6596, 28725, 24728,   622,
          2796, 28705, 28750,  3316,   398, 28705, 28770,   290,   721,   327,
          2087, 28750, 28736, 28770, 28746, 28784,  4060, 28784,  6052, 28723]],
       device='cuda:0'), tensor([[  560,   272,  1676,   744,   302,   559,  6596, 28725, 24728,   622,
           927,   298,  2796,   396,  4870, 28705, 28740, 28734,  6052,   387,
         28705, 28784,  6052,   327,  2087, 28740, 28734, 28733, 28784, 28746,
         28781,  4060, 28781,  6052, 28723]], device='cuda:0'), tensor([[ 1791,  2796, 28705, 28781,  6052,   398, 28705, 28740,   290,   721,
           327,   622,  1388, 24728,  2087, 28781, 28736, 28740, 28746, 28781,
          4060, 28781,  3316, 28723]], device='cuda:0'), tensor([[10711,   287, 16040,   727,   298,   625,  1611,   354, 24728,   622,
           347, 28705, 28750,  3316,   648, 28705, 28781,  3316,   327,  2087,
         28750, 28806, 28781, 28746, 28784,  4060, 28784,  3316, 28723, 28705,
             2]], device='cuda:0')]
REMOVE TEST?! 0 0 1.3082191780821917
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5165937542915344
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19627486169338226
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12384585291147232
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.1211359896587965e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.2881405920857105e-09
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.708109706072719e-09
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.429714243135095e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.3508312690646562e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.233814543866174e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.7830913040816085e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.2756893283949466e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.802235253009712e-06
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001286846527364105
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.998459811147768e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.8716806152951904e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08540096879005432
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0077337343245744705
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.012678862549364567
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005327481776475906
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008343543857336044
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0049982573837041855
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00904245674610138
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0050801122561097145
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.011768021620810032
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006430842448025942
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0037904733326286077
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2741740643978119
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2763015329837799
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2848714292049408
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2802276313304901
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.274962455034256
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.27404141426086426
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2736741602420807
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2780744433403015
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23918858170509338
 33%|███▎      | 193/584 [19:40<19:27,  2.99s/it]REMOVE TEST?! 0 0 0.6643835616438356
Cross Entropy List Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.23253190517425537
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06962406635284424
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07952471077442169
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07957392930984497
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08109098672866821
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08240923285484314
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08249905705451965
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0812716856598854
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07935326546430588
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08061221241950989
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.49574407935142517
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5660755038261414
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4399314224720001
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19927793741226196
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.464237856107502e-08
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.37228698299441e-08
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.311800966798728e-08
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.458050000266667e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05441084876656532
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07488235086202621
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07412564009428024
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07344257831573486
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07349883764982224
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07480435818433762
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07623866200447083
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0762498527765274
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0768071860074997
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07666343450546265
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07572462409734726
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07515448331832886
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07471553236246109
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07401382178068161
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0732596293091774
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07349742203950882
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04824838787317276
 33%|███▎      | 194/584 [19:48<23:54,  3.68s/it]REMOVE TEST?! 0 0 0.6678082191780822
Cross Entropy List tensor([[10.3732, 10.3784, 10.3512, 10.2456, 10.2456, 10.2456, 10.2456, 10.2456,
         10.3735]], device='cuda:0')
REMOVE TEST?! 1 0 1.3082191780821917
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3568, 10.2859, 10.4781, 10.4295, 10.4295,
         10.3735]], device='cuda:1')
[0]
REMOVE TEST?! 0 0 1.660958904109589
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735,  9.0795, 10.6832,
          8.4638]], device='cuda:2')
REMOVE TEST?! 1 0 0.6678082191780822
tensor([[10.3733, 10.3776, 10.3721, 10.2283, 10.2283, 10.2283, 10.2283, 10.2283,
         10.3735]], device='cuda:0')
REMOVE TEST?! 2 0 1.3082191780821917
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3717, 10.0078, 11.3693, 10.6920, 10.6920,
         10.3735]], device='cuda:1')
REMOVE TEST?! 1 1 1.660958904109589
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735,  8.4046, 11.3659,
          8.4595]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.6678082191780822
tensor([[10.3732, 10.3695, 10.4197, 10.5332, 10.5332, 10.5332, 10.5332, 10.5332,
         10.3735]], device='cuda:0')
REMOVE TEST?! 3 1 1.3082191780821917
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3535, 10.0660, 10.4459, 10.1642, 10.1642,
         10.3735]], device='cuda:1')
REMOVE TEST?! 2 1 1.660958904109589
Cross Entropy List tensor([[10.3735, 10.3735, 10.3734, 10.3735, 10.3735, 10.3735,  8.4551, 10.8971,
          8.1598]], device='cuda:2')
REMOVE TEST?! 1 0 0.6678082191780822
tensor([[10.3732, 10.3705, 10.4224, 10.5380, 10.5380, 10.5380, 10.5380, 10.5380,
         10.3735]], device='cuda:0')
[2, 3]
REMOVE TEST?! 0 0 0.3270547945205479
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3537, 10.0632, 10.4315, 10.1553, 10.1553,
         10.3735]], device='cuda:1')
REMOVE TEST?! 3 1 1.660958904109589
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735,  8.0708,  9.8104,
          7.4440]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.3339041095890411
tensor([[10.3712, 10.3676, 10.4213, 10.5442, 10.5442, 10.5442, 10.5442, 10.5442,
         10.3735]], device='cuda:0')
[0]
REMOVE TEST?! 0 0 0.9811643835616437
Cross Entropy List Cross Entropy List tensor([[10.3730, 10.3730, 10.3730, 10.3534, 10.0581, 10.4064, 10.1356, 10.1357,
         10.3735]], device='cuda:1')
REMOVE TEST?! 4 1 1.660958904109589
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.3736,  8.8170, 12.4450,
          9.5375]], device='cuda:2')
[0]
REMOVE TEST?! 0 0 0.6678082191780822
tensor([[10.3730, 10.3746, 10.4202, 10.4597, 10.4597, 10.4597, 10.4597, 10.4597,
         10.3735]], device='cuda:0')
[0]
REMOVE TEST?! 0 0 0.3270547945205479
Cross Entropy List Cross Entropy List tensor([[10.3727, 10.3727, 10.3727, 10.3536, 10.0643, 10.3934, 10.1304, 10.1304,
         10.3735]], device='cuda:1')
[0]
REMOVE TEST?! 0 0 1.9931506849315068
Cross Entropy List tensor([[10.3737, 10.3737, 10.3736, 10.3736, 10.3737, 10.3737,  9.0110, 11.7043,
          8.9441]], device='cuda:2')
REMOVE TEST?! 1 0 0.6678082191780822
tensor([[10.3732, 10.3711, 10.4262, 10.5516, 10.5516, 10.5516, 10.5516, 10.5516,
         10.3735]], device='cuda:0')
[0]
After Process
A-INPUT tensor([    1, 24728,  3208,   298, 13045, 28705, 28740, 28734,  6052,   298,
          625,  1611, 28723, 28705,   985,   541, 13045, 28705, 28770,   290,
          721,   354,   989,  3316,  1159,   630,  4739, 10272, 28725,   304,
          630,   541, 13045, 28705, 28740,   290,   721,  1996,   630,  4739,
         1611, 28723, 28705,  1602,  1043,   622,   378,  1388, 24728,   298,
          625,  1611, 28804, 28705,     2,   560,   272,   907,   744,   302,
          559,  6596, 28725, 24728,   622,  2796, 28705, 28750,  3316,   398,
        28705, 28770,   290,   721,   327,  2087, 28750, 28736, 28770, 28746,
        28784,  4060, 28784,  6052, 28723,   560,   272,  1676,   744,   302,
          559,  6596, 28725, 24728,   622,   927,   298,  2796,   396,  4870,
        28705, 28740, 28734,  6052,   387, 28705, 28784,  6052,   327,  2087,
        28740, 28734, 28733, 28784, 28746, 28781,  4060, 28781,  6052, 28723,
         2476, 28784, 28705,     2], device='cuda:0')
A-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,   560,   272,   907,   744,   302,
          559,  6596, 28725, 24728,   622,  2796, 28705, 28750,  3316,   398,
        28705, 28770,   290,   721,   327,  2087, 28750, 28736, 28770, 28746,
        28784,  4060, 28784,  6052, 28723,   560,   272,  1676,   744,   302,
          559,  6596, 28725, 24728,   622,   927,   298,  2796,   396,  4870,
        28705, 28740, 28734,  6052,   387, 28705, 28784,  6052,   327,  2087,
        28740, 28734, 28733, 28784, 28746, 28781,  4060, 28781,  6052, 28723,
         2476, 28784, 28705,     2], device='cuda:0')
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3541, 10.1170, 10.6384, 10.2724, 10.2724,
         10.3735]], device='cuda:1')
Loss REMOVE TEST?! 1 0 1.9931506849315068
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.3736,  8.5458, 10.4324,
          8.0088]], device='cuda:2')
[]
tensor(10.3735, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor([[10.3734, 10.3734, 10.3734, 10.3546, 10.1183, 10.6517, 10.2884, 10.2884,
         10.3735]], device='cuda:1')
REMOVE TEST?! 2 0 1.9931506849315068
Loss Cross Entropy List tensor(6.2213, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor([[10.3735, 10.3735, 10.3735, 10.3785, 10.2281, 10.2927, 10.2931, 10.2931,
         10.3735]], device='cuda:1')
REMOVE TEST?! 3 0 1.9931506849315068
Cross Entropy List Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.42879799008369446
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13579674065113068
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.157207652926445
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15842145681381226
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1556103676557541
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1543339192867279
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15233905613422394
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15101321041584015
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15212590992450714
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15493007004261017
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15860867500305176
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16718928515911102
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16120657324790955
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15676391124725342
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15410742163658142
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15361326932907104
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15400095283985138
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15766078233718872
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15773499011993408
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16129916906356812
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15631115436553955
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1550547331571579
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1533435732126236
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15086200833320618
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15047957003116608
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15410755574703217
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15739716589450836
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15619970858097076
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16315840184688568
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15834693610668182
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1552010476589203
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15338486433029175
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1535249650478363
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15667642652988434
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1358664184808731
 33%|███▎      | 191/584 [19:47<23:54,  3.65s/it]Before Process
B-INPUT tensor([    1,  6213,   264,  5028,   356, 10966, 28725,   264,  8626, 28254,
          559,   875,  7201,   559,  3567,   989,  4224, 28723, 28705,   415,
          907,  2996,   403,  3161,   590,  5273,  9540,   442, 18097, 28725,
          304,   272,  1676,  2996,   403,  3161,   590, 10615,   442,  3798,
         3897, 28723, 28705,  4529,   272, 28705, 28770, 28734,  3567,   297,
          559,   875, 28725, 28705, 28782, 28734, 28823, 10008,  9540,   304,
         3798,  3897,   390,   652,   989, 11194, 28725,  1312, 28705, 28740,
        28734, 28823, 10008,  9540,   304, 10615,   390,   652,   989, 11194,
        28723, 28705,   560,  3102, 28725,   910,  1287,  3567,   297,   456,
         8626, 28742, 28713,   875,  5273,  9540,   754, 18097, 28804, 28705,
            2,   415, 28705, 28782, 28734, 28823,   302,   272,   875,   369,
        10008,  9540,   304,  3798,  3897, 14838,   298, 28705, 28770, 28734,
        28736, 28734, 28723, 28782,   327,  2087, 28782, 28734,  2414, 28734,
        28740, 28736, 28770, 28734, 28746, 28740, 28782,  4060, 28740, 28782,
         3567,   693,  5273,  9540,   754, 18097, 28723, 19190, 28725,   272,
        28705, 28740, 28734, 28823,   369, 10008,  9540,   304, 10615,  3558,
          298, 28705, 28770, 28734, 28736, 28734, 28723, 28740,   327,  2087,
        28770, 28734, 28736, 28734, 28723, 28740, 28746, 28770,  4060, 28770,
         3567,   693,  5273,  9540,   754, 18097, 28723,  5518,  1167,   460,
          272,   865,   989,  4342,   369,   264,  5716,   829, 11634,   652,
        21448,   354,  9540, 28725,   304,  1096,  1167,  4938,   511,   459,
        26808, 28725,   264,  3102,   302, 28705, 28740, 28782,   648, 28705,
        28770,   327,  2087, 28740, 28782, 28806, 28770, 28746, 28740, 28783,
         4060, 28740, 28783,  3567,  4268,  9540,   754, 18097,   297,   456,
         8626, 28742, 28713,   875, 28723, 28705,     2,  2476, 28740, 28783,
        28705,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2], device='cuda:0')
B-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,   415, 28705, 28782, 28734, 28823,   302,   272,   875,   369,
        10008,  9540,   304,  3798,  3897, 14838,   298, 28705, 28770, 28734,
        28736, 28734, 28723, 28782,   327,  2087, 28782, 28734,  2414, 28734,
        28740, 28736, 28770, 28734, 28746, 28740, 28782,  4060, 28740, 28782,
         3567,   693,  5273,  9540,   754, 18097, 28723, 19190, 28725,   272,
        28705, 28740, 28734, 28823,   369, 10008,  9540,   304, 10615,  3558,
          298, 28705, 28770, 28734, 28736, 28734, 28723, 28740,   327,  2087,
        28770, 28734, 28736, 28734, 28723, 28740, 28746, 28770,  4060, 28770,
         3567,   693,  5273,  9540,   754, 18097, 28723,  5518,  1167,   460,
          272,   865,   989,  4342,   369,   264,  5716,   829, 11634,   652,
        21448,   354,  9540, 28725,   304,  1096,  1167,  4938,   511,   459,
        26808, 28725,   264,  3102,   302, 28705, 28740, 28782,   648, 28705,
        28770,   327,  2087, 28740, 28782, 28806, 28770, 28746, 28740, 28783,
         4060, 28740, 28783,  3567,  4268,  9540,   754, 18097,   297,   456,
         8626, 28742, 28713,   875, 28723, 28705,     2,  2476, 28740, 28783,
        28705,     2,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100], device='cuda:0')
[tensor([[  415, 28705, 28782, 28734, 28823,   302,   272,   875,   369, 10008,
          9540,   304,  3798,  3897, 14838,   298, 28705, 28770, 28734, 28736,
         28734, 28723]], device='cuda:0'), tensor([[28782,   327,  2087, 28782, 28734,  2414, 28734, 28740, 28736, 28770,
         28734, 28746, 28740, 28782,  4060, 28740, 28782,  3567,   693,  5273,
          9540,   754, 18097, 28723]], device='cuda:0'), tensor([[19190, 28725,   272, 28705, 28740, 28734, 28823,   369, 10008,  9540,
           304, 10615,  3558,   298, 28705, 28770, 28734, 28736, 28734, 28723]],
       device='cuda:0'), tensor([[28740,   327,  2087, 28770, 28734, 28736, 28734, 28723]],
       device='cuda:0'), tensor([[28740, 28746, 28770,  4060, 28770,  3567,   693,  5273,  9540,   754,
         18097, 28723]], device='cuda:0'), tensor([[ 5518,  1167,   460,   272,   865,   989,  4342,   369,   264,  5716,
           829, 11634,   652, 21448,   354,  9540, 28725,   304,  1096,  1167,
          4938,   511,   459, 26808, 28725,   264,  3102,   302, 28705, 28740,
         28782,   648, 28705, 28770,   327,  2087, 28740, 28782, 28806, 28770,
         28746, 28740, 28783,  4060, 28740, 28783,  3567,  4268,  9540,   754,
         18097,   297,   456,  8626, 28742, 28713,   875, 28723, 28705,     2]],
       device='cuda:0')]
REMOVE TEST?! 0 0 1.9726027397260273
tensor([[10.3734, 10.3734, 10.3734, 10.3296, 11.3871, 10.5750, 10.6579, 10.6579,
         10.3735]], device='cuda:1')
REMOVE TEST?! 4 1 1.9931506849315068
Cross Entropy List Cross Entropy List Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2313937395811081
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0693940743803978
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07963287830352783
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07963447272777557
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08114854246377945
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08247523754835129
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08257721364498138
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08134555071592331
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0794316753745079
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08068735897541046
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.49528396129608154
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5661759972572327
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4404657781124115
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20069840550422668
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.8174578286789256e-08
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.4975742363153586e-08
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.722005293913753e-08
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.7598394680694582e-08
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.057343125343322754
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07481568306684494
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07406190782785416
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07337918132543564
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07343467324972153
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07476691156625748
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07613788545131683
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07619114220142365
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0767073780298233
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07660821080207825
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07566874474287033
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07510499656200409
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07464873045682907
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07396435737609863
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07319317013025284
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07343457639217377
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04371606186032295
 33%|███▎      | 195/584 [19:50<20:46,  3.21s/it]REMOVE TEST?! 0 0 1.0068493150684932
tensor([[10.3736, 10.3736, 10.3736, 10.4398, 10.2246, 10.1953, 10.2295, 10.2295,
         10.3735]], device='cuda:1')
REMOVE TEST?! 5 1 1.9931506849315068
tensor([[10.3733, 10.3471, 10.3498, 10.3475, 10.3475, 10.3476, 10.3475, 10.3475,
         10.3735]], device='cuda:0')
REMOVE TEST?! 1 1 1.9726027397260273
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3736, 10.3737, 10.3737, 10.3736, 10.3736, 10.3736,  9.5625, 10.5471,
          8.9587]], device='cuda:2')
REMOVE TEST?! 1 0 1.0068493150684932
tensor([[10.3732, 10.3732, 10.3732, 10.3881, 10.0865, 10.2870, 10.1818, 10.1818,
         10.3735]], device='cuda:1')
[3]
REMOVE TEST?! 0 0 0.3321917808219178
tensor([[10.3734, 10.3762, 10.4555, 10.3874, 10.3874, 10.3874, 10.3874, 10.3874,
         10.3735]], device='cuda:0')
[0, 1]
REMOVE TEST?! 0 0 0.3287671232876712
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.3736,  9.7562,  9.3926,
          8.5153]], device='cuda:2')
REMOVE TEST?! 2 0 1.0068493150684932
tensor([[10.3736, 10.3736, 10.3736, 10.3628, 10.1351, 11.4059, 11.1091, 11.1091,
         10.3735]], device='cuda:1')
[]
tensor([[10.3734, 10.3756, 10.3645, 10.3625, 10.3625, 10.3624, 10.3625, 10.3625,
         10.3735]], device='cuda:0')
[]
REMOVE TEST?! 0 0 0.3287671232876712
Cross Entropy List Cross Entropy List Loss tensor([[10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.3736,  9.7350,  9.1634,
          8.3389]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.3356164383561644
tensor(10.3735, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor([[10.3709, 10.3765, 10.3755, 10.2736, 10.2736, 10.2736, 10.2736, 10.2736,
         10.3735]], device='cuda:0')
[]
REMOVE TEST?! 0 0 0.3287671232876712
Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735,  8.4574,  8.8357,
          7.2988]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.6712328767123288
tensor([[10.3732, 10.3823, 10.4235, 10.2345, 10.2345, 10.2345, 10.2345, 10.2345,
         10.3735]], device='cuda:0')
[]
After Process
A-INPUT tensor([    1,  6213,   264,  5028,   356, 10966, 28725,   264,  8626, 28254,
          559,   875,  7201,   559,  3567,   989,  4224, 28723, 28705,   415,
          907,  2996,   403,  3161,   590,  5273,  9540,   442, 18097, 28725,
          304,   272,  1676,  2996,   403,  3161,   590, 10615,   442,  3798,
         3897, 28723, 28705,  4529,   272, 28705, 28770, 28734,  3567,   297,
          559,   875, 28725, 28705, 28782, 28734, 28823, 10008,  9540,   304,
         3798,  3897,   390,   652,   989, 11194, 28725,  1312, 28705, 28740,
        28734, 28823, 10008,  9540,   304, 10615,   390,   652,   989, 11194,
        28723, 28705,   560,  3102, 28725,   910,  1287,  3567,   297,   456,
         8626, 28742, 28713,   875,  5273,  9540,   754, 18097, 28804, 28705,
            2, 19190, 28725,   272, 28705, 28740, 28734, 28823,   369, 10008,
         9540,   304, 10615,  3558,   298, 28705, 28770, 28734, 28736, 28734,
        28723, 28740,   327,  2087, 28770, 28734, 28736, 28734, 28723, 28740,
        28746, 28770,  4060, 28770,  3567,   693,  5273,  9540,   754, 18097,
        28723,  5518,  1167,   460,   272,   865,   989,  4342,   369,   264,
         5716,   829, 11634,   652, 21448,   354,  9540, 28725,   304,  1096,
         1167,  4938,   511,   459, 26808, 28725,   264,  3102,   302, 28705,
        28740, 28782,   648, 28705, 28770,   327,  2087, 28740, 28782, 28806,
        28770, 28746, 28740, 28783,  4060, 28740, 28783,  3567,  4268,  9540,
          754, 18097,   297,   456,  8626, 28742, 28713,   875, 28723, 28705,
            2,  2476, 28740, 28783, 28705,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2], device='cuda:0')
A-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100, 19190, 28725,   272, 28705, 28740, 28734, 28823,   369, 10008,
         9540,   304, 10615,  3558,   298, 28705, 28770, 28734, 28736, 28734,
        28723, 28740,   327,  2087, 28770, 28734, 28736, 28734, 28723, 28740,
        28746, 28770,  4060, 28770,  3567,   693,  5273,  9540,   754, 18097,
        28723,  5518,  1167,   460,   272,   865,   989,  4342,   369,   264,
         5716,   829, 11634,   652, 21448,   354,  9540, 28725,   304,  1096,
         1167,  4938,   511,   459, 26808, 28725,   264,  3102,   302, 28705,
        28740, 28782,   648, 28705, 28770,   327,  2087, 28740, 28782, 28806,
        28770, 28746, 28740, 28783,  4060, 28740, 28783,  3567,  4268,  9540,
          754, 18097,   297,   456,  8626, 28742, 28713,   875, 28723, 28705,
            2,  2476, 28740, 28783, 28705,     2,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100], device='cuda:0')
Cross Entropy List Loss tensor([[10.3737, 10.3737, 10.3737, 10.3737, 10.3737, 10.3737,  8.9565, 10.5348,
          8.3464]], device='cuda:2')
REMOVE TEST?! 1 0 0.6712328767123288
tensor(10.3735, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.425817608833313
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13485926389694214
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1526831090450287
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16214700043201447
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1609216034412384
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15794754028320312
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15507395565509796
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.155229851603508
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15682756900787354
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1578151285648346
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15716451406478882
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15836071968078613
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15593065321445465
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15499022603034973
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15366452932357788
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1528603434562683
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1537514477968216
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15609197318553925
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15645423531532288
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1566813886165619
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16153539717197418
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15890498459339142
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15592022240161896
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15539836883544922
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15519694983959198
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15768463909626007
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1579923927783966
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1580495685338974
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1568826586008072
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1554141640663147
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15457876026630402
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15245632827281952
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15221945941448212
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15594254434108734
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13485926389694214
 33%|███▎      | 194/584 [19:46<24:37,  3.79s/it]REMOVE TEST?! 0 0 0.6678082191780822
Cross Entropy List Cross Entropy List tensor([[10.3737, 10.3737, 10.3737, 10.3737, 10.3737, 10.3737,  8.6889, 10.4633,
          8.1494]], device='cuda:2')
[]
REMOVE TEST?! 0 0 1.0068493150684932
Cross Entropy List tensor([[10.3737, 10.3737, 10.3737, 10.4176, 10.8554, 10.1204, 10.1885, 10.1885,
         10.3728]], device='cuda:1')
REMOVE TEST?! 1 0 0.6678082191780822
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  8.9269, 10.8471,
          8.8202]], device='cuda:2')
REMOVE TEST?! 1 0 1.0068493150684932
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15517836809158325
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.049186065793037415
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.056867197155952454
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05735771730542183
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05634136497974396
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.055880289524793625
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05516010522842407
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05467728152871132
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05508468672633171
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05609852820634842
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05742755904793739
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07746235281229019
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05907779559493065
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05732192471623421
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.056204523891210556
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05553099513053894
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0555972158908844
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05672334134578705
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05716387555003166
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05693382769823074
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05713846907019615
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05629752576351166
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0558098703622818
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.054969485849142075
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05453226715326309
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05533147230744362
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05633403733372688
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.056177232414484024
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5666449666023254
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5071005821228027
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.42741501331329346
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3570360839366913
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.6757013528503895e-12
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.806657579615789e-12
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 5.370639696855584e-12
 33%|███▎      | 192/584 [19:53<27:05,  4.15s/it]Before Process
B-INPUT tensor([    1,   320,  1380, 28742, 28713, 19729,   659,   272,  1348,  3558,
          302,  3567,   390,  6068,  2614, 28742, 28713, 28723,  1054,   468,
        28742, 28713, 19729,   659,  2795,   272,  3558,   302,  3102,  3567,
         1444,   320,  1380,   304,  6068,  2614, 28742, 28713,   875, 14520,
        28723,  1602,  1287,  3567,   460,   736,   297,  3102,  1444,   272,
        28705, 28770,   875, 14520,   513,   739,  1054,   468,   403,  7946,
          736,   654, 28705, 28750, 28750,  3567,   297,   516,   875, 28804,
        28705,     2,  1047,  1054,   468, 28742, 28713, 19729,   553, 28705,
        28750, 28750,  3567,   739,   400,   403, 20311, 28725,   868,   272,
         3102,  3567,   297,   516,   875,   460, 28705, 28750, 28750, 28806,
        28740,   327,  2087, 28750, 28750, 28806, 28740, 28746, 28750, 28770,
         4060, 28750, 28770,  1047,   320,  1380, 28742, 28713, 19729,   659,
          390,  1287,  3567,   390,  6068,  2614, 28742, 28713,   868,   320,
        28746, 28755,  1047,  1054,   468, 28742, 28713, 19729,   659,  2795,
          272,  3558,   302,  3102,  3567,  1444,   320,  1380,   304,  6068,
         2614, 28742, 28713,   875, 14520,   868, 28705, 28750, 28770,   327,
        28705, 28740, 28748, 28750, 28736,   325, 28738, 28806, 28755,  1143,
        28705, 28750, 28770,   327, 28705, 28740, 28748, 28750, 13411, 28738,
        28806, 28755, 28731,   816,   873,   477,  2747,   369,   320, 28746,
        28755, 28725,  6166, 28705, 28750, 28770,   327,   325, 28740, 28748,
        28750, 28731,   398,   325, 28755, 28806, 28755, 28731,   442, 28705,
        28750, 28770,   327,   325, 28740, 28748, 28750,  4869, 28750, 28755,
        28705, 28750, 28770,   327,   351,  5518,   320,   327,   351, 28725,
          868,   320,   349,   835,   320, 28746, 28750, 28770, 28723, 18046,
          272,  1712,  6709,   868,   478,   506,   264,  3102,   302,   320,
        28806, 28755, 28806, 28828,   442, 28705, 28750, 28770, 28806, 28750,
        28770, 28806, 28750, 28770, 28746,  5275, 28750, 28770, 28806, 28750,
        28770, 28806, 28750, 28770, 28746, 28784, 28774,  4060, 28784, 28774,
        28705,     2,  2476, 28784, 28774, 28705,     2], device='cuda:0')
B-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  1047,  1054,   468, 28742, 28713, 19729,   553, 28705,
        28750, 28750,  3567,   739,   400,   403, 20311, 28725,   868,   272,
         3102,  3567,   297,   516,   875,   460, 28705, 28750, 28750, 28806,
        28740,   327,  2087, 28750, 28750, 28806, 28740, 28746, 28750, 28770,
         4060, 28750, 28770,  1047,   320,  1380, 28742, 28713, 19729,   659,
          390,  1287,  3567,   390,  6068,  2614, 28742, 28713,   868,   320,
        28746, 28755,  1047,  1054,   468, 28742, 28713, 19729,   659,  2795,
          272,  3558,   302,  3102,  3567,  1444,   320,  1380,   304,  6068,
         2614, 28742, 28713,   875, 14520,   868, 28705, 28750, 28770,   327,
        28705, 28740, 28748, 28750, 28736,   325, 28738, 28806, 28755,  1143,
        28705, 28750, 28770,   327, 28705, 28740, 28748, 28750, 13411, 28738,
        28806, 28755, 28731,   816,   873,   477,  2747,   369,   320, 28746,
        28755, 28725,  6166, 28705, 28750, 28770,   327,   325, 28740, 28748,
        28750, 28731,   398,   325, 28755, 28806, 28755, 28731,   442, 28705,
        28750, 28770,   327,   325, 28740, 28748, 28750,  4869, 28750, 28755,
        28705, 28750, 28770,   327,   351,  5518,   320,   327,   351, 28725,
          868,   320,   349,   835,   320, 28746, 28750, 28770, 28723, 18046,
          272,  1712,  6709,   868,   478,   506,   264,  3102,   302,   320,
        28806, 28755, 28806, 28828,   442, 28705, 28750, 28770, 28806, 28750,
        28770, 28806, 28750, 28770, 28746,  5275, 28750, 28770, 28806, 28750,
        28770, 28806, 28750, 28770, 28746, 28784, 28774,  4060, 28784, 28774,
        28705,     2,  2476, 28784, 28774, 28705,     2], device='cuda:0')
[tensor([[ 1047,  1054,   468, 28742, 28713, 19729,   553, 28705, 28750, 28750,
          3567,   739,   400,   403, 20311, 28725,   868,   272,  3102,  3567,
           297,   516,   875,   460, 28705, 28750, 28750, 28806, 28740,   327,
          2087, 28750, 28750, 28806, 28740, 28746, 28750, 28770,  4060, 28750,
         28770,  1047,   320,  1380, 28742, 28713, 19729,   659,   390,  1287,
          3567,   390,  6068,  2614, 28742, 28713,   868,   320, 28746, 28755,
          1047,  1054,   468, 28742, 28713, 19729,   659,  2795,   272,  3558,
           302,  3102,  3567,  1444,   320,  1380,   304,  6068,  2614, 28742,
         28713,   875, 14520,   868, 28705, 28750, 28770,   327, 28705, 28740,
         28748, 28750, 28736,   325, 28738, 28806, 28755,  1143, 28705, 28750,
         28770,   327, 28705, 28740, 28748, 28750, 13411, 28738, 28806, 28755,
         28731,   816,   873,   477,  2747,   369,   320, 28746, 28755, 28725,
          6166, 28705, 28750, 28770,   327,   325, 28740, 28748, 28750, 28731,
           398,   325, 28755, 28806, 28755, 28731,   442, 28705, 28750, 28770,
           327,   325, 28740, 28748, 28750,  4869, 28750, 28755, 28705, 28750,
         28770,   327,   351,  5518,   320,   327,   351, 28725,   868,   320,
           349,   835,   320, 28746, 28750, 28770, 28723, 18046,   272,  1712,
          6709,   868,   478,   506,   264,  3102,   302,   320, 28806, 28755,
         28806, 28828,   442, 28705, 28750, 28770, 28806, 28750, 28770, 28806,
         28750, 28770, 28746,  5275, 28750, 28770, 28806, 28750, 28770, 28806,
         28750, 28770, 28746, 28784, 28774,  4060, 28784, 28774, 28705,     2]],
       device='cuda:0')]
REMOVE TEST?! 0 0 0.3304794520547945
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.4189, 10.6198, 10.0827, 10.1575, 10.1575,
         10.3725]], device='cuda:1')
[]
REMOVE TEST?! 0 0 0.3339041095890411
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3733, 10.3734, 10.3733,  8.4544, 12.0867,
          8.9206]], device='cuda:2')
REMOVE TEST?! 2 0 1.0068493150684932
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3716, 10.1513, 11.0200, 10.6353, 10.6353,
         10.3733]], device='cuda:1')
[0]
REMOVE TEST?! 0 0 0.3339041095890411
tensor([[10.3729, 10.3766, 10.3680, 10.3642, 10.3642, 10.3642, 10.3642, 10.3642,
         10.3738]], device='cuda:0')
[]
REMOVE TEST?! 0 0 1.321917808219178
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  9.5479,  9.4777,
          8.3718]], device='cuda:2')
[]
tensor([[10.3733, 10.3733, 10.3733, 10.4099, 10.1817, 10.2630, 10.2264, 10.2264,
         10.3728]], device='cuda:1')
[]
REMOVE TEST?! 0 0 0.3339041095890411
tensor([[10.3733, 10.3732, 10.3096, 10.2620, 10.2620, 10.2620, 10.2620, 10.2620,
         10.3707]], device='cuda:0')
Loss REMOVE TEST?! 1 0 1.321917808219178
Cross Entropy List Cross Entropy List tensor(8.1757, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor([[10.3736, 10.3736, 10.3736, 10.4404, 10.0742, 10.4576, 10.1645, 10.1645,
         10.3731]], device='cuda:1')
[]
tensor([[10.3733, 10.3746, 10.3247, 10.2511, 10.2511, 10.2511, 10.2511, 10.2511,
         10.3707]], device='cuda:0')
REMOVE TEST?! 2 0 1.321917808219178
Loss Cross Entropy List tensor(10.3726, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor([[10.3733, 10.3706, 11.0873, 11.0899, 11.0899, 11.0899, 11.0899, 11.0899,
         10.3734]], device='cuda:0')
REMOVE TEST?! 3 1 1.321917808219178
Cross Entropy List Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8148914575576782
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2921677827835083
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06143622472882271
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06221293285489082
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06315592676401138
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06438827514648438
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06389649212360382
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06219920516014099
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.061766672879457474
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05814654752612114
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0675792321562767
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06644614785909653
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06676749140024185
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06700354814529419
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06621865183115005
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06564932316541672
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06414183229207993
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06342559307813644
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0616881363093853
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06171529367566109
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06279698014259338
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06392975151538849
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06403618305921555
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.33363884687423706
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08694811910390854
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07006652653217316
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07064959406852722
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0677172988653183
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06800007075071335
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06789692491292953
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06724070012569427
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06676603853702545
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06506514549255371
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06383755058050156
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07262024283409119
 34%|███▎      | 196/584 [19:57<27:03,  4.19s/it]REMOVE TEST?! 0 0 1.0119863013698631
tensor([[10.3734, 10.3797, 10.3767, 10.2331, 10.2331, 10.2331, 10.2331, 10.2330,
         10.3709]], device='cuda:0')
[2]
REMOVE TEST?! 0 0 2.3133561643835616
Cross Entropy List Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.3736,  8.4641, 12.2284,
          8.4562]], device='cuda:2')
REMOVE TEST?! 1 0 1.0119863013698631
tensor([[10.3734, 10.3699, 10.3309, 10.2811, 10.2810, 10.2810, 10.2810, 10.2810,
         10.3713]], device='cuda:0')
REMOVE TEST?! 1 0 2.3133561643835616
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09143226593732834
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02896019071340561
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03722904995083809
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03362378478050232
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03464066982269287
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03407563641667366
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03343196213245392
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03333454579114914
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03327789530158043
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03383580222725868
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.033904995769262314
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.033917203545570374
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03366740047931671
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.033351361751556396
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0331735759973526
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03270701318979263
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03266187384724617
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03346255049109459
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03367834910750389
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6669961214065552
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.43863818049430847
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.42540639638900757
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.38048508763313293
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0369994193315506
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.034363385289907455
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03291440010070801
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03360903263092041
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014579987153410912
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021991724148392677
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02197156473994255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021863525733351707
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021799761801958084
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021520446985960007
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02123994752764702
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02387499064207077
 33%|███▎      | 195/584 [19:51<28:01,  4.32s/it]REMOVE TEST?! 0 0 0.3356164383561644
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  8.3396,  9.8300,
          7.3810]], device='cuda:2')
REMOVE TEST?! 2 0 1.0119863013698631
tensor([[10.3734, 10.3696, 10.3567, 10.3085, 10.3085, 10.3085, 10.3085, 10.3085,
         10.3727]], device='cuda:0')
REMOVE TEST?! 2 0 2.3133561643835616
Cross Entropy List Cross Entropy List tensor([[10.3726, 10.3726, 10.3726, 10.3898, 10.1210, 10.6711, 10.2423, 10.2423,
         10.3733]], device='cuda:1')
[0]
REMOVE TEST?! 0 0 1.0068493150684932
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  7.7693, 10.3530,
          7.3279]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.3373287671232877
tensor([[10.3735, 10.3691, 10.3868, 10.2712, 10.2712, 10.2712, 10.2712, 10.2712,
         10.3713]], device='cuda:0')
REMOVE TEST?! 3 0 2.3133561643835616
Cross Entropy List Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.4994, 11.3978, 10.1364, 10.1101, 10.1101,
         10.3736]], device='cuda:1')
REMOVE TEST?! 1 0 1.0068493150684932
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735,  8.8289, 12.9496,
          9.2910]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.3373287671232877
tensor([[10.3734, 10.3616, 10.3430, 10.5200, 10.5200, 10.5201, 10.5200, 10.5200,
         10.3752]], device='cuda:0')
REMOVE TEST?! 4 1 2.3133561643835616
Cross Entropy List Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.4875, 11.4060, 10.1506, 10.1253, 10.1253,
         10.3736]], device='cuda:1')
REMOVE TEST?! 2 0 1.0068493150684932
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.3736,  7.9870, 11.9602,
          8.4493]], device='cuda:2')
[]
REMOVE TEST?! 0 0 4.0479452054794525
tensor([[10.3734, 10.3617, 10.3388, 10.5171, 10.5171, 10.5171, 10.5171, 10.5171,
         10.3752]], device='cuda:0')
REMOVE TEST?! 5 2 2.3133561643835616
Cross Entropy List Cross Entropy List tensor([[10.3737, 10.3737, 10.3737, 10.4663, 11.4436, 10.1718, 10.1440, 10.1440,
         10.3735]], device='cuda:1')
[]
REMOVE TEST?! 0 0 2.0136986301369864
Cross Entropy List tensor([[10.3737, 10.3737, 10.3737, 10.3737, 10.3737, 10.3737,  9.0567, 14.2820,
          9.9436]], device='cuda:2')
REMOVE TEST?! 1 0 4.0479452054794525
tensor([[10.3734, 10.3621, 10.3435, 10.5220, 10.5220, 10.5220, 10.5220, 10.5220,
         10.3752]], device='cuda:0')
[3, 4, 5]
REMOVE TEST?! 0 0 0.9914383561643836
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.4280, 11.4230, 10.1661, 10.1577, 10.1577,
         10.3735]], device='cuda:1')
REMOVE TEST?! 1 0 2.0136986301369864
Cross Entropy List Cross Entropy List tensor([[10.3737, 10.3737, 10.3737, 10.3737, 10.3737, 10.3737,  8.8699, 13.7255,
          9.5918]], device='cuda:2')
REMOVE TEST?! 2 0 4.0479452054794525
tensor([[10.3735, 10.3638, 10.3934, 10.4689, 10.4689, 10.4689, 10.4689, 10.4689,
         10.3750]], device='cuda:0')
[0]
After Process
A-INPUT tensor([    1,   320,  1380, 28742, 28713, 19729,   659,   272,  1348,  3558,
          302,  3567,   390,  6068,  2614, 28742, 28713, 28723,  1054,   468,
        28742, 28713, 19729,   659,  2795,   272,  3558,   302,  3102,  3567,
         1444,   320,  1380,   304,  6068,  2614, 28742, 28713,   875, 14520,
        28723,  1602,  1287,  3567,   460,   736,   297,  3102,  1444,   272,
        28705, 28770,   875, 14520,   513,   739,  1054,   468,   403,  7946,
          736,   654, 28705, 28750, 28750,  3567,   297,   516,   875, 28804,
        28705,     2,  1047,  1054,   468, 28742, 28713, 19729,   553, 28705,
        28750, 28750,  3567,   739,   400,   403, 20311, 28725,   868,   272,
         3102,  3567,   297,   516,   875,   460, 28705, 28750, 28750, 28806,
        28740,   327,  2087, 28750, 28750, 28806, 28740, 28746, 28750, 28770,
         4060, 28750, 28770,  1047,   320,  1380, 28742, 28713, 19729,   659,
          390,  1287,  3567,   390,  6068,  2614, 28742, 28713,   868,   320,
        28746, 28755,  1047,  1054,   468, 28742, 28713, 19729,   659,  2795,
          272,  3558,   302,  3102,  3567,  1444,   320,  1380,   304,  6068,
         2614, 28742, 28713,   875, 14520,   868, 28705, 28750, 28770,   327,
        28705, 28740, 28748, 28750, 28736,   325, 28738, 28806, 28755,  1143,
        28705, 28750, 28770,   327, 28705, 28740, 28748, 28750, 13411, 28738,
        28806, 28755, 28731,   816,   873,   477,  2747,   369,   320, 28746,
        28755, 28725,  6166, 28705, 28750, 28770,   327,   325, 28740, 28748,
        28750, 28731,   398,   325, 28755, 28806, 28755, 28731,   442, 28705,
        28750, 28770,   327,   325, 28740, 28748, 28750,  4869, 28750, 28755,
        28705, 28750, 28770,   327,   351,  5518,   320,   327,   351, 28725,
          868,   320,   349,   835,   320, 28746, 28750, 28770, 28723, 18046,
          272,  1712,  6709,   868,   478,   506,   264,  3102,   302,   320,
        28806, 28755, 28806, 28828,   442, 28705, 28750, 28770, 28806, 28750,
        28770, 28806, 28750, 28770, 28746,  5275, 28750, 28770, 28806, 28750,
        28770, 28806, 28750, 28770, 28746, 28784, 28774,  4060, 28784, 28774,
        28705,     2,  2476, 28784, 28774, 28705,     2], device='cuda:0')
A-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  1047,  1054,   468, 28742, 28713, 19729,   553, 28705,
        28750, 28750,  3567,   739,   400,   403, 20311, 28725,   868,   272,
         3102,  3567,   297,   516,   875,   460, 28705, 28750, 28750, 28806,
        28740,   327,  2087, 28750, 28750, 28806, 28740, 28746, 28750, 28770,
         4060, 28750, 28770,  1047,   320,  1380, 28742, 28713, 19729,   659,
          390,  1287,  3567,   390,  6068,  2614, 28742, 28713,   868,   320,
        28746, 28755,  1047,  1054,   468, 28742, 28713, 19729,   659,  2795,
          272,  3558,   302,  3102,  3567,  1444,   320,  1380,   304,  6068,
         2614, 28742, 28713,   875, 14520,   868, 28705, 28750, 28770,   327,
        28705, 28740, 28748, 28750, 28736,   325, 28738, 28806, 28755,  1143,
        28705, 28750, 28770,   327, 28705, 28740, 28748, 28750, 13411, 28738,
        28806, 28755, 28731,   816,   873,   477,  2747,   369,   320, 28746,
        28755, 28725,  6166, 28705, 28750, 28770,   327,   325, 28740, 28748,
        28750, 28731,   398,   325, 28755, 28806, 28755, 28731,   442, 28705,
        28750, 28770,   327,   325, 28740, 28748, 28750,  4869, 28750, 28755,
        28705, 28750, 28770,   327,   351,  5518,   320,   327,   351, 28725,
          868,   320,   349,   835,   320, 28746, 28750, 28770, 28723, 18046,
          272,  1712,  6709,   868,   478,   506,   264,  3102,   302,   320,
        28806, 28755, 28806, 28828,   442, 28705, 28750, 28770, 28806, 28750,
        28770, 28806, 28750, 28770, 28746,  5275, 28750, 28770, 28806, 28750,
        28770, 28806, 28750, 28770, 28746, 28784, 28774,  4060, 28784, 28774,
        28705,     2,  2476, 28784, 28774, 28705,     2], device='cuda:0')
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.4242, 11.4347, 10.1597, 10.1491, 10.1491,
         10.3735]], device='cuda:1')
REMOVE TEST?! 2 0 2.0136986301369864
Loss Cross Entropy List tensor([[10.3737, 10.3737, 10.3737, 10.3737, 10.3737, 10.3737,  8.8137, 13.5500,
          9.4836]], device='cuda:2')
REMOVE TEST?! 3 0 4.0479452054794525
tensor(10.3751, device='cuda:0', grad_fn=<NllLossBackward0>)
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.4235, 11.4450, 10.1600, 10.1487, 10.1487,
         10.3735]], device='cuda:1')
REMOVE TEST?! 3 0 2.0136986301369864
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.3736,  8.7595, 12.0534,
          8.6609]], device='cuda:2')
REMOVE TEST?! 4 0 4.0479452054794525
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.4126, 13.9516, 12.5809, 13.1117, 13.1117,
         10.3737]], device='cuda:1')
REMOVE TEST?! 4 1 2.0136986301369864
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735,  8.5021, 11.9612,
          8.7636]], device='cuda:2')
REMOVE TEST?! 5 1 4.0479452054794525
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.42885515093803406
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13593576848506927
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15716491639614105
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15851986408233643
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1557110697031021
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15443691611289978
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15244744718074799
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15111370384693146
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1522401124238968
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15504100918769836
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15884654223918915
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16723603010177612
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16125719249248505
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15681974589824677
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15423372387886047
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15367376804351807
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15406158566474915
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1577305793762207
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1578119844198227
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15815836191177368
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15641137957572937
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1551552265882492
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15344864130020142
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1509784460067749
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15059731900691986
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15422111749649048
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15755043923854828
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15637288987636566
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16321982443332672
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15840330719947815
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15531344711780548
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15344780683517456
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15358862280845642
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1567472368478775
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13593576848506927
 33%|███▎      | 193/584 [19:57<26:24,  4.05s/it]Before Process
B-INPUT tensor([    1,   393,  6519, 25061,   264,  1253,   811,  2302,  2496, 28723,
         1387,   460,  1712,  2760,  8300,   304,   989,  3075,  8300,  2632,
          298,  7358, 28723,   399,   308,   288,   272,  3075,  1253,  6966,
          429, 28750,   354,  1012,  7117,   304,   272,  2760,  1253,   429,
        28770,   354,  1012,  7117, 28723,  1682,  8300,   654,  7358,   286,
          354, 28705, 28770,  3316, 28723,  1602,  1188,  2445,   863,   393,
         6519,  6384, 28804, 28705,     2,  7829,  3075,  8300,   654,  7358,
          286,   354, 28705, 28750,   398, 28705, 28750,   327,   429,  5275,
        28750, 28736, 28750, 28746, 28781,  4060, 28781,   354,  1012,  7117,
        28723,  1682,  1712,  2760,  8300,   654,  7358,   286,   354, 28705,
        28770,   398, 28705, 28770,   327,   429,  5275, 28770, 28736, 28770,
        28746, 28774,  4060, 28774,   354,  1012,  7117, 28723,  1537,   544,
          393,  6519, 28742, 28713,  8300,   654,  7358,   286,   354, 28705,
        28781,   648, 28705, 28774,   327,   429,  5275, 28781, 28806, 28774,
        28746, 28740, 28770,  4060, 28740, 28770,   354,  1012,  7117, 28723,
         9673,  3316,   460, 28705, 28740, 28783, 28734,  3486, 28725,   579,
          393,  6519, 12839, 28705, 28740, 28770,   398, 28705, 28740, 28783,
        28734,   327,   429,  5275, 28740, 28770, 28736, 28740, 28783, 28734,
        28746, 28750, 28770, 28781, 28734,  4060, 28750, 28770, 28781, 28734,
          354,  7358,   288,   544,   272,  8300, 28723, 28705,     2,  2476,
        28750, 28770, 28781, 28734, 28705,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2], device='cuda:0')
B-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  7829,  3075,  8300,   654,  7358,
          286,   354, 28705, 28750,   398, 28705, 28750,   327,   429,  5275,
        28750, 28736, 28750, 28746, 28781,  4060, 28781,   354,  1012,  7117,
        28723,  1682,  1712,  2760,  8300,   654,  7358,   286,   354, 28705,
        28770,   398, 28705, 28770,   327,   429,  5275, 28770, 28736, 28770,
        28746, 28774,  4060, 28774,   354,  1012,  7117, 28723,  1537,   544,
          393,  6519, 28742, 28713,  8300,   654,  7358,   286,   354, 28705,
        28781,   648, 28705, 28774,   327,   429,  5275, 28781, 28806, 28774,
        28746, 28740, 28770,  4060, 28740, 28770,   354,  1012,  7117, 28723,
         9673,  3316,   460, 28705, 28740, 28783, 28734,  3486, 28725,   579,
          393,  6519, 12839, 28705, 28740, 28770,   398, 28705, 28740, 28783,
        28734,   327,   429,  5275, 28740, 28770, 28736, 28740, 28783, 28734,
        28746, 28750, 28770, 28781, 28734,  4060, 28750, 28770, 28781, 28734,
          354,  7358,   288,   544,   272,  8300, 28723, 28705,     2,  2476,
        28750, 28770, 28781, 28734, 28705,     2,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100], device='cuda:0')
[tensor([[ 7829,  3075,  8300,   654,  7358,   286,   354, 28705, 28750,   398,
         28705, 28750,   327,   429,  5275, 28750, 28736, 28750, 28746, 28781,
          4060, 28781,   354,  1012,  7117, 28723]], device='cuda:0'), tensor([[ 1682,  1712,  2760,  8300,   654,  7358,   286,   354, 28705, 28770,
           398, 28705, 28770,   327,   429,  5275, 28770, 28736, 28770, 28746,
         28774,  4060, 28774,   354,  1012,  7117, 28723]], device='cuda:0'), tensor([[ 1537,   544,   393,  6519, 28742, 28713,  8300,   654,  7358,   286,
           354, 28705, 28781,   648, 28705, 28774,   327,   429,  5275, 28781,
         28806, 28774, 28746, 28740, 28770,  4060, 28740, 28770,   354,  1012,
          7117, 28723]], device='cuda:0'), tensor([[ 9673,  3316,   460, 28705, 28740, 28783, 28734,  3486, 28725,   579,
           393,  6519, 12839, 28705, 28740, 28770,   398, 28705, 28740, 28783,
         28734,   327,   429,  5275, 28740, 28770, 28736, 28740, 28783, 28734,
         28746, 28750, 28770, 28781, 28734,  4060, 28750, 28770, 28781, 28734,
           354,  7358,   288,   544,   272,  8300, 28723, 28705,     2]],
       device='cuda:0')]
REMOVE TEST?! 0 0 1.3287671232876712
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.5206, 11.5933, 10.1782, 10.1614, 10.1614,
         10.3736]], device='cuda:1')
REMOVE TEST?! 5 1 2.0136986301369864
Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735,  8.3694, 12.8867,
          8.9027]], device='cuda:2')
REMOVE TEST?! 6 1 4.0479452054794525
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3690, 10.3505, 10.1313, 10.1824, 10.1824,
         10.3728]], device='cuda:1')
[3]
REMOVE TEST?! 0 0 1.3424657534246576
tensor([[10.3733, 10.4009, 10.3881, 10.3668, 10.3668, 10.3668, 10.3667, 10.3667,
         10.3736]], device='cuda:0')
REMOVE TEST?! 1 0 1.3287671232876712
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  8.3688, 13.2147,
          9.5910]], device='cuda:2')
REMOVE TEST?! 7 2 4.0479452054794525
Cross Entropy List tensor([[10.3731, 10.3731, 10.3731, 10.3892, 11.3581, 10.1520, 10.1606, 10.1606,
         10.3732]], device='cuda:1')
REMOVE TEST?! 1 1 1.3424657534246576
tensor([[10.3733, 10.3774, 10.3349, 10.2473, 10.2472, 10.2472, 10.2472, 10.2472,
         10.3712]], device='cuda:0')
REMOVE TEST?! 2 0 1.3287671232876712
Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735,  8.1766, 14.0908,
          9.7827]], device='cuda:2')
REMOVE TEST?! 8 3 4.0479452054794525
Cross Entropy List tensor([[10.3737, 10.3737, 10.3737, 10.3547, 10.3316, 10.1959, 10.4381, 10.4381,
         10.3723]], device='cuda:1')
REMOVE TEST?! 2 1 1.3424657534246576
tensor([[10.3732, 10.3775, 10.3373, 10.2415, 10.2415, 10.2415, 10.2415, 10.2415,
         10.3711]], device='cuda:0')
REMOVE TEST?! 3 0 1.3287671232876712
Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735,  8.2047, 14.1460,
          9.8260]], device='cuda:2')
REMOVE TEST?! 9 4 4.0479452054794525
Cross Entropy List tensor([[10.3737, 10.3737, 10.3737, 10.3563, 10.3228, 10.1900, 10.4156, 10.4157,
         10.3723]], device='cuda:1')
REMOVE TEST?! 3 1 1.3424657534246576
tensor([[10.3733, 10.3773, 10.3413, 10.2356, 10.2355, 10.2355, 10.2355, 10.2355,
         10.3712]], device='cuda:0')
[]
REMOVE TEST?! 0 0 0.3321917808219178
Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735,  8.2548, 14.2907,
          9.9279]], device='cuda:2')
[4, 6, 7, 8, 9]
tensor([[10.3737, 10.3737, 10.3737, 10.3584, 10.2885, 10.1632, 10.3444, 10.3444,
         10.3722]], device='cuda:1')
[0]
tensor([[10.3733, 10.3762, 10.3578, 10.2464, 10.2463, 10.2463, 10.2464, 10.2464,
         10.3712]], device='cuda:0')
[]
REMOVE TEST?! 0 0 0.3321917808219178
Loss Cross Entropy List Loss tensor(7.5380, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(10.3725, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor([[10.3733, 10.3793, 10.3783, 10.2625, 10.2625, 10.2625, 10.2625, 10.2625,
         10.3715]], device='cuda:0')
[]
REMOVE TEST?! 0 0 0.3321917808219178
Cross Entropy List tensor([[10.3733, 10.3750, 10.3612, 10.2952, 10.2952, 10.2952, 10.2952, 10.2952,
         10.3709]], device='cuda:0')
[]
After Process
A-INPUT tensor([    1,   393,  6519, 25061,   264,  1253,   811,  2302,  2496, 28723,
         1387,   460,  1712,  2760,  8300,   304,   989,  3075,  8300,  2632,
          298,  7358, 28723,   399,   308,   288,   272,  3075,  1253,  6966,
          429, 28750,   354,  1012,  7117,   304,   272,  2760,  1253,   429,
        28770,   354,  1012,  7117, 28723,  1682,  8300,   654,  7358,   286,
          354, 28705, 28770,  3316, 28723,  1602,  1188,  2445,   863,   393,
         6519,  6384, 28804, 28705,     2,  7829,  3075,  8300,   654,  7358,
          286,   354, 28705, 28750,   398, 28705, 28750,   327,   429,  5275,
        28750, 28736, 28750, 28746, 28781,  4060, 28781,   354,  1012,  7117,
        28723,  1682,  1712,  2760,  8300,   654,  7358,   286,   354, 28705,
        28770,   398, 28705, 28770,   327,   429,  5275, 28770, 28736, 28770,
        28746, 28774,  4060, 28774,   354,  1012,  7117, 28723,  1537,   544,
          393,  6519, 28742, 28713,  8300,   654,  7358,   286,   354, 28705,
        28781,   648, 28705, 28774,   327,   429,  5275, 28781, 28806, 28774,
        28746, 28740, 28770,  4060, 28740, 28770,   354,  1012,  7117, 28723,
         9673,  3316,   460, 28705, 28740, 28783, 28734,  3486, 28725,   579,
          393,  6519, 12839, 28705, 28740, 28770,   398, 28705, 28740, 28783,
        28734,   327,   429,  5275, 28740, 28770, 28736, 28740, 28783, 28734,
        28746, 28750, 28770, 28781, 28734,  4060, 28750, 28770, 28781, 28734,
          354,  7358,   288,   544,   272,  8300, 28723, 28705,     2,  2476,
        28750, 28770, 28781, 28734, 28705,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2], device='cuda:0')
A-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  7829,  3075,  8300,   654,  7358,
          286,   354, 28705, 28750,   398, 28705, 28750,   327,   429,  5275,
        28750, 28736, 28750, 28746, 28781,  4060, 28781,   354,  1012,  7117,
        28723,  1682,  1712,  2760,  8300,   654,  7358,   286,   354, 28705,
        28770,   398, 28705, 28770,   327,   429,  5275, 28770, 28736, 28770,
        28746, 28774,  4060, 28774,   354,  1012,  7117, 28723,  1537,   544,
          393,  6519, 28742, 28713,  8300,   654,  7358,   286,   354, 28705,
        28781,   648, 28705, 28774,   327,   429,  5275, 28781, 28806, 28774,
        28746, 28740, 28770,  4060, 28740, 28770,   354,  1012,  7117, 28723,
         9673,  3316,   460, 28705, 28740, 28783, 28734,  3486, 28725,   579,
          393,  6519, 12839, 28705, 28740, 28770,   398, 28705, 28740, 28783,
        28734,   327,   429,  5275, 28740, 28770, 28736, 28740, 28783, 28734,
        28746, 28750, 28770, 28781, 28734,  4060, 28750, 28770, 28781, 28734,
          354,  7358,   288,   544,   272,  8300, 28723, 28705,     2,  2476,
        28750, 28770, 28781, 28734, 28705,     2,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100], device='cuda:0')
Loss Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4320179224014282
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12810483574867249
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14784321188926697
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14962339401245117
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1519223004579544
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15481145679950714
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1537628024816513
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14982931315898895
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14861507713794708
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14195901155471802
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16268983483314514
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1599714159965515
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1607424020767212
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1612851619720459
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15939216315746307
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15802785754203796
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15441055595874786
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15269142389297485
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1485254168510437
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14858824014663696
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1511857807636261
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1539490967988968
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1542235016822815
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15217873454093933
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1484529972076416
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1509469896554947
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1617584228515625
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1596992015838623
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1610163152217865
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16141819953918457
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1608155518770218
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16009096801280975
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1561686247587204
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15362057089805603
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1740366369485855
 34%|███▎      | 197/584 [20:00<26:27,  4.10s/it]REMOVE TEST?! 0 0 0.339041095890411
tensor(10.3711, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.25622862577438354
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08168918639421463
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09320489317178726
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11507566273212433
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10803375393152237
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10845989733934402
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8505263924598694
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00019317484111525118
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00019836255523841828
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00019024549692403525
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005331134307198226
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08075810223817825
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0835576131939888
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08370150625705719
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08339613676071167
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08323837071657181
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08213520795106888
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0810685008764267
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08171761780977249
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0814417228102684
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08212167024612427
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0827394500374794
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08281125873327255
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08310110867023468
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08330845087766647
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08395223319530487
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08459607511758804
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08438475430011749
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08394648879766464
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08450721204280853
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08430686593055725
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08440239727497101
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08379702270030975
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08260446786880493
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00271466001868248
 34%|███▎      | 196/584 [19:55<26:51,  4.15s/it]REMOVE TEST?! 0 0 0.3373287671232877
Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3736, 10.3736, 10.3736, 10.3736, 10.3736,  8.2032,  8.2495,
          7.6510]], device='cuda:2')
[0]
REMOVE TEST?! 0 0 0.678082191780822
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3409, 11.0293, 10.1764, 10.3803, 10.3803,
         10.3740]], device='cuda:1')
[0]
REMOVE TEST?! 0 0 0.6746575342465754
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  8.1002,  8.8934,
          7.6156]], device='cuda:2')
REMOVE TEST?! 1 0 0.678082191780822
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15528294444084167
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.049214188009500504
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05690711736679077
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05740281939506531
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.056386109441518784
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05592576414346695
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05516218766570091
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05467996746301651
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05513732507824898
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05614941567182541
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05752398446202278
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.077472023665905
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.059116385877132416
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.057358212769031525
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05626073107123375
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.055566929280757904
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05563389137387276
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05676255002617836
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05720244720578194
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05697089433670044
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05715262517333031
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.056323789060115814
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05583742633461952
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05493651330471039
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05450740084052086
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.055434051901102066
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0564279668033123
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.056020285934209824
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5666313767433167
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5071194171905518
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4274944067001343
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3567654490470886
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.7909881939413026e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.900210140272975e-05
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 3.491060851956718e-05
 33%|███▎      | 194/584 [19:59<23:07,  3.56s/it]Before Process
B-INPUT tensor([    1,  5058,   276, 28809, 28713,  3140,   659,   396,  9119,  1955,
         2541,  4089,   272,  1862,  2668, 28723,  1418,   264, 11463,  3970,
        28725,   516,  3140, 20980,   713,   298,   576,   304,  5902, 28705,
        28740, 28734,   467,   748,   302, 14636,   354,  7796,   477,   652,
         4143, 28723,  4023, 14617,   272, 14636,   778,   272,  1253, 28725,
          400, 27630, 17472,   989,   467,   748, 28723,   650,  6470,   516,
         3140,  7124,   713,   456, 28725,   304,   349,  2240,   298,   967,
        28705, 28787,   680,   467,   748,   354,  7796, 28723,  1602,  1287,
        14636,   654,  3910,   369,  1370, 28804, 28705,     2,  1684,  5058,
          276, 12469, 28705, 28740, 28734,   467,   748,   304,  7679, 28705,
        28750,   467,   748, 28725,   400,   403,  1749,   395, 28705, 28740,
        28734,   467,   748,   387, 28705, 28750,   467,   748,   327,  2087,
        28740, 28734, 28733, 28750, 28746, 28783,  4060, 28783,   467,   748,
        28723,  1684,   400,  3886, 28705, 28787,   680,   467,   748, 28725,
          272,  3102,  1474,   302,   467,   748,  3246, 28705, 28783,   467,
          748,   648, 28705, 28787,   467,   748,   327,  2087, 28783, 28806,
        28787, 28746, 28740, 28782,  4060, 28740, 28782,   467,   748, 28723,
         4577,  1430, 22517,  5876, 28705, 28770, 28784, 14636, 28725,   272,
         3102,  1474,   302, 14636,   298,   347,  3910,   349, 28705, 28770,
        28784, 14636, 28748,   434,   339,   398, 28705, 28740, 28782,   467,
          748,   327, 28705, 28782, 28781, 28734, 14636, 28723, 28705,     2,
         2476, 28782, 28781, 28734, 28705,     2], device='cuda:0')
B-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  1684,  5058,
          276, 12469, 28705, 28740, 28734,   467,   748,   304,  7679, 28705,
        28750,   467,   748, 28725,   400,   403,  1749,   395, 28705, 28740,
        28734,   467,   748,   387, 28705, 28750,   467,   748,   327,  2087,
        28740, 28734, 28733, 28750, 28746, 28783,  4060, 28783,   467,   748,
        28723,  1684,   400,  3886, 28705, 28787,   680,   467,   748, 28725,
          272,  3102,  1474,   302,   467,   748,  3246, 28705, 28783,   467,
          748,   648, 28705, 28787,   467,   748,   327,  2087, 28783, 28806,
        28787, 28746, 28740, 28782,  4060, 28740, 28782,   467,   748, 28723,
         4577,  1430, 22517,  5876, 28705, 28770, 28784, 14636, 28725,   272,
         3102,  1474,   302, 14636,   298,   347,  3910,   349, 28705, 28770,
        28784, 14636, 28748,   434,   339,   398, 28705, 28740, 28782,   467,
          748,   327, 28705, 28782, 28781, 28734, 14636, 28723, 28705,     2,
         2476, 28782, 28781, 28734, 28705,     2], device='cuda:0')
[tensor([[ 1684,  5058,   276, 12469, 28705, 28740, 28734,   467,   748,   304,
          7679, 28705, 28750,   467,   748, 28725,   400,   403,  1749,   395,
         28705, 28740, 28734,   467,   748,   387, 28705, 28750,   467,   748,
           327,  2087, 28740, 28734, 28733, 28750, 28746, 28783,  4060, 28783,
           467,   748, 28723]], device='cuda:0'), tensor([[ 1684,   400,  3886, 28705, 28787,   680,   467,   748, 28725,   272,
          3102,  1474,   302,   467,   748,  3246, 28705, 28783,   467,   748,
           648, 28705, 28787,   467,   748,   327,  2087, 28783, 28806, 28787,
         28746, 28740, 28782,  4060, 28740, 28782,   467,   748, 28723]],
       device='cuda:0'), tensor([[ 4577,  1430, 22517,  5876, 28705, 28770, 28784, 14636, 28725,   272,
          3102,  1474,   302, 14636,   298,   347,  3910,   349, 28705, 28770,
         28784, 14636, 28748,   434,   339,   398, 28705, 28740, 28782,   467,
           748,   327, 28705, 28782, 28781, 28734, 14636, 28723, 28705,     2]],
       device='cuda:0')]
REMOVE TEST?! 0 0 1.0017123287671232
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.4073, 11.0780, 10.1201, 10.1362, 10.1362,
         10.3730]], device='cuda:1')
REMOVE TEST?! 1 0 0.6746575342465754
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  7.1523,  7.8866,
          6.6181]], device='cuda:2')
[]
REMOVE TEST?! 0 0 1.695205479452055
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3698, 10.0782, 10.6467, 10.4960, 10.4960,
         10.3736]], device='cuda:1')
[1]
REMOVE TEST?! 0 0 0.6746575342465754
tensor([[10.3734, 10.3990, 10.3899, 10.3780, 10.3780, 10.3780, 10.3780, 10.3780,
         10.3738]], device='cuda:0')
REMOVE TEST?! 1 1 1.0017123287671232
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  9.6335, 11.6763,
          9.7667]], device='cuda:2')
REMOVE TEST?! 1 0 1.695205479452055
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3791, 10.0854, 10.2221, 10.2352, 10.2352,
         10.3706]], device='cuda:1')
REMOVE TEST?! 1 0 0.6746575342465754
tensor([[10.3734, 10.3745, 10.3446, 10.2108, 10.2108, 10.2108, 10.2108, 10.2108,
         10.3712]], device='cuda:0')
REMOVE TEST?! 2 1 1.0017123287671232
Cross Entropy List Cross Entropy List tensor([[10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.3733,  9.4259, 13.3021,
          9.6224]], device='cuda:2')
REMOVE TEST?! 2 0 1.695205479452055
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3778, 10.0459, 11.4863, 10.9474, 10.9474,
         10.3716]], device='cuda:1')
[1]
REMOVE TEST?! 0 0 1.3493150684931507
tensor([[10.3734, 10.3755, 10.3536, 10.2005, 10.2005, 10.2005, 10.2005, 10.2005,
         10.3711]], device='cuda:0')
[0]
REMOVE TEST?! 0 0 1.0017123287671232
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  9.1412, 12.4909,
          9.2260]], device='cuda:2')
REMOVE TEST?! 3 0 1.695205479452055
Cross Entropy List tensor([[10.3737, 10.3737, 10.3737, 10.3993, 10.0901, 10.7141, 10.2430, 10.2430,
         10.3714]], device='cuda:1')
REMOVE TEST?! 1 0 1.3493150684931507
tensor([[10.3735, 10.3785, 10.3298, 10.2178, 10.2178, 10.2177, 10.2178, 10.2178,
         10.3712]], device='cuda:0')
REMOVE TEST?! 1 0 1.0017123287671232
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  9.1079, 12.4038,
          9.1771]], device='cuda:2')
REMOVE TEST?! 4 0 1.695205479452055
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3962, 10.0868, 10.5992, 10.2005, 10.2005,
         10.3715]], device='cuda:1')
REMOVE TEST?! 2 0 1.3493150684931507
tensor([[10.3735, 10.3785, 10.3400, 10.2118, 10.2118, 10.2118, 10.2118, 10.2118,
         10.3712]], device='cuda:0')
REMOVE TEST?! 2 0 1.0017123287671232
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  8.8151, 11.6447,
          8.7666]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.339041095890411
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3963, 10.0811, 10.5572, 10.1802, 10.1802,
         10.3715]], device='cuda:1')
REMOVE TEST?! 3 0 1.3493150684931507
tensor([[10.3735, 10.3786, 10.3518, 10.2139, 10.2138, 10.2138, 10.2138, 10.2138,
         10.3713]], device='cuda:0')
[]
REMOVE TEST?! 0 0 1.0017123287671232
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  8.0632, 10.0989,
          7.7447]], device='cuda:2')
[]
tensor([[10.3736, 10.3736, 10.3736, 10.3961, 10.0781, 10.5070, 10.1565, 10.1565,
         10.3714]], device='cuda:1')
[]
tensor([[10.3729, 10.3737, 10.3018, 10.2692, 10.2692, 10.2692, 10.2692, 10.2692,
         10.3706]], device='cuda:0')
REMOVE TEST?! 1 0 1.0017123287671232
Loss Cross Entropy List Loss tensor(6.7703, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor(10.3713, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor([[10.3730, 10.3744, 10.3127, 10.2625, 10.2625, 10.2625, 10.2625, 10.2625,
         10.3706]], device='cuda:0')
REMOVE TEST?! 2 0 1.0017123287671232
Cross Entropy List tensor([[10.3730, 10.3793, 10.3470, 10.2402, 10.2402, 10.2402, 10.2402, 10.2402,
         10.3703]], device='cuda:0')
[]
REMOVE TEST?! 0 0 0.3339041095890411
Cross Entropy List Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.43134167790412903
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12860533595085144
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14841192960739136
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15019719302654266
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1525024026632309
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15568387508392334
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1546364426612854
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15070097148418427
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14948417246341705
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1428350806236267
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16322197020053864
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16054730117321014
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1613422930240631
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16188618540763855
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15998834371566772
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1586204469203949
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15499247610569
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15327182412147522
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14909696578979492
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14915987849235535
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15176387131214142
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15474574267864227
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15510490536689758
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1528974026441574
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14930394291877747
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15179350972175598
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16229335963726044
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1601826250553131
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1614765077829361
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16183440387248993
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1611872762441635
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16051581501960754
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1564871221780777
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15418939292430878
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15662260353565216
 34%|███▍      | 198/584 [20:03<23:29,  3.65s/it]REMOVE TEST?! 0 0 0.6815068493150684
tensor([[10.3734, 10.3847, 10.3760, 10.1882, 10.1882, 10.1882, 10.1882, 10.1882,
         10.3707]], device='cuda:0')
[]
After Process
A-INPUT tensor([    1,  5058,   276, 28809, 28713,  3140,   659,   396,  9119,  1955,
         2541,  4089,   272,  1862,  2668, 28723,  1418,   264, 11463,  3970,
        28725,   516,  3140, 20980,   713,   298,   576,   304,  5902, 28705,
        28740, 28734,   467,   748,   302, 14636,   354,  7796,   477,   652,
         4143, 28723,  4023, 14617,   272, 14636,   778,   272,  1253, 28725,
          400, 27630, 17472,   989,   467,   748, 28723,   650,  6470,   516,
         3140,  7124,   713,   456, 28725,   304,   349,  2240,   298,   967,
        28705, 28787,   680,   467,   748,   354,  7796, 28723,  1602,  1287,
        14636,   654,  3910,   369,  1370, 28804, 28705,     2,  1684,   400,
         3886, 28705, 28787,   680,   467,   748, 28725,   272,  3102,  1474,
          302,   467,   748,  3246, 28705, 28783,   467,   748,   648, 28705,
        28787,   467,   748,   327,  2087, 28783, 28806, 28787, 28746, 28740,
        28782,  4060, 28740, 28782,   467,   748, 28723,  4577,  1430, 22517,
         5876, 28705, 28770, 28784, 14636, 28725,   272,  3102,  1474,   302,
        14636,   298,   347,  3910,   349, 28705, 28770, 28784, 14636, 28748,
          434,   339,   398, 28705, 28740, 28782,   467,   748,   327, 28705,
        28782, 28781, 28734, 14636, 28723, 28705,     2,  2476, 28782, 28781,
        28734, 28705,     2], device='cuda:0')
A-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  1684,   400,
         3886, 28705, 28787,   680,   467,   748, 28725,   272,  3102,  1474,
          302,   467,   748,  3246, 28705, 28783,   467,   748,   648, 28705,
        28787,   467,   748,   327,  2087, 28783, 28806, 28787, 28746, 28740,
        28782,  4060, 28740, 28782,   467,   748, 28723,  4577,  1430, 22517,
         5876, 28705, 28770, 28784, 14636, 28725,   272,  3102,  1474,   302,
        14636,   298,   347,  3910,   349, 28705, 28770, 28784, 14636, 28748,
          434,   339,   398, 28705, 28740, 28782,   467,   748,   327, 28705,
        28782, 28781, 28734, 14636, 28723, 28705,     2,  2476, 28782, 28781,
        28734, 28705,     2], device='cuda:0')
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2566346526145935
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0818200409412384
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0933670625090599
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.11516564339399338
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10814101994037628
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.10855638235807419
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.8500820994377136
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002456691872794181
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0002220473252236843
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00021236733300611377
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.000983945094048977
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08088362962007523
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08367644995450974
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08381451666355133
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08350971341133118
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08335136622190475
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08225065469741821
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08118623495101929
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08184008300304413
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0815621018409729
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08224380016326904
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0828593447804451
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08292990922927856
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08322230726480484
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08342889696359634
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08407071977853775
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08471281081438065
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08450131863355637
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08406216651201248
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08462197333574295
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08442230522632599
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08445046097040176
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08390823006629944
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0826927125453949
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.002068884205073118
 34%|███▎      | 197/584 [19:58<23:44,  3.68s/it]REMOVE TEST?! 0 0 0.339041095890411
Cross Entropy List Loss Cross Entropy List tensor([[10.3738, 10.3738, 10.3738, 10.3738, 10.3738, 10.3738,  9.3130, 12.1235,
          9.3719]], device='cuda:2')
REMOVE TEST?! 1 0 0.6815068493150684
tensor(10.3716, device='cuda:0', grad_fn=<NllLossBackward0>)
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.4139, 10.0571, 10.2639, 10.0299, 10.0299,
         10.3719]], device='cuda:1')
[]
REMOVE TEST?! 0 0 1.695205479452055
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.3736,  8.7772, 10.3853,
          8.3134]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.3407534246575342
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3790, 10.1862, 10.4751, 10.9622, 10.9622,
         10.3732]], device='cuda:1')
REMOVE TEST?! 1 1 1.695205479452055
Cross Entropy List tensor([[10.3733, 10.3734, 10.3733, 10.3734, 10.3734, 10.3733,  7.9834,  9.4831,
          8.1879]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.6815068493150684
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.42570066452026367
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1348951905965805
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1560060828924179
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15738117694854736
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15459591150283813
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1533372700214386
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1510903537273407
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14977256953716278
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15120205283164978
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15396946668624878
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15772655606269836
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16598039865493774
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1600647270679474
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15567173063755035
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15325021743774414
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15254680812358856
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15293094515800476
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15656161308288574
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15662828087806702
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15702994167804718
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15528887510299683
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1540469229221344
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1522666960954666
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14963799715042114
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14935418963432312
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15315909683704376
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15643908083438873
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.19390510022640228
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16431590914726257
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15892869234085083
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15511664748191833
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15264034271240234
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15241692960262299
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15398453176021576
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13523131608963013
 33%|███▎      | 195/584 [20:02<21:24,  3.30s/it]Before Process
B-INPUT tensor([    1, 17177,   293,  6098,   264,  2843,   302, 15668,  1012,  2102,
        28723,  1047,  1430,  2843,   302, 15668,  6966,   429, 28781, 28725,
          910,  1188,  1235,   400,  6305,   356, 13529,   302, 15668,   297,
          989,  1267, 28804, 28705,     2,   330,   879,   349, 28705, 28740,
        28750,  3370, 28725,   579, 17177,   293,   668,  2827, 28705, 28781,
          398, 28705, 28740, 28750,   327,   429,  5275, 28781, 28736, 28740,
        28750, 28746, 28781, 28783,  4060, 28781, 28783,   660,   879,   356,
        13529,   302, 15668, 28723,   560,   989,  1267, 28725,   400,   668,
         2827, 28705, 28750,   398, 28705, 28781, 28783,   327,   429,  5275,
        28750, 28736, 28781, 28783, 28746, 28774, 28784,  4060, 28774, 28784,
          356, 13529,   302, 15668, 28723, 28705,     2,  2476, 28774, 28784,
        28705,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2], device='cuda:0')
B-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,   330,   879,   349, 28705, 28740,
        28750,  3370, 28725,   579, 17177,   293,   668,  2827, 28705, 28781,
          398, 28705, 28740, 28750,   327,   429,  5275, 28781, 28736, 28740,
        28750, 28746, 28781, 28783,  4060, 28781, 28783,   660,   879,   356,
        13529,   302, 15668, 28723,   560,   989,  1267, 28725,   400,   668,
         2827, 28705, 28750,   398, 28705, 28781, 28783,   327,   429,  5275,
        28750, 28736, 28781, 28783, 28746, 28774, 28784,  4060, 28774, 28784,
          356, 13529,   302, 15668, 28723, 28705,     2,  2476, 28774, 28784,
        28705,     2,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100], device='cuda:0')
[tensor([[  330,   879,   349, 28705, 28740, 28750,  3370, 28725,   579, 17177,
           293,   668,  2827, 28705, 28781,   398, 28705, 28740, 28750,   327,
           429,  5275, 28781, 28736, 28740, 28750, 28746, 28781, 28783,  4060,
         28781, 28783,   660,   879,   356, 13529,   302, 15668, 28723]],
       device='cuda:0'), tensor([[  560,   989,  1267, 28725,   400,   668,  2827, 28705, 28750,   398,
         28705, 28781, 28783,   327,   429,  5275, 28750, 28736, 28781, 28783,
         28746, 28774, 28784,  4060, 28774, 28784,   356, 13529,   302, 15668,
         28723, 28705,     2]], device='cuda:0')]
REMOVE TEST?! 0 0 0.6712328767123288
Cross Entropy List tensor([[10.3735, 10.3734, 10.3734, 10.5514, 11.4890, 10.1403, 10.1341, 10.1341,
         10.3734]], device='cuda:1')
REMOVE TEST?! 2 1 1.695205479452055
Cross Entropy List Cross Entropy List tensor([[10.3732, 10.3732, 10.3732, 10.3732, 10.3732, 10.3732,  8.4666, 11.1025,
          8.1171]], device='cuda:2')
REMOVE TEST?! 1 0 0.6815068493150684
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.4234, 10.3985, 10.1836, 10.2806, 10.2806,
         10.3732]], device='cuda:1')
REMOVE TEST?! 3 1 1.695205479452055
tensor([[10.3733, 10.3808, 10.3677, 10.3383, 10.3383, 10.3383, 10.3383, 10.3383,
         10.3738]], device='cuda:0')
REMOVE TEST?! 1 0 0.6712328767123288
Cross Entropy ListCross Entropy List  tensor([[10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.3733,  7.8605,  9.6060,
          7.4929]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.6815068493150684
Cross Entropy List tensor([[10.3733, 10.3733, 10.3733, 10.4058, 11.0746, 10.1152, 10.1325, 10.1325,
         10.3735]], device='cuda:1')
[0, 3]
REMOVE TEST?! 0 0 0.678082191780822
tensor([[10.3733, 10.3760, 10.3150, 10.1958, 10.1958, 10.1957, 10.1957, 10.1957,
         10.3708]], device='cuda:0')
[]
REMOVE TEST?! 0 0 0.6712328767123288
Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735,  8.5968, 14.0709,
          9.5485]], device='cuda:2')
REMOVE TEST?! 1 0 0.6815068493150684
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3967, 10.1571, 10.1233, 10.1568, 10.1568,
         10.3714]], device='cuda:1')
REMOVE TEST?! 1 0 0.678082191780822
tensor([[10.3733, 10.3788, 10.3452, 10.2152, 10.2152, 10.2152, 10.2152, 10.2152,
         10.3712]], device='cuda:0')
REMOVE TEST?! 1 0 0.6712328767123288
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  7.7523, 11.8935,
          8.1548]], device='cuda:2')
[1]
tensor([[10.3734, 10.3734, 10.3734, 10.3977, 10.1560, 10.1078, 10.1444, 10.1444,
         10.3714]], device='cuda:1')
[]
REMOVE TEST?! 0 0 0.339041095890411
Loss tensor([[10.3733, 10.3810, 10.3752, 10.1918, 10.1918, 10.1918, 10.1918, 10.1918,
         10.3710]], device='cuda:0')
[]
REMOVE TEST?! 0 0 0.6712328767123288
Cross Entropy List Cross Entropy List tensor(7.0625, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor([[10.3737, 10.3737, 10.3737, 10.4050, 10.1752, 10.1232, 10.1235, 10.1235,
         10.3711]], device='cuda:1')
[]
tensor([[10.3733, 10.3739, 10.3442, 10.1869, 10.1869, 10.1869, 10.1869, 10.1869,
         10.3713]], device='cuda:0')
REMOVE TEST?! 1 0 0.6712328767123288
Cross Entropy List Loss tensor(10.3720, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor([[10.3733, 10.3721, 10.3374, 10.3044, 10.3044, 10.3044, 10.3044, 10.3044,
         10.3712]], device='cuda:0')
[]
REMOVE TEST?! 0 0 0.3356164383561644
Cross Entropy List Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.431415855884552
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.12861619889736176
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.148545041680336
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15040382742881775
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1526641696691513
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15606936812400818
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1549033671617508
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15085193514823914
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14981310069561005
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14114642143249512
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16294094920158386
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16027101874351501
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16106455028057098
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1618083417415619
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15999957919120789
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1586359590291977
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1550198644399643
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15330345928668976
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14914695918560028
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14920571446418762
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15180490911006927
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15484608709812164
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15522974729537964
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15299269556999207
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14945603907108307
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15193653106689453
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.162070631980896
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15991860628128052
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16121967136859894
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16177289187908173
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16123689711093903
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16056415438652039
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15657076239585876
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15421898663043976
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15709172189235687
 34%|███▍      | 199/584 [20:05<20:44,  3.23s/it]REMOVE TEST?! 0 0 0.3424657534246575
tensor([[10.3733, 10.3773, 10.3215, 10.2765, 10.2765, 10.2765, 10.2765, 10.2765,
         10.3706]], device='cuda:0')
[]
After Process
A-INPUT tensor([    1, 17177,   293,  6098,   264,  2843,   302, 15668,  1012,  2102,
        28723,  1047,  1430,  2843,   302, 15668,  6966,   429, 28781, 28725,
          910,  1188,  1235,   400,  6305,   356, 13529,   302, 15668,   297,
          989,  1267, 28804, 28705,     2,   330,   879,   349, 28705, 28740,
        28750,  3370, 28725,   579, 17177,   293,   668,  2827, 28705, 28781,
          398, 28705, 28740, 28750,   327,   429,  5275, 28781, 28736, 28740,
        28750, 28746, 28781, 28783,  4060, 28781, 28783,   660,   879,   356,
        13529,   302, 15668, 28723,   560,   989,  1267, 28725,   400,   668,
         2827, 28705, 28750,   398, 28705, 28781, 28783,   327,   429,  5275,
        28750, 28736, 28781, 28783, 28746, 28774, 28784,  4060, 28774, 28784,
          356, 13529,   302, 15668, 28723, 28705,     2,  2476, 28774, 28784,
        28705,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2], device='cuda:0')
A-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,   330,   879,   349, 28705, 28740,
        28750,  3370, 28725,   579, 17177,   293,   668,  2827, 28705, 28781,
          398, 28705, 28740, 28750,   327,   429,  5275, 28781, 28736, 28740,
        28750, 28746, 28781, 28783,  4060, 28781, 28783,   660,   879,   356,
        13529,   302, 15668, 28723,   560,   989,  1267, 28725,   400,   668,
         2827, 28705, 28750,   398, 28705, 28781, 28783,   327,   429,  5275,
        28750, 28736, 28781, 28783, 28746, 28774, 28784,  4060, 28774, 28784,
          356, 13529,   302, 15668, 28723, 28705,     2,  2476, 28774, 28784,
        28705,     2,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100], device='cuda:0')
Cross Entropy List Loss tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  8.8131, 10.1744,
          8.4244]], device='cuda:2')
[]
REMOVE TEST?! 0 0 1.7123287671232876
tensor(10.3708, device='cuda:0', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.09221598505973816
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.029216645285487175
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03750678151845932
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03386368229985237
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03487539663910866
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03431151434779167
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03367576003074646
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03361661359667778
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03354736045002937
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03412392735481262
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03419800475239754
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03421340510249138
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03396535664796829
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03364958614110947
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.033472444862127304
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.032987356185913086
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.032945506274700165
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03374414145946503
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.033968355506658554
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6684517860412598
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.43960413336753845
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.42634329199790955
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.38132578134536743
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 7.160574023146182e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.879719457065221e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.8369071767665446e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.4905013560783118e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.014709525741636753
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022150879725813866
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02213033102452755
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02202303148806095
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02195858396589756
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021679485216736794
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.021400058642029762
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024073293432593346
 34%|███▍      | 198/584 [20:00<21:26,  3.33s/it]REMOVE TEST?! 0 0 0.6815068493150684
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3733, 10.3733,  8.9297, 10.1668,
          8.5555]], device='cuda:2')
REMOVE TEST?! 1 0 1.7123287671232876
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3764, 13.7012, 11.2997, 12.9728, 12.9729,
         10.3732]], device='cuda:1')
[0]
REMOVE TEST?! 0 0 1.3630136986301369
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  8.5616,  9.7407,
          8.0063]], device='cuda:2')
REMOVE TEST?! 2 0 1.7123287671232876
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15542523562908173
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04926031082868576
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.056969720870256424
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05747130140662193
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05645473301410675
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0559953898191452
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.055175572633743286
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.054694924503564835
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.055216867476701736
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05622656270861626
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.057643789798021317
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07748692482709885
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05916823074221611
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05740884691476822
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05633128061890602
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.055607810616493225
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.055674970149993896
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05682462826371193
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05726355314254761
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05703812092542648
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05724257975816727
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.056403450667858124
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.055916715413331985
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05498555302619934
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.054550040513277054
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05546420440077782
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05646335333585739
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05639361962676048
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5665165781974792
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5069928765296936
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.42733338475227356
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.35696443915367126
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.692571019404568e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.828805322176777e-05
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 5.038182280259207e-05
 34%|███▎      | 196/584 [20:04<19:26,  3.01s/it]Before Process
B-INPUT tensor([    1,  2997,   535,  7620,  3359,  5666,  1214,   354,   429, 28740,
        28734,   297,  3102,   304,   989,  6830, 28727, 25809,   354,   429,
        28784,   297,  3102, 28723,  1602,  1188,   682,   630,   927,   298,
         2136, 28725,   513,   630,   682,   865,  3848,   624, 28267,   304,
          624, 18342, 28804, 28705,     2,  2997,   535,  7620,  3359,  5666,
         1214,   354,   429, 28740, 28734, 28725,   579,   624, 18342,  6966,
        28705, 28740, 28734,   732, 28705, 28782,   327,   429,  5275, 28740,
        28734, 28748, 28782, 28746, 28750,  4060, 28750, 28723,   985,   835,
         7620,   989,  6830, 28727, 25809,   354,   429, 28784, 28725,   579,
          624, 28267,  6966, 28705, 28784,   732, 28705, 28750,   327,   429,
         5275, 28784, 28748, 28750, 28746, 28770,  4060, 28770, 28723,  1537,
          354,   624, 18342,   304,   624, 28267, 28725,  2997,   535,   682,
          927,   298,  2136, 28705, 28750,   648, 28705, 28770,   327,   429,
         5275, 28750, 28806, 28770, 28746, 28782,  4060, 28782, 28723, 28705,
            2,  2476, 28782, 28705,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2], device='cuda:0')
B-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  2997,   535,  7620,  3359,  5666,
         1214,   354,   429, 28740, 28734, 28725,   579,   624, 18342,  6966,
        28705, 28740, 28734,   732, 28705, 28782,   327,   429,  5275, 28740,
        28734, 28748, 28782, 28746, 28750,  4060, 28750, 28723,   985,   835,
         7620,   989,  6830, 28727, 25809,   354,   429, 28784, 28725,   579,
          624, 28267,  6966, 28705, 28784,   732, 28705, 28750,   327,   429,
         5275, 28784, 28748, 28750, 28746, 28770,  4060, 28770, 28723,  1537,
          354,   624, 18342,   304,   624, 28267, 28725,  2997,   535,   682,
          927,   298,  2136, 28705, 28750,   648, 28705, 28770,   327,   429,
         5275, 28750, 28806, 28770, 28746, 28782,  4060, 28782, 28723, 28705,
            2,  2476, 28782, 28705,     2,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100], device='cuda:0')
[tensor([[ 2997,   535,  7620,  3359,  5666,  1214,   354,   429, 28740, 28734,
         28725,   579,   624, 18342,  6966, 28705, 28740, 28734,   732, 28705,
         28782,   327,   429,  5275, 28740, 28734, 28748, 28782, 28746, 28750,
          4060, 28750, 28723]], device='cuda:0'), tensor([[  985,   835,  7620,   989,  6830, 28727, 25809,   354,   429, 28784,
         28725,   579,   624, 28267,  6966, 28705, 28784,   732, 28705, 28750,
           327,   429,  5275, 28784, 28748, 28750, 28746, 28770,  4060, 28770,
         28723]], device='cuda:0'), tensor([[ 1537,   354,   624, 18342,   304,   624, 28267, 28725,  2997,   535,
           682,   927,   298,  2136, 28705, 28750,   648, 28705, 28770,   327,
           429,  5275, 28750, 28806, 28770, 28746, 28782,  4060, 28782, 28723,
         28705,     2]], device='cuda:0')]
REMOVE TEST?! 0 0 1.0119863013698631
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.4090, 10.8107, 10.1157, 10.1590, 10.1590,
         10.3727]], device='cuda:1')
REMOVE TEST?! 1 0 1.3630136986301369
Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735,  8.2029, 10.1551,
          7.6904]], device='cuda:2')
REMOVE TEST?! 3 0 1.7123287671232876
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3583, 10.1791, 10.8629, 10.5328, 10.5328,
         10.3735]], device='cuda:1')
REMOVE TEST?! 2 0 1.3630136986301369
tensor([[10.3734, 10.3776, 10.3687, 10.3568, 10.3568, 10.3568, 10.3568, 10.3569,
         10.3738]], device='cuda:0')
REMOVE TEST?! 1 0 1.0119863013698631
Cross Entropy List Cross Entropy List tensor([[10.3733, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  8.0672,  9.1743,
          7.4459]], device='cuda:2')
REMOVE TEST?! 4 0 1.7123287671232876
Cross Entropy List tensor([[10.3733, 10.3733, 10.3733, 10.3814, 10.1730, 10.3834, 10.4279, 10.4279,
         10.3727]], device='cuda:1')
REMOVE TEST?! 3 1 1.3630136986301369
tensor([[10.3734, 10.3731, 10.3385, 10.2545, 10.2545, 10.2545, 10.2545, 10.2545,
         10.3711]], device='cuda:0')
REMOVE TEST?! 2 0 1.0119863013698631
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  7.8001,  9.6297,
          7.2426]], device='cuda:2')
[]
REMOVE TEST?! 0 0 1.7123287671232876
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3640, 10.0875, 10.8128, 10.2908, 10.2908,
         10.3725]], device='cuda:1')
[2]
REMOVE TEST?! 0 0 0.3407534246575342
tensor([[10.3734, 10.3742, 10.3410, 10.2447, 10.2446, 10.2446, 10.2446, 10.2446,
         10.3709]], device='cuda:0')
[]
REMOVE TEST?! 0 0 0.6746575342465754
Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3734, 10.3734,  8.6850, 11.8368,
          8.4008]], device='cuda:2')
REMOVE TEST?! 1 0 1.7123287671232876
Cross Entropy List tensor([[10.3737, 10.3737, 10.3737, 10.3253, 10.0387, 10.9070, 10.4973, 10.4973,
         10.3721]], device='cuda:1')
[0]
REMOVE TEST?! 0 0 1.3630136986301369
tensor([[10.3732, 10.3774, 10.2968, 10.2135, 10.2135, 10.2135, 10.2135, 10.2135,
         10.3709]], device='cuda:0')
REMOVE TEST?! 1 0 0.6746575342465754
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  8.4305, 11.1217,
          8.0445]], device='cuda:2')
REMOVE TEST?! 2 0 1.7123287671232876
Cross Entropy List tensor([[10.3737, 10.3737, 10.3737, 10.4308, 10.1122, 10.6526, 10.2323, 10.2322,
         10.3727]], device='cuda:1')
REMOVE TEST?! 1 0 1.3630136986301369
tensor([[10.3733, 10.3775, 10.3128, 10.2057, 10.2057, 10.2057, 10.2057, 10.2057,
         10.3710]], device='cuda:0')
[]
REMOVE TEST?! 0 0 0.3373287671232877
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  8.2220, 10.5444,
          7.7246]], device='cuda:2')
REMOVE TEST?! 3 0 1.7123287671232876
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.4299, 10.1159, 10.5418, 10.2142, 10.2142,
         10.3727]], device='cuda:1')
REMOVE TEST?! 2 0 1.3630136986301369
tensor([[10.3734, 10.3806, 10.3487, 10.1939, 10.1939, 10.1938, 10.1938, 10.1938,
         10.3708]], device='cuda:0')
[]
REMOVE TEST?! 0 0 0.3373287671232877
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  8.0182,  9.9914,
          7.4541]], device='cuda:2')
REMOVE TEST?! 4 0 1.7123287671232876
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.4278, 10.1115, 10.4689, 10.1839, 10.1839,
         10.3728]], device='cuda:1')
REMOVE TEST?! 3 0 1.3630136986301369
tensor([[10.3733, 10.3727, 10.3360, 10.2088, 10.2088, 10.2088, 10.2088, 10.2087,
         10.3711]], device='cuda:0')
[]
After Process
A-INPUT tensor([    1,  2997,   535,  7620,  3359,  5666,  1214,   354,   429, 28740,
        28734,   297,  3102,   304,   989,  6830, 28727, 25809,   354,   429,
        28784,   297,  3102, 28723,  1602,  1188,   682,   630,   927,   298,
         2136, 28725,   513,   630,   682,   865,  3848,   624, 28267,   304,
          624, 18342, 28804, 28705,     2,  2997,   535,  7620,  3359,  5666,
         1214,   354,   429, 28740, 28734, 28725,   579,   624, 18342,  6966,
        28705, 28740, 28734,   732, 28705, 28782,   327,   429,  5275, 28740,
        28734, 28748, 28782, 28746, 28750,  4060, 28750, 28723,   985,   835,
         7620,   989,  6830, 28727, 25809,   354,   429, 28784, 28725,   579,
          624, 28267,  6966, 28705, 28784,   732, 28705, 28750,   327,   429,
         5275, 28784, 28748, 28750, 28746, 28770,  4060, 28770, 28723,  1537,
          354,   624, 18342,   304,   624, 28267, 28725,  2997,   535,   682,
          927,   298,  2136, 28705, 28750,   648, 28705, 28770,   327,   429,
         5275, 28750, 28806, 28770, 28746, 28782,  4060, 28782, 28723, 28705,
            2,  2476, 28782, 28705,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2], device='cuda:0')
A-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  2997,   535,  7620,  3359,  5666,
         1214,   354,   429, 28740, 28734, 28725,   579,   624, 18342,  6966,
        28705, 28740, 28734,   732, 28705, 28782,   327,   429,  5275, 28740,
        28734, 28748, 28782, 28746, 28750,  4060, 28750, 28723,   985,   835,
         7620,   989,  6830, 28727, 25809,   354,   429, 28784, 28725,   579,
          624, 28267,  6966, 28705, 28784,   732, 28705, 28750,   327,   429,
         5275, 28784, 28748, 28750, 28746, 28770,  4060, 28770, 28723,  1537,
          354,   624, 18342,   304,   624, 28267, 28725,  2997,   535,   682,
          927,   298,  2136, 28705, 28750,   648, 28705, 28770,   327,   429,
         5275, 28750, 28806, 28770, 28746, 28782,  4060, 28782, 28723, 28705,
            2,  2476, 28782, 28705,     2,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100], device='cuda:0')
Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  7.8864,  9.6738,
          7.2732]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.3424657534246575
Loss Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.4248, 10.1083, 10.3882, 10.1541, 10.1541,
         10.3729]], device='cuda:1')
[]
tensor(10.3710, device='cuda:0', grad_fn=<NllLossBackward0>)
Loss tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  8.5984,  8.3466,
          7.8965]], device='cuda:2')
[]
Loss tensor(10.3723, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor(6.9006, device='cuda:2', grad_fn=<NllLossBackward0>)
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.287998765707016
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1116969883441925
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08246388286352158
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.6802740693092346
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.20684438943862915
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02709721401333809
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.027002884075045586
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005900891963392496
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008164842613041401
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0005560634308494627
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.8180684492108412e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03932001814246178
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03969211131334305
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03997823968529701
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04033294692635536
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04085985943675041
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04126230999827385
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04206351935863495
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15542754530906677
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1606372445821762
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15491360425949097
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15066282451152802
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14830715954303741
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14761412143707275
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14799892902374268
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15155720710754395
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15162119269371033
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.152009516954422
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15032552182674408
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14912283420562744
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14740172028541565
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14485932886600494
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14458538591861725
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14826565980911255
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13161075115203857
 34%|███▎      | 197/584 [20:06<17:07,  2.65s/it]Before Process
B-INPUT tensor([    1,   415,  7162,   302,   264, 23612,  9926,  2613,   298, 10221,
         7062, 18454,   354,   396, 17962, 20744, 28723,   985,  8346,  3414,
        21189, 28725,   297,  2308, 28733, 28720,   687, 17948, 28725,   477,
         1712,  1581,   562,   338,   404, 28723,   415,  2296,  3970, 28725,
          272,   907,   562,  6113, 11448, 28705, 28740, 28734, 17948, 28723,
          330,  4308,   302,  3316,  2062, 28725, 28705, 28787, 17948,  6792,
          477,   272,  1676,   562,  6113, 28723,  8126, 28725,   272,  4008,
          562,  6113, 28809, 28713,  9562,  6792,   438,   281, 14948, 28723,
         1047,   544,   272,  3414, 21189, 11448,   486,   272,  1712,   562,
          338,   404,   478, 24776, 28705, 28740, 28734, 28734, 14090, 28725,
          910,  1287, 17948,   863,   272,  4008,   562,  6113,  5663, 28804,
        28705,     2,  4577,  1430,  3660,   478, 24776, 28705, 28781, 14090,
        28725,   272,   907,   562,  6113, 11448, 28705, 28740, 28734,   398,
        28705, 28781,   327,  2087, 28740, 28734, 28736, 28781, 28746, 28781,
        28734,  4060, 28781, 28734, 14090,   415,  1676,   562,  6113, 28742,
        28713,  9562,   403, 28705, 28787,   398, 28705, 28781,   327,  2087,
        28787, 28736, 28781, 28746, 28750, 28783,  4060, 28750, 28783, 14090,
          415,   907,   989,   562,   338,   404,  6166, 11448, 28705, 28781,
        28734,   648, 28705, 28750, 28783,   327,  2087, 28781, 28734, 28806,
        28750, 28783, 28746, 28784, 28783,  4060, 28784, 28783, 14090,  5078,
         2107,   288,   369,  4336,   477,   272,  3102,  4336,   302,  3414,
        21189,  5212, 28705, 28740, 28734, 28734,   387, 28705, 28784, 28783,
          327,  2087, 28740, 28734, 28734, 28733, 28784, 28783, 28746, 28770,
        28750,  4060, 28770, 28750, 14090,   661,  6166,  2825,   272,  4008,
          562,  6113, 11448, 28705, 28770, 28750, 28748, 28781,   327,  2087,
        28770, 28750, 28748, 28781, 28746, 28783,  4060, 28783, 17948, 28723,
        28705,     2,  2476, 28783, 28705,     2], device='cuda:0')
B-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  4577,  1430,  3660,   478, 24776, 28705, 28781, 14090,
        28725,   272,   907,   562,  6113, 11448, 28705, 28740, 28734,   398,
        28705, 28781,   327,  2087, 28740, 28734, 28736, 28781, 28746, 28781,
        28734,  4060, 28781, 28734, 14090,   415,  1676,   562,  6113, 28742,
        28713,  9562,   403, 28705, 28787,   398, 28705, 28781,   327,  2087,
        28787, 28736, 28781, 28746, 28750, 28783,  4060, 28750, 28783, 14090,
          415,   907,   989,   562,   338,   404,  6166, 11448, 28705, 28781,
        28734,   648, 28705, 28750, 28783,   327,  2087, 28781, 28734, 28806,
        28750, 28783, 28746, 28784, 28783,  4060, 28784, 28783, 14090,  5078,
         2107,   288,   369,  4336,   477,   272,  3102,  4336,   302,  3414,
        21189,  5212, 28705, 28740, 28734, 28734,   387, 28705, 28784, 28783,
          327,  2087, 28740, 28734, 28734, 28733, 28784, 28783, 28746, 28770,
        28750,  4060, 28770, 28750, 14090,   661,  6166,  2825,   272,  4008,
          562,  6113, 11448, 28705, 28770, 28750, 28748, 28781,   327,  2087,
        28770, 28750, 28748, 28781, 28746, 28783,  4060, 28783, 17948, 28723,
        28705,     2,  2476, 28783, 28705,     2], device='cuda:0')
[tensor([[ 4577,  1430,  3660,   478, 24776, 28705, 28781, 14090, 28725,   272,
           907,   562,  6113, 11448, 28705, 28740, 28734,   398, 28705, 28781,
           327,  2087, 28740, 28734, 28736, 28781, 28746, 28781, 28734,  4060,
         28781, 28734, 14090,   415,  1676,   562,  6113, 28742, 28713,  9562,
           403, 28705, 28787,   398, 28705, 28781,   327,  2087, 28787, 28736,
         28781, 28746, 28750, 28783,  4060, 28750, 28783, 14090,   415,   907,
           989,   562,   338,   404,  6166, 11448, 28705, 28781, 28734,   648,
         28705, 28750, 28783,   327,  2087, 28781, 28734, 28806, 28750, 28783,
         28746, 28784, 28783,  4060, 28784, 28783, 14090,  5078,  2107,   288,
           369,  4336,   477,   272,  3102,  4336,   302,  3414, 21189,  5212,
         28705, 28740, 28734, 28734,   387, 28705, 28784, 28783,   327,  2087,
         28740, 28734, 28734, 28733, 28784, 28783, 28746, 28770, 28750,  4060,
         28770, 28750, 14090,   661,  6166,  2825,   272,  4008,   562,  6113,
         11448, 28705, 28770, 28750, 28748, 28781,   327,  2087, 28770, 28750,
         28748, 28781, 28746, 28783,  4060, 28783, 17948, 28723, 28705,     2]],
       device='cuda:0')]
REMOVE TEST?! 0 0 0.339041095890411
Cross Entropy List Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.3430626392364502
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.13046136498451233
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.08219587057828903
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.974577171244164e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.710898562938382e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.006727921141874e-09
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1718665149373919e-08
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.477550822277408e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1516048559201408e-08
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 6.502856919610167e-09
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 5.893587626815133e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 4.086185612095505e-09
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.00025071119307540357
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.8062573872157373e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.9364748368388973e-05
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.024368057027459145
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007857013493776321
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0018660883652046323
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.032996103167533875
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.7114094495773315
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2309132069349289
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03451750427484512
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03148724138736725
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.010555049404501915
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007955484092235565
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0007202554843388498
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18171550333499908
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1830737143754959
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1886187344789505
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18557681143283844
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18216457962989807
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18182308971881866
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18145014345645905
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.18455985188484192
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15880492329597473
 34%|███▍      | 199/584 [20:03<20:09,  3.14s/it]REMOVE TEST?! 0 0 0.684931506849315
tensor([[1.2029e+09, 1.6494e+11, 5.1761e+09, 8.0414e+11, 8.0395e+11, 8.0419e+11,
         8.0390e+11, 8.0455e+11, 1.0426e+10]], device='cuda:0')
[0]
REMOVE TEST?! 0 0 0.339041095890411
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.5943127274513245
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07808656990528107
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07333814352750778
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06999687105417252
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07056370377540588
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07079224288463593
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07057170569896698
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.07027588039636612
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06850707530975342
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06755370646715164
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06599858403205872
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06499315053224564
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06606554985046387
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06697676330804825
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06842119991779327
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0679876059293747
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0657493844628334
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.06606007367372513
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05694358050823212
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.4925641119480133
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.41530007123947144
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.29460370540618896
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0272543802857399
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.006398285739123821
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005133139900863171
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0009498260915279388
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.023824073374271393
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.226841002702713
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.05898123234510422
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007571416441351175
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.008787611499428749
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0016654266510158777
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0020143231377005577
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0001374105195282027
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0651613101363182
 34%|███▍      | 200/584 [20:09<21:02,  3.29s/it]REMOVE TEST?! 0 0 1.0325342465753424
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.4129, 10.2996, 10.3731, 10.2939, 10.2939,
         10.3735]], device='cuda:1')
REMOVE TEST?! 1 0 0.684931506849315
tensor([[9.9631e+08, 1.6615e+11, 1.0314e+01, 1.2833e+10, 1.2836e+10, 1.2842e+10,
         1.2851e+10, 1.2842e+10, 1.7189e+10]], device='cuda:0')
[0]
REMOVE TEST?! 0 0 1.0171232876712328
Cross Entropy List Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3736, 10.3736, 10.3736,  9.0554, 11.6729,
          8.3310]], device='cuda:2')
REMOVE TEST?! 1 0 1.0325342465753424
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.4144, 10.2289, 10.6031, 10.2845, 10.2845,
         10.3735]], device='cuda:1')
[]
REMOVE TEST?! 0 0 0.3424657534246575
tensor([[4.7024e+09, 1.6067e+11, 2.1384e+10, 8.6752e+11, 8.6734e+11, 8.6767e+11,
         8.6735e+11, 8.6806e+11, 1.5105e+10]], device='cuda:0')
REMOVE TEST?! 1 1 1.0171232876712328
Cross Entropy List tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735,  8.4368, 12.7029,
          8.1665]], device='cuda:2')
REMOVE TEST?! 2 0 1.0325342465753424
Cross Entropy List Cross Entropy List tensor([[10.3725, 10.3725, 10.3725, 10.4094, 10.6106, 26.6921, 30.2275, 30.2275,
         10.3735]], device='cuda:1')
[0]
REMOVE TEST?! 0 0 0.684931506849315
tensor([[3.4175e+09, 1.1203e+11, 1.2219e+10, 2.7281e+11, 2.7271e+11, 2.7310e+11,
         2.7271e+11, 2.7346e+11, 1.5550e+10]], device='cuda:0')
[0, 1]
REMOVE TEST?! 0 0 0.678082191780822
Cross Entropy List Cross Entropy List tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  8.0996, 11.8483,
          7.7112]], device='cuda:2')
[]
REMOVE TEST?! 0 0 1.0325342465753424
Cross Entropy List tensor([[10.3737, 10.3737, 10.3737, 10.5094, 12.3384, 12.5586, 10.3818, 10.3818,
         10.3735]], device='cuda:1')
[0]
REMOVE TEST?! 0 0 0.684931506849315
tensor([[3.8868e+09, 9.0792e+10, 3.0768e+09, 2.5524e+11, 2.5516e+11, 2.5559e+11,
         2.5514e+11, 2.5581e+11, 1.5759e+10]], device='cuda:0')
[0]
After Process
A-INPUT tensor([    1,   415,  7162,   302,   264, 23612,  9926,  2613,   298, 10221,
         7062, 18454,   354,   396, 17962, 20744, 28723,   985,  8346,  3414,
        21189, 28725,   297,  2308, 28733, 28720,   687, 17948, 28725,   477,
         1712,  1581,   562,   338,   404, 28723,   415,  2296,  3970, 28725,
          272,   907,   562,  6113, 11448, 28705, 28740, 28734, 17948, 28723,
          330,  4308,   302,  3316,  2062, 28725, 28705, 28787, 17948,  6792,
          477,   272,  1676,   562,  6113, 28723,  8126, 28725,   272,  4008,
          562,  6113, 28809, 28713,  9562,  6792,   438,   281, 14948, 28723,
         1047,   544,   272,  3414, 21189, 11448,   486,   272,  1712,   562,
          338,   404,   478, 24776, 28705, 28740, 28734, 28734, 14090, 28725,
          910,  1287, 17948,   863,   272,  4008,   562,  6113,  5663, 28804,
        28705,     2,  2476, 28783, 28705,     2], device='cuda:0')
A-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  2476, 28783, 28705,     2], device='cuda:0')
Cross Entropy List tensor([[10.3735, 10.3734, 10.3734, 10.3734, 10.3734, 10.3734,  8.8486, 14.1459,
          9.1393]], device='cuda:2')
REMOVE TEST?! 1 0 1.0325342465753424
Loss Cross Entropy List tensor([[10.3731, 10.3731, 10.3731, 10.3980, 10.6781, 19.9923, 19.8114, 19.8115,
         10.3735]], device='cuda:1')
[0]
tensor(1.4936e+10, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor([[  10.3735,   10.3735,   10.3734,   10.3734,   10.3734,   10.3735,
         1058.4648, 1605.5688,   10.6937]], device='cuda:2')
REMOVE TEST?! 2 0 1.0325342465753424
Loss Cross Entropy List tensor(10.3735, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor([[19.1309, 19.1310, 19.1310, 19.1309, 19.1309, 19.1311, 16.7300, 16.8188,
          8.4745]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.3441780821917808
Cross Entropy List Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.9967706799507141
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.04644550755620003
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.005682779476046562
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007266698870807886
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.007277993485331535
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01233126875013113
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.01764988712966442
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.02335428074002266
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.022374628111720085
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.019852017983794212
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.025994477793574333
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.03966742381453514
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.733424377600386e-08
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.005072363113868e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 2.931780035755893e-12
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.546761165462158e-08
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.993782157380338e-08
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 3.0760203412194542e-12
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1001822031175834e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.856288502556708e-08
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1265485072575743e-11
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.300003966927761e-08
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.81987034517806e-08
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.179974114204015e-08
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 8.223346981139912e-08
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1015285905635608e-11
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.0045560827620648e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.947152790346081e-08
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.0925665754057956e-11
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1479097139499572e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1009260703076507e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.0528379383589748e-11
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 1.1363480467707632e-07
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 9.39648430176021e-08
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 9.566524655779673e-12
 34%|███▍      | 198/584 [20:08<16:43,  2.60s/it]Before Process
B-INPUT tensor([    1,  1791,   625, 23488,   778,   264,  2052,  4150, 28725,  1430,
         6569,  1918,  4292,  1580,  2136,   429, 28781, 28734, 28723,  1047,
          736,   460, 28705, 28784, 28734,  5117,   356,   272,  6569,  1918,
          304,   272,  3293,  1918,   998,  2827, 28705, 28783,  1259,  8209,
          297,   264,   879, 28725, 13911,   272,  3102,  3558,   302,  2445,
        12469,   297,   272, 28705, 28783,  8209, 28723, 28705,     2,   560,
          624,  4150, 28725,   272,  3102,  3558,   302,  2445, 12469,   477,
          272,  6569,  5117,   349,   429, 28781, 28734, 28736, 28784, 28734,
        28746,   429,  5275, 28781, 28734, 28736, 28784, 28734, 28746, 28750,
        28781, 28734, 28734,  4060, 28750, 28781, 28734, 28734,  1047,  5435,
         1259,  8209,   460,  2203,   297,   264,   879, 28725,   272,  3102,
         3558,   302,  2445, 12469,   477,   272,  8209,   349,   429, 28750,
        28781, 28734, 28734, 28736, 28783,   327,   429,  5275, 28750, 28781,
        28734, 28734, 28736, 28783, 28746, 28740, 28774, 28750, 28734, 28734,
         4060, 28740, 28774, 28750, 28734, 28734, 28705,     2,  2476, 28740,
        28774, 28750, 28734, 28734, 28705,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2], device='cuda:0')
B-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,   560,
          624,  4150, 28725,   272,  3102,  3558,   302,  2445, 12469,   477,
          272,  6569,  5117,   349,   429, 28781, 28734, 28736, 28784, 28734,
        28746,   429,  5275, 28781, 28734, 28736, 28784, 28734, 28746, 28750,
        28781, 28734, 28734,  4060, 28750, 28781, 28734, 28734,  1047,  5435,
         1259,  8209,   460,  2203,   297,   264,   879, 28725,   272,  3102,
         3558,   302,  2445, 12469,   477,   272,  8209,   349,   429, 28750,
        28781, 28734, 28734, 28736, 28783,   327,   429,  5275, 28750, 28781,
        28734, 28734, 28736, 28783, 28746, 28740, 28774, 28750, 28734, 28734,
         4060, 28740, 28774, 28750, 28734, 28734, 28705,     2,  2476, 28740,
        28774, 28750, 28734, 28734, 28705,     2,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100], device='cuda:0')
[tensor([[  560,   624,  4150, 28725,   272,  3102,  3558,   302,  2445, 12469,
           477,   272,  6569,  5117,   349,   429, 28781, 28734, 28736, 28784,
         28734, 28746,   429,  5275, 28781, 28734, 28736, 28784, 28734, 28746,
         28750, 28781, 28734, 28734,  4060, 28750, 28781, 28734, 28734,  1047,
          5435,  1259,  8209,   460,  2203,   297,   264,   879, 28725,   272,
          3102,  3558,   302,  2445, 12469,   477,   272,  8209,   349,   429,
         28750, 28781, 28734, 28734, 28736, 28783,   327,   429,  5275, 28750,
         28781, 28734, 28734, 28736, 28783, 28746, 28740, 28774, 28750, 28734,
         28734,  4060, 28740, 28774, 28750, 28734, 28734, 28705,     2]],
       device='cuda:0')]
REMOVE TEST?! 0 0 0.3407534246575342
tensor([[1.0373e+01, 1.0373e+01, 1.0373e+01, 1.0373e+01, 4.3576e+01, 7.5180e+01,
         9.3002e+12, 2.1699e+28, 1.0373e+01]], device='cuda:2')
[0]
REMOVE TEST?! 0 0 1.0325342465753424
Cross Entropy List Cross Entropy List Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.0
 34%|███▍      | 200/584 [20:05<18:51,  2.95s/it]REMOVE TEST?! 0 0 0.3441780821917808
tensor([[1.3322e+11, 2.4227e+17, 4.5720e+17, 4.7233e+17, 4.7233e+17, 4.7233e+17,
         4.7233e+17, 4.7233e+17, 1.0373e+01]], device='cuda:2')
REMOVE TEST?! 1 1 1.0325342465753424
tensor([[3.3404e+06, 1.9549e+08, 4.8542e+08, 6.3539e+08,        nan,        nan,
                nan,        nan,        nan]], device='cuda:0')
[0]
REMOVE TEST?! 0 0 1.3630136986301369
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.4716, 19.2232, 23.3463, 14.6279, 14.6276,
         10.3737]], device='cuda:1')
tensor([[10.3731, 10.3731, 10.3731, 10.3731, 10.3731, 10.3731,  9.7892,  9.5816,
          9.0882]], device='cuda:2')
[0]
REMOVE TEST?! 2 1 1.0325342465753424
REMOVE TEST?! 0 0 1.3767123287671232
tensor([[1.0373e+01, 1.0408e+01, 1.0484e+01, 4.0576e+06,        nan,        nan,
                nan,        nan,        nan]], device='cuda:0')
REMOVE TEST?! 1 1 1.3630136986301369
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3737, 10.3737, 10.3737, 10.4212, 10.3160, 10.6682, 10.5723, 10.5723,
         10.3736]], device='cuda:1')
REMOVE TEST?! 1 1 1.3767123287671232
tensor([[10.3735, 10.3735, 10.3735, 10.3735, 10.3735, 10.3735,  9.3756,  8.4425,
          8.7123]], device='cuda:2')
[0]
tensor([[1.0373e+01, 1.0408e+01, 1.0492e+01, 4.2502e+06,        nan,        nan,
                nan,        nan,        nan]], device='cuda:0')
[0, 1]
REMOVE TEST?! 0 0 2.044520547945205
Cross Entropy List Cross Entropy List Loss tensor([[10.3737, 10.3737, 10.3737, 10.4191, 10.3151, 10.6775, 10.5745, 10.5745,
         10.3735]], device='cuda:1')
[0, 1]
REMOVE TEST?! 0 0 1.720890410958904
tensor(7.5884, device='cuda:2', grad_fn=<NllLossBackward0>)
tensor([[1.0373e+01, 1.0419e+01, 1.0519e+01, 4.4066e+06,        nan,        nan,
                nan,        nan,        nan]], device='cuda:0')
REMOVE TEST?! 1 1 2.044520547945205
Cross Entropy List Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.4363, 12.2740, 11.4499, 10.4204, 10.4204,
         10.3737]], device='cuda:1')
REMOVE TEST?! 1 1 1.720890410958904
tensor([[1.0373e+01, 1.0430e+01, 1.0521e+01, 4.0732e+06,        nan,        nan,
                nan,        nan,        nan]], device='cuda:0')
REMOVE TEST?! 2 2 2.044520547945205
Cross Entropy List Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3956, 10.5109, 15.1775, 10.6208, 10.6208,
         10.3736]], device='cuda:1')
[0, 1]
REMOVE TEST?! 0 0 0.6883561643835616
tensor([[1.0373e+01, 1.0419e+01, 1.0499e+01, 4.3041e+06,        nan,        nan,
                nan,        nan,        nan]], device='cuda:0')
[0, 1, 2]
REMOVE TEST?! 0 0 0.6815068493150684
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient Norm: 0.44016531109809875
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.embed_tokens._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1604129523038864
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.0.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15674763917922974
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.1.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15517668426036835
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.2.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15597020089626312
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.3.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15668591856956482
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.4.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15493974089622498
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.5.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15362396836280823
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.6.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15013247728347778
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.7.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14845304191112518
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.8.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1443810760974884
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.9.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14443759620189667
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.10.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14694932103157043
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.11.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15012575685977936
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.12.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15059351921081543
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.13.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1482258439064026
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.14.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14499406516551971
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.15.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14738400280475616
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.16.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1568419635295868
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.17.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15475234389305115
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.18.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15600551664829254
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.19.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15651078522205353
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.20.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1559717357158661
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.21.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.2174408882856369
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.22.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.16064710915088654
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.23.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1529531031847
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.24.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1483863890171051
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.25.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14469757676124573
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.26.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1465284526348114
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.27.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14847229421138763
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.28.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15165069699287415
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.29.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1509293168783188
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.30.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.1461097151041031
Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module.layers.31.mlp._fsdp_wrapped_module._flat_param | Gradient Norm: 0.14608749747276306
Layer: _fsdp_wrapped_module.base_model.lm_head._fsdp_wrapped_module._flat_param | Gradient Norm: 0.15635645389556885
 34%|███▍      | 201/584 [20:12<21:12,  3.32s/it]REMOVE TEST?! 0 0 0.3458904109589041
Cross Entropy List Cross Entropy List Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.3911, 10.5697, 10.4537, 10.3253, 10.3253,
         10.3736]], device='cuda:1')
REMOVE TEST?! 1 0 0.6883561643835616
tensor([[1.0373e+01, 1.0420e+01, 1.0501e+01, 3.8225e+06,        nan,        nan,
                nan,        nan,        nan]], device='cuda:0')
[0]
After Process
A-INPUT tensor([    1,  1791,   625, 23488,   778,   264,  2052,  4150, 28725,  1430,
         6569,  1918,  4292,  1580,  2136,   429, 28781, 28734, 28723,  1047,
          736,   460, 28705, 28784, 28734,  5117,   356,   272,  6569,  1918,
          304,   272,  3293,  1918,   998,  2827, 28705, 28783,  1259,  8209,
          297,   264,   879, 28725, 13911,   272,  3102,  3558,   302,  2445,
        12469,   297,   272, 28705, 28783,  8209, 28723, 28705,     2,  2476,
        28740, 28774, 28750, 28734, 28734, 28705,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
            2,     2,     2,     2,     2], device='cuda:0')
A-LABEL tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  2476,
        28740, 28774, 28750, 28734, 28734, 28705,     2,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100], device='cuda:0')
Cross Entropy List Loss tensor([[10.3733, 10.3733, 10.3733, 10.3733, 10.3733, 10.3733,  6.4297,  7.6636,
          5.4643]], device='cuda:2')
[0]
REMOVE TEST?! 0 0 0.3458904109589041
Cross Entropy List tensor([[10.3736, 10.3736, 10.3736, 10.4611, 10.4962, 10.6569, 10.2976, 10.2975,
         10.3737]], device='cuda:1')
[]
tensor(nan, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor([[10.3734, 10.3734, 10.3734, 10.3734, 10.3734,     nan,     nan,     nan,
             nan]], device='cuda:2')
[]
REMOVE TEST?! 0 0 0.6917808219178082
Loss Cross Entropy List tensor(nan, device='cuda:1', grad_fn=<NllLossBackward0>)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan]], device='cuda:2')
[0]
REMOVE TEST?! 0 0 0.6917808219178082
Cross Entropy List Layer: _fsdp_wrapped_module.base_model.model._fsdp_wrapped_module._flat_param | Gradient contains NaN
Gradient Norm: nan
Gradient: tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0')
 34%|███▍      | 198/584 [20:11<39:21,  6.12s/it]
wandb: 
wandb: Run history:
wandb:            step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb: train_step_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█
wandb:  train_step_ppl ▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁ 
wandb: 
wandb: Run summary:
wandb:            step 198
wandb: train_step_loss 14935678976.0
wandb:  train_step_ppl inf
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/kaoara/CoT-Internalize/wandb/offline-run-20240911_002903-hmrooypw
wandb: Find logs at: ./wandb/offline-run-20240911_002903-hmrooypw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
[E ProcessGroupNCCL.cpp:828] [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=28490, OpType=_ALLGATHER_BASE, Timeout(ms)=1800000) ran for 1808998 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:828] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=28502, OpType=_REDUCE_SCATTER_BASE, Timeout(ms)=1800000) ran for 1808997 milliseconds before timing out.
tensor([[10.3735,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan]], device='cuda:2')
[0]
 34%|███▍      | 201/584 [50:24<1:36:03, 15.05s/it]
Traceback (most recent call last):
  File "/home/kaoara/CoT-Internalize/src/train.py", line 432, in <module>
    main()
  File "/home/kaoara/CoT-Internalize/src/train.py", line 356, in main
    outputs = model.compute_loss(input_ids=input_ids, labels=labels)
  File "/home/kaoara/CoT-Internalize/src/mistral.py", line 26, in compute_loss
    outputs = self.forward(input_ids=input_ids, labels=labels)
  File "/home/kaoara/CoT-Internalize/src/mistral.py", line 22, in forward
    outputs = self.base_model(input_ids=input_ids, labels=labels, output_hidden_states=output_hidden_states)
  File "/home/kaoara/.conda/envs/cot/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/kaoara/.conda/envs/cot/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py", line 1033, in forward
    outputs = self.model(
  File "/home/kaoara/.conda/envs/cot/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/kaoara/.conda/envs/cot/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 748, in forward
    output = self._fsdp_wrapped_module(*args, **kwargs)
  File "/home/kaoara/.conda/envs/cot/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/kaoara/.conda/envs/cot/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py", line 761, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/home/kaoara/.conda/envs/cot/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/kaoara/.conda/envs/cot/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 739, in forward
    args, kwargs = _pre_forward(
  File "/home/kaoara/.conda/envs/cot/lib/python3.10/site-packages/torch/distributed/fsdp/_runtime_utils.py", line 413, in _pre_forward
    unshard_fn()
  File "/home/kaoara/.conda/envs/cot/lib/python3.10/site-packages/torch/distributed/fsdp/_runtime_utils.py", line 434, in _pre_forward_unshard
    _unshard(state, handles, state._streams["unshard"], state._streams["pre_unshard"])
  File "/home/kaoara/.conda/envs/cot/lib/python3.10/site-packages/torch/distributed/fsdp/_runtime_utils.py", line 329, in _unshard
    handle.unshard()
  File "/home/kaoara/.conda/envs/cot/lib/python3.10/site-packages/torch/distributed/fsdp/flat_param.py", line 919, in unshard
    padded_unsharded_flat_param = self._all_gather_flat_param(unsharded_flat_param)
  File "/home/kaoara/.conda/envs/cot/lib/python3.10/site-packages/torch/distributed/fsdp/flat_param.py", line 987, in _all_gather_flat_param
    dist.all_gather_into_tensor(
  File "/home/kaoara/.conda/envs/cot/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1451, in wrapper
    return func(*args, **kwargs)
  File "/home/kaoara/.conda/envs/cot/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 2532, in all_gather_into_tensor
    work = group._allgather_base(output_tensor, input_tensor)
RuntimeError: NCCL communicator was aborted on rank 2.  Original reason for failure was: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=28490, OpType=_ALLGATHER_BASE, Timeout(ms)=1800000) ran for 1808998 milliseconds before timing out.
Exception raised from getNcclComm at ../torch/csrc/distributed/c10d/NCCLUtils.cpp:17 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f7a266784d7 in /home/kaoara/.conda/envs/cot/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x7f7a2664236b in /home/kaoara/.conda/envs/cot/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0xebae8b (0x7f7a27602e8b in /home/kaoara/.conda/envs/cot/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::_allgather_base(at::Tensor&, at::Tensor&, c10d::AllgatherOptions const&) + 0x584 (0x7f7a2760d964 in /home/kaoara/.conda/envs/cot/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x538e561 (0x7f7a51b96561 in /home/kaoara/.conda/envs/cot/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: <unknown function> + 0x53917a5 (0x7f7a51b997a5 in /home/kaoara/.conda/envs/cot/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #6: <unknown function> + 0x53a8663 (0x7f7a51bb0663 in /home/kaoara/.conda/envs/cot/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #7: <unknown function> + 0xb6ba37 (0x7f7a66257a37 in /home/kaoara/.conda/envs/cot/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x3b7285 (0x7f7a65aa3285 in /home/kaoara/.conda/envs/cot/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x172df4 (0x55afef0eadf4 in /home/kaoara/.conda/envs/cot/bin/python)
frame #10: _PyObject_MakeTpCall + 0x15e (0x55afef0b1d1e in /home/kaoara/.conda/envs/cot/bin/python)
frame #11: <unknown function> + 0xeb5a7 (0x55afef0635a7 in /home/kaoara/.conda/envs/cot/bin/python)
frame #12: <unknown function> + 0x10669e (0x55afef07e69e in /home/kaoara/.conda/envs/cot/bin/python)
frame #13: <unknown function> + 0x1871eb (0x55afef0ff1eb in /home/kaoara/.conda/envs/cot/bin/python)
frame #14: _PyObject_Call + 0x1f6 (0x55afef0b83f6 in /home/kaoara/.conda/envs/cot/bin/python)
frame #15: _PyEval_EvalFrameDefault + 0x2216 (0x55afef152c16 in /home/kaoara/.conda/envs/cot/bin/python)
frame #16: <unknown function> + 0x1871eb (0x55afef0ff1eb in /home/kaoara/.conda/envs/cot/bin/python)
frame #17: <unknown function> + 0x10669e (0x55afef07e69e in /home/kaoara/.conda/envs/cot/bin/python)
frame #18: <unknown function> + 0x1871eb (0x55afef0ff1eb in /home/kaoara/.conda/envs/cot/bin/python)
frame #19: <unknown function> + 0x106c30 (0x55afef07ec30 in /home/kaoara/.conda/envs/cot/bin/python)
frame #20: <unknown function> + 0x1871eb (0x55afef0ff1eb in /home/kaoara/.conda/envs/cot/bin/python)
frame #21: <unknown function> + 0x106c30 (0x55afef07ec30 in /home/kaoara/.conda/envs/cot/bin/python)
frame #22: <unknown function> + 0x1871eb (0x55afef0ff1eb in /home/kaoara/.conda/envs/cot/bin/python)
frame #23: <unknown function> + 0x105472 (0x55afef07d472 in /home/kaoara/.conda/envs/cot/bin/python)
frame #24: <unknown function> + 0x1871eb (0x55afef0ff1eb in /home/kaoara/.conda/envs/cot/bin/python)
frame #25: <unknown function> + 0x219b98 (0x55afef191b98 in /home/kaoara/.conda/envs/cot/bin/python)
frame #26: <unknown function> + 0x21ce6d (0x55afef194e6d in /home/kaoara/.conda/envs/cot/bin/python)
frame #27: <unknown function> + 0x105472 (0x55afef07d472 in /home/kaoara/.conda/envs/cot/bin/python)
frame #28: <unknown function> + 0x1871eb (0x55afef0ff1eb in /home/kaoara/.conda/envs/cot/bin/python)
frame #29: <unknown function> + 0x105472 (0x55afef07d472 in /home/kaoara/.conda/envs/cot/bin/python)
frame #30: <unknown function> + 0x1871eb (0x55afef0ff1eb in /home/kaoara/.conda/envs/cot/bin/python)
frame #31: <unknown function> + 0x1b75d2 (0x55afef12f5d2 in /home/kaoara/.conda/envs/cot/bin/python)
frame #32: _PyObject_Call + 0x1f6 (0x55afef0b83f6 in /home/kaoara/.conda/envs/cot/bin/python)
frame #33: _PyEval_EvalFrameDefault + 0x2216 (0x55afef152c16 in /home/kaoara/.conda/envs/cot/bin/python)
frame #34: <unknown function> + 0x1871eb (0x55afef0ff1eb in /home/kaoara/.conda/envs/cot/bin/python)
frame #35: _PyObject_FastCallDictTstate + 0xa3 (0x55afef0ff9d3 in /home/kaoara/.conda/envs/cot/bin/python)
frame #36: <unknown function> + 0x192055 (0x55afef10a055 in /home/kaoara/.conda/envs/cot/bin/python)
frame #37: _PyObject_MakeTpCall + 0x15e (0x55afef0b1d1e in /home/kaoara/.conda/envs/cot/bin/python)
frame #38: _PyEval_EvalFrameDefault + 0x4d15 (0x55afef155715 in /home/kaoara/.conda/envs/cot/bin/python)
frame #39: <unknown function> + 0x1b6ca5 (0x55afef12eca5 in /home/kaoara/.conda/envs/cot/bin/python)
frame #40: _PyObject_Call + 0x295 (0x55afef0b8495 in /home/kaoara/.conda/envs/cot/bin/python)
frame #41: _PyEval_EvalFrameDefault + 0x2216 (0x55afef152c16 in /home/kaoara/.conda/envs/cot/bin/python)
frame #42: <unknown function> + 0x1871eb (0x55afef0ff1eb in /home/kaoara/.conda/envs/cot/bin/python)
frame #43: _PyObject_FastCallDictTstate + 0x162 (0x55afef0ffa92 in /home/kaoara/.conda/envs/cot/bin/python)
frame #44: <unknown function> + 0x192055 (0x55afef10a055 in /home/kaoara/.conda/envs/cot/bin/python)
frame #45: _PyObject_Call + 0x259 (0x55afef0b8459 in /home/kaoara/.conda/envs/cot/bin/python)
frame #46: _PyEval_EvalFrameDefault + 0x2216 (0x55afef152c16 in /home/kaoara/.conda/envs/cot/bin/python)
frame #47: <unknown function> + 0x1b6ca5 (0x55afef12eca5 in /home/kaoara/.conda/envs/cot/bin/python)
frame #48: _PyObject_Call + 0x295 (0x55afef0b8495 in /home/kaoara/.conda/envs/cot/bin/python)
frame #49: _PyEval_EvalFrameDefault + 0x2216 (0x55afef152c16 in /home/kaoara/.conda/envs/cot/bin/python)
frame #50: <unknown function> + 0x1871eb (0x55afef0ff1eb in /home/kaoara/.conda/envs/cot/bin/python)
frame #51: _PyObject_FastCallDictTstate + 0x162 (0x55afef0ffa92 in /home/kaoara/.conda/envs/cot/bin/python)
frame #52: <unknown function> + 0x192055 (0x55afef10a055 in /home/kaoara/.conda/envs/cot/bin/python)
frame #53: _PyObject_MakeTpCall + 0x1f8 (0x55afef0b1db8 in /home/kaoara/.conda/envs/cot/bin/python)
frame #54: _PyEval_EvalFrameDefault + 0x15b1 (0x55afef151fb1 in /home/kaoara/.conda/envs/cot/bin/python)
frame #55: <unknown function> + 0x1b6ca5 (0x55afef12eca5 in /home/kaoara/.conda/envs/cot/bin/python)
frame #56: _PyObject_Call + 0x295 (0x55afef0b8495 in /home/kaoara/.conda/envs/cot/bin/python)
frame #57: _PyEval_EvalFrameDefault + 0x2216 (0x55afef152c16 in /home/kaoara/.conda/envs/cot/bin/python)
frame #58: <unknown function> + 0x1871eb (0x55afef0ff1eb in /home/kaoara/.conda/envs/cot/bin/python)
frame #59: _PyObject_FastCallDictTstate + 0x162 (0x55afef0ffa92 in /home/kaoara/.conda/envs/cot/bin/python)
frame #60: <unknown function> + 0x192055 (0x55afef10a055 in /home/kaoara/.conda/envs/cot/bin/python)
frame #61: _PyObject_MakeTpCall + 0x1f8 (0x55afef0b1db8 in /home/kaoara/.conda/envs/cot/bin/python)
frame #62: _PyEval_EvalFrameDefault + 0x15b1 (0x55afef151fb1 in /home/kaoara/.conda/envs/cot/bin/python)
frame #63: <unknown function> + 0x1b6ca5 (0x55afef12eca5 in /home/kaoara/.conda/envs/cot/bin/python)

WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 2690255 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 2 (pid: 2690256) of binary: /home/kaoara/.conda/envs/cot/bin/python
Traceback (most recent call last):
  File "/home/kaoara/.conda/envs/cot/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/kaoara/.conda/envs/cot/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/kaoara/.conda/envs/cot/lib/python3.10/site-packages/torch/distributed/run.py", line 794, in main
    run(args)
  File "/home/kaoara/.conda/envs/cot/lib/python3.10/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/home/kaoara/.conda/envs/cot/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/kaoara/.conda/envs/cot/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
src/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-09-11_01:19:51
  host      : n77.gasi-cluster.cluster
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 2690256)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
